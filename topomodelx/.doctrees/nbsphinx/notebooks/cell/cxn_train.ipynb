{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Set-up, create and train a convolutional CCXN\n",
    "\n",
    "In this notebook, we create and train a CCXN network, originally proposed in the paper by [Hajij et. al : Cell Complex Neural Networks (2020)](https://arxiv.org/pdf/2010.00743.pdf).\n",
    "\n",
    "We will load a cell complex dataset (MUTAG, from the TUDataset) from the web and train the model to perform classification on this dataset.\n",
    "\n",
    "The equations of one layer of this neural network are given by:\n",
    "\n",
    "#### 1. A convolution from nodes to nodes using an adjacency message passing scheme (AMPS):\n",
    "\n",
    "游린 $\\quad m_{y \\rightarrow \\{z\\} \\rightarrow x}^{(0 \\rightarrow 1 \\rightarrow 0)} = M_{\\mathcal{L}_\\uparrow}^t(h_x^{t,(0)}, h_y^{t,(0)}, \\Theta^{t,(y \\rightarrow x)})$ \n",
    "\n",
    "游릲 $\\quad m_x^{(0 \\rightarrow 1 \\rightarrow 0)} = AGG_{y \\in \\mathcal{L}_\\uparrow(x)}(m_{y \\rightarrow \\{z\\} \\rightarrow x}^{0 \\rightarrow 1 \\rightarrow 0})$ \n",
    "\n",
    "游릴 $\\quad m_x^{(0)} = m_x^{(0 \\rightarrow 1 \\rightarrow 0)}$ \n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(0)} = U^{t}(h_x^{t,(0)}, m_x^{(0)})$\n",
    "\n",
    "#### 2. A convolution from edges to faces using a cohomology message passing scheme:\n",
    "\n",
    "游린 $\\quad m_{y \\rightarrow x}^{(r' \\rightarrow r)} = M^t_{\\mathcal{C}}(h_{x}^{t,(r)}, h_y^{t,(r')}, x, y)$ \n",
    "\n",
    "游릲 $\\quad m_x^{(r' \\rightarrow r)}  = AGG_{y \\in \\mathcal{C}(x)} m_{y \\rightarrow x}^{(r' \\rightarrow r)}$ \n",
    "\n",
    "游릴 $\\quad m_x^{(r)} = m_x^{(r' \\rightarrow r)}$ \n",
    "\n",
    "游릱 $\\quad h_{x}^{t+1,(r)} = U^{t,(r)}(h_{x}^{t,(r)}, m_{x}^{(r)})$\n",
    "\n",
    "Where the notations are defined in [Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)](https://arxiv.org/abs/2304.10031)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from toponetx import CellComplex\n",
    "\n",
    "from topomodelx.nn.cell.cxn_layer import CCXNLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPU's are available, we will make use of them. Otherwise, this will run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import data ##\n",
    "\n",
    "The first step is to import the dataset, MUTAG, a benchmark dataset for graph classification. We then lift each graph into our domain of choice, a cell complex.\n",
    "\n",
    "We will also retrieve:\n",
    "- input signal on the nodes and edges for each of these cell complexes, as that will be what we feed the model in input\n",
    "- the binary label associated to the cell complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(\n",
    "    root=\"/tmp/MUTAG\", name=\"MUTAG\", use_edge_attr=True, use_node_attr=True\n",
    ")\n",
    "dataset = dataset[:20]\n",
    "cell_list = []\n",
    "x_0_list = []\n",
    "x_1_list = []\n",
    "y_list = []\n",
    "for graph in dataset:\n",
    "    cellcomplex = CellComplex(to_networkx(graph))\n",
    "    cell_list.append(cellcomplex)\n",
    "    x_0 = graph.x  # torch.chunk(graph.x, 2, dim=0)[1]\n",
    "    x_1 = graph.edge_attr  # torch.chunk(graph.edge_attr, 2, dim=0)[1]\n",
    "    x_0_list.append(x_0)\n",
    "    x_1_list.append(x_1)\n",
    "    y_list.append(int(graph.y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neighborhood structures. ##\n",
    "\n",
    "Now we retrieve the neighborhood structures (i.e. their representative matrices) that we will use to send messges on each simplicial complex. In the case of this architecture, we need the adjacency matrix $A_{\\uparrow, 0}$ and the coboundary matrix $B_2^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidence_2_t_list = []\n",
    "adjacency_0_list = []\n",
    "for cellcomplex in cell_list:\n",
    "    incidence_2_t = cellcomplex.incidence_matrix(rank=2).T\n",
    "    adjacency_0 = cellcomplex.adjacency_matrix(rank=0)\n",
    "    incidence_2_t = torch.from_numpy(incidence_2_t.todense()).to_sparse()\n",
    "    adjacency_0 = torch.from_numpy(adjacency_0.todense()).to_sparse()\n",
    "    incidence_2_t_list.append(incidence_2_t)\n",
    "    adjacency_0_list.append(adjacency_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Neural Network\n",
    "\n",
    "Using the CCXNLayer class, we create a neural network with stacked layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ch_0 = x_0_list[0].shape[-1]\n",
    "in_ch_1 = x_1_list[0].shape[-1]\n",
    "in_ch_2 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCXN(torch.nn.Module):\n",
    "    \"\"\"Convolutional CCXN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_ch_0 : int\n",
    "        Dimension of input features on nodes.\n",
    "    in_ch_1 : int\n",
    "        Dimension of input features on edges.\n",
    "    in_ch_2 : int\n",
    "        Dimension of input features on faces.\n",
    "    num_classes : int\n",
    "        Number of classes.\n",
    "    n_layers : int\n",
    "        Number of CCXN layers.\n",
    "    att : bool\n",
    "        Whether to use attention.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_ch_0, in_ch_1, in_ch_2, num_classes, n_layers=2, att=False):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(\n",
    "                CCXNLayer(\n",
    "                    in_channels_0=in_ch_0,\n",
    "                    in_channels_1=in_ch_1,\n",
    "                    in_channels_2=in_ch_2,\n",
    "                    att=att,\n",
    "                )\n",
    "            )\n",
    "        self.layers = layers\n",
    "        self.lin_0 = torch.nn.Linear(in_ch_0, num_classes)\n",
    "        self.lin_1 = torch.nn.Linear(in_ch_1, num_classes)\n",
    "        self.lin_2 = torch.nn.Linear(in_ch_2, num_classes)\n",
    "\n",
    "    def forward(self, x_0, x_1, neighborhood_0_to_0, neighborhood_1_to_2):\n",
    "        \"\"\"Forward computation through layers, then linear layers, then avg pooling.\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        x_0 : tensor\n",
    "            shape = [n_nodes, in_ch_0]\n",
    "            Node features.\n",
    "\n",
    "        x_1 : tensor\n",
    "            shape = [n_edges, in_ch_1]\n",
    "            Edge features.\n",
    "\n",
    "        neighborhood_0_to_0 : tensor\n",
    "            shape = [n_nodes, n_nodes]\n",
    "            Adjacency matrix of rank 0 (up).\n",
    "\n",
    "        neighborhood_1_to_2 : tensor\n",
    "            shape = [n_faces, n_edges]\n",
    "            Transpose of boundary matrix of rank 2.\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        _ : tensor\n",
    "            shape = [1]\n",
    "            Label assigned to whole complex.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x_0, x_1, x_2 = layer(x_0, x_1, neighborhood_0_to_0, neighborhood_1_to_2)\n",
    "        x_0 = self.lin_0(x_0)\n",
    "        x_1 = self.lin_1(x_1)\n",
    "        x_2 = self.lin_2(x_2)\n",
    "        y_hat = torch.mean(x_2, dim=0) + torch.mean(x_1, dim=0) + torch.mean(x_0, dim=0)\n",
    "        return torch.mean(x_2, dim=0) + torch.mean(x_1, dim=0) + torch.mean(x_0, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model, initialize loss, and specify an optimizer. We first try it without any attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CCXN(in_ch_0, in_ch_1, in_ch_2, num_classes=2, n_layers=2)\n",
    "model = model.to(device)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0_train, x_0_test = train_test_split(x_0_list, test_size=0.2, shuffle=False)\n",
    "x_1_train, x_1_test = train_test_split(x_1_list, test_size=0.2, shuffle=False)\n",
    "incidence_2_t_train, incidence_2_t_test = train_test_split(\n",
    "    incidence_2_t_list, test_size=0.2, shuffle=False\n",
    ")\n",
    "adjacency_0_train, adjacency_0_test = train_test_split(\n",
    "    adjacency_0_list, test_size=0.2, shuffle=False\n",
    ")\n",
    "y_train, y_test = train_test_split(y_list, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell performs the training, looping over the network for a low amount of epochs. We keep training minimal for the purpose of rapid testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: nan Train_acc: 0.3750\n",
      "Epoch: 2 loss: nan Train_acc: 0.3750\n",
      "Test_acc: 0.5000\n",
      "Epoch: 3 loss: nan Train_acc: 0.3750\n",
      "Epoch: 4 loss: nan Train_acc: 0.3750\n",
      "Test_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "test_interval = 2\n",
    "for epoch_i in range(1, 5):\n",
    "    epoch_loss = []\n",
    "    num_samples = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for x_0, x_1, incidence_2_t, adjacency_0, y in zip(\n",
    "        x_0_train, x_1_train, incidence_2_t_train, adjacency_0_train, y_train\n",
    "    ):\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        y_hat = model(\n",
    "            x_0.float(), x_1.float(), adjacency_0.float(), incidence_2_t.float()\n",
    "        )\n",
    "        y = torch.tensor(y).long()\n",
    "        loss = crit(y_hat, y)\n",
    "        correct += (y_hat.argmax() == y).sum().item()\n",
    "        num_samples += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    train_acc = correct / num_samples\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {train_acc:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            num_samples = 0\n",
    "            correct = 0\n",
    "            for x_0, x_1, incidence_2_t, adjacency_0, y in zip(\n",
    "                x_0_test, x_1_test, incidence_2_t_test, adjacency_0_test, y_test\n",
    "            ):\n",
    "                y = torch.tensor(y).long()\n",
    "                y_hat = model(\n",
    "                    x_0.float(), x_1.float(), adjacency_0.float(), incidence_2_t.float()\n",
    "                )\n",
    "\n",
    "                correct += (y_hat.argmax() == y).sum().item()\n",
    "                num_samples += 1\n",
    "            test_acc = correct / num_samples\n",
    "            print(f\"Test_acc: {test_acc:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a new neural network, that uses the attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CCXN(in_ch_0, in_ch_1, in_ch_2, num_classes=2, n_layers=2, att=True)\n",
    "model = model.to(device)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the training for this neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: nan Train_acc: 0.3750\n",
      "Epoch: 2 loss: nan Train_acc: 0.3750\n",
      "Test_acc: 0.5000\n",
      "Epoch: 3 loss: nan Train_acc: 0.3750\n",
      "Epoch: 4 loss: nan Train_acc: 0.3750\n",
      "Test_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "test_interval = 2\n",
    "for epoch_i in range(1, 5):\n",
    "    epoch_loss = []\n",
    "    num_samples = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for x_0, x_1, incidence_2_t, adjacency_0, y in zip(\n",
    "        x_0_train, x_1_train, incidence_2_t_train, adjacency_0_train, y_train\n",
    "    ):\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        y_hat = model(\n",
    "            x_0.float(), x_1.float(), adjacency_0.float(), incidence_2_t.float()\n",
    "        )\n",
    "        y = torch.tensor(y).long()\n",
    "        loss = crit(y_hat, y)\n",
    "        correct += (y_hat.argmax() == y).sum().item()\n",
    "        num_samples += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    train_acc = correct / num_samples\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {train_acc:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            num_samples = 0\n",
    "            correct = 0\n",
    "            for x_0, x_1, incidence_2_t, adjacency_0, y in zip(\n",
    "                x_0_test, x_1_test, incidence_2_t_test, adjacency_0_test, y_test\n",
    "            ):\n",
    "                y = torch.tensor(y).long()\n",
    "                y_hat = model(\n",
    "                    x_0.float(), x_1.float(), adjacency_0.float(), incidence_2_t.float()\n",
    "                )\n",
    "\n",
    "                correct += (y_hat.argmax() == y).sum().item()\n",
    "                num_samples += 1\n",
    "            test_acc = correct / num_samples\n",
    "            print(f\"Test_acc: {test_acc:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
