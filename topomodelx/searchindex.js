Search.setIndex({"docnames": ["api/base", "api/index", "api/nn", "api/utils", "challenge/index", "contributing/index", "index", "notebooks/cell/can_train", "notebooks/cell/can_train_bis", "notebooks/cell/ccxn_train", "notebooks/cell/cwn_train", "notebooks/hypergraph/allset_train", "notebooks/hypergraph/allset_transformer_train", "notebooks/hypergraph/dhgcn_train", "notebooks/hypergraph/hmpnn_train", "notebooks/hypergraph/hnhn_train", "notebooks/hypergraph/hnhn_train_bis", "notebooks/hypergraph/hypergat_train", "notebooks/hypergraph/hypersage_train", "notebooks/hypergraph/template_train", "notebooks/hypergraph/unigcn_train", "notebooks/hypergraph/unigcnii_train", "notebooks/hypergraph/unigin_train", "notebooks/hypergraph/unisage_train", "notebooks/simplicial/dist2cycle_train", "notebooks/simplicial/hsn_train", "notebooks/simplicial/san_train", "notebooks/simplicial/sca_cmps_train", "notebooks/simplicial/sccn_train", "notebooks/simplicial/sccnn_train", "notebooks/simplicial/scconv_train", "notebooks/simplicial/scn2_train", "notebooks/simplicial/scnn_train", "notebooks/simplicial/scone_train", "notebooks/simplicial/scone_train_bis", "tutorials/index"], "filenames": ["api/base.rst", "api/index.rst", "api/nn.rst", "api/utils.rst", "challenge/index.rst", "contributing/index.rst", "index.rst", "notebooks/cell/can_train.ipynb", "notebooks/cell/can_train_bis.ipynb", "notebooks/cell/ccxn_train.ipynb", "notebooks/cell/cwn_train.ipynb", "notebooks/hypergraph/allset_train.ipynb", "notebooks/hypergraph/allset_transformer_train.ipynb", "notebooks/hypergraph/dhgcn_train.ipynb", "notebooks/hypergraph/hmpnn_train.ipynb", "notebooks/hypergraph/hnhn_train.ipynb", "notebooks/hypergraph/hnhn_train_bis.ipynb", "notebooks/hypergraph/hypergat_train.ipynb", "notebooks/hypergraph/hypersage_train.ipynb", "notebooks/hypergraph/template_train.ipynb", "notebooks/hypergraph/unigcn_train.ipynb", "notebooks/hypergraph/unigcnii_train.ipynb", "notebooks/hypergraph/unigin_train.ipynb", "notebooks/hypergraph/unisage_train.ipynb", "notebooks/simplicial/dist2cycle_train.ipynb", "notebooks/simplicial/hsn_train.ipynb", "notebooks/simplicial/san_train.ipynb", "notebooks/simplicial/sca_cmps_train.ipynb", "notebooks/simplicial/sccn_train.ipynb", "notebooks/simplicial/sccnn_train.ipynb", "notebooks/simplicial/scconv_train.ipynb", "notebooks/simplicial/scn2_train.ipynb", "notebooks/simplicial/scnn_train.ipynb", "notebooks/simplicial/scone_train.ipynb", "notebooks/simplicial/scone_train_bis.ipynb", "tutorials/index.rst"], "titles": ["Base", "API Reference", "Neural Networks", "Utils", "ICML 2023 Topological Deep Learning Challenge", "Contributing", "\ud83c\udf10 TopoModelX (TMX) \ud83c\udf69", "Train a Cell Attention Network (CAN)", "Train a Cellular Attention Network (CAN)", "Train a Convolutional Cell Complex Network (CCXN)", "Train a CW Network (CWN)", "Train a Hypergraph Neural Network", "Train a Hypergraph Neural Network", "Train a Hypergraph Neural Network", "Train a Hypergraph Message Passing Neural Network (HMPNN)", "Train a Hypergraph Networks with Hyperedge Neurons (HNHN)", "Train a Hypergraph Network with Hyperedge Neurons (HNHN)", "Train a Hypergraph Neural Network", "Train a Hypergraph Neural Network", "Train a Hypergraph Neural Network", "Pre-processing", "Train a hypergraph neural network using UniGCNII layers", "Pre-processing", "Pre-processing", "Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)", "Train a Simplicial High-Skip Network (HSN)", "Train a Simplicial Attention Network (SAN)", "Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)", "Train a Simplicial Complex Convolutional Network (SCCN)", "Train a SCCNN", "Train a Simplicial 2-complex convolutional neural network (SCConv)", "Train a Simplex Convolutional Network (SCN) of Rank 2", "Train a Simplicial Convolutional Neural Network (SCNN)", "Train a Simplicial Complex Net (SCoNe)", "Train a Simplicial Complex Network (SCoNe)", "Tutorials"], "terms": {"messag": [0, 1, 2, 4, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 34], "pass": [0, 1, 2, 4, 7, 8, 9, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34], "modul": [0, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "class": [0, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "topomodelx": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "message_pass": 0, "messagepass": [0, 1], "aggr_func": [0, 7, 27, 30], "liter": 0, "sum": [0, 7, 8, 9, 10, 15, 17, 26, 28, 29, 30, 31, 33], "mean": [0, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "add": [0, 3, 5, 21], "att": [0, 2, 8, 9, 17, 27], "bool": [0, 2, 5, 7, 8, 9, 11, 12, 27], "fals": [0, 2, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 27, 29, 30, 31, 32], "initi": [0, 2, 7, 8, 9, 11, 12, 14, 15, 16, 18, 26, 29, 30, 32, 33], "xavier_uniform": [0, 18], "xavier_norm": 0, "initialization_gain": 0, "float": [0, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "1": [0, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34], "414": [0, 15, 20], "sourc": [0, 2, 3, 4], "thi": [0, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "defin": [0, 4, 5, 7, 8, 9, 10, 11, 21, 26, 27, 33], "through": [0, 4, 8, 9, 10, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 27, 29, 32, 33], "singl": [0, 4, 10], "neighborhood": [0, 2, 4, 7, 8, 9, 10, 11, 12, 18, 26, 27, 33], "n": [0, 4, 5, 6, 7, 10, 17, 18, 26, 27, 33], "decompos": 0, "2": [0, 2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 33, 34], "step": [0, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "creat": [0, 4, 5, 12, 17, 18], "go": [0, 6, 7, 10, 26, 33], "from": [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "cell": [0, 1, 4, 8, 10, 11, 12, 13, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33], "target": [0, 8, 9], "aggreg": [0, 1, 4, 7, 17, 18, 26, 27, 28, 30, 32], "come": 0, "differ": [0, 5, 8, 9, 15, 24, 25, 26, 28, 29, 33], "onto": [0, 26], "each": [0, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33], "should": [0, 4, 5, 33], "instanti": [0, 10], "directli": [0, 21], "rather": [0, 4, 5, 34], "inherit": [0, 4], "subclass": 0, "effect": 0, "function": [0, 3, 4, 5, 7, 10, 11, 12, 18, 21, 24, 25, 26, 28, 29, 32, 33, 34], "doe": [0, 4, 5, 29, 32, 33], "have": [0, 4, 5, 8, 9, 11, 12, 13, 15, 17, 18, 19, 24, 25, 28, 29, 33], "trainabl": [0, 17], "weight": [0, 5, 12, 17, 26, 28, 29, 33], "its": [0, 4, 5, 14, 16, 17, 34], "paramet": [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "default": [0, 2, 5, 7, 11, 12, 16, 18, 21, 26], "us": [0, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "whether": [0, 2, 7, 8, 9, 11, 12, 27], "attent": [0, 2, 4, 12, 17, 27], "method": [0, 4, 5, 14, 16], "layer": [0, 1, 2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "refer": [0, 2, 5, 7, 18, 26], "h23": 0, "hajij": [0, 2, 4, 6, 7, 9, 25, 26, 34], "zamzmi": [0, 2, 6], "papamark": [0, 4, 6], "miolan": [0, 2, 4, 6], "guzm\u00e1n": [0, 2, 4, 6], "s\u00e1enz": [0, 2, 4, 6], "ramamurthi": [0, 2, 4, 6], "birdal": [0, 4, 6], "dei": [0, 4, 6], "mukherje": [0, 4, 6], "samaga": [0, 4, 6], "livesai": [0, 4, 6], "walter": [0, 4, 6], "rosen": [0, 4, 6], "schaub": [0, 4, 6], "topolog": [0, 1, 2, 6, 7, 8, 9, 10, 15, 24, 25, 26, 27, 28, 30, 32, 33, 34], "deep": [0, 2, 6, 7, 8, 9, 10, 12, 15, 24, 25, 26, 27, 28, 30, 32, 33, 34], "learn": [0, 2, 5, 6, 7, 8, 9, 10, 15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "beyond": [0, 2, 6, 7, 26], "graph": [0, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34], "data": [0, 2, 5, 6, 7, 14, 16, 26, 28, 31, 34], "2023": [0, 2, 6, 7, 8, 9, 10, 15, 21, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34], "http": [0, 2, 7, 15, 16, 21, 23, 24, 25, 26, 28, 29, 31], "arxiv": [0, 2, 6], "org": [0, 2, 15, 24, 25, 26, 28, 29], "ab": [0, 2, 30], "2206": [0, 6, 24], "00606": [0, 6], "pshm23": [0, 2], "papillon": [0, 2, 4, 6, 7, 8, 9, 10, 15, 24, 25, 26, 27, 28, 30, 32, 33, 34], "sanborn": [0, 2, 4, 6], "architectur": [0, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 24, 25, 26, 27, 28, 30, 32, 33, 34], "A": [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34], "survei": [0, 2, 4, 6, 7, 8, 9, 10, 15, 24, 25, 26, 27, 28, 30, 32, 33, 34], "neural": [0, 1, 4, 6], "network": [0, 1, 4, 6], "2304": [0, 2, 6, 15], "10031": [0, 2, 6], "x_messag": 0, "receiv": [0, 4], "sever": [0, 1, 4], "output": [0, 2, 4, 5, 7, 11, 12, 13, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34], "featur": [0, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "per": [0, 4, 5], "correspond": [0, 7, 12, 14, 16, 21], "within": [0, 5, 7, 14, 16, 26], "tensor": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "shape": [0, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "n_messag": 0, "out_channel": [0, 2, 7, 10, 11, 12, 13, 17, 18, 19, 20, 22, 23, 26, 29, 32], "associ": [0, 5, 7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29], "One": [0, 4, 24, 25, 26, 28, 29, 31, 32, 33, 34], "i": [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "sent": [0, 21], "return": [0, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "_": [0, 2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "n_target_cel": 0, "assum": 0, "all": [0, 3, 4, 5, 7, 11, 12, 13, 17, 18, 19, 21, 24, 25, 26, 28, 29, 32, 33, 34], "same": [0, 4, 5, 7, 8, 9, 26, 27, 29, 33], "rank": [0, 4, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34], "": [0, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 19, 21, 24, 25, 27, 28, 29, 33], "x_sourc": 0, "x_target": 0, "none": [0, 2, 3, 5, 11, 29, 32, 33], "comput": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "provid": [0, 4, 5, 8, 27, 29, 32], "scheme": [0, 2, 4, 8, 9, 26], "altern": [0, 4], "user": [0, 8, 9, 24, 28, 34], "can": [0, 2, 4, 5, 6, 17, 18, 21, 24, 25, 26, 28, 29, 30, 32, 33, 34], "overwrit": 0, "order": [0, 2, 4, 7, 25, 26, 28, 29, 31, 32, 33, 34], "replac": 0, "own": 0, "mechan": [0, 2, 7, 8, 9, 12, 17, 26], "detail": [0, 4, 5, 7, 12, 26], "definit": [0, 32], "higher": [0, 2, 4, 7, 25, 28, 31, 32, 34], "torch": [0, 2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "n_source_cel": 0, "in_channel": [0, 2, 7, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32], "input": [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "r": [0, 2, 5, 7, 9, 10, 11, 12, 17, 26, 27, 28, 33], "one": [0, 4, 5, 8, 9, 15, 21, 24, 25, 26, 27, 28, 29, 30, 33, 34], "scalar": [0, 9, 10, 27, 33], "between": [0, 2, 7, 9, 26, 28], "forward": [0, 2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "implement": [0, 1, 2, 4, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "given": [0, 2, 4, 7, 8, 9, 10, 11, 12, 15, 17, 18, 21, 24, 25, 26, 28, 29, 30, 32, 33, 34], "via": [0, 2, 28, 32], "where": [0, 4, 5, 7, 8, 9, 10, 12, 15, 17, 18, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34], "In": [0, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "practic": [0, 11, 12], "updat": [0, 7, 11, 12, 16, 26, 33], "If": [0, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 21, 26, 27, 28, 29, 31], "e": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 24, 25, 26, 29, 31, 32, 33, 34], "send": [0, 2, 4, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 24, 25, 26, 31, 34], "themselv": [0, 28], "The": [0, 1, 2, 4, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34], "two": [0, 2, 7, 11, 12, 13, 15, 17, 18, 19, 24, 25, 26, 28, 29, 32, 33, 34], "m_": [0, 2, 7, 8, 9, 10, 11, 12, 15, 17, 18, 24, 25, 26, 27, 28, 30, 32, 33, 34], "y": [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "rightarrow": [0, 2, 7, 8, 9, 10, 11, 12, 15, 17, 18, 24, 25, 26, 27, 28, 30, 32, 33, 34], "x": [0, 2, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "left": [0, 5, 10, 17, 18, 33], "right": [0, 5, 10, 17, 18, 33], "travel": 0, "denot": [0, 8, 11, 12, 17, 18, 32, 33], "mathcal": [0, 2, 7, 8, 9, 10, 11, 12, 15, 17, 18, 24, 25, 26, 27, 28, 30, 32, 33, 34], "mathbf": [0, 29, 32], "h": [0, 2, 7, 12, 17, 18, 21, 25, 26, 28, 29, 30, 32, 34], "_x": [0, 7, 24, 26, 30], "_y": [0, 2, 25, 28, 34], "theta": [0, 2, 7, 8, 9, 12, 15, 17, 18, 24, 25, 27, 28, 29, 30, 32, 33, 34], "ar": [0, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "call": [0, 5, 12, 33], "option": [0, 2, 4, 5, 7, 9, 11, 12, 26], "appli": [0, 7, 8, 11, 12, 14, 17, 26, 30, 33], "leftarrow": [0, 18], "across": 0, "belong": [0, 5, 15, 24, 25, 26, 28, 29], "m_x": [0, 2, 8, 9, 10, 15, 17, 18, 24, 25, 27, 28, 30, 32, 33, 34], "text": [0, 2, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 26, 27, 28, 29, 34], "agg": [0, 2, 27], "result": [0, 5, 7, 8, 9, 12, 15], "spars": [0, 1, 2, 5, 11, 12, 14, 15, 16, 17, 18, 21, 24, 26, 28, 30], "matrix": [0, 2, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "construct": [0, 14, 16, 21, 33, 34], "reset_paramet": [0, 2, 33], "gain": 0, "reset": [0, 2], "learnabl": [0, 2, 7, 12, 26, 32], "note": [0, 2, 4, 5, 11, 12, 13, 17, 18, 19, 24, 25, 29, 32, 33], "convolut": [0, 2, 4, 8, 10, 26], "conv": [0, 1, 2], "aggr_norm": [0, 29, 32], "update_func": [0, 7, 27, 28, 29, 30, 32, 33], "relu": [0, 7, 17, 22, 33], "sigmoid": [0, 7, 11, 12, 17, 18, 19, 20, 22, 23, 26, 27, 28, 29, 30, 33], "with_linear_transform": 0, "true": [0, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "3": [0, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "build": [0, 4, 5, 33], "rout": 0, "includ": [0, 4, 5, 33], "an": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34], "specif": [0, 4, 5, 10, 15, 17, 21], "int": [0, 2, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "dimens": [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "normal": [0, 11, 12, 28, 30, 31, 34], "size": [0, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "linear": [0, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "transform": [0, 5, 16, 21, 26], "nb": 0, "ha": [0, 5, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "equal": [0, 5, 17, 33], "x_message_on_target": 0, "embed": [0, 27], "4": [0, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "tanh": 0, "inter": [0, 18, 29], "merg": 0, "list": [0, 5, 11, 12, 13, 21, 27, 33], "len": [0, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33], "n_messages_to_merg": 0, "n_skeleton_in": 0, "channel": [0, 2, 7, 8, 21, 24, 25, 26, 28, 29, 30, 31, 32, 34], "arrai": [0, 5, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], "like": [0, 5, 7, 8, 9, 26, 28], "n_skeleton_out": 0, "skeleton": [0, 7, 33], "out": [0, 3, 4, 5, 6, 7, 13, 15, 16, 19, 27, 28, 33, 34], "give": [1, 7, 12, 26], "overview": 1, "which": [1, 4, 5, 8, 11, 12, 14, 16, 17, 21, 24, 25, 26, 27, 28, 29, 32, 33], "consist": [1, 4, 5, 21, 33], "base": [1, 4, 12, 27, 29, 30, 32, 33, 34], "core": 1, "mathemat": 1, "concept": 1, "nn": [1, 2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "organ": [1, 4, 28], "domain": [1, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "util": [1, 7, 8, 11, 12, 20, 21, 22, 23, 26, 33], "hypergraph": [1, 4, 20, 22, 23], "simplici": [1, 4, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 31], "complex": [1, 4, 5, 7, 8, 10, 11, 12, 13, 17, 18, 19, 20, 22, 23, 24, 25, 26, 31, 32], "scatter": [1, 16, 33], "templat": [2, 5, 17, 19], "template_lay": [2, 4, 19], "templatelay": [2, 11, 13, 19], "intermediate_channel": [2, 13, 19, 22, 32], "intermedi": [2, 29, 32], "x_1": [2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "incidence_1": [2, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 30, 32, 33], "n_edg": [2, 8, 9, 10, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 29, 30, 32, 34], "edg": [2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "n_node": [2, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 34], "incid": [2, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 25, 26, 27, 28, 29, 30, 32], "map": [2, 15, 28, 29, 30, 33], "node": [2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34], "b_1": [2, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 26, 30, 32], "high": [2, 24, 34], "skip": [2, 7, 21, 24, 33, 34], "hsn": [2, 4], "hsn_layer": [2, 4, 25], "hsnlayer": [2, 4, 25, 28], "propos": [2, 7, 8, 9, 10, 15, 18, 24, 25, 26, 29, 30, 31, 32, 33, 34], "hrgz22": 2, "classif": [2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 34], "complic": 2, "gener": [2, 5, 7, 11, 12, 21, 25, 26, 29, 34], "connect": [2, 7, 17, 21, 25, 29, 33, 34], "geometr": [2, 4], "represent": [2, 4, 7, 11, 12, 14, 15, 16, 17, 28, 31, 33], "workshop": [2, 4], "iclr": 2, "2022": [2, 4, 7, 8, 14, 24, 25, 26, 28, 32, 34], "openreview": 2, "net": [2, 4, 34], "pdf": [2, 5], "id": [2, 5], "sc8glb": 2, "k6e9": 2, "x_0": [2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "adjacency_0": [2, 7, 9, 24, 25], "wa": [2, 27, 32], "Its": 2, "equat": [2, 5, 6, 7, 8, 9, 10, 15, 24, 25, 26, 28, 30, 33, 34], "tnn23": 2, "graphic": [2, 6], "illustr": [2, 31], "begin": [2, 5, 7, 26], "align": [2, 7, 26, 32], "quad": [2, 7, 8, 9, 10, 11, 12, 15, 17, 18, 24, 25, 26, 27, 28, 30, 32, 33, 34], "z": [2, 7, 8, 9, 10, 11, 12, 17, 18, 25, 32, 33, 34], "0": [2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "sigma": [2, 8, 11, 15, 17, 18, 24, 25, 28, 29, 30, 32, 33, 34], "a_": [2, 7, 9, 10, 17, 24, 25, 26], "uparrow": [2, 7, 8, 9, 10, 24, 25, 26, 28, 29, 30, 32, 33, 34], "xy": [2, 8, 15, 24, 25, 28, 30, 32, 33, 34], "cdot": [2, 7, 8, 15, 17, 18, 24, 25, 26, 28, 30, 32, 33, 34], "t": [2, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 21, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34], "zy": [2, 17, 18, 25], "h_y": [2, 7, 8, 9, 10, 11, 12, 15, 18, 25, 26, 30, 32, 33], "xz": [2, 17, 18, 25], "sum_": [2, 8, 15, 17, 18, 24, 25, 28, 29, 30, 32, 33, 34], "l": [2, 7, 8, 9, 10, 17, 18, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34], "c": [2, 6, 7, 8, 9, 11, 12, 15, 16, 17, 18, 24, 25, 28, 30, 33, 34], "h_x": [2, 7, 8, 9, 10, 11, 12, 15, 17, 18, 24, 25, 26, 27, 28, 32, 33, 34], "end": [2, 5, 7, 24, 25, 26, 28, 33, 34], "awesom": [2, 6, 12, 18], "tnn": [2, 4, 6, 12, 18], "adjac": [2, 7, 9, 10, 14, 24, 25, 26, 28, 29, 30, 33], "a_0": 2, "simplifi": [2, 9], "version": [2, 8, 9, 10, 29, 32], "ccxn": 2, "et": [2, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34], "al": [2, 4, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34], "ccxn_layer": [2, 9], "ccxnlayer": [2, 9], "in_channels_0": [2, 7, 8, 9, 10, 29, 31, 32], "in_channels_1": [2, 7, 8, 9, 10, 29, 31, 32], "in_channels_2": [2, 7, 8, 9, 10, 29, 31, 32], "hiz20": 2, "compos": 2, "face": [2, 4, 7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "entir": [2, 7, 8, 9, 10], "istvan": 2, "analysi": 2, "neurip": 2, "2020": [2, 4, 9, 14, 15, 17, 18, 30], "2010": 2, "00743": 2, "neighborhood_0_to_0": [2, 7, 9], "neighborhood_1_to_2": [2, 9], "x_2": [2, 8, 9, 10, 11, 12, 13, 17, 18, 19, 24, 25, 26, 27, 28, 29, 30, 31, 32], "amp": [2, 9, 27], "u": [2, 4, 9, 10, 11, 12, 17, 27, 33], "cohomologi": [2, 9], "coboundari": [2, 9, 10], "m": [2, 5, 8, 9, 17, 24, 27, 30, 32, 33, 34], "t_": [2, 9, 18], "h_": [2, 8, 9, 17, 24, 27, 28], "n_0_cell": 2, "n_1_cell": 2, "a_0_up": 2, "n_2_cell": 2, "b_2": [2, 9, 26, 30], "onli": [2, 4, 5, 7, 13, 21, 26, 29, 31, 33], "requir": [2, 5, 7, 8, 27], "num_class": [2, 7, 8, 9, 10, 14, 16, 21, 27, 29, 31], "predict": [2, 5, 7, 11, 12, 14, 15, 16, 32, 33], "adapt": 3, "torch_scatt": 3, "py": [3, 4, 5, 8, 9, 16, 21, 24, 28, 30, 34], "rusty1": 3, "pytorch_scatt": 3, "broadcast": [3, 8, 9], "src": [3, 21], "other": [3, 5, 33], "dim": [3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34], "str": [3, 5, 28, 30], "scatter_add": 3, "index": [3, 5, 28, 33], "dim_siz": 3, "valu": [3, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 24, 26, 27, 29, 30, 31, 32, 33], "indic": [3, 16, 24, 25, 26, 28, 29, 33, 34], "scatter_mean": 3, "scatter_sum": 3, "welcom": [4, 5], "host": 4, "second": [4, 11, 12, 27, 34], "annual": 4, "topologi": [4, 13, 26], "geometri": 4, "tag": 4, "machin": [4, 31, 32], "review": [4, 5, 6], "contributor": [4, 5], "mathild": [4, 6], "mustafa": [4, 6], "nina": [4, 6], "florian": 4, "frantzen": 4, "ghada": [4, 6], "alzamzmi": 4, "theodor": [4, 6], "michael": [4, 6], "scholkemp": 4, "josef": 4, "hopp": 4, "karthikeyan": [4, 6], "natesan": [4, 6], "johan": 4, "math": [4, 5, 7, 8, 12, 17, 18, 28, 30, 32, 33], "audun": 4, "myer": 4, "helen": 4, "jenn": 4, "tim": 4, "doster": 4, "tegan": 4, "emerson": 4, "henri": 4, "kving": 4, "bastian": [4, 31], "rieck": [4, 31], "sophia": [4, 6], "jan": 4, "meissner": 4, "paul": [4, 6, 31], "tolga": [4, 6], "vincent": 4, "grand": 4, "aldo": [4, 6], "tamal": [4, 6], "soham": [4, 6], "shreya": [4, 6], "neal": [4, 6], "robin": [4, 6], "edit": [4, 5], "now": [4, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 25, 26, 31, 33, 34], "over": [4, 7, 11, 12, 13, 14, 16, 18, 19, 20, 23, 24, 25, 26, 28, 30, 31, 33, 34], "thank": 4, "you": [4, 5, 21, 34], "stellar": 4, "contirbut": 4, "foster": 4, "reproduc": [4, 6], "open": [4, 21], "research": [4, 31], "winner": 4, "announc": 4, "here": [4, 5, 7, 13, 14, 16, 21, 24, 25, 28, 29, 33], "luca": 4, "scofano": 4, "claudio": 4, "battiloro": [4, 26], "guillermo": 4, "bernardez": 4, "simon": 4, "fiorellino": 4, "indro": 4, "spinelli": 4, "scardapan": 4, "lev": 4, "telyatninkov": 4, "olga": 4, "zaghen": 4, "allsettransform": [4, 12], "chien": [4, 11, 12], "sadrodin": 4, "barikbin": [4, 16], "hmpnn": 4, "heydari": [4, 14], "san": [4, 7], "giusti": [4, 7, 8, 26], "odin": 4, "hoff": 4, "gardaa": 4, "scone": 4, "roddenberri": [4, 32, 33], "2021": [4, 10, 11, 12, 32, 33], "cellular": [4, 10], "dmitrii": 4, "gavrilev": 4, "gleb": 4, "bazhenov": 4, "suraj": 4, "singh": 4, "cw": 4, "cwn": 4, "bodnar": [4, 10], "combinatori": 4, "rub\u00e9n": 4, "ballest": 4, "manuel": 4, "lecha": 4, "sergio": 4, "escalera": 4, "hoan": 4, "aiden": 4, "brent": 4, "honor": 4, "mention": 4, "jen": 4, "agerberg": 4, "georg": 4, "b\u00f6kman": 4, "pavlo": 4, "melnyk": 4, "sccn": 4, "yang": [4, 28, 29, 31, 32], "autoencod": 4, "sca": 4, "alessandro": 4, "salatiello": 4, "hyperedg": [4, 11, 12, 13, 14, 17, 18, 19], "neuron": 4, "hnhn": 4, "dong": [4, 15, 16], "alexand": 4, "nikitin": 4, "unigcn": [4, 20], "huang": 4, "purpos": [4, 5, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 23, 24, 25, 26, 28, 29], "crowdsourc": 4, "ask": 4, "contribut": [4, 17, 29], "code": [4, 5, 33], "previous": 4, "exist": 4, "train": 4, "benchmark": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34], "dataset": [4, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27], "built": [4, 5], "python": [4, 5, 6], "packag": [4, 6, 8, 9, 16, 21, 24, 28, 29, 30, 32], "take": [4, 7, 8, 9, 10, 26, 29, 31, 33], "form": [4, 11, 12, 24, 25, 28, 29, 33], "pull": [4, 5], "request": [4, 5, 21, 33], "contain": [4, 7, 11, 12, 14, 16, 21, 29, 33], "necessari": [4, 7, 26], "literatur": [4, 6, 21], "leverag": [4, 26], "infrastructur": 4, "block": 4, "we": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34], "invit": 4, "file": [4, 5], "regularli": 4, "ad": [4, 5], "when": [4, 5, 7, 26, 33], "everi": [4, 21, 22], "respect": [4, 10, 11, 12, 17, 18, 26, 27, 29, 32, 33], "white": 4, "paper": [4, 7, 14, 15, 16, 24, 25, 26, 29, 30, 31, 32, 33, 34], "summar": 4, "find": [4, 7, 33], "publish": 4, "qualifi": 4, "opportun": 4, "co": [4, 21], "author": [4, 6, 16, 33], "top": [4, 7, 29], "8": [4, 7, 8, 9, 10, 12, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 31, 33, 34], "best": [4, 12], "addit": 4, "softwar": [4, 5], "journal": 4, "special": 4, "recognit": 4, "final": [4, 14, 15, 16, 21, 26, 32, 33], "date": 4, "time": [4, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 26, 28, 29, 32, 33, 34], "must": [4, 11, 12, 13, 15, 17, 18, 19, 24, 25, 26, 28, 29, 32], "place": [4, 5, 11, 12], "befor": [4, 5, 21, 33], "juli": 4, "13": [4, 8, 9, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 33], "16": [4, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33], "59": [4, 8, 14, 15, 20, 24, 28], "pacif": 4, "standard": [4, 5, 21, 26], "modifi": [4, 5, 27], "until": 4, "everyon": [4, 5], "free": [4, 33], "It": [4, 14, 16, 21], "suffici": 4, "accept": 4, "automat": [4, 26], "subscrib": 4, "team": [4, 34], "encourag": 4, "start": [4, 5, 21, 27, 33], "earli": 4, "help": [4, 5], "debug": 4, "fail": 4, "test": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29], "address": 4, "potenti": 4, "issu": [4, 21], "case": [4, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 24, 25, 26, 31, 33, 34], "multipl": [4, 5, 11, 12, 33], "similar": [4, 28], "qualiti": 4, "earlier": [4, 28], "prioriti": 4, "consider": 4, "restrict": 4, "number": [4, 7, 8, 9, 10, 11, 12, 14, 15, 16, 21, 24, 25, 26, 27, 28, 30, 31, 33, 34], "member": 4, "more": [4, 5, 6, 24, 28, 33], "than": [4, 32, 33, 34], "model": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 34], "There": [4, 5, 14, 15, 16, 24, 25, 26, 28, 32], "amount": [4, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 29, 31, 34], "princip": 4, "develop": [4, 5], "allow": [4, 28], "pre": [4, 33], "fig": [4, 33], "11": [4, 7, 8, 9, 10, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34], "compli": 4, "github": [4, 12, 16, 18, 21], "action": 4, "workflow": 4, "successfulli": 4, "lint": 4, "format": [4, 5, 21], "black": [4, 33], "isort": 4, "flake8": 4, "three": [4, 5, 21], "new": [4, 5, 8, 9], "name": [4, 5, 7, 11, 12, 14, 20, 22, 23], "_layer": 4, "ex": 4, "store": [4, 15], "directori": [4, 5], "primit": 4, "equival": [4, 5], "depict": 4, "diagram": 4, "exampl": [4, 26, 29, 32, 33], "check": [4, 5, 6, 15, 24, 25, 34], "_train": 4, "ipynb": 4, "hsn_train": 4, "tutori": [4, 6, 21], "follow": [4, 5, 6, 7, 8, 11, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], "process": [4, 5, 21], "import": [4, 5, 7, 8, 9, 10, 11, 12, 14, 16, 18, 21, 26, 33], "well": [4, 5], "load": [4, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 23, 24, 25, 27, 28, 29, 30, 31, 32], "matric": [4, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 24, 25, 26, 27, 28, 29, 31, 32, 34], "toponetx": [4, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "either": [4, 5, 26, 33], "shrec16": [4, 8, 9, 10, 11, 12, 13, 17, 18, 19, 27, 29, 32, 34], "suitabl": [4, 15], "level": [4, 7, 11, 12, 13, 15, 17, 18, 19, 21, 24, 25, 26, 27, 28, 29, 32], "see": [4, 5, 6, 16, 33], "karat": [4, 15, 24, 25, 26, 28, 29], "club": [4, 15, 24, 25, 26, 28, 29], "abov": [4, 5, 32, 33], "lift": [4, 7, 8, 9, 10, 11, 12, 15, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32], "choic": [4, 7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20, 22, 23, 27], "along": [4, 7, 8, 26], "task": [4, 11, 12, 14, 15, 16, 21, 24, 25, 28, 29, 32, 33], "simpl": [4, 32], "loop": [4, 11, 12, 13, 14, 16, 18, 19, 20, 21, 23, 24, 25, 26, 28, 30, 31, 33, 34], "depend": 4, "perform": [4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 30, 31, 33, 34], "accuraci": [4, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34], "test_": [4, 5], "name_of_model": 4, "test_hsn_lay": 4, "testhsnlay": 4, "unit": [4, 5, 33], "pleas": [4, 5, 7, 8, 9, 16, 21, 26], "pytest": [4, 5], "unittest": 4, "further": [4, 7, 26], "manipul": 4, "mai": 4, "modif": 4, "accompani": 4, "appropri": [4, 5], "locat": [4, 5, 21], "With": [4, 17], "being": [4, 26, 27], "said": 4, "highli": 4, "make": [4, 7, 8, 9, 10, 11, 12, 13, 14, 16, 19, 21, 27, 33, 34], "most": [4, 5, 26, 28], "resort": 4, "absolut": 4, "condorcet": 4, "decid": [4, 26], "criteria": 4, "chosen": [4, 28], "correctli": 4, "term": [4, 26], "do": [4, 14, 16, 24, 25, 28, 33], "need": [4, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 24, 25, 26, 31, 33, 34], "match": 4, "origin": [4, 5, 7, 8, 9, 10, 21, 26, 28, 29, 31, 32, 33], "readabl": [4, 5], "clean": 4, "api": [4, 5], "written": 4, "docstr": 4, "clearli": 4, "explain": 4, "robust": 4, "reward": 4, "nor": 4, "goal": 4, "accur": 4, "our": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34], "field": 4, "select": [4, 28, 32], "maintain": 4, "collabor": 4, "whose": [4, 5], "vote": 4, "onc": [4, 11, 12, 13, 17, 18, 19], "googl": [4, 5], "express": [4, 17], "prefer": [4, 5], "get": [4, 26, 29, 32, 33], "even": 4, "link": [4, 5], "record": [4, 5, 11, 12, 13, 17, 18, 19], "while": [4, 5, 26], "email": 4, "identifi": 4, "voter": 4, "ident": [4, 12, 24, 25, 29], "remain": [4, 33], "secret": 4, "share": [4, 7], "feel": [4, 33], "contact": 4, "repositori": [4, 5], "slack": 4, "ucsb": 4, "edu": 4, "guid": 5, "aim": [5, 7, 26], "eas": 5, "both": [5, 7, 26, 33], "novic": 5, "experienc": 5, "commun": 5, "effort": 5, "wai": [5, 26], "fork": 5, "upstream": 5, "submit": [5, 21], "pr": 5, "synchron": 5, "your": 5, "main": [5, 21], "branch": 5, "git": 5, "checkout": 5, "hold": 5, "b": [5, 8, 10, 11, 12, 15, 17, 18, 27, 28, 29, 30], "sure": [5, 34], "next": [5, 15, 17, 21, 33], "section": [5, 33], "re": [5, 24, 33], "done": [5, 8, 9, 10, 11, 12, 13, 17, 18, 19, 23, 27, 29, 30, 31, 32, 33], "commit": 5, "modified_fil": 5, "my": [5, 27], "Then": [5, 8, 9, 10], "push": 5, "toponextx": 5, "instruct": 5, "repeat": 5, "folder": 5, "valid": [5, 20, 21, 22, 23, 33], "filenam": 5, "For": [5, 6, 8, 15, 18, 24, 25, 29, 32, 33, 34], "test_add": 5, "def": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "test_capital_cas": 5, "assert": [5, 28, 33], "5": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "9": [5, 7, 8, 9, 10, 12, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 31, 33, 34], "statement": 5, "under": 5, "correct": [5, 7, 20, 22, 23, 33], "instal": 5, "tool": 5, "pip": 5, "dev": 5, "verifi": 5, "break": 5, "doc": 5, "descript": [5, 33], "usag": 5, "inform": [5, 11, 12, 14, 17, 18, 32], "markdown": 5, "languag": 5, "common": [5, 7], "restructuredtext": 5, "numpi": [5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "style": 5, "up": [5, 24, 25, 26, 28, 33], "understand": 5, "role": 5, "syntax": 5, "also": [5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 31, 32, 34], "autom": 5, "pars": 5, "inclus": 5, "look": [5, 33], "ani": [5, 7, 8, 9, 18, 29, 33], "object": 5, "print": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "__doc__": 5, "attribut": 5, "try": [5, 7, 8, 9, 26, 33], "np": [5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "good": [5, 31], "These": 5, "some": [5, 28, 33], "element": [5, 12], "ones": [5, 14, 16], "d": [5, 17, 24, 30], "summari": 5, "line": 5, "79": [5, 8, 13, 14, 15, 20, 28], "char": 5, "immedi": 5, "after": [5, 7, 16, 22], "first": [5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "capit": 5, "letter": 5, "period": 5, "describ": [5, 12], "verb": 5, "imper": 5, "mood": 5, "g": [5, 11, 12, 17, 26, 32, 33], "v": [5, 11, 12, 15, 17, 18, 21, 24, 25, 26, 28, 29, 32, 34], "possibl": [5, 21], "uncertain": 5, "oppos": 5, "calcul": [5, 26, 34], "evalu": [5, 7, 14, 15, 16, 21, 22], "multi": [5, 12], "separ": 5, "blank": 5, "argument": [5, 11, 12, 26], "type": 5, "On": 5, "state": [5, 18, 21], "rest": 5, "space": [5, 29, 33], "side": 5, "default_valu": 5, "indent": 5, "esp": 5, "would": [5, 24, 25], "want": [5, 21, 33], "mani": [5, 7], "veri": [5, 21], "rais": [5, 29, 32], "etc": [5, 21, 27], "latex": 5, "cite": [5, 21], "my_method": 5, "self": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "my_param_1": 5, "my_param_2": 5, "vector": [5, 12, 14, 16, 17, 33], "big": 5, "o": [5, 12, 15, 26], "short": 5, "my_result": 5, "relev": 5, "snippet": 5, "show": [5, 15, 24, 25, 33, 34], "how": [5, 12, 24, 25, 26], "script": 5, "wikipedia": 5, "page": [5, 31], "And": 5, "fill": 5, "scikit": 5, "project": [5, 10, 26, 27, 32], "fit_predict": 5, "sample_weight": 5, "cluster": [5, 27], "center": [5, 33], "sampl": [5, 7, 15, 33], "conveni": 5, "fit": 5, "sparse_matrix": 5, "n_featur": 5, "ignor": [5, 20, 23], "Not": 5, "present": [5, 7], "convent": [5, 7], "observ": 5, "assign": [5, 8, 9, 10, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34], "label": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 30, 31, 33], "labels_": 5, "mind": 5, "instead": [5, 21], "boolean": 5, "vari": 5, "notat": [5, 7, 8, 9, 10, 15, 24, 25, 26, 27, 28, 30, 32, 33, 34], "axi": [5, 33], "string": [5, 18], "bracket": 5, "log": [5, 28, 33], "squar": [5, 33], "multinomi": 5, "1d": [5, 8, 9, 10, 29, 31], "2d": [5, 8, 9, 10, 29, 31], "subset": [5, 7, 14, 16], "ndarrai": [5, 33], "datafram": 5, "explicitli": 5, "relat": [5, 14], "colon": 5, "explan": 5, "_weight_boost": 5, "adaboost": 5, "great": 5, "ve": 5, "discuss": 5, "Of": 5, "cours": [5, 29], "verbos": 5, "thei": [5, 7, 8, 9, 10, 11, 12, 24, 25, 26, 28, 29, 31], "compon": [5, 26], "rst": 5, "keep": [5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 23, 24, 25, 26, 28, 29, 34], "length": [5, 14, 16, 21, 28], "80": [5, 8, 13, 14, 15, 20, 27, 28], "charact": 5, "except": [5, 7, 26], "tabl": 5, "tdl": 6, "blue": 6, "laid": 6, "extend": [6, 29], "avail": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 21, 26, 27], "To": [6, 11, 15, 23, 24, 25, 32, 33, 34], "about": 6, "blueprint": 6, "k": [6, 7, 10, 12, 15, 17, 24, 25, 26, 27, 28, 30, 32, 33, 34], "misc": 6, "hajij2023topolog": 6, "titl": [6, 15], "year": 6, "eprint": 6, "archiveprefix": 6, "primaryclass": 6, "lg": 6, "papillon2023architectur": 6, "notebook": [7, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 26, 29, 30, 31, 32, 33, 34], "didact": [7, 26], "clear": [7, 26], "technic": [7, 26], "document": [7, 14, 16, 21, 26], "sinc": [7, 24, 25, 28, 29, 33], "introduct": 7, "achiev": [7, 12, 28, 33], "outstand": 7, "howev": [7, 21, 29, 32], "consid": [7, 26, 29, 32], "pairwis": [7, 11, 12, 13, 17, 18, 19, 33], "relationship": 7, "among": 7, "abl": [7, 26, 34], "fulli": 7, "exploit": 7, "interact": 7, "real": [7, 33], "world": [7, 33], "introduc": [7, 14, 16, 17, 26], "oper": [7, 12, 17, 26, 28, 29, 33], "vertic": [7, 33], "repres": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 25, 26, 31, 33, 34], "captur": 7, "particular": 7, "lower": [7, 26, 27, 28, 29, 32, 33, 34], "upper": [7, 10, 26, 28, 29, 30, 32, 33, 34], "encod": [7, 15, 24, 25, 26, 29, 33], "design": 7, "independ": [7, 12], "mask": [7, 8, 14, 26, 33], "thu": [7, 8, 26, 31], "strategi": [7, 18], "approach": 7, "hierarch": 7, "incorpor": 7, "algorithm": 7, "ii": 7, "optim": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "combin": [7, 11, 12], "neighbor": [7, 18, 32, 33], "iii": 7, "pool": [7, 8, 9, 10, 13, 17, 18, 19, 20, 22, 23, 27], "extract": [7, 11, 12, 17, 18, 23], "compact": 7, "meaning": 7, "remark": [7, 26], "custom": [7, 26], "symbol": [7, 26], "signal": [7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20, 22, 23, 26, 27], "could": [7, 26, 28], "involv": [7, 26], "n_1": [7, 26], "n_2": [7, 26], "downarrow": [7, 8, 24, 26, 27, 28, 29, 30, 32, 33, 34], "made": [7, 15, 24, 25, 26, 28, 29, 31, 32], "stage": 7, "nbsphinx": [7, 8, 12, 17, 18, 32], "textrm": [7, 26], "alpha": [7, 18, 21, 26, 33], "h_z": [7, 10, 11, 12], "phi": [7, 26], "parameter": 7, "mathbb": [7, 11, 12, 17, 33], "2f_0": 7, "f_0": 7, "head": [7, 12], "concaten": [7, 12, 17, 33], "textbf": [7, 11, 12, 18, 26], "bigg": [7, 26, 29, 32], "bigotimes_": [7, 26], "_k": [7, 10, 26, 27], "bigoplus_": [7, 26], "alpha_k": [7, 26], "a_k": [7, 26, 33], "psi_k": [7, 26], "foral": [7, 17, 26], "n_k": [7, 26], "f": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "respons": [7, 21], "reciproc": 7, "part": [7, 24, 25, 26, 28, 29], "round": [7, 27, 30], "gamma": [7, 16], "tau": 7, "tcdot": 7, "xin": 7, "c_r": 7, "coeffici": [7, 17], "score": [7, 33], "non": [7, 26, 33], "_r": 7, "coars": 7, "mutag": [7, 20, 22, 23], "tudataset": [7, 20, 22, 23], "paperswithcod": 7, "com": [7, 16, 21, 23], "__": 7, "188": [7, 15, 20, 28], "chemic": 7, "compound": 7, "7": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34], "discret": 7, "mutagen": 7, "salmonella": 7, "typhimurium": 7, "gat": [7, 26], "gatv2": 7, "random": [7, 8, 16, 33], "sklearn": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 27, 29, 31, 32, 34], "model_select": [7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 27, 29, 31, 32, 34], "train_test_split": [7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 27, 29, 31, 32, 34], "cell_complex": [7, 8, 9, 10], "cellcomplex": 7, "torch_geometr": [7, 14, 16, 20, 22, 23, 26], "convert": [7, 8, 9, 10, 15, 20, 22, 23, 24, 25, 26, 29, 31, 34], "to_networkx": [7, 20, 22, 23, 26], "can_lay": 7, "canlay": [7, 8], "multiheadliftlay": 7, "poollay": 7, "gpu": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 21, 27], "them": [7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 19, 21, 26, 27, 28, 29, 31], "otherwis": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 21, 27, 33], "run": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 21, 28, 33], "cpu": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 26, 27, 30, 31, 34], "devic": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 26, 27, 30, 31, 34], "cuda": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 26, 27, 30, 31, 34], "is_avail": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 26, 27, 30, 31, 34], "els": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 26, 27, 29, 30, 31, 32, 34], "retriev": [7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 34], "binari": [7, 8, 14, 15, 16, 20, 22, 23, 26, 30, 31, 34], "root": [7, 20, 22, 23], "tmp": [7, 20, 21, 22, 23], "use_edge_attr": [7, 20, 22, 23], "use_node_attr": 7, "cc_list": [7, 8, 9, 10], "x_0_list": 7, "x_1_list": [7, 20, 22, 23], "y_list": [7, 20, 22, 23], "append": [7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "edge_attr": 7, "i_cc": [7, 8], "th": [7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 26, 27, 30, 31], "edge_index": [7, 11, 12, 14, 17, 18], "36": [7, 9, 14, 15, 16, 20, 22, 23, 24, 28], "0th": [7, 30], "17": [7, 14, 15, 16, 20, 22, 23, 24, 28], "38": [7, 14, 15, 16, 20, 22, 23, 24, 28], "structur": [7, 8, 9, 10, 11, 12, 18, 26, 29, 32], "lower_neighborhood_list": 7, "upper_neighborhood_list": 7, "adjacency_0_list": [7, 9], "adjacency_matrix": [7, 9, 10, 24, 25, 28, 29, 30, 33], "from_numpi": [7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "todens": [7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "to_spars": [7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "lower_neighborhood_t": 7, "down_laplacian_matrix": [7, 8, 24, 26, 27, 29, 30, 32, 34], "upper_neighborhood_t": 7, "up_laplacian_matrix": [7, 8, 26, 29, 30, 32, 34], "zero": [7, 11, 12, 21, 24, 25, 26, 29, 32, 33], "stack": [7, 9, 10, 11, 13, 14, 15, 16, 19, 20, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34], "6": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34], "__init__": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "dropout": [7, 11, 12, 14, 16], "concat": 7, "skip_connect": 7, "att_activ": 7, "leakyrelu": [7, 17, 26], "n_layer": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "att_lift": 7, "arg": [7, 30], "probabl": [7, 11, 12, 29], "activ": [7, 12, 28, 30], "super": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "lift_lay": 7, "signal_lift_dropout": 7, "rang": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "k_pool": 7, "signal_pool_activ": 7, "readout": [7, 29], "modulelist": [7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33], "lin_0": [7, 8, 9, 10, 31], "128": [7, 15, 20, 28], "lin_1": [7, 8, 9, 10, 31], "lower_neighborhood": 7, "upper_neighborhood": 7, "hasattr": 7, "isinst": 7, "p": [7, 17, 18, 26], "max": [7, 11, 12, 17, 18, 19, 20, 22, 23, 28], "feed": [7, 11, 12, 13, 17, 18, 19, 20, 22, 23, 33], "foward": 7, "specifi": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 31, 32], "loss": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "without": [7, 8, 9], "32": [7, 11, 14, 15, 16, 17, 20, 22, 23, 24, 28, 33], "crit": [7, 8, 9, 20, 22, 23], "crossentropyloss": [7, 8, 9, 14, 15, 16, 21, 22], "opt": [7, 8, 9, 11, 12, 13, 17, 18, 19, 27, 28, 30], "adam": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "lr": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "001": [7, 22, 31], "liftlay": 7, "lower_att": 7, "multiheadcellattent": 7, "negative_slop": 7, "lin": 7, "in_featur": [7, 14, 16, 21, 29, 32], "out_featur": [7, 29, 32], "64": [7, 11, 12, 14, 15, 20, 24, 28], "bia": [7, 29, 32], "upper_att": 7, "split": [7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 30, 33], "test_siz": [7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 27, 29, 31, 32, 33, 34], "x_1_train": [7, 8, 9, 10, 19, 20, 22, 23, 27, 29, 30], "x_1_test": [7, 8, 9, 10, 19, 20, 22, 23, 27, 29], "shuffl": [7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20, 22, 23, 27, 29, 31, 32, 33, 34], "x_0_train": [7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 27, 29, 30], "x_0_test": [7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 27, 29], "lower_neighborhood_train": 7, "lower_neighborhood_test": 7, "upper_neighborhood_train": 7, "upper_neighborhood_test": 7, "adjacency_0_train": [7, 9], "adjacency_0_test": [7, 9], "y_train": [7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34], "y_test": [7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34], "test_interv": [7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "num_epoch": [7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "epoch_i": [7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 24, 25, 26, 27, 28, 29, 30, 31, 32], "epoch_loss": [7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "num_sampl": 7, "zip": [7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20, 22, 23, 27, 29, 30, 31, 32], "dtype": [7, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 29, 32, 34], "long": [7, 14, 16, 28], "zero_grad": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "y_hat": [7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "argmax": [7, 14, 15, 16, 21, 22, 33], "item": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "backward": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "train_acc": [7, 14, 15, 21, 24, 25, 26, 28, 29, 32, 33, 34], "epoch": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "4f": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 26, 28, 29, 31, 32, 34], "flush": [7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "no_grad": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "test_acc": [7, 14, 15, 21, 24, 25, 26, 28, 29, 32, 34], "6234": 7, "6794": 7, "5965": 7, "6047": 7, "6947": 7, "5953": 7, "5879": 7, "7099": 7, "5614": 7, "5801": 7, "6316": 7, "5755": [7, 15], "7405": 7, "7544": 7, "5624": [7, 24, 31], "5565": [7, 15], "7719": 7, "down": [8, 26, 27, 29, 30, 34], "laplacian": [8, 26, 27, 28, 29, 31, 34], "rodenberri": 8, "l_": [8, 26, 27, 32, 33, 34], "odot": [8, 17, 24], "epsilon": [8, 26], "theta_": 8, "small": [8, 9, 10, 11, 12, 13, 17, 18, 19, 27, 28, 29, 30, 31, 32], "can_layer_bi": 8, "3d": [8, 9, 10, 11, 12, 13, 17, 18, 19, 27, 30, 31], "mesh": [8, 9, 10, 11, 12, 13, 17, 18, 19, 27, 29, 30, 31, 32], "shrec": [8, 9, 10, 11, 12, 13, 17, 18, 19, 27, 30, 31, 32], "shrec_16": [8, 9, 10, 11, 12, 13, 17, 18, 19, 27, 29, 30, 31, 32], "kei": [8, 9, 10, 11, 12, 13, 17, 18, 19, 27, 29, 30, 31, 32], "node_feat": [8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 24, 25, 26, 27, 28, 29, 30, 31, 32], "edge_feat": [8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "face_feat": [8, 9, 10, 11, 12, 13, 17, 18, 19, 24, 25, 26, 27, 28, 29, 30, 31, 32], "simplex": [8, 9, 10, 11, 12, 13, 17, 18, 19, 24, 25, 26, 27, 28, 29, 30, 32, 33], "i_complex": [8, 9, 10, 11, 12, 13, 17, 18, 19, 27, 30, 31], "6th": [8, 9, 10, 11, 12, 13, 17, 18, 19, 27, 31], "252": [8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 27, 30, 31], "750": [8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 27, 30, 31], "10": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34], "500": [8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 27, 30, 31], "taht": 8, "act": [8, 34], "down_laplacian_list": 8, "up_laplacian_list": 8, "to_cell_complex": [8, 9, 10], "down_laplacian": 8, "up_laplacian": 8, "lin_2": [8, 9, 10, 31], "avg": [8, 9, 27], "n_face": [8, 9, 10, 29, 30], "whole": [8, 9, 10, 13, 17, 18, 19, 20, 22, 23, 27, 29, 30], "averag": [8, 9, 10, 13, 29, 31, 32, 33], "0d": [8, 9, 10, 29, 31], "nan": [8, 9, 10, 15, 29, 30, 31], "two_dimensional_cells_mean": [8, 9, 10, 27, 29, 31], "nanmean": [8, 9, 10, 27, 29, 30, 31, 32], "isnan": [8, 9, 10, 27, 29, 30, 31, 32], "one_dimensional_cells_mean": [8, 9, 10, 27, 29, 31, 32], "zero_dimensional_cells_mean": [8, 9, 10, 27, 29, 31], "loss_fn": [8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 21, 27, 29, 30, 31, 32], "mseloss": [8, 9, 10, 11, 12, 13, 17, 18, 19, 27, 29, 30, 31, 32], "x_2_train": [8, 10, 27, 29, 30], "x_2_test": [8, 10, 27, 29], "up_laplacian_train": 8, "up_laplacian_test": 8, "down_laplacian_train": 8, "down_laplacian_test": 8, "minim": [8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 23, 29], "rapid": [8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 23, 29], "12": [8, 9, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 28, 31, 33], "up_laplcian": 8, "test_loss": [8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 27, 29, 30, 31, 32], "abrah": 8, "anaconda3": [8, 9, 24, 28, 30], "env": [8, 9, 24, 28, 30], "topological_2": 8, "lib": [8, 9, 16, 24, 28, 30], "site": [8, 9, 16, 24, 28, 30], "536": [8, 9, 15], "userwarn": [8, 9, 21, 30, 34], "lead": [8, 9], "incorrect": [8, 9], "due": [8, 9, 28], "ensur": [8, 9], "mse_loss": [8, 9], "reduct": [8, 9, 29], "89": [8, 14, 15, 16, 20, 28], "3527": 8, "81": [8, 13, 14, 15, 20, 28], "9469": 8, "5947": 8, "1082": [8, 15], "3476": 8, "55": [8, 14, 15, 20, 24, 28, 32], "3188": 8, "6493": 8, "0137": [8, 14], "51": [8, 10, 14, 15, 16, 20, 21, 24, 28, 32], "6529": 8, "78": [8, 13, 14, 15, 20, 24, 25, 26, 28, 29, 31, 32, 34], "4377": 8, "77": [8, 13, 14, 15, 20, 24, 27, 28, 31], "9167": 8, "48": [8, 14, 15, 16, 20, 22, 23, 24, 28, 32], "4984": 8, "4454": 8, "0191": 8, "45": [8, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 34], "7851": 8, "14": [8, 14, 15, 16, 17, 20, 21, 22, 23, 24, 28, 29, 33], "96": [8, 9, 14, 15, 16, 20, 28, 29], "6442": [8, 15], "76": [8, 13, 14, 15, 20, 24, 28], "8734": 8, "52": [8, 14, 15, 20, 21, 24, 28, 32], "6675": [8, 15], "2222": 8, "75": [8, 13, 14, 15, 20, 21, 22, 23, 24, 27, 28], "4701": 8, "46": [8, 14, 15, 16, 20, 22, 23, 24, 28, 32], "0780": [8, 15], "74": [8, 14, 15, 20, 24, 28], "7502": 8, "0797": [8, 15], "40": [8, 13, 14, 15, 16, 20, 21, 22, 23, 24, 28, 29, 32], "4300": 8, "73": [8, 14, 15, 20, 24, 28], "4617": 8, "72": [8, 14, 15, 20, 24, 28], "8948": 8, "35": [8, 11, 14, 15, 16, 20, 21, 22, 23, 24, 28], "5483": 8, "3760": 8, "71": [8, 14, 15, 20, 24, 28], "9013": 8, "31": [8, 11, 14, 15, 16, 20, 22, 23, 24, 28], "3371": 8, "agg_": [9, 10, 11, 12, 27], "messg": [9, 11, 12, 17, 18, 19, 24, 25, 31, 34], "incidence_2_t_list": 9, "incidence_2_t": 9, "incidence_matrix": [9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33], "transpos": [9, 27, 30], "boundari": [9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 28, 33], "incidence_2_t_train": 9, "incidence_2_t_test": 9, "low": [9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 23, 24, 25, 26, 28, 29, 30, 31, 34], "4544": 9, "ninamiolan": [9, 28], "tmxtest": 9, "python3": [9, 16, 28, 30], "82": [9, 13, 14, 15, 20, 21, 28], "0496": [9, 15], "4422": [9, 15], "83": [9, 13, 14, 15, 16, 20, 28], "8916": 9, "9388": 9, "49": [9, 14, 15, 16, 20, 22, 23, 24, 28, 32], "7630": 9, "99": [9, 14, 15, 16, 20, 21, 28, 29, 30, 33], "6948": [9, 26], "84": [9, 10, 13, 14, 15, 20, 28], "4177": 9, "39": [9, 14, 15, 16, 20, 21, 22, 23, 24, 28, 30, 32], "5379": [9, 24], "85": [9, 10, 13, 14, 15, 16, 20, 28], "5503": 9, "8946": 9, "6596": 9, "weisfeil": 10, "lehman": 10, "cwn_layer": 10, "cwnlayer": 10, "b_r": [10, 28], "interc": 10, "b_": [10, 27, 28], "incidence_2_list": [10, 29, 30, 32], "adjacency_1_list": 10, "incidence_1_t_list": 10, "incidence_2": [10, 29, 30, 32, 33], "adjacency_1": [10, 30], "incidence_1_t": 10, "hid_channel": 10, "hidden": [10, 11, 12, 14, 16, 17, 26, 33], "proj_0": 10, "proj_1": 10, "proj_2": 10, "neighborhood_1_to_1": 10, "neighborhood_2_to_1": 10, "neighborhood_0_to_1": 10, "elu": 10, "05": [10, 33], "criterion": [10, 15], "adjacency_1_train": 10, "adjacency_1_test": 10, "incidence_2_train": [10, 29], "incidence_2_test": [10, 29], "incidence_1_t_train": 10, "incidence_1_t_test": 10, "106": [10, 15, 20, 28, 29], "5665": 10, "4893": [10, 14], "54": [10, 14, 15, 20, 21, 24, 28, 32], "3770": 10, "0177": 10, "6247": 10, "4964": 10, "allset": [11, 12], "collect": [11, 12, 13, 14, 16, 17, 18, 19, 32], "vertex": [11, 12, 33], "let": [11, 12, 17, 18, 33], "addition": [11, 12, 28], "v_": [11, 12, 17], "multiset": [11, 12], "e_": [11, 12], "set": [11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 26, 28, 33, 34], "rule": [11, 12], "framework": [11, 12], "put": [11, 12, 28], "f_": [11, 12], "permut": [11, 12], "invari": [11, 12], "parametr": [11, 12], "learnt": [11, 12], "25": [11, 14, 15, 16, 20, 21, 22, 23, 24, 28, 33], "allset_lay": 11, "allsetlay": 11, "load_ext": [11, 12, 20, 23, 26], "autoreload": [11, 12, 20, 23, 26], "extens": [11, 23], "alreadi": [11, 23], "reload": [11, 23], "reload_ext": [11, 23], "26": [11, 14, 15, 16, 20, 22, 23, 24, 28], "what": [11, 12, 13, 17, 18, 19, 20, 22, 23, 28, 34], "27": [11, 14, 15, 16, 20, 22, 23, 24, 28, 30], "28": [11, 14, 15, 16, 20, 22, 23, 24, 28], "n_": [11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 26, 28, 29, 32, 34], "amtric": [11, 12, 13, 17, 18, 19], "unsign": [11, 12, 13, 17, 18, 19], "becom": [11, 12, 13, 17, 18, 19, 26], "simplciial": [11, 12, 13, 17, 18, 19], "wise": [11, 12, 13, 17, 18, 19], "29": [11, 14, 15, 16, 20, 22, 23, 24, 28], "hg_list": [11, 12, 13, 17, 18, 19, 20, 22, 23], "incidence_1_list": [11, 12, 13, 17, 18, 19, 20, 22, 23, 29, 30, 32], "sign": [11, 12, 13, 15, 17, 18, 19, 30, 33, 34], "hg": [11, 12, 13, 17, 18, 19, 20, 22, 23], "to_hypergraph": [11, 12, 13, 15, 17, 18, 19, 20, 22, 23], "30": [11, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33], "1250": [11, 12, 15, 17, 18], "channels_edg": [11, 13, 15, 17, 18, 19, 20, 23], "channels_nod": [11, 13, 15, 17, 18, 19, 20, 23, 24, 25, 26, 28, 29, 32], "allsetnn": 11, "in_dim": [11, 12], "hid_dim": [11, 12], "out_dim": [11, 12, 17, 22], "input_dropout": [11, 12], "mlp_num_lay": [11, 12], "mlp": [11, 12, 22, 29], "mlp_norm": [11, 12], "hidden_channel": [11, 12, 26], "mlp_activ": 11, "mlp_dropout": [11, 12], "cidx": 11, "min": 11, "reversed_edge_index": 11, "pooled_x": [11, 12, 13, 17, 18, 19, 20, 23], "33": [11, 14, 15, 16, 20, 22, 23, 24, 28, 34], "34": [11, 14, 15, 16, 20, 22, 23, 24, 25, 26, 28, 29, 30, 32, 34], "incidence_1_train": [11, 12, 17, 18, 19, 20, 22, 23, 29], "incidence_1_test": [11, 12, 17, 18, 19, 20, 22, 23, 29], "to_edge_index": [11, 12, 17, 18], "274": [11, 12, 15, 18, 19, 20], "8233": 11, "529": [11, 12, 15, 17, 18, 19], "0000": [11, 12, 15, 17, 18, 24, 25, 28, 29, 32], "6125": [11, 12, 18], "repo": [12, 16, 18], "ln": 12, "rise": 12, "so": [12, 24, 25, 26, 28, 29, 32, 33, 34], "dive": 12, "iter": 12, "Their": 12, "dimension": [12, 33], "omega": 12, "overset": [12, 26], "delta": 12, "mathbin": 12, "vert": [12, 18, 33], "mh": 12, "ba": 12, "2016": 12, "hf_": 12, "multihead": 12, "vaswani": 12, "2017": [12, 24], "perceptron": 12, "row": 12, "allset_transformer_lay": 12, "allsettransformerlay": 12, "q_n": 12, "9018": 12, "dhgcn_layer": 13, "dhgcnlayer": 13, "100": [13, 14, 15, 16, 20, 21, 22, 23, 27, 28, 29, 30, 31, 33], "dir": 13, "dhgcn": 13, "dynam": 13, "global": [13, 17, 18, 19, 20, 22, 23], "node_channel": [13, 30], "86": [13, 14, 15, 16, 20, 27, 28, 31], "87": [13, 14, 15, 20, 28], "88": [13, 14, 15, 20, 28, 29], "8821578": 13, "6946": 13, "36521": 13, "6562": 13, "17477": 13, "7685": 13, "212": [13, 15, 20], "8590": 13, "152": [13, 15, 20, 28], "9723": 13, "0999": 13, "177": [13, 15, 20, 28], "0583": [13, 15], "163": [13, 15, 20, 28], "9508": 13, "202": [13, 15, 20], "9814": 13, "22": [13, 14, 15, 16, 20, 22, 23, 24, 28], "2991": 13, "livi": 14, "cora": [14, 21], "2708": 14, "academ": [14, 16], "5429": 14, "citat": [14, 21], "categori": [14, 16], "case_bas": 14, "genetic_algorithm": 14, "neural_network": 14, "probabilistic_method": 14, "reinforcement_learn": 14, "rule_learn": 14, "theori": 14, "1433": [14, 15], "stand": [14, 16], "uniqu": [14, 15, 16, 30], "word": [14, 16], "presenc": [14, 16], "planetoid": 14, "metric": [14, 15, 16], "accuracy_scor": [14, 16], "hmpnn_layer": 14, "hmpnnlayer": 14, "24": [14, 15, 16, 20, 22, 23, 24, 28], "download": [14, 16, 21, 23], "val": [14, 20, 22, 23, 33], "below": [14, 22, 33], "sparse_coo_tensor": [14, 16], "hidden_featur": [14, 16], "tupl": [14, 29, 33], "gradual": 14, "reduc": 14, "last": [14, 28, 32, 33], "adjacency_dropout_r": 14, "rate": [14, 16], "regular_dropout_r": 14, "regular": 14, "to_hidden_linear": [14, 16], "sequenti": [14, 16, 22], "adjacency_dropout": 14, "updating_dropout": 14, "to_categories_linear": [14, 16], "n_hyperedg": [14, 16], "b1": [14, 15, 24, 25, 28, 29, 30, 32], "y_pred": [14, 16, 21, 24, 25, 26, 28, 29, 32, 34], "logit": [14, 15, 16, 21, 24, 25, 28, 29, 32, 33], "hyperparamet": [14, 16, 21], "manual_se": [14, 33], "41": [14, 15, 16, 20, 22, 23, 24, 28, 32], "256": [14, 15, 20], "01": [14, 21, 24, 29, 32, 33], "train_y_tru": [14, 16], "train_mask": [14, 16], "val_y_tru": 14, "val_mask": 14, "initial_x_1": 14, "zeros_lik": 14, "y_pred_logit": [14, 16], "train_loss": [14, 33], "eval": [14, 16, 20, 21, 22, 23, 33], "val_loss": [14, 33], "val_acc": [14, 33], "acc": [14, 16], "2f": [14, 16], "1079": [14, 15], "1436": [14, 15], "0234": 14, "15": [14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 33], "1016": [14, 15], "9800": 14, "0681": [14, 15], "9504": 14, "18": [14, 15, 16, 20, 21, 22, 23, 24, 28], "0389": [14, 15], "9194": 14, "21": [14, 15, 16, 20, 22, 23, 24, 28, 29, 31], "9241": 14, "19": [14, 15, 16, 20, 22, 23, 24, 28, 30, 33], "9917": 14, "8917": 14, "9729": 14, "8710": 14, "23": [14, 15, 16, 20, 22, 23, 24, 28], "9556": 14, "8574": 14, "9402": 14, "8646": 14, "9265": 14, "8540": 14, "9136": 14, "8430": 14, "9012": 14, "8336": 14, "8886": 14, "8405": 14, "8775": 14, "8264": 14, "8668": 14, "8065": 14, "8562": 14, "37": [14, 15, 16, 20, 21, 22, 23, 24, 28], "8158": 14, "8456": 14, "7957": 14, "44": [14, 15, 16, 20, 22, 23, 24, 28, 32], "8346": 14, "8028": 14, "8249": 14, "20": [14, 15, 16, 20, 21, 22, 23, 24, 28, 29, 33], "7882": 14, "8156": 14, "42": [14, 15, 16, 20, 22, 23, 24, 28, 32], "7912": 14, "8070": 14, "7610": 14, "7987": 14, "7617": 14, "47": [14, 15, 16, 20, 22, 23, 24, 28, 32], "7905": 14, "7596": 14, "7830": 14, "7391": 14, "7740": 14, "7315": 14, "7655": 14, "7365": 14, "7565": 14, "43": [14, 15, 16, 20, 22, 23, 24, 28, 30, 32], "7184": 14, "7459": 14, "7085": 14, "7367": 14, "6815": [14, 15], "7279": 14, "6673": 14, "50": [14, 15, 16, 20, 21, 22, 23, 24, 28, 32], "7178": 14, "6846": 14, "7077": 14, "6483": 14, "7000": [14, 28], "6436": 14, "6971": 14, "6353": 14, "6991": 14, "6336": 14, "6982": 14, "5938": 14, "60": [14, 15, 20, 24, 28, 33], "6980": 14, "5886": 14, "56": [14, 15, 20, 24, 28, 32], "6979": 14, "5974": 14, "6881": [14, 15], "5600": 14, "6694": 14, "5445": 14, "6513": 14, "5501": 14, "6308": 14, "5397": [14, 24], "6141": 14, "5096": 14, "6020": 14, "4992": 14, "5915": [14, 15], "5020": 14, "58": [14, 15, 20, 24, 28], "5829": 14, "4710": 14, "5747": 14, "4608": 14, "67": [14, 15, 16, 20, 24, 28], "5703": 14, "4341": 14, "62": [14, 15, 20, 24, 28], "5632": 14, "4428": 14, "66": [14, 15, 16, 20, 24, 28], "5630": 14, "4209": 14, "5502": 14, "4151": 14, "63": [14, 15, 20, 28], "5303": 14, "53": [14, 15, 20, 21, 24, 28, 32], "4090": 14, "5051": 14, "4021": 14, "3847": 14, "65": [14, 15, 20, 24, 28], "4842": 14, "3907": 14, "61": [14, 15, 20, 24, 28, 29], "4849": 14, "57": [14, 15, 16, 20, 24, 28, 32], "3434": 14, "70": [14, 15, 20, 24, 28], "4866": 14, "3253": 14, "69": [14, 15, 20, 24, 28], "4864": 14, "3380": 14, "4896": 14, "2933": 14, "4921": 14, "3124": 14, "68": [14, 15, 20, 24, 28], "4948": 14, "3091": 14, "4931": 14, "2768": 14, "4881": 14, "2749": 14, "4827": [14, 15], "2740": 14, "4833": 14, "2773": 14, "4744": 14, "2430": 14, "4646": 14, "4648": 14, "1958": [14, 15], "4734": 14, "1895": [14, 15], "4748": 14, "2008": 14, "4760": 14, "1573": [14, 15], "4385": 14, "1751": [14, 15], "4242": 14, "1889": [14, 15], "4183": 14, "1762": [14, 15], "4250": 14, "1737": [14, 15], "4471": 14, "1242": [14, 15], "4559": 14, "0648": [14, 15], "4498": 14, "0717": [14, 15], "4506": 14, "0568": [14, 15, 16], "4410": 14, "0650": [14, 15, 24], "4375": [14, 34], "0475": [14, 15], "4441": 14, "0293": [14, 28], "4450": 14, "0494": [14, 15], "4622": 14, "0200": 14, "4609": 14, "0358": [14, 15], "4645": 14, "9877": 14, "0173": 14, "4788": 14, "9744": 14, "4970": 14, "90": [14, 15, 20, 28, 29], "9497": 14, "4981": 14, "91": [14, 15, 16, 20, 28, 29], "9345": 14, "4736": 14, "92": [14, 15, 20, 28, 29], "9636": 14, "4339": 14, "93": [14, 15, 16, 20, 21, 28, 29, 30], "9197": 14, "4162": 14, "94": [14, 15, 16, 20, 28, 29, 32], "8984": 14, "3813": 14, "95": [14, 15, 16, 20, 28, 29], "8895": 14, "3547": 14, "9048": 14, "3499": 14, "97": [14, 15, 16, 20, 28, 29, 30], "8737": 14, "3502": [14, 16], "98": [14, 15, 16, 20, 27, 28, 29], "9479": 14, "3518": 14, "8906": 14, "3639": 14, "8589": 14, "3789": 14, "against": [14, 16], "test_y_tru": [14, 16], "test_mask": [14, 16], "2982": 14, "karateclub": [15, 24, 25, 26, 28, 29, 34], "w": [15, 17, 26], "hnhn_layer": 15, "hnhnlayer": [15, 16], "matplotlib": [15, 16, 33], "pyplot": [15, 16, 33], "plt": [15, 16, 33], "www": [15, 23, 24, 25, 26, 28, 29], "jstor": [15, 24, 25, 26, 28, 29], "stabl": [15, 16, 24, 25, 26, 28, 29], "3629752": [15, 24, 25, 26, 28, 29], "singular": [15, 24, 25, 26, 28, 29], "social": [15, 24, 25, 26, 28, 29], "group": [15, 24, 25, 26, 28, 29], "dataset_sim": 15, "karate_club": [15, 24, 25, 26, 28, 29, 32, 34], "complex_typ": [15, 24, 25, 26, 28, 29, 32, 34], "dataset_hyp": 15, "santii": [15, 24, 25, 34], "classifi": [15, 16, 21], "channels_": 15, "hot": [15, 24, 25, 26, 29, 31, 34], "get_simplex_attribut": [15, 24, 25, 26, 28, 29, 32, 34], "n_class": [15, 28, 30], "y_1h": 15, "ey": [15, 21, 24, 26, 28, 34], "astyp": 15, "stratifi": 15, "ind_train": 15, "ind_test": 15, "arang": [15, 34], "random_st": 15, "float32": [15, 19, 21], "int32": 15, "fraction": 15, "hnhnnetwork": 15, "multiclass": 15, "hypernod": 15, "softmax": [15, 21, 24, 25, 26, 32, 33, 34], "1e": [15, 20, 23, 26, 33], "2000": 15, "get_accuraci": 15, "lambda": 15, "yhat": 15, "ytrue": 15, "full": 15, "y_hat_cl": 15, "nloss": 15, "ntrain_acc": 15, "7157": 15, "5000": [15, 28, 29], "7135": 15, "7113": 15, "7093": 15, "7074": 15, "7056": 15, "7039": [15, 25], "7024": 15, "7010": 15, "6997": 15, "6985": 15, "6975": 15, "6966": 15, "6958": 15, "6951": 15, "6945": 15, "6940": 15, "6936": 15, "6933": 15, "6931": 15, "6930": 15, "6929": 15, "6928": 15, "6932": 15, "6927": 15, "6926": 15, "6925": 15, "6924": 15, "6429": 15, "6923": 15, "6922": 15, "6921": 15, "6920": 15, "6919": 15, "8571": 15, "9643": 15, "6918": 15, "7500": [15, 24, 28, 29], "6917": 15, "5714": 15, "5357": 15, "6916": 15, "6915": 15, "6914": 15, "6913": 15, "6912": 15, "6911": 15, "6910": 15, "6909": 15, "6908": 15, "6667": [15, 28, 29], "101": [15, 20, 28, 29, 32], "6907": 15, "102": [15, 20, 28, 29], "103": [15, 20, 28, 29, 30], "6906": 15, "104": [15, 20, 28, 29, 30], "105": [15, 20, 28, 29, 30, 32], "6905": 15, "107": [15, 20, 28, 29, 31], "6904": 15, "108": [15, 20, 21, 28, 29], "109": [15, 20, 21, 28], "6903": 15, "110": [15, 20, 21, 28], "6902": 15, "111": [15, 20, 21, 28], "112": [15, 20, 28], "6901": 15, "113": [15, 20, 28, 30], "114": [15, 20, 28], "6900": 15, "115": [15, 20, 28], "6899": 15, "116": [15, 20, 28], "117": [15, 20, 27, 28], "6898": 15, "118": [15, 20, 28], "6897": 15, "119": [15, 20, 28], "120": [15, 20, 28], "6896": 15, "121": [15, 20, 21, 28], "6895": 15, "122": [15, 20, 28], "6894": 15, "123": [15, 20, 28, 32], "124": [15, 20, 27, 28], "6893": 15, "125": [15, 20, 28], "6892": 15, "126": [15, 20, 28], "6891": [15, 28], "127": [15, 20, 28], "6890": 15, "129": [15, 20, 28], "6889": 15, "130": [15, 20, 28], "6888": 15, "131": [15, 20, 27, 28], "6887": 15, "132": [15, 20, 27, 28], "6886": 15, "133": [15, 20, 21, 27, 28, 31], "134": [15, 20, 27, 28], "6885": 15, "135": [15, 20, 27, 28], "6884": 15, "136": [15, 20, 27, 28], "6883": 15, "137": [15, 20, 27, 28], "6882": 15, "138": [15, 20, 27, 28], "139": [15, 20, 27, 28, 29], "6880": 15, "140": [15, 20, 21, 28], "6879": [15, 24], "141": [15, 20, 28], "6878": 15, "142": [15, 20, 27, 28], "6877": 15, "143": [15, 20, 24, 27, 28], "6876": 15, "144": [15, 20, 28], "6875": [15, 20], "145": [15, 20, 28], "6874": 15, "146": [15, 20, 28], "6873": 15, "147": [15, 20, 28], "6871": 15, "148": [15, 20, 28], "6870": 15, "149": [15, 20, 28], "6869": 15, "150": [15, 20, 28, 33], "6868": 15, "151": [15, 20, 28], "6867": 15, "6865": 15, "153": [15, 20, 28], "6864": 15, "154": [15, 20, 28], "6863": 15, "155": [15, 20, 28], "6861": 15, "156": [15, 20, 28], "6860": 15, "157": [15, 20, 28], "6859": 15, "158": [15, 20, 28], "6857": 15, "159": [15, 20, 28], "6856": 15, "160": [15, 20, 28], "6855": 15, "161": [15, 20, 28], "6853": 15, "162": [15, 20, 28], "6852": 15, "6850": 15, "164": [15, 20, 28, 29], "6849": 15, "165": [15, 20, 28], "6847": 15, "166": [15, 20, 28], "6845": 15, "167": [15, 20, 28], "6844": 15, "168": [15, 20, 28], "6842": 15, "169": [15, 20, 28], "6840": 15, "170": [15, 20, 28], "6839": 15, "171": [15, 20, 28], "6837": 15, "172": [15, 20, 28], "6835": 15, "173": [15, 20, 28], "6833": 15, "174": [15, 20, 28], "6831": 15, "175": [15, 20, 28], "6829": [15, 26], "176": [15, 20, 28], "6827": 15, "6825": 15, "178": [15, 20, 28], "6823": 15, "179": [15, 20, 28], "6821": 15, "180": [15, 20, 28, 32], "6819": 15, "181": [15, 20, 28], "6817": 15, "182": [15, 20, 27, 28], "183": [15, 20, 28], "6813": 15, "184": [15, 20, 28], "6810": 15, "185": [15, 20, 21, 28], "6808": 15, "186": [15, 20, 28], "6806": 15, "187": [15, 20, 28], "6803": 15, "6801": 15, "189": [15, 20, 28], "6799": 15, "190": [15, 20, 28], "6796": 15, "191": [15, 20, 28], "6793": 15, "192": [15, 20, 28], "6791": 15, "193": [15, 20, 28], "6788": 15, "194": [15, 20, 28], "6785": 15, "195": [15, 20, 28], "6783": 15, "196": [15, 20, 28], "6780": 15, "197": [15, 20, 28], "6777": 15, "198": [15, 20, 28, 31], "6774": 15, "199": [15, 20, 21, 28], "6771": 15, "200": [15, 16, 20, 21, 28], "6768": 15, "201": [15, 20], "6765": 15, "6762": 15, "203": [15, 20], "6758": 15, "204": [15, 20], "6755": 15, "205": [15, 20], "6752": 15, "206": [15, 20], "6748": 15, "207": [15, 20], "6745": 15, "208": [15, 20], "6741": 15, "209": [15, 20], "6738": 15, "210": [15, 20, 27, 29], "6734": 15, "211": [15, 20, 31], "6730": 15, "6726": 15, "213": [15, 20, 31], "6723": 15, "214": [15, 20], "6719": 15, "215": [15, 20], "6715": 15, "216": [15, 20], "6710": 15, "217": [15, 20], "6706": 15, "218": [15, 20], "6702": 15, "6786": 15, "219": [15, 20], "6698": [15, 26], "220": [15, 20], "6693": 15, "221": [15, 20], "6689": 15, "222": [15, 20], "6684": 15, "223": [15, 20], "6679": 15, "224": [15, 20], "225": [15, 20], "6670": 15, "226": [15, 20], "6665": 15, "227": [15, 20], "6660": 15, "228": [15, 20], "6655": 15, "229": [15, 20], "6649": 15, "230": [15, 20], "6644": 15, "231": [15, 20], "6639": 15, "232": [15, 20], "6633": 15, "233": [15, 20], "6628": 15, "234": [15, 20], "6622": 15, "235": [15, 20], "6616": 15, "236": [15, 20], "6610": 15, "237": [15, 20], "6604": 15, "238": [15, 20], "6598": 15, "239": [15, 20], "6592": 15, "240": [15, 20], "6585": 15, "7143": 15, "241": [15, 20], "6579": 15, "242": [15, 20], "6572": 15, "243": [15, 20], "6566": 15, "244": [15, 20], "6559": 15, "245": [15, 20], "6552": 15, "246": [15, 20], "6545": 15, "247": [15, 20], "6538": 15, "248": [15, 20], "6531": 15, "249": [15, 20], "6523": 15, "250": [15, 20], "6516": 15, "8214": 15, "251": [15, 20], "6508": 15, "6500": 15, "253": [15, 20], "6492": 15, "254": [15, 20], "6484": 15, "255": [15, 20], "6476": 15, "6468": 15, "257": [15, 20], "6459": 15, "258": [15, 20], "6451": 15, "259": [15, 20], "260": [15, 20], "6433": 15, "261": [15, 20], "6424": 15, "262": [15, 20], "6415": 15, "263": [15, 20], "6406": 15, "264": [15, 20], "6397": 15, "265": [15, 20], "6387": 15, "266": [15, 20], "6378": 15, "267": [15, 20], "6368": 15, "268": [15, 20], "6358": 15, "269": [15, 20], "6348": 15, "270": [15, 20, 24], "6337": 15, "271": [15, 20, 31], "6327": 15, "272": [15, 20], "6317": 15, "273": [15, 20], "6306": 15, "6295": 15, "275": [15, 18, 20], "6284": [15, 28], "276": [15, 20], "6273": 15, "277": [15, 20], "6262": 15, "278": [15, 17, 20], "6250": 15, "279": [15, 20], "6239": 15, "280": [15, 20], "6227": 15, "281": [15, 17, 20], "6215": 15, "282": [15, 17, 20], "6203": 15, "283": [15, 20], "6191": 15, "284": [15, 20], "6178": 15, "285": [15, 20], "6166": 15, "286": [15, 20], "6153": 15, "287": [15, 20], "6140": 15, "288": [15, 20], "6127": 15, "289": [15, 20], "6114": 15, "290": [15, 20], "6101": 15, "291": [15, 20], "6088": 15, "292": [15, 20], "6074": 15, "293": [15, 20], "6060": 15, "294": [15, 20], "6046": [15, 16], "295": [15, 20], "6032": 15, "296": [15, 20, 29], "6018": 15, "297": [15, 20], "6004": 15, "298": [15, 20], "5989": 15, "299": [15, 20], "5975": 15, "300": [15, 20], "5960": 15, "301": [15, 20], "5945": 15, "302": [15, 20, 21], "5930": 15, "303": [15, 20], "304": [15, 20], "5900": 15, "305": [15, 20], "5884": 15, "306": [15, 20], "5868": 15, "307": [15, 20, 31], "5853": 15, "308": [15, 20], "5837": 15, "309": [15, 20], "5821": 15, "310": [15, 20, 27], "5805": [15, 24], "311": [15, 20], "5788": 15, "312": [15, 20], "5772": 15, "313": [15, 20], "314": [15, 20], "5739": 15, "315": [15, 20], "5722": 15, "316": [15, 20], "5705": 15, "317": [15, 20], "5688": 15, "318": [15, 20], "5671": 15, "319": [15, 20], "5653": 15, "320": [15, 20], "5636": 15, "321": [15, 20], "5618": 15, "322": [15, 20], "5601": 15, "323": [15, 20], "5583": 15, "324": [15, 20], "325": [15, 20], "5547": 15, "326": [15, 20], "5529": 15, "327": [15, 20], "5511": 15, "328": [15, 20], "5492": 15, "329": [15, 20], "5474": 15, "330": [15, 20], "5455": 15, "331": [15, 20], "5437": 15, "332": [15, 20], "5418": 15, "333": [15, 20], "5399": 15, "334": [15, 20], "5381": 15, "335": [15, 20], "5362": [15, 24], "336": [15, 20], "5343": 15, "337": [15, 20], "5323": [15, 34], "338": [15, 20], "5304": 15, "339": [15, 20], "5285": 15, "340": [15, 20], "5266": 15, "8929": 15, "341": [15, 20], "5246": [15, 24], "342": [15, 20], "5227": 15, "343": [15, 20], "5207": 15, "344": [15, 20], "5188": [15, 24], "345": [15, 20], "5168": 15, "346": [15, 20], "5148": 15, "347": [15, 20], "5129": 15, "348": [15, 20], "5109": 15, "349": [15, 20], "5089": 15, "350": [15, 20], "5069": 15, "9286": 15, "351": [15, 20], "5049": 15, "352": [15, 20], "5029": 15, "353": [15, 20], "5009": 15, "354": [15, 20], "4989": 15, "355": [15, 20], "4969": 15, "356": [15, 20], "4949": 15, "357": [15, 20], "4928": 15, "358": [15, 20], "4908": 15, "359": [15, 20], "4888": 15, "360": [15, 20], "4868": 15, "361": [15, 20], "4847": 15, "362": [15, 20], "363": [15, 20], "4807": 15, "364": [15, 20], "4787": 15, "365": [15, 20], "4766": 15, "366": [15, 20], "4746": 15, "367": [15, 20], "4726": 15, "368": [15, 20], "4705": 15, "369": [15, 20], "4685": 15, "370": [15, 20], "4665": 15, "371": [15, 20], "4644": 15, "372": [15, 20], "4624": 15, "373": [15, 20], "4604": 15, "374": [15, 20], "4583": 15, "375": [15, 20], "4563": 15, "376": [15, 20], "4543": 15, "377": [15, 20], "4523": 15, "378": [15, 20], "4503": 15, "379": [15, 20], "4482": 15, "380": [15, 20], "4462": 15, "381": [15, 20], "4442": 15, "382": [15, 20], "383": [15, 20], "4402": 15, "384": [15, 20], "4382": 15, "385": [15, 20], "4362": 15, "386": [15, 20], "4342": 15, "387": [15, 20], "4322": 15, "388": [15, 20], "4302": 15, "389": [15, 20], "4282": 15, "390": [15, 20], "4262": 15, "391": [15, 20], "4243": 15, "392": [15, 20], "4223": 15, "393": [15, 20], "4203": 15, "394": [15, 20], "4184": 15, "395": [15, 20, 21], "4164": 15, "396": [15, 20], "4145": 15, "397": [15, 20], "4125": 15, "398": [15, 20], "4106": 15, "399": [15, 20], "4086": 15, "400": [15, 16, 20], "4067": 15, "401": [15, 20], "4048": 15, "402": [15, 20], "4029": 15, "403": [15, 20], "4010": 15, "404": [15, 20], "3991": 15, "405": [15, 20], "3972": 15, "406": [15, 20], "3953": 15, "407": [15, 20], "3934": 15, "408": [15, 20], "3915": 15, "409": [15, 20], "3897": 15, "410": [15, 20], "3878": 15, "411": [15, 20, 32], "3859": 15, "412": [15, 20], "3841": 15, "413": [15, 20], "3823": 15, "3804": 15, "415": [15, 20], "3786": 15, "416": [15, 20], "3768": 15, "417": [15, 20], "3750": [15, 17, 34], "418": [15, 20], "3732": 15, "419": [15, 20], "3714": 15, "420": [15, 20], "3696": 15, "421": [15, 20], "3678": 15, "422": [15, 20], "3661": 15, "423": [15, 20], "3643": 15, "424": [15, 20], "3626": 15, "425": [15, 20], "3608": 15, "426": [15, 20], "3591": 15, "427": [15, 20], "3573": 15, "428": [15, 20], "3556": 15, "429": [15, 20], "3539": 15, "430": [15, 20], "3522": 15, "431": [15, 20], "3505": 15, "432": [15, 20], "3488": 15, "433": [15, 20], "3472": 15, "434": [15, 20], "3455": 15, "435": [15, 20], "3438": 15, "436": [15, 20], "3422": 15, "437": [15, 20], "3406": 15, "438": [15, 20], "3389": 15, "439": [15, 20], "3373": 15, "440": [15, 20], "3357": 15, "441": [15, 20], "3341": 15, "442": [15, 20], "3325": 15, "443": [15, 20, 21], "3309": 15, "444": [15, 20], "3293": 15, "445": [15, 20], "3278": 15, "446": [15, 20], "3262": 15, "447": [15, 20], "3247": 15, "448": [15, 20], "3231": 15, "449": [15, 20], "3216": 15, "450": [15, 20], "3201": 15, "451": [15, 20], "3185": 15, "452": [15, 20], "3170": 15, "453": [15, 20], "3155": 15, "454": [15, 20], "3140": 15, "455": [15, 20], "3126": 15, "456": [15, 20], "3111": 15, "457": [15, 20], "3096": 15, "458": [15, 20], "3082": 15, "459": [15, 20], "3067": 15, "460": [15, 20], "3053": 15, "461": [15, 20], "3039": [15, 32], "462": [15, 20], "3025": 15, "463": [15, 20], "3011": 15, "464": [15, 20], "2997": 15, "465": [15, 20], "2983": 15, "466": [15, 20], "2969": 15, "467": [15, 20], "2955": 15, "468": [15, 20], "2941": 15, "469": [15, 20], "2928": 15, "470": [15, 20], "2914": [15, 16], "471": [15, 20], "2901": 15, "472": [15, 20], "2888": 15, "473": [15, 20], "2874": 15, "474": [15, 20], "2861": 15, "475": [15, 20], "2848": 15, "476": [15, 20], "2835": 15, "477": [15, 20], "2822": 15, "478": [15, 20], "2810": 15, "479": [15, 20], "2797": 15, "480": [15, 20], "2784": 15, "481": [15, 20], "2772": 15, "482": [15, 20], "2759": 15, "483": [15, 20], "2747": 15, "484": [15, 20], "2735": 15, "485": [15, 20], "2722": 15, "486": [15, 20], "2710": 15, "487": [15, 20], "2698": 15, "488": [15, 20], "2686": 15, "489": [15, 20, 31], "2674": 15, "490": [15, 20], "2662": 15, "491": [15, 20], "2651": 15, "492": [15, 20], "2639": 15, "493": [15, 20], "2627": 15, "494": [15, 20], "2616": 15, "495": [15, 20], "2604": 15, "496": [15, 20], "2593": 15, "497": [15, 20], "2582": 15, "498": [15, 20], "2571": 15, "499": [15, 20], "2559": 15, "2548": [15, 31], "501": 15, "2537": 15, "502": 15, "2526": 15, "503": 15, "2516": 15, "504": 15, "2505": 15, "505": 15, "2494": 15, "506": 15, "2484": 15, "507": 15, "2473": 15, "508": 15, "2463": 15, "509": 15, "2452": [15, 16], "510": 15, "2442": 15, "511": 15, "2432": 15, "512": 15, "2421": 15, "513": 15, "2411": 15, "514": 15, "2401": 15, "515": 15, "2391": 15, "516": 15, "2381": 15, "517": 15, "2371": 15, "518": 15, "2362": 15, "519": 15, "2352": 15, "520": 15, "2342": 15, "521": 15, "2333": 15, "522": 15, "2323": 15, "523": 15, "2314": 15, "524": 15, "525": 15, "2295": 15, "526": 15, "2286": 15, "527": 15, "2276": 15, "528": 15, "2267": 15, "2258": 15, "530": 15, "2249": 15, "531": 15, "2240": 15, "532": 15, "2231": [15, 16], "533": 15, "2223": 15, "534": 15, "2214": 15, "535": 15, "2205": 15, "2196": 15, "537": 15, "2188": 15, "538": 15, "2179": 15, "539": 15, "2171": 15, "540": 15, "2162": 15, "541": 15, "2154": 15, "542": 15, "2146": 15, "543": 15, "2137": 15, "544": 15, "2129": 15, "545": 15, "2121": 15, "546": [15, 30], "2113": 15, "547": 15, "2105": 15, "548": 15, "2097": 15, "549": 15, "2089": 15, "550": 15, "2081": 15, "551": 15, "2073": 15, "552": 15, "2066": 15, "553": 15, "2058": 15, "554": 15, "2050": 15, "555": 15, "2043": 15, "556": 15, "2035": 15, "557": 15, "2028": 15, "558": 15, "559": 15, "2013": 15, "560": 15, "2005": 15, "561": 15, "1998": 15, "562": 15, "1991": 15, "563": 15, "1983": 15, "564": 15, "1976": 15, "565": 15, "1969": 15, "566": 15, "1962": [15, 24], "567": 15, "1955": 15, "568": 15, "1948": 15, "569": 15, "1941": 15, "570": 15, "1934": 15, "571": 15, "1927": 15, "572": 15, "1921": 15, "573": 15, "1914": 15, "574": 15, "1907": 15, "575": 15, "1900": 15, "576": 15, "1894": 15, "577": 15, "1887": 15, "578": 15, "1881": 15, "579": 15, "1874": 15, "580": 15, "1868": 15, "581": 15, "1861": 15, "582": 15, "1855": 15, "583": 15, "1849": 15, "584": 15, "1842": 15, "585": 15, "1836": [15, 24], "586": 15, "1830": 15, "587": 15, "1824": 15, "588": 15, "1818": 15, "589": 15, "1811": 15, "590": 15, "1805": 15, "591": 15, "1799": 15, "592": 15, "1793": 15, "593": 15, "1788": 15, "594": 15, "1782": 15, "595": 15, "1776": 15, "596": 15, "1770": 15, "597": 15, "1764": 15, "598": 15, "1758": 15, "599": 15, "1753": 15, "600": 15, "1747": 15, "601": 15, "1741": 15, "602": 15, "1736": 15, "603": 15, "1730": [15, 24], "604": 15, "1725": [15, 24], "605": 15, "1719": 15, "606": 15, "1714": 15, "607": 15, "1708": 15, "608": 15, "1703": 15, "609": 15, "1697": 15, "610": 15, "1692": 15, "611": 15, "1687": 15, "612": 15, "1682": 15, "613": [15, 33], "1676": 15, "614": 15, "1671": 15, "615": 15, "1666": 15, "616": 15, "1661": 15, "617": 15, "1656": 15, "618": 15, "1651": 15, "619": 15, "1646": 15, "620": 15, "1640": 15, "621": 15, "1636": 15, "622": 15, "1631": 15, "623": 15, "1626": 15, "624": 15, "1621": 15, "625": [15, 20], "1616": 15, "626": 15, "1611": 15, "627": 15, "1606": 15, "628": 15, "1601": 15, "629": 15, "1597": 15, "630": 15, "1592": 15, "631": 15, "1587": 15, "632": 15, "1583": [15, 29], "633": 15, "1578": 15, "634": 15, "635": 15, "1569": 15, "636": 15, "1564": 15, "637": 15, "1560": [15, 24], "638": 15, "1555": 15, "639": 15, "1551": 15, "640": 15, "1546": 15, "641": 15, "1542": 15, "642": 15, "1537": 15, "643": 15, "1533": 15, "644": 15, "1529": 15, "645": 15, "1524": 15, "646": 15, "1520": 15, "647": 15, "1516": [15, 28], "648": 15, "1511": [15, 24], "649": 15, "1507": 15, "650": 15, "1503": 15, "651": 15, "1499": 15, "652": 15, "1495": [15, 24], "653": 15, "1491": 15, "654": 15, "1487": [15, 24], "655": 15, "1482": 15, "656": 15, "1478": 15, "657": 15, "1474": [15, 24], "658": 15, "1470": 15, "659": 15, "1466": 15, "660": 15, "1462": 15, "661": 15, "1458": 15, "662": 15, "1454": 15, "663": 15, "1451": 15, "664": 15, "1447": 15, "665": 15, "1443": 15, "666": 15, "1439": 15, "667": 15, "1435": 15, "668": 15, "1431": 15, "669": 15, "1428": 15, "670": 15, "1424": 15, "671": 15, "1420": 15, "672": 15, "1416": 15, "673": 15, "1413": 15, "674": 15, "1409": 15, "675": 15, "1405": 15, "676": 15, "1402": 15, "677": 15, "1398": 15, "678": 15, "1395": 15, "679": 15, "1391": 15, "680": 15, "1387": 15, "681": 15, "1384": 15, "682": 15, "1380": [15, 24, 32], "683": 15, "1377": 15, "684": 15, "1373": 15, "685": 15, "1370": 15, "686": 15, "1367": 15, "687": 15, "1363": 15, "688": 15, "1360": 15, "689": 15, "1356": [15, 24], "690": 15, "1353": 15, "691": 15, "1350": 15, "692": 15, "1346": 15, "693": 15, "1343": [15, 24], "694": 15, "1340": 15, "695": 15, "1336": 15, "696": 15, "1333": 15, "697": 15, "1330": 15, "698": 15, "1327": 15, "699": 15, "1323": 15, "700": 15, "1320": 15, "701": 15, "1317": 15, "702": 15, "1314": 15, "703": 15, "1311": 15, "704": 15, "1308": 15, "705": 15, "1304": 15, "706": 15, "1301": 15, "707": 15, "1298": 15, "708": 15, "1295": 15, "709": 15, "1292": 15, "710": 15, "1289": 15, "711": 15, "1286": 15, "712": 15, "1283": [15, 28], "713": 15, "1280": 15, "714": 15, "1277": 15, "715": 15, "1274": 15, "716": 15, "1271": 15, "717": 15, "1268": 15, "718": 15, "1265": 15, "719": 15, "1263": 15, "720": 15, "1260": 15, "721": 15, "1257": [15, 28], "722": 15, "1254": 15, "723": 15, "1251": 15, "724": 15, "1248": 15, "725": 15, "1245": 15, "726": 15, "1243": 15, "727": 15, "1240": 15, "728": 15, "1237": 15, "729": 15, "1234": 15, "730": 15, "1232": 15, "731": 15, "1229": 15, "732": 15, "1226": 15, "733": 15, "1223": 15, "734": 15, "1221": 15, "735": 15, "1218": 15, "736": 15, "1215": 15, "737": 15, "1213": 15, "738": 15, "1210": 15, "739": 15, "1207": 15, "740": 15, "1205": 15, "741": 15, "1202": 15, "742": 15, "1200": [15, 33], "743": 15, "1197": 15, "744": 15, "1194": 15, "745": 15, "1192": 15, "746": 15, "1189": 15, "747": 15, "1187": 15, "748": 15, "1184": 15, "749": 15, "1182": 15, "1179": [15, 24], "751": 15, "1177": 15, "752": 15, "1174": 15, "753": 15, "1172": 15, "754": 15, "1169": 15, "755": 15, "1167": 15, "756": 15, "1165": 15, "757": 15, "1162": 15, "758": 15, "1160": 15, "759": 15, "1157": 15, "760": 15, "1155": 15, "761": 15, "1153": 15, "762": 15, "1150": 15, "763": 15, "1148": 15, "764": 15, "1146": 15, "765": 15, "1143": 15, "766": 15, "1141": 15, "767": 15, "1139": [15, 16], "768": 15, "1136": [15, 28], "769": 15, "1134": 15, "770": 15, "1132": 15, "771": 15, "1130": 15, "772": 15, "1127": 15, "773": 15, "1125": 15, "774": 15, "1123": 15, "775": 15, "1121": 15, "776": 15, "1118": 15, "777": 15, "1116": 15, "778": 15, "1114": 15, "779": 15, "1112": 15, "780": 15, "1110": 15, "781": 15, "1107": [15, 16], "782": 15, "1105": 15, "783": 15, "1103": 15, "784": 15, "1101": [15, 28], "785": 15, "1099": 15, "786": 15, "1097": 15, "787": 15, "1095": 15, "788": 15, "1093": 15, "789": 15, "1090": 15, "790": 15, "1088": 15, "791": 15, "1086": 15, "792": 15, "1084": 15, "793": 15, "794": 15, "1080": [15, 24], "795": [15, 16], "1078": 15, "796": 15, "1076": 15, "797": 15, "1074": 15, "798": 15, "1072": 15, "799": 15, "1070": 15, "800": 15, "1068": 15, "801": 15, "1066": 15, "802": 15, "1064": 15, "803": 15, "1062": 15, "804": 15, "1060": 15, "805": [15, 16], "1058": 15, "806": 15, "1056": 15, "807": 15, "1054": 15, "808": 15, "1052": 15, "809": 15, "1050": 15, "810": 15, "1049": 15, "811": 15, "1047": 15, "812": 15, "1045": 15, "813": 15, "1043": 15, "814": 15, "1041": 15, "815": 15, "1039": 15, "816": 15, "1037": 15, "817": 15, "1035": 15, "818": 15, "1033": 15, "819": 15, "1032": 15, "820": 15, "1030": 15, "821": 15, "1028": 15, "822": 15, "1026": 15, "823": 15, "1024": 15, "824": 15, "1023": [15, 24], "825": 15, "1021": 15, "826": 15, "1019": [15, 24], "827": 15, "1017": 15, "828": 15, "1015": 15, "829": 15, "1014": 15, "830": 15, "1012": [15, 24], "831": 15, "1010": 15, "832": 15, "1008": 15, "833": 15, "1007": 15, "834": 15, "1005": 15, "835": 15, "1003": 15, "836": 15, "1001": 15, "837": 15, "1000": [15, 33], "838": 15, "0998": [15, 24], "839": 15, "0996": [15, 24], "840": 15, "0995": 15, "841": 15, "0993": 15, "842": 15, "0991": 15, "843": 15, "0990": 15, "844": 15, "0988": 15, "845": 15, "0986": 15, "846": 15, "0985": 15, "847": 15, "0983": 15, "848": 15, "0981": 15, "849": 15, "0980": 15, "850": 15, "0978": 15, "851": 15, "0976": 15, "852": 15, "0975": 15, "853": 15, "0973": 15, "854": 15, "0972": 15, "855": 15, "0970": 15, "856": 15, "0968": [15, 24], "857": 15, "0967": 15, "858": 15, "0965": 15, "859": 15, "0964": 15, "860": 15, "0962": 15, "861": 15, "0961": 15, "862": 15, "0959": [15, 24], "863": 15, "0957": 15, "864": 15, "0956": 15, "865": 15, "0954": [15, 24], "866": 15, "0953": 15, "867": 15, "0951": 15, "868": 15, "0950": 15, "869": 15, "0948": [15, 24], "870": 15, "0947": 15, "871": 15, "0945": 15, "872": 15, "0944": 15, "873": 15, "0942": 15, "874": 15, "0941": 15, "875": 15, "0939": 15, "876": 15, "0938": 15, "877": 15, "0936": 15, "878": 15, "0935": 15, "879": 15, "0933": 15, "880": 15, "0932": 15, "881": 15, "0930": [15, 24], "882": 15, "0929": 15, "883": 15, "0928": 15, "884": 15, "0926": 15, "885": 15, "0925": 15, "886": 15, "0923": [15, 24], "887": 15, "0922": 15, "888": 15, "0920": [15, 24], "889": 15, "0919": 15, "890": 15, "0918": 15, "891": 15, "0916": 15, "892": 15, "0915": 15, "893": 15, "0913": 15, "894": 15, "0912": 15, "895": 15, "0911": 15, "896": 15, "0909": 15, "897": 15, "0908": 15, "898": 15, "0907": 15, "899": 15, "0905": 15, "900": 15, "0904": 15, "901": 15, "0902": 15, "902": 15, "0901": 15, "903": 15, "0900": 15, "904": 15, "0898": 15, "905": 15, "0897": [15, 24], "906": 15, "0896": 15, "907": 15, "0894": 15, "908": 15, "0893": 15, "909": 15, "0892": [15, 24], "910": 15, "0891": [15, 24], "911": 15, "0889": 15, "912": 15, "0888": 15, "913": 15, "0887": 15, "914": 15, "0885": 15, "915": 15, "0884": 15, "916": 15, "0883": 15, "917": 15, "0881": 15, "918": 15, "0880": 15, "919": 15, "0879": 15, "920": 15, "0878": 15, "921": 15, "0876": 15, "922": 15, "0875": 15, "923": 15, "0874": 15, "924": 15, "0873": [15, 28], "925": 15, "0871": 15, "926": 15, "0870": 15, "927": 15, "0869": 15, "928": 15, "0868": 15, "929": 15, "0866": 15, "930": 15, "0865": 15, "931": 15, "0864": [15, 24], "932": 15, "0863": 15, "933": 15, "0862": 15, "934": 15, "0860": 15, "935": 15, "0859": 15, "936": 15, "0858": 15, "937": 15, "0857": 15, "938": 15, "0856": 15, "939": 15, "0854": 15, "940": 15, "0853": 15, "941": 15, "0852": 15, "942": 15, "0851": [15, 28], "943": 15, "0850": 15, "944": 15, "0848": 15, "945": 15, "0847": 15, "946": 15, "0846": 15, "947": 15, "0845": 15, "948": 15, "0844": 15, "949": 15, "0843": 15, "950": 15, "0842": 15, "951": 15, "0840": 15, "952": 15, "0839": 15, "953": 15, "0838": 15, "954": 15, "0837": 15, "955": 15, "0836": 15, "956": 15, "0835": 15, "957": 15, "0834": 15, "958": 15, "0833": 15, "959": 15, "0831": 15, "960": 15, "0830": 15, "961": 15, "0829": 15, "962": 15, "0828": 15, "963": 15, "0827": 15, "964": 15, "0826": 15, "965": 15, "0825": 15, "966": 15, "0824": 15, "967": 15, "0823": 15, "968": 15, "0822": 15, "969": 15, "0820": 15, "970": 15, "0819": [15, 24], "971": 15, "0818": 15, "972": 15, "0817": 15, "973": 15, "0816": 15, "974": 15, "0815": 15, "975": 15, "0814": 15, "976": 15, "0813": 15, "977": 15, "0812": 15, "978": 15, "0811": 15, "979": 15, "0810": 15, "980": 15, "0809": 15, "981": 15, "0808": 15, "982": 15, "0807": 15, "983": 15, "0806": 15, "984": 15, "0805": 15, "985": 15, "0804": [15, 24], "986": 15, "0803": [15, 24], "987": 15, "0802": 15, "988": 15, "0800": 15, "989": 15, "0799": 15, "990": 15, "0798": 15, "991": 15, "992": 15, "0796": 15, "993": 15, "0795": 15, "994": 15, "0794": 15, "995": 15, "0793": 15, "996": 15, "0792": 15, "997": 15, "0791": 15, "998": 15, "0790": 15, "999": 15, "0789": [15, 24], "0788": 15, "0787": 15, "1002": 15, "0786": [15, 16], "1004": 15, "0785": 15, "0784": 15, "1006": [15, 24], "0783": 15, "0782": 15, "0781": 15, "1009": [15, 24], "0779": 15, "1011": 15, "0778": 15, "0777": 15, "1013": 15, "0776": 15, "0775": 15, "0774": 15, "0773": 15, "0772": 15, "1018": 15, "0771": 15, "0770": 15, "1020": 15, "0769": 15, "0768": 15, "1022": 15, "0767": 15, "0766": 15, "1025": 15, "0765": 15, "0764": 15, "1027": 15, "0763": 15, "0762": [15, 24], "1029": 15, "0761": 15, "0760": 15, "1031": 15, "0759": [15, 24], "0758": 15, "1034": 15, "0757": 15, "0756": 15, "1036": 15, "0755": 15, "0754": [15, 24], "1038": 15, "0753": 15, "0752": 15, "1040": 15, "0751": 15, "0750": 15, "1042": 15, "0749": [15, 24], "1044": 15, "0748": 15, "0747": 15, "1046": [15, 24], "0746": [15, 24], "0745": 15, "1048": 15, "0744": 15, "0743": 15, "1051": 15, "0742": 15, "0741": 15, "1053": 15, "0740": 15, "0739": 15, "1055": 15, "0738": 15, "1057": 15, "0737": 15, "0736": 15, "1059": 15, "0735": 15, "0734": 15, "1061": 15, "0733": 15, "1063": 15, "0732": 15, "0731": [15, 24], "1065": 15, "0730": 15, "0729": 15, "1067": 15, "0728": 15, "1069": 15, "0727": 15, "0726": 15, "1071": 15, "0725": [15, 24], "0724": [15, 24], "1073": 15, "0723": 15, "1075": 15, "0722": 15, "0721": [15, 24], "1077": 15, "0720": [15, 24], "0719": 15, "0718": 15, "1081": 15, "0716": 15, "1083": 15, "0715": 15, "1085": 15, "0714": 15, "0713": 15, "1087": 15, "0712": 15, "1089": 15, "0711": 15, "0710": 15, "1091": 15, "0709": 15, "1092": 15, "0708": 15, "1094": 15, "0707": 15, "0706": 15, "1096": 15, "0705": 15, "1098": 15, "0704": 15, "0703": 15, "1100": 15, "0702": 15, "1102": 15, "0701": [15, 24], "0700": 15, "1104": 15, "0699": [15, 24], "1106": [15, 24], "0698": 15, "0697": 15, "1108": 15, "1109": 15, "0696": 15, "0695": 15, "1111": 15, "0694": 15, "1113": 15, "0693": [15, 24], "0692": 15, "1115": 15, "0691": 15, "1117": 15, "0690": 15, "0689": 15, "1119": 15, "1120": 15, "0688": 15, "0687": [15, 24], "1122": 15, "0686": 15, "1124": 15, "0685": [15, 24], "0684": 15, "1126": 15, "0683": 15, "1128": 15, "0682": 15, "1129": 15, "1131": 15, "0680": 15, "0679": 15, "1133": 15, "0678": 15, "1135": 15, "0677": 15, "1137": 15, "0676": 15, "1138": 15, "0675": 15, "0674": [15, 28], "1140": 15, "0673": 15, "1142": 15, "0672": 15, "1144": 15, "0671": 15, "1145": 15, "0670": 15, "1147": 15, "0669": 15, "0668": 15, "1149": 15, "0667": 15, "1151": 15, "0666": 15, "1152": 15, "0665": 15, "1154": 15, "0664": 15, "1156": 15, "0663": [15, 24], "0662": 15, "1158": 15, "1159": 15, "0661": 15, "0660": 15, "1161": 15, "0659": 15, "1163": 15, "0658": 15, "1164": 15, "0657": 15, "1166": 15, "0656": 15, "1168": 15, "0655": 15, "1170": 15, "0654": 15, "1171": 15, "0653": 15, "1173": 15, "0652": 15, "0651": 15, "1175": 15, "1176": 15, "1178": 15, "0649": 15, "1180": 15, "1181": 15, "0647": 15, "0646": 15, "1183": 15, "0645": 15, "1185": 15, "1186": 15, "0644": 15, "0643": 15, "1188": 15, "0642": 15, "1190": 15, "0641": 15, "1191": 15, "0640": 15, "1193": 15, "0639": 15, "1195": 15, "0638": 15, "1196": 15, "0637": 15, "1198": 15, "1199": 15, "0636": 15, "0635": 15, "1201": 15, "0634": 15, "1203": 15, "1204": 15, "0633": 15, "0632": 15, "1206": 15, "0631": 15, "1208": 15, "1209": 15, "0630": 15, "0629": 15, "1211": 15, "1212": 15, "0628": 15, "1214": 15, "0627": 15, "1216": 15, "0626": 15, "1217": 15, "0625": 15, "1219": 15, "0624": 15, "1220": 15, "0623": 15, "1222": 15, "0622": 15, "1224": 15, "0621": 15, "1225": 15, "0620": 15, "1227": 15, "1228": 15, "0619": 15, "1230": 15, "0618": 15, "1231": 15, "0617": 15, "1233": 15, "0616": 15, "1235": 15, "0615": 15, "1236": 15, "0614": 15, "1238": 15, "0613": 15, "1239": 15, "0612": 15, "1241": 15, "0611": 15, "1244": 15, "0610": 15, "1246": 15, "0609": 15, "1247": 15, "0608": 15, "1249": 15, "0607": [15, 24], "0606": 15, "1252": 15, "1253": 15, "0605": 15, "1255": [15, 24], "0604": 15, "1256": 15, "0603": 15, "1258": 15, "1259": 15, "0602": 15, "1261": 15, "0601": 15, "1262": 15, "0600": 15, "1264": 15, "0599": 15, "1266": 15, "0598": 15, "1267": 15, "0597": 15, "1269": 15, "1270": 15, "0596": 15, "1272": 15, "0595": 15, "1273": 15, "0594": 15, "1275": 15, "1276": 15, "0593": 15, "1278": 15, "0592": 15, "1279": 15, "0591": 15, "1281": 15, "1282": 15, "0590": 15, "1284": 15, "0589": 15, "1285": 15, "0588": 15, "1287": 15, "0587": 15, "1288": [15, 24], "0586": 15, "1290": 15, "1291": 15, "0585": 15, "1293": [15, 24], "0584": 15, "1294": [15, 24], "1296": 15, "1297": 15, "0582": 15, "1299": 15, "0581": 15, "1300": 15, "0580": [15, 24], "1302": 15, "1303": 15, "0579": 15, "1305": 15, "1306": 15, "0578": 15, "1307": 15, "0577": 15, "1309": 15, "1310": 15, "0576": [15, 24], "1312": [15, 29], "0575": 15, "1313": 15, "0574": 15, "1315": 15, "1316": [15, 24], "0573": 15, "1318": 15, "0572": 15, "1319": 15, "0571": 15, "1321": 15, "1322": 15, "0570": 15, "1324": 15, "0569": 15, "1325": 15, "1326": 15, "1328": 15, "0567": 15, "1329": 15, "1331": 15, "0566": 15, "1332": [15, 24], "0565": 15, "1334": 15, "1335": 15, "0564": 15, "1337": 15, "0563": 15, "1338": 15, "1339": 15, "0562": [15, 28], "1341": 15, "0561": [15, 16], "1342": 15, "1344": 15, "0560": [15, 16], "1345": 15, "0559": [15, 16], "1347": [15, 32], "1348": [15, 28], "0558": 15, "1349": 15, "0557": 15, "1351": 15, "1352": 15, "0556": 15, "1354": 15, "1355": 15, "0555": 15, "1357": 15, "0554": 15, "1358": 15, "1359": 15, "0553": [15, 24], "1361": 15, "0552": 15, "1362": 15, "0551": 15, "1364": 15, "1365": 15, "1366": 15, "0550": 15, "1368": 15, "0549": 15, "1369": 15, "0548": 15, "1371": 15, "1372": 15, "0547": 15, "1374": 15, "1375": 15, "0546": [15, 24], "1376": 15, "0545": 15, "1378": 15, "1379": 15, "0544": 15, "1381": 15, "1382": 15, "0543": 15, "1383": 15, "0542": 15, "1385": 15, "1386": 15, "0541": 15, "1388": 15, "1389": 15, "0540": 15, "1390": 15, "0539": 15, "1392": 15, "1393": 15, "1394": 15, "0538": 15, "1396": 15, "0537": [15, 24], "1397": 15, "0536": 15, "1399": 15, "1400": 15, "1401": 15, "0535": 15, "1403": 15, "0534": 15, "1404": 15, "0533": 15, "1406": 15, "1407": 15, "1408": 15, "0532": 15, "1410": 15, "0531": 15, "1411": 15, "1412": 15, "0530": 15, "1414": 15, "1415": 15, "0529": [15, 28], "1417": 15, "1418": 15, "0528": 15, "1419": 15, "0527": 15, "1421": 15, "1422": 15, "1423": 15, "0526": 15, "1425": 15, "0525": 15, "1426": [15, 24], "1427": 15, "0524": 15, "1429": [15, 24], "1430": 15, "0523": 15, "1432": 15, "0522": 15, "1434": 15, "0521": 15, "1437": 15, "1438": 15, "0520": 15, "1440": 15, "0519": 15, "1441": 15, "1442": 15, "0518": 15, "1444": 15, "1445": 15, "0517": 15, "1446": 15, "1448": 15, "0516": 15, "1449": 15, "1450": 15, "0515": 15, "1452": 15, "1453": 15, "0514": [15, 29], "1455": 15, "0513": 15, "1456": 15, "1457": [15, 24], "0512": [15, 28], "1459": 15, "1460": 15, "1461": 15, "0511": 15, "1463": 15, "0510": 15, "1464": 15, "1465": 15, "0509": 15, "1467": 15, "1468": 15, "1469": 15, "0508": 15, "1471": 15, "0507": 15, "1472": 15, "1473": [15, 24], "0506": 15, "1475": [15, 24], "1476": 15, "0505": 15, "1477": 15, "1479": 15, "0504": 15, "1480": 15, "1481": 15, "0503": 15, "1483": 15, "1484": [15, 24], "1485": 15, "0502": 15, "1486": 15, "0501": 15, "1488": 15, "1489": 15, "1490": 15, "0500": 15, "1492": 15, "1493": 15, "0499": 15, "1494": 15, "0498": 15, "1496": 15, "1497": 15, "1498": [15, 16], "0497": 15, "1500": 15, "1501": 15, "1502": 15, "1504": 15, "0495": 15, "1505": 15, "1506": 15, "1508": 15, "1509": 15, "0493": 15, "1510": 15, "1512": 15, "0492": 15, "1513": 15, "1514": 15, "1515": 15, "0491": 15, "1517": 15, "1518": [15, 24], "0490": 15, "1519": [15, 24], "0489": 15, "1521": 15, "1522": 15, "1523": 15, "0488": 15, "1525": 15, "1526": 15, "0487": 15, "1527": 15, "1528": 15, "0486": 15, "1530": 15, "1531": 15, "1532": 15, "0485": 15, "1534": 15, "1535": 15, "0484": 15, "1536": 15, "1538": 15, "0483": 15, "1539": 15, "1540": 15, "1541": 15, "0482": 15, "1543": 15, "1544": 15, "0481": 15, "1545": [15, 24], "0480": 15, "1547": 15, "1548": 15, "1549": 15, "0479": 15, "1550": 15, "1552": 15, "0478": 15, "1553": 15, "1554": 15, "0477": 15, "1556": 15, "1557": 15, "1558": 15, "0476": 15, "1559": 15, "1561": 15, "1562": 15, "1563": 15, "0474": 15, "1565": 15, "1566": 15, "1567": 15, "0473": 15, "1568": 15, "1570": 15, "0472": 15, "1571": 15, "1572": 15, "0471": 15, "1574": 15, "1575": [15, 24], "1576": 15, "0470": 15, "1577": 15, "1579": 15, "0469": [15, 28], "1580": 15, "1581": 15, "1582": 15, "0468": 15, "1584": 15, "1585": 15, "1586": 15, "0467": 15, "1588": 15, "1589": 15, "0466": 15, "1590": 15, "1591": 15, "0465": 15, "1593": 15, "1594": 15, "1595": 15, "0464": 15, "1596": 15, "1598": 15, "0463": 15, "1599": 15, "1600": 15, "0462": 15, "1602": 15, "1603": 15, "1604": 15, "0461": 15, "1605": 15, "1607": 15, "0460": 15, "1608": 15, "1609": 15, "1610": 15, "0459": 15, "1612": 15, "1613": 15, "1614": 15, "0458": 15, "1615": 15, "1617": 15, "0457": 15, "1618": 15, "1619": 15, "1620": 15, "0456": 15, "1622": 15, "1623": 15, "0455": 15, "1624": 15, "1625": 15, "0454": 15, "1627": 15, "1628": [15, 24], "1629": 15, "1630": 15, "0453": 15, "1632": 15, "1633": 15, "0452": 15, "1634": 15, "1635": 15, "0451": 15, "1637": 15, "1638": 15, "1639": 15, "0450": 15, "1641": 15, "1642": 15, "1643": 15, "0449": 15, "1644": 15, "1645": 15, "0448": 15, "1647": 15, "1648": 15, "1649": 15, "0447": [15, 16], "1650": 15, "1652": 15, "0446": 15, "1653": 15, "1654": [15, 24], "1655": 15, "0445": 15, "1657": 15, "1658": 15, "1659": 15, "0444": 15, "1660": 15, "1662": 15, "1663": 15, "0443": 15, "1664": 15, "1665": 15, "0442": 15, "1667": 15, "1668": 15, "1669": 15, "0441": 15, "1670": 15, "1672": 15, "1673": 15, "0440": 15, "1674": 15, "1675": 15, "0439": 15, "1677": 15, "1678": 15, "1679": 15, "0438": 15, "1680": 15, "1681": 15, "1683": 15, "0437": 15, "1684": 15, "1685": 15, "1686": 15, "0436": 15, "1688": 15, "1689": 15, "1690": 15, "0435": 15, "1691": 15, "1693": 15, "0434": 15, "1694": 15, "1695": 15, "1696": 15, "0433": 15, "1698": 15, "1699": 15, "1700": 15, "0432": 15, "1701": 15, "1702": 15, "1704": 15, "0431": 15, "1705": 15, "1706": 15, "1707": 15, "0430": 15, "1709": 15, "1710": 15, "1711": 15, "0429": 15, "1712": 15, "1713": 15, "0428": 15, "1715": 15, "1716": 15, "1717": 15, "1718": 15, "0427": 15, "1720": 15, "1721": 15, "0426": 15, "1722": 15, "1723": 15, "1724": [15, 24], "0425": 15, "1726": 15, "1727": 15, "1728": 15, "0424": 15, "1729": 15, "1731": 15, "1732": 15, "0423": 15, "1733": 15, "1734": [15, 24], "1735": 15, "0422": 15, "1738": [15, 24], "1739": 15, "0421": 15, "1740": 15, "1742": 15, "1743": 15, "0420": 15, "1744": 15, "1745": 15, "1746": 15, "0419": 15, "1748": 15, "1749": 15, "1750": 15, "0418": 15, "1752": 15, "1754": 15, "0417": 15, "1755": 15, "1756": 15, "1757": 15, "0416": 15, "1759": 15, "1760": 15, "1761": 15, "0415": 15, "1763": [15, 24], "1765": 15, "0414": 15, "1766": 15, "1767": 15, "1768": 15, "1769": 15, "0413": 15, "1771": 15, "1772": 15, "0412": 15, "1773": 15, "1774": 15, "1775": 15, "0411": 15, "1777": 15, "1778": 15, "1779": 15, "1780": [15, 24], "0410": 15, "1781": 15, "1783": 15, "1784": 15, "0409": 15, "1785": 15, "1786": 15, "1787": 15, "0408": 15, "1789": 15, "1790": 15, "1791": 15, "0407": 15, "1792": 15, "1794": 15, "1795": 15, "0406": [15, 16], "1796": 15, "1797": 15, "1798": 15, "0405": 15, "1800": 15, "1801": 15, "1802": 15, "1803": 15, "0404": 15, "1804": [15, 24], "1806": 15, "1807": 15, "0403": 15, "1808": 15, "1809": 15, "1810": 15, "0402": 15, "1812": [15, 24], "1813": 15, "1814": 15, "0401": 15, "1815": 15, "1816": 15, "1817": 15, "0400": 15, "1819": 15, "1820": 15, "1821": [15, 24], "1822": 15, "0399": 15, "1823": 15, "1825": 15, "1826": 15, "0398": 15, "1827": 15, "1828": 15, "1829": 15, "0397": 15, "1831": [15, 24], "1832": 15, "1833": 15, "1834": 15, "0396": [15, 16], "1835": 15, "1837": 15, "1838": 15, "0395": 15, "1839": 15, "1840": 15, "1841": 15, "0394": 15, "1843": 15, "1844": 15, "1845": 15, "1846": 15, "0393": 15, "1847": 15, "1848": 15, "1850": 15, "0392": 15, "1851": [15, 24], "1852": 15, "1853": 15, "1854": 15, "0391": 15, "1856": 15, "1857": 15, "1858": 15, "0390": 15, "1859": 15, "1860": 15, "1862": 15, "1863": 15, "1864": 15, "1865": 15, "1866": 15, "0388": 15, "1867": 15, "1869": 15, "1870": 15, "0387": 15, "1871": 15, "1872": 15, "1873": 15, "0386": 15, "1875": 15, "1876": 15, "1877": 15, "1878": 15, "0385": 15, "1879": 15, "1880": 15, "1882": 15, "0384": [15, 31], "1883": 15, "1884": 15, "1885": 15, "1886": 15, "0383": 15, "1888": 15, "1890": 15, "1891": 15, "0382": 15, "1892": 15, "1893": 15, "0381": 15, "1896": 15, "1897": 15, "1898": 15, "1899": 15, "0380": 15, "1901": 15, "1902": 15, "1903": 15, "0379": 15, "1904": 15, "1905": 15, "1906": 15, "0378": 15, "1908": 15, "1909": 15, "1910": 15, "1911": 15, "1912": 15, "0377": 15, "1913": [15, 28], "1915": 15, "1916": 15, "0376": 15, "1917": 15, "1918": 15, "1919": 15, "1920": 15, "0375": 15, "1922": 15, "1923": 15, "1924": 15, "0374": 15, "1925": 15, "1926": 15, "1928": 15, "1929": 15, "0373": 15, "1930": 15, "1931": 15, "1932": 15, "1933": 15, "0372": 15, "1935": 15, "1936": 15, "1937": 15, "0371": 15, "1938": 15, "1939": 15, "1940": 15, "1942": 15, "0370": 15, "1943": 15, "1944": 15, "1945": 15, "1946": 15, "0369": 15, "1947": 15, "1949": 15, "1950": 15, "0368": 15, "1951": 15, "1952": 15, "1953": 15, "1954": 15, "0367": 15, "1956": 15, "1957": 15, "1959": 15, "0366": 15, "1960": 15, "1961": 15, "1963": 15, "0365": 15, "1964": 15, "1965": 15, "1966": 15, "1967": 15, "1968": 15, "0364": 15, "1970": 15, "1971": 15, "1972": 15, "0363": [15, 28], "1973": 15, "1974": 15, "1975": 15, "1977": 15, "0362": 15, "1978": 15, "1979": 15, "1980": 15, "1981": 15, "0361": 15, "1982": 15, "1984": 15, "1985": 15, "0360": 15, "1986": 15, "1987": 15, "1988": 15, "1989": 15, "1990": 15, "0359": 15, "1992": 15, "1993": 15, "1994": 15, "1995": 15, "1996": 15, "1997": 15, "1999": 15, "0357": 15, "plot": [15, 33], "figur": 15, "dpi": 15, "test_epoch": 15, "isfinit": 15, "linestyl": 15, "marker": 15, "legend": [15, 33], "xlabel": 15, "cites": 16, "3703": 16, "manifold": 16, "tsne": 16, "hnhn_layer_bi": 16, "randomnodesplit": 16, "home": [16, 30], "sadra": 16, "local": [16, 34], "tqdm": [16, 33], "auto": 16, "tqdmwarn": 16, "iprogress": 16, "found": [16, 21], "jupyt": 16, "ipywidget": 16, "readthedoc": 16, "io": 16, "en": 16, "user_instal": 16, "html": [16, 31], "autonotebook": 16, "notebook_tqdm": 16, "offici": 16, "accord": [16, 31], "wget": [16, 21], "twistedcub": 16, "raw": [16, 21], "master": [16, 21], "citeseer6cls3703": 16, "pt": [16, 33], "paper_x": 16, "longtensor": [16, 21], "paper_author": 16, "train_test_splitt": 16, "num_test": 16, "num_val": 16, "dropout_r": 16, "normalization_param_alpha": 16, "normalization_param_beta": 16, "enumer": [16, 21, 33], "schedul": 16, "initial_lr": 16, "04": [16, 24, 33], "lr_schedul": 16, "steplr": 16, "7889": 16, "6347": 16, "6458": 16, "9118": 16, "5491": 16, "7203": 16, "5956": 16, "4068": 16, "4721": 16, "7964": 16, "3431": 16, "5075": 16, "0124": 16, "9682": 16, "2804": 16, "2483": 16, "2004": 16, "2019": [16, 28], "0248": 16, "0219": 16, "0217": 16, "0328": 16, "0180": 16, "0220": 16, "0232": 16, "0241": 16, "0130": 16, "0239": 16, "0240": 16, "0284": 16, "0295": 16, "0163": 16, "0195": 16, "0323": 16, "8441": 16, "worth": 16, "visual": [16, 33], "n_compon": 16, "fit_transform": 16, "ax1": 16, "ax2": 16, "subplot": [16, 33], "suptitl": 16, "set_titl": [16, 33], "_t_sne": 16, "futurewarn": 16, "chang": [16, 24, 28, 33], "pca": 16, "warn": [16, 20, 23, 30], "hypergat": 17, "ding": 17, "t_1": 17, "m_z": [17, 18], "rightarrow0": [17, 30], "As": 17, "j": [17, 18, 24, 28, 30, 33], "highlight": 17, "those": [17, 26], "formal": [17, 26], "alpha_": 17, "jk": 17, "nonlinear": [17, 32], "frac": [17, 18], "operatornam": 17, "exp": 17, "u_": 17, "limits_": 17, "context": 17, "again": [17, 26, 27], "vi": [17, 18], "beta_": 17, "ij": 17, "anoth": 17, "measur": 17, "hypergat_lay": 17, "hypergatlay": 17, "7875": 17, "9625": 17, "hypersag": 18, "arya": 18, "w_y": 18, "w_z": 18, "lvert": 18, "rvert": 18, "interpret": 18, "propag": 18, "problem": [18, 21], "divid": 18, "intra": 18, "obtain": [18, 21, 26, 29, 32, 33], "hypersage_lay": 18, "hypersagelay": 18, "hypersagemodel": 18, "kwarg": 18, "features_nod": 18, "2431": 18, "templatenn": 19, "6126": 19, "0002": 19, "0001": 19, "simplicial_complex": [20, 22, 23, 33], "simplicialcomplex": [20, 22, 23, 33], "unigcn_lay": 20, "unigcnlay": 20, "filterwarn": [20, 23], "to_sparse_csr": [20, 21, 23], "bceloss": [20, 23], "x_1_val": [20, 22, 23], "incidence_1_v": [20, 22, 23], "y_val": [20, 22, 23], "pred": [20, 22, 23, 33], "0971908569336": 20, "94380187988281": 20, "2369270324707": 20, "26074981689453": 20, "98492431640625": 20, "20859909057617": 20, "80668640136719": 20, "686824798583984": 20, "83675765991211": 20, "03213882446289": 20, "238582611083984": 20, "33390426635742": 20, "644731521606445": 20, "585487365722656": 20, "487186431884766": 20, "787471771240234": 20, "63153076171875": 20, "06392478942871": 20, "550783157348633": 20, "08787727355957": 20, "46900749206543": 20, "992172241210938": 20, "090089797973633": 20, "6256160736084": 20, "858888626098633": 20, "25303077697754": 20, "14973258972168": 20, "443086624145508": 20, "693538665771484": 20, "53269386291504": 20, "046640396118164": 20, "61376190185547": 20, "491796493530273": 20, "60036277770996": 20, "690528869628906": 20, "603723526000977": 20, "351343154907227": 20, "073862075805664": 20, "908754348754883": 20, "88480567932129": 20, "900497436523438": 20, "822755813598633": 20, "63096809387207": 20, "415300369262695": 20, "28574562072754": 20, "239614486694336": 20, "227548599243164": 20, "16373634338379": 20, "053255081176758": 20, "935653686523438": 20, "852752685546875": 20, "81441307067871": 20, "792282104492188": 20, "750215530395508": 20, "678442001342773": 20, "601423263549805": 20, "548017501831055": 20, "518722534179688": 20, "489871978759766": 20, "43247413635254": 20, "345685958862305": 20, "245248794555664": 20, "150096893310547": 20, "066505432128906": 20, "986852645874023": 20, "90121841430664": 20, "803401947021484": 20, "703289031982422": 20, "632183074951172": 20, "587385177612305": 20, "54228401184082": 20, "49706268310547": 20, "451065063476562": 20, "407331466674805": 20, "371335983276367": 20, "337526321411133": 20, "306472778320312": 20, "273452758789062": 20, "237478256225586": 20, "20127296447754": 20, "167097091674805": 20, "132389068603516": 20, "098857879638672": 20, "060476303100586": 20, "02267837524414": 20, "9860782623291": 20, "950490951538086": 20, "914758682250977": 20, "878108978271484": 20, "842838287353516": 20, "811080932617188": 20, "780370712280273": 20, "74917221069336": 20, "71664810180664": 20, "699419021606445": 20, "676870346069336": 20, "647939682006836": 20, "61389923095703": 20, "5761775970459": 20, "549442291259766": 20, "5289249420166": 20, "49772071838379": 20, "474157333374023": 20, "45038414001465": 20, "424612045288086": 20, "40214729309082": 20, "378002166748047": 20, "351882934570312": 20, "324098587036133": 20, "298376083374023": 20, "274303436279297": 20, "24971580505371": 20, "228342056274414": 20, "197002410888672": 20, "17634391784668": 20, "151491165161133": 20, "128210067749023": 20, "113391876220703": 20, "088733673095703": 20, "06772232055664": 20, "04320526123047": 20, "0169734954834": 20, "99879264831543": 20, "976442337036133": 20, "94951820373535": 20, "926555633544922": 20, "90591812133789": 20, "884706497192383": 20, "859689712524414": 20, "834184646606445": 20, "812297821044922": 20, "79071807861328": 20, "770198822021484": 20, "74526596069336": 20, "72126579284668": 20, "695659637451172": 20, "671920776367188": 20, "650121688842773": 20, "63254737854004": 20, "603469848632812": 20, "58234405517578": 20, "55916976928711": 20, "540271759033203": 20, "513303756713867": 20, "49028968811035": 20, "466527938842773": 20, "449338912963867": 20, "419330596923828": 20, "39695167541504": 20, "375646591186523": 20, "3538875579834": 20, "334510803222656": 20, "312015533447266": 20, "285579681396484": 20, "269054412841797": 20, "242639541625977": 20, "22045135498047": 20, "203929901123047": 20, "183347702026367": 20, "160404205322266": 20, "133930206298828": 20, "104745864868164": 20, "098697662353516": 20, "078676223754883": 20, "040504455566406": 20, "02244758605957": 20, "011486053466797": 20, "993385314941406": 20, "96799087524414": 20, "939449310302734": 20, "912992477416992": 20, "884111404418945": 20, "86220359802246": 20, "8441219329834": 20, "813901901245117": 20, "801708221435547": 20, "786155700683594": 20, "761951446533203": 20, "740060806274414": 20, "71567726135254": 20, "68885040283203": 20, "670719146728516": 20, "652807235717773": 20, "618999481201172": 20, "5964298248291": 20, "57932472229004": 20, "557270050048828": 20, "530651092529297": 20, "504606246948242": 20, "476253509521484": 20, "45449447631836": 20, "434545516967773": 20, "411243438720703": 20, "382360458374023": 20, "362293243408203": 20, "335590362548828": 20, "30755043029785": 20, "284061431884766": 20, "25484275817871": 20, "22318458557129": 20, "19426155090332": 20, "173973083496094": 20, "14513397216797": 20, "10979652404785": 20, "082422256469727": 20, "0560359954834": 20, "033998489379883": 20, "013517379760742": 20, "987682342529297": 20, "960020065307617": 20, "938085556030273": 20, "911584854125977": 20, "887819290161133": 20, "859230041503906": 20, "83808708190918": 20, "825475692749023": 20, "791316986083984": 20, "769617080688477": 20, "746116638183594": 20, "724519729614258": 20, "69559097290039": 20, "676664352416992": 20, "659330368041992": 20, "623565673828125": 20, "596616744995117": 20, "573455810546875": 20, "547086715698242": 20, "527324676513672": 20, "50086784362793": 20, "473081588745117": 20, "447193145751953": 20, "41757583618164": 20, "402799606323242": 20, "38097381591797": 20, "355859756469727": 20, "32827377319336": 20, "316627502441406": 20, "297752380371094": 20, "263805389404297": 20, "23656463623047": 20, "23184585571289": 20, "2138671875": 20, "183242797851562": 20, "142995834350586": 20, "137985229492188": 20, "11527442932129": 20, "083709716796875": 20, "5625": [20, 22, 23], "04819107055664": 20, "046104431152344": 20, "027341842651367": 20, "99266242980957": 20, "961795806884766": 20, "930912017822266": 20, "911731719970703": 20, "880786895751953": 20, "845874786376953": 20, "83226203918457": 20, "812429428100586": 20, "780649185180664": 20, "75445556640625": 20, "74269676208496": 20, "706310272216797": 20, "682571411132812": 20, "67528533935547": 20, "641508102416992": 20, "615623474121094": 20, "612245559692383": 20, "574350357055664": 20, "543176651000977": 20, "523324966430664": 20, "500341415405273": 20, "460468292236328": 20, "45850944519043": 20, "433353424072266": 20, "38702392578125": 20, "373823165893555": 20, "356149673461914": 20, "33302116394043": 20, "2984619140625": 20, "27631950378418": 20, "242095947265625": 20, "220375061035156": 20, "19377326965332": 20, "166545867919922": 20, "145954132080078": 20, "118263244628906": 20, "103313446044922": 20, "090181350708008": 20, "05240821838379": 20, "038013458251953": 20, "01729965209961": 20, "008516311645508": 20, "97707748413086": 20, "94068717956543": 20, "90737533569336": 20, "87880516052246": 20, "850223541259766": 20, "817041397094727": 20, "79216194152832": 20, "768423080444336": 20, "73453712463379": 20, "714162826538086": 20, "683536529541016": 20, "661930084228516": 20, "627168655395508": 20, "591276168823242": 20, "575401306152344": 20, "538806915283203": 20, "532752990722656": 20, "491992950439453": 20, "470623016357422": 20, "447834014892578": 20, "417621612548828": 20, "395700454711914": 20, "371519088745117": 20, "34141731262207": 20, "317161560058594": 20, "290822982788086": 20, "27621078491211": 20, "252424240112305": 20, "223106384277344": 20, "191679000854492": 20, "167285919189453": 20, "146617889404297": 20, "1218204498291": 20, "092159271240234": 20, "068817138671875": 20, "043107986450195": 20, "020431518554688": 20, "99953842163086": 20, "965152740478516": 20, "948270797729492": 20, "9256591796875": 20, "89617347717285": 20, "867271423339844": 20, "838720321655273": 20, "820175170898438": 20, "80241584777832": 20, "77659797668457": 20, "735746383666992": 20, "71509552001953": 20, "694164276123047": 20, "66806411743164": 20, "638553619384766": 20, "61126136779785": 20, "588682174682617": 20, "57335090637207": 20, "55010223388672": 20, "518211364746094": 20, "497529983520508": 20, "474842071533203": 20, "450790405273438": 20, "426084518432617": 20, "395307540893555": 20, "374881744384766": 20, "35700798034668": 20, "3305721282959": 20, "315614700317383": 20, "27733039855957": 20, "254539489746094": 20, "226396560668945": 20, "21523666381836": 20, "177637100219727": 20, "150047302246094": 20, "121498107910156": 20, "07767677307129": 20, "025562286376953": 20, "97791290283203": 20, "93244743347168": 20, "88832664489746": 20, "836246490478516": 20, "796043395996094": 20, "74243927001953": 20, "702007293701172": 20, "6556339263916": 20, "615976333618164": 20, "584707260131836": 20, "56226348876953": 20, "522308349609375": 20, "483394622802734": 20, "425535202026367": 20, "371274948120117": 20, "33834457397461": 20, "30695152282715": 20, "257896423339844": 20, "215682983398438": 20, "17093849182129": 20, "115076065063477": 20, "079204559326172": 20, "051490783691406": 20, "033987045288086": 20, "01789093017578": 20, "02878189086914": 20, "052005767822266": 20, "115055084228516": 20, "044801712036133": 20, "891642570495605": 20, "728387832641602": 20, "788483619689941": 20, "005611419677734": 20, "045494079589844": 20, "028085708618164": 20, "70627212524414": 20, "557747840881348": 20, "639880180358887": 20, "732135772705078": 20, "785037994384766": 20, "548952102661133": 20, "409181594848633": 20, "439441680908203": 20, "51244068145752": 20, "506211280822754": 20, "33906364440918": 20, "261138916015625": 20, "3150053024292": 20, "368926048278809": 20, "32858943939209": 20, "185369491577148": 20, "1485595703125": 20, "187846183776855": 20, "209299087524414": 20, "182910919189453": 20, "098752975463867": 20, "044387817382812": 20, "052579879760742": 20, "05774211883545": 20, "031035423278809": 20, "977952003479004": 20, "939553260803223": 20, "92505931854248": 20, "922098159790039": 20, "910082817077637": 20, "877153396606445": 20, "838932991027832": 20, "809442520141602": 20, "788487434387207": 20, "78007698059082": 20, "799392700195312": 20, "814967155456543": 20, "780838966369629": 20, "738446235656738": 20, "707448959350586": 20, "675198554992676": 20, "641422271728516": 20, "6210355758667": 20, "609297752380371": 20, "609857559204102": 20, "6266508102417": 20, "633983612060547": 20, "6951904296875": 20, "658025741577148": 20, "600869178771973": 20, "535354614257812": 20, "497736930847168": 20, "458619117736816": 20, "456388473510742": 20, "473320007324219": 20, "49333667755127": 20, "535053253173828": 20, "544401168823242": 20, "582549095153809": 20, "526555061340332": 20, "50399112701416": 20, "38758373260498": 20, "308337211608887": 20, "299043655395508": 20, "327571868896484": 20, "388229370117188": 20, "417525291442871": 20, "455561637878418": 20, "416516304016113": 20, "392356872558594": 20, "28682804107666": 20, "192612648010254": 20, "12002182006836": 20, "091236114501953": 20, "14907455444336": 20, "283432006835938": 20, "588083267211914": 20, "7717866897583": 20, "171638488769531": 20, "575143814086914": 20, "168379783630371": 20, "044833183288574": 20, "277763366699219": 20, "634512901306152": 20, "24776554107666": 20, "931353569030762": 20, "041153907775879": 20, "249833106994629": 20, "302783966064453": 20, "985976219177246": 20, "880131721496582": 20, "02563762664795": 20, "059005737304688": 20, "942398071289062": 20, "796463012695312": 20, "87881088256836": 20, "039618492126465": 20, "918492317199707": 20, "420305252075195": 20, "406696319580078": 20, "394020080566406": 20, "37169075012207": 20, "35594940185547": 20, "34318733215332": 20, "33356475830078": 20, "31667137145996": 20, "302318572998047": 20, "28500747680664": 20, "26559066772461": 20, "25322914123535": 20, "238706588745117": 20, "220836639404297": 20, "208791732788086": 20, "1856746673584": 20, "171249389648438": 20, "15633201599121": 20, "145591735839844": 20, "12535285949707": 20, "112903594970703": 20, "096086502075195": 20, "082990646362305": 20, "068315505981445": 20, "050025939941406": 20, "046539306640625": 20, "030738830566406": 20, "007352828979492": 20, "004419326782227": 20, "990276336669922": 20, "96859359741211": 20, "95843505859375": 20, "941267013549805": 20, "93852424621582": 20, "93297004699707": 20, "905284881591797": 20, "90688705444336": 20, "88941764831543": 20, "867488861083984": 20, "852458953857422": 20, "82878303527832": 20, "848604202270508": 20, "816743850708008": 20, "798707962036133": 20, "782867431640625": 20, "770641326904297": 20, "765010833740234": 20, "74397087097168": 20, "730905532836914": 20, "71582794189453": 20, "692882537841797": 20, "678205490112305": 20, "659757614135742": 20, "66231918334961": 20, "63972282409668": 20, "637910842895508": 20, "620912551879883": 20, "613643646240234": 20, "592449188232422": 20, "578832626342773": 20, "5690860748291": 20, "5478572845459": 20, "536046981811523": 20, "518606185913086": 20, "507850646972656": 20, "49575424194336": 20, "47629737854004": 20, "466197967529297": 20, "446958541870117": 20, "431520462036133": 20, "42148780822754": 20, "418920516967773": 20, "382413864135742": 20, "38419532775879": 20, "382558822631836": 20, "373292922973633": 20, "359771728515625": 20, "339229583740234": 20, "32771873474121": 20, "31146240234375": 20, "291799545288086": 20, "266311645507812": 20, "25176429748535": 20, "275617599487305": 20, "243261337280273": 20, "198863983154297": 20, "190418243408203": 20, "180404663085938": 20, "159381866455078": 20, "132848739624023": 20, "08831024169922": 20, "07340431213379": 20, "040719985961914": 20, "018062591552734": 20, "98824119567871": 20, "994766235351562": 20, "97658348083496": 20, "954269409179688": 20, "931133270263672": 20, "923803329467773": 20, "900142669677734": 20, "883092880249023": 20, "874980926513672": 20, "859506607055664": 20, "83385467529297": 20, "821224212646484": 20, "808631896972656": 20, "790834426879883": 20, "770950317382812": 20, "753965377807617": 20, "74176597595215": 20, "726638793945312": 20, "71209144592285": 20, "717884063720703": 20, "69021987915039": 20, "684720993041992": 20, "65319061279297": 20, "64687728881836": 20, "641027450561523": 20, "62809181213379": 20, "599239349365234": 20, "57975196838379": 20, "56479835510254": 20, "56086540222168": 20, "538368225097656": 20, "528959274291992": 20, "50667953491211": 20, "503355026245117": 20, "473203659057617": 20, "480627059936523": 20, "455434799194336": 20, "448516845703125": 20, "433578491210938": 20, "42472267150879": 20, "41015625": 20, "397563934326172": 20, "366233825683594": 20, "36186981201172": 20, "347782135009766": 20, "334121704101562": 20, "319826126098633": 20, "311002731323242": 20, "29153060913086": 20, "269283294677734": 20, "26325225830078": 20, "24094581604004": 20, "23046112060547": 20, "2217960357666": 20, "21772575378418": 20, "204160690307617": 20, "186527252197266": 20, "18400764465332": 20, "16082763671875": 20, "150056838989258": 20, "157442092895508": 20, "121925354003906": 20, "12659454345703": 20, "10972023010254": 20, "108051300048828": 20, "09576988220215": 20, "07231903076172": 20, "065282821655273": 20, "032222747802734": 20, "040668487548828": 20, "02615737915039": 20, "99028778076172": 20, "992895126342773": 20, "986125946044922": 20, "971839904785156": 20, "947101593017578": 20, "93064308166504": 20, "940488815307617": 20, "926761627197266": 20, "89728355407715": 20, "92677116394043": 20, "90224266052246": 20, "888980865478516": 20, "871950149536133": 20, "850805282592773": 20, "85380744934082": 20, "83152961730957": 20, "820480346679688": 20, "813871383666992": 20, "811283111572266": 20, "79723358154297": 20, "773174285888672": 20, "76585578918457": 20, "763370513916016": 20, "74306297302246": 20, "733776092529297": 20, "727794647216797": 20, "726064682006836": 20, "721574783325195": 20, "69578742980957": 20, "671518325805664": 20, "67192268371582": 20, "675018310546875": 20, "652587890625": 20, "63589859008789": 20, "632600784301758": 20, "618101119995117": 20, "61069679260254": 20, "603355407714844": 20, "587169647216797": 20, "568763732910156": 20, "55999183654785": 20, "554792404174805": 20, "530359268188477": 20, "52699851989746": 20, "524051666259766": 20, "511272430419922": 20, "492382049560547": 20, "48703384399414": 20, "472692489624023": 20, "478933334350586": 20, "467594146728516": 20, "44580841064453": 20, "4395809173584": 20, "439208984375": 20, "427417755126953": 20, "416553497314453": 20, "407917022705078": 20, "396162033081055": 20, "377273559570312": 20, "370101928710938": 20, "381824493408203": 20, "365995407104492": 20, "33931541442871": 20, "341108322143555": 20, "34080696105957": 20, "326269149780273": 20, "295074462890625": 20, "290189743041992": 20, "294099807739258": 20, "279863357543945": 20, "259613037109375": 20, "255352020263672": 20, "243770599365234": 20, "24730682373047": 20, "235071182250977": 20, "221952438354492": 20, "20149803161621": 20, "19734001159668": 20, "199737548828125": 20, "179275512695312": 20, "176069259643555": 20, "170211791992188": 20, "16652488708496": 20, "136791229248047": 20, "125789642333984": 20, "123292922973633": 20, "109601974487305": 20, "100919723510742": 20, "0986270904541": 20, "09308624267578": 20, "078474044799805": 20, "067218780517578": 20, "05537223815918": 20, "03988265991211": 20, "03138542175293": 20, "026723861694336": 20, "008121490478516": 20, "018474578857422": 20, "014162063598633": 20, "001453399658203": 20, "981800079345703": 20, "987455368041992": 20, "983600616455078": 20, "cicitationcora": 21, "hgnn": 21, "utlil": 21, "neccessari": 21, "pickl": 21, "scipi": [21, 24, 28, 30, 33], "sp": 21, "unigcnii_lay": 21, "unigcniilay": 21, "computation": 21, "expens": [21, 24, 28], "malllabiisc": 21, "hypergcn": 21, "cocit": 21, "07": [21, 24, 33], "ca": 21, "certif": 21, "ssl": 21, "cert": 21, "crt": 21, "resolv": 21, "await": 21, "githubusercont": 21, "ok": 21, "404937": 21, "395k": 21, "applic": 21, "octet": 21, "stream": 21, "save": 21, "gt": [21, 33], "45k": 21, "kb": 21, "mb": 21, "101905": 21, "100k": 21, "52k": 21, "02": [21, 24, 33], "5436": 21, "3k": 21, "31k": 21, "51582": 21, "50k": 21, "37k": 21, "rb": 21, "handl": 21, "ipykernel_14655": 21, "121206761": 21, "deprecationwarn": 21, "csr_matrix": [21, 24, 28], "namespac": 21, "csr": 21, "deprec": 21, "pytorch": 21, "floattensor": 21, "num": 21, "hyper": [21, 33], "expect": [21, 28, 30], "gcnii": 21, "h2": [21, 28], "hstack": 21, "2226475299": 21, "support": [21, 26, 29, 32], "beta": [21, 33], "miss": 21, "trigger": 21, "intern": [21, 32], "aten": 21, "sparsecsrtensorimpl": 21, "cpp": 21, "predefin": 21, "train_idx": 21, "test_idx": 21, "unigcniimodel": 21, "num_lay": [21, 29, 32], "num_featur": 21, "num_nod": 21, "num_edg": 21, "copi": [21, 34], "x_0_skip": 21, "clone": [21, 34], "ommit": 21, "cross": 21, "entropi": 21, "current": [21, 26, 29, 32], "readi": [21, 33], "mode": 21, "7071428298950195": 21, "39291277527809143": 21, "4376946985721588": 21, "9357143044471741": 21, "6137071847915649": 21, "8714285492897034": 21, "45210281014442444": 21, "9071428775787354": 21, "5502336621284485": 21, "9785714149475098": 21, "5463395714759827": 21, "5747663378715515": 21, "9857142567634583": 21, "5673676133155823": 21, "9428571462631226": 21, "552570104598999": 21, "9571428298950195": 21, "5607476830482483": 21, "unigin_lay": 22, "uniginlay": 22, "unigin_nn": 22, "unigin": 22, "in_channels_nod": 22, "inp_emb": 22, "out_decod": 22, "pooled_x_0": 22, "node_dim": 22, "seper": 22, "unsqueez": [22, 33], "3916015625": 22, "91788864135742": 22, "573387145996094": 22, "32501220703125": 22, "29070281982422": 22, "48554229736328": 22, "905006408691406": 22, "502838134765625": 22, "23980712890625": 22, "084415435791016": 22, "003536224365234": 22, "96804428100586": 22, "95846939086914": 22, "9611930847168": 22, "96879196166992": 22, "977806091308594": 22, "98638916015625": 22, "99394989013672": 22, "00029754638672": 22, "00556945800781": 22, "00981521606445": 22, "01326370239258": 22, "01602554321289": 22, "018226623535156": 22, "01999282836914": 22, "0213737487793": 22, "02241897583008": 22, "02317810058594": 22, "023704528808594": 22, "02401351928711": 22, "02414321899414": 22, "024078369140625": 22, "023826599121094": 22, "02338790893555": 22, "02278137207031": 22, "021995544433594": 22, "02100372314453": 22, "019805908203125": 22, "018394470214844": 22, "01671600341797": 22, "0147590637207": 22, "01249313354492": 22, "00986862182617": 22, "0068359375": 22, "003334045410156": 22, "999298095703125": 22, "99464416503906": 22, "98926544189453": 22, "98302459716797": 22, "975791931152344": 22, "unisage_lay": 23, "unisagelay": 23, "chrsmrr": 23, "graphkerneldataset": 23, "unisagenn": 23, "unisag": 23, "38711929321289": 23, "50642013549805": 23, "88081741333008": 23, "313419342041016": 23, "208885192871094": 23, "00963592529297": 23, "59610366821289": 23, "292537689208984": 23, "19595718383789": 23, "106815338134766": 23, "913330078125": 23, "710723876953125": 23, "6346549987793": 23, "63870620727539": 23, "57096481323242": 23, "44948196411133": 23, "391658782958984": 23, "39373779296875": 23, "34821319580078": 23, "241302490234375": 23, "159812927246094": 23, "131492614746094": 23, "08507537841797": 23, "99526023864746": 23, "924638748168945": 23, "894010543823242": 23, "868173599243164": 23, "829978942871094": 23, "808109283447266": 23, "807811737060547": 23, "785655975341797": 23, "746475219726562": 23, "724843978881836": 23, "700727462768555": 23, "660417556762695": 23, "624387741088867": 23, "606855392456055": 23, "585779190063477": 23, "568805694580078": 23, "556062698364258": 23, "53620147705078": 23, "51841163635254": 23, "507102966308594": 23, "491756439208984": 23, "478620529174805": 23, "475711822509766": 23, "467418670654297": 23, "449710845947266": 23, "429576873779297": 23, "42317771911621": 23, "alexandro": 24, "kero": 24, "dist2cycle_lay": 24, "dist2cyclelay": 24, "linalg": [24, 26], "npla": 24, "a0": [24, 25], "becaus": [24, 25, 27, 29, 32], "serv": [24, 25], "simpli": [24, 25, 33], "demonstr": [24, 25], "similarli": [24, 25, 28], "emerg": [24, 25, 26, 28, 29], "four": [24, 25, 26, 28, 29], "y_true": [24, 25, 26, 29, 32], "ld": [24, 26], "l_tilde_pinv": 24, "pinv": 24, "invers": 24, "linv": 24, "x_1e": 24, "0971": 24, "0937": 24, "2140": 24, "2069": 24, "2927": 24, "3018": 24, "2309": 24, "0992": 24, "0943": 24, "0927": 24, "2678": 24, "3090": 24, "0960": 24, "2077": 24, "2056": 24, "2813": 24, "nnz": 24, "layout": 24, "sparse_coo": 24, "56771909e": 24, "49643084e": 24, "13434650e": 24, "60154799e": 24, "03": [24, 33], "73820292e": 24, "65885226e": 24, "04038181e": 24, "08": [24, 33], "51925802e": 24, "09": [24, 31, 33], "73643677e": 24, "95577741e": 24, "09312067e": 24, "39698386e": 24, "11006736e": 24, "25540316e": 24, "87149896e": 24, "65674657e": 24, "43987098e": 24, "79396772e": 24, "00662204e": 24, "45058060e": 24, "36910174e": 24, "82942520e": 24, "24798042e": 24, "85055751e": 24, "78386103e": 24, "24821486e": 24, "81510593e": 24, "07917011e": 24, "30485535e": 24, "19925834e": 24, "56662779e": 24, "25658545e": 24, "29514395e": 24, "73054542e": 24, "57650283e": 24, "87089108e": 24, "31973699e": 24, "45874534e": 24, "78385898e": 24, "24821523e": 24, "38282800e": 24, "29527006e": 24, "24821542e": 24, "45585343e": 24, "20149602e": 24, "39614227e": 24, "52603984e": 24, "02427802e": 24, "38569428e": 24, "20058507e": 24, "89658767e": 24, "67997003e": 24, "90682733e": 24, "88636552e": 24, "61071175e": 24, "75768661e": 24, "22418800e": 24, "07488209e": 24, "26928225e": 24, "52925774e": 24, "50903371e": 24, "71863856e": 24, "40345353e": 24, "36909867e": 24, "82943824e": 24, "90223058e": 24, "08467136e": 24, "43380561e": 24, "27135092e": 24, "31898531e": 24, "01219751e": 24, "78963115e": 24, "97890193e": 24, "49229891e": 24, "67953214e": 24, "75078206e": 24, "75904313e": 24, "03583546e": 24, "12457962e": 24, "10897127e": 24, "18870673e": 24, "28672193e": 24, "61245163e": 24, "48166016e": 24, "75217551e": 24, "67996958e": 24, "90682673e": 24, "44834775e": 24, "90006804e": 24, "59747154e": 24, "69860917e": 24, "59747209e": 24, "69862127e": 24, "59747284e": 24, "69861429e": 24, "59747191e": 24, "59747247e": 24, "69860823e": 24, "59747135e": 24, "11979373e": 24, "90869734e": 24, "59747228e": 24, "69860637e": 24, "59747303e": 24, "69861010e": 24, "59747116e": 24, "17587730e": 24, "43268425e": 24, "43105909e": 24, "32787512e": 24, "03376685e": 24, "44168448e": 24, "62169540e": 24, "41996737e": 24, "73246880e": 24, "97727704e": 24, "03496753e": 24, "71378374e": 24, "92902595e": 24, "15740368e": 24, "94057676e": 24, "48602486e": 24, "40909785e": 24, "14646482e": 24, "38315065e": 24, "76777497e": 24, "38311899e": 24, "76780128e": 24, "37373477e": 24, "49392605e": 24, "30545244e": 24, "10224779e": 24, "69429579e": 24, "59057510e": 24, "11831834e": 24, "86165255e": 24, "07662510e": 24, "53556532e": 24, "82225195e": 24, "76254632e": 24, "62731223e": 24, "63466549e": 24, "16528196e": 24, "62805045e": 24, "36022410e": 24, "48832843e": 24, "19494419e": 24, "13972221e": 24, "zia003": 24, "topox2": 24, "_index": [24, 28], "sparseefficiencywarn": [24, 28], "sparsiti": [24, 28], "lil_matrix": [24, 28], "effici": [24, 28, 31], "_set_arrayxarrai": [24, 28], "produc": [24, 25, 26, 28, 32, 34], "compar": [24, 25, 26, 28, 32, 34], "binary_cross_entropy_with_logit": [24, 25, 26, 28, 32, 34], "y_hat_test": [24, 25, 26, 28, 29, 32, 34], "y_pred_test": [24, 25, 26, 28, 29, 32, 34], "test_accuraci": [24, 25, 26, 28, 29, 32, 34], "eq": [24, 25, 26, 29, 32, 34], "7231": 24, "6000": 24, "6989": 24, "5667": [24, 25, 28, 29, 32], "2500": [24, 26, 29], "6737": 24, "6564": 24, "6434": 24, "6362": 24, "6290": 24, "4333": [24, 26], "6199": 24, "6117": 24, "6057": 24, "6011": 24, "5964": 24, "5911": 24, "5855": 24, "5764": 24, "4000": [24, 29], "5730": 24, "5696": 24, "5660": 24, "5593": 24, "5567": 24, "5544": 24, "5520": 24, "5496": 24, "5472": 24, "5451": 24, "5432": 24, "5414": 24, "5346": 24, "5333": 24, "5320": 24, "5308": 24, "5295": 24, "5284": 24, "5273": 24, "5264": 24, "5255": 24, "5238": 24, "5230": 24, "5223": 24, "5216": 24, "5210": 24, "5204": 24, "5198": 24, "5193": 24, "5183": 24, "5178": 24, "5174": 24, "5170": 24, "5166": 24, "5163": 24, "5159": 24, "5156": 24, "7216": 25, "7169": 25, "7151": 25, "7109": 25, "work": 26, "novel": 26, "hing": 26, "proper": [26, 34], "triangl": [26, 29, 33], "total": 26, "orient": 26, "fashion": 26, "2p": 26, "q_r": 26, "kernel": 26, "hodg": [26, 28, 29], "l_r": 26, "widetild": 26, "hy": 26, "neq": [26, 33], "affin": 26, "entri": [26, 29], "therefor": 26, "hop": [26, 32], "suppos": 26, "_j": 26, "underset": 26, "w_": 26, "q_": 26, "san_lay": 26, "sanlay": 26, "tb_1": 26, "b_2b_2": 26, "notic": 26, "pattern": 26, "simplic": [26, 28, 29, 32, 33], "just": [26, 28, 33], "maxium": 26, "simplex_order_k": 26, "ldown": 26, "valueerror": [26, 29, 32], "lup": 26, "gradient": 26, "tx_0": 26, "estim": 26, "multipli": 26, "diverg": 26, "deriv": 26, "seen": 26, "incidence_0_1": 26, "plu": 26, "accordingli": 26, "mm": 26, "henc": 26, "num_filters_j": 26, "approxim": [26, 33], "filter": [26, 29], "j_har": 26, "harmon": 26, "epsilon_har": 26, "compute_projection_matrix": 26, "matrix_pow": 26, "channels_in": 26, "y_hat_edg": 26, "fn": 26, "y_hat_edge_test": 26, "_pred_test": 26, "ge": 26, "7240": 26, "7114": 26, "7333": [26, 28], "6760": 26, "6721": [26, 28], "6685": 26, "6677": 26, "6672": 26, "qquad": 27, "sca_cmps_lay": 27, "scacmpslay": 27, "sc": [27, 29, 32, 33], "down_lap1_list": 27, "down_lap2_list": 27, "incidence1_t_list": 27, "incidence2_t_list": 27, "down_lap1": [27, 34], "down_lap2": 27, "incidence_1t": 27, "incidence_2t": 27, "channels_list": 27, "complex_dim": 27, "ampssca": 27, "tetahedron": 27, "complex_dimens": 27, "highest": [27, 33], "lin0": 27, "lin1": 27, "lin2": 27, "aggr": [27, 30], "x_list": 27, "down_lap_list": 27, "incidencet_list": 27, "x_2f": 27, "flatten": [27, 30], "x_1f": 27, "x_0f": 27, "down_lap1_train": 27, "down_lap1_test": 27, "down_lap2_train": 27, "down_lap2_test": 27, "incidence1_t_train": 27, "incidence1_t_test": 27, "incidence2_t_train": 27, "incidence2_t_test": 27, "hzpmc22": 27, "did": 27, "incidence_t_list": 27, "correct_count": [27, 30], "15074526998214": 27, "42108154296875": 27, "16418675570749": 27, "73768615722656": 27, "16661446671351": 27, "76749420166016": 27, "8968961050734": 27, "735595703125": 27, "84987897076644": 27, "7345199584961": 27, "18321903655306": 27, "809326171875": 27, "la": 28, "r_": 28, "mathrm": 28, "leq": [28, 33], "bigcup": 28, "sccn_layer": 28, "sccnlayer": 28, "feat_dim": 28, "arbitrari": 28, "maximum": [28, 33], "max_rank": [28, 29, 32], "choos": [28, 33], "dictionari": 28, "tha": 28, "arbitrarili": 28, "formul": 28, "quit": 28, "close": 28, "h_r": 28, "2i": 28, "usual": 28, "suggest": 28, "refrain": 28, "tetrahedron": 28, "sparse_to_torch": 28, "rank_": 28, "rank_0": 28, "coadjacency_matrix": [28, 29], "h0": 28, "h1": 28, "b2": [28, 29, 30, 32], "h3": 28, "b3": 28, "tmx": 28, "x_3": 28, "tetrahedron_feat": 28, "track": 28, "rank_1": 28, "rank_2": 28, "rank_3": 28, "dict": 28, "n_rank_r_cel": 28, "n_rank_r_minus_1_cel": 28, "squeez": [28, 33], "typic": 28, "6333": [28, 29], "6173": 28, "6110": 28, "5831": 28, "5695": 28, "5638": 28, "5493": 28, "5384": 28, "7667": 28, "5141": 28, "5201": 28, "5038": 28, "5016": 28, "4906": 28, "4763": 28, "4545": 28, "4483": 28, "4153": 28, "8000": 28, "4062": 28, "3790": 28, "8333": 28, "3916": 28, "3529": 28, "8667": 28, "2900": 28, "2359": 28, "9333": 28, "2002": 28, "9667": 28, "2970": 28, "9000": 28, "2032": 28, "2329": 28, "0272": 28, "0264": 28, "0245": 28, "0207": 28, "0165": 28, "0132": 28, "0114": 28, "0113": 28, "0117": 28, "0101": 28, "0081": 28, "0071": 28, "0065": 28, "0061": 28, "0057": 28, "0054": 28, "0050": 28, "0046": 28, "0043": 28, "0040": 28, "0038": 28, "0036": 28, "0034": 28, "0033": 28, "0032": 28, "0031": 28, "0030": 28, "0029": [28, 31], "0028": 28, "0027": 28, "0026": 28, "0025": 28, "0024": 28, "0023": 28, "0022": 28, "0021": 28, "0020": 28, "0019": 28, "0018": 28, "0017": 28, "0016": 28, "0015": 28, "0014": 28, "0013": 28, "0012": 28, "0011": 28, "0010": 28, "0009": 28, "0008": 28, "scnn": 29, "account": 29, "At": [29, 32], "_t": [29, 32], "p_d": [29, 32], "p_u": [29, 32], "likewis": 29, "essenti": 29, "sccnn_layer": 29, "sccnnlayer": 29, "in_channels_al": 29, "_1": [29, 30, 32], "_2": [29, 30], "_0": 29, "yet": [29, 32], "laplacian_0_list": [29, 32], "laplacian_down_1_list": [29, 32], "laplacian_up_1_list": [29, 32], "laplacian_2_list": [29, 32], "laplacian_0": [29, 31, 32], "hodge_laplacian_matrix": [29, 32], "laplacian_down_1": [29, 32], "laplacian_up_1": [29, 32], "laplacian_2": [29, 31, 32], "amend": 29, "intermediate_channels_al": 29, "out_channels_al": 29, "conv_ord": 29, "sc_order": 29, "numer": [29, 32], "in_linear_0": 29, "in_linear_1": 29, "in_linear_2": 29, "out_channels_0": 29, "out_channels_1": 29, "out_channels_2": 29, "out_linear_0": 29, "out_linear_1": 29, "out_linear_2": 29, "x_all": 29, "laplacian_al": 29, "incidence_al": 29, "n_simplic": [29, 32], "l0": 29, "l1_d": 29, "l1_u": 29, "l2": 29, "pf": 29, "in_x_0": 29, "in_x_1": 29, "in_x_2": 29, "size_averag": 29, "laplacian_0_train": 29, "laplacian_0_test": 29, "laplacian_down_1_train": 29, "laplacian_down_1_test": 29, "laplacian_up_1_train": 29, "laplacian_up_1_test": 29, "laplacian_2_train": 29, "laplacian_2_test": 29, "288238": 29, "2517": 29, "7562": 29, "7251": 29, "7232": 29, "9496": 29, "2592": 29, "7179": 29, "8378": 29, "7978": 29, "laplacian_down_2": [29, 32], "laplacian_up_2": [29, 32], "get_simplicial_featur": [29, 32], "which_feat": [29, 32], "elif": [29, 32], "binary_cross_entropi": 29, "0333": 29, "6766": 29, "3667": 29, "6162": 29, "bunch": 30, "tild": 30, "rightarrow1": 30, "coo_matrix": 30, "diag": 30, "scconv_lay": 30, "scconvlay": 30, "return_count": 30, "normalize_higher_order_adj": 30, "a_opt": 30, "cochain": 30, "num_of_k_simplic": 30, "num_of_j_simplic": 30, "rowsum": 30, "r_inv_sqrt": 30, "power": 30, "isinf": 30, "r_mat_inv_sqrt": 30, "a_opt_to": 30, "dot": 30, "neigborood": 30, "ssconv": 30, "incidence_1_norm": 30, "incidence_2_norm": 30, "adjacency_up_0_norm": 30, "adjacency_up_1_norm": 30, "adjacency_down_1_norm": 30, "adjacency_down_2_norm": 30, "get_neighborhood": 30, "incidence_1_norm_list": 30, "incidence_2_norm_list": 30, "adjacency_up_0_norm_list": 30, "adjacency_up_1_norm_list": 30, "adjacency_down_1_norm_list": 30, "adjacency_down_2_norm_list": 30, "up_laplacian_1_list": 30, "up_laplacian_2_list": 30, "down_laplacian_1_list": 30, "down_laplacian_2_list": 30, "up_laplacian_1": 30, "up_laplacian_2": 30, "down_laplacian_1": 30, "down_laplacian_2": 30, "edge_channel": [30, 34], "face_channel": 30, "linear_x0": 30, "linear_x1": 30, "linear_x2": 30, "node_mean": 30, "edge_mean": 30, "face_mean": 30, "todo": 30, "kha053": 30, "nvml": 30, "incid1": 30, "incid1_norm": 30, "incid2": 30, "incid2_norm": 30, "adj0_up_norm": 30, "adj1_up_norm": 30, "adj1_down_norm": 30, "adj2_down_norm": 30, "x_0t": 30, "x_1t": 30, "x_2t": 30, "incid1t": 30, "incid1_normt": 30, "incid2t": 30, "incid2_normt": 30, "adj0_up_normt": 30, "adj1_up_normt": 30, "adj1_down_normt": 30, "adj2_down_normt": 30, "yt": 30, "yang22c": 31, "ysb22": 31, "ruochen": 31, "freder": 31, "sala": 31, "bogdan": 31, "razvan": 31, "pascanu": 31, "editor": 31, "proceed": 31, "confer": [31, 32], "volum": 31, "pmlr": 31, "dec": 31, "2022a": 31, "mlr": 31, "press": 31, "v198": 31, "yang22a": 31, "scn2_layer": 31, "scn2layer": 31, "chose": 31, "reshap": 31, "laplacian_1": 31, "normalized_laplacian_matrix": 31, "scn2": 31, "x_0s_train": 31, "x_0s_test": 31, "x_1s_train": 31, "x_1s_test": 31, "x_2s_train": 31, "x_2s_test": 31, "laplacian_0s_train": 31, "laplacian_0s_test": 31, "laplacian_1s_train": 31, "laplacian_1s_test": 31, "laplacian_2s_train": 31, "laplacian_2s_test": 31, "3329": 31, "0158": 31, "3648": 31, "2150": 31, "6805": 31, "8108": 31, "7633": 31, "3024": 31, "itself": 32, "scnn_layer": 32, "scnnlayer": 32, "simplci": 32, "challeng": 32, "conv_order_down": 32, "conv_order_up": 32, "inter_channel": 32, "laplacian_down": 32, "laplacian_up": 32, "larger": 32, "x_train": 32, "x_test": 32, "laplacian_down_train": 32, "laplacian_down_test": 32, "laplacian_up_train": 32, "laplacian_up_test": 32, "simplex_order_select": 32, "8446": 32, "4423": 32, "6270": 32, "9483": 32, "9201": 32, "3076": 32, "6582": 32, "2524": 32, "maxim": 32, "chennel_edg": 32, "channel_fac": 32, "certain": 32, "classm": 32, "rm": 32, "mitchel": 32, "nichola": 32, "glaze": 32, "santiago": 32, "segarra": 32, "principl": [32, 33], "trajectori": 32, "channels_x": 32, "7199": 32, "7196": 32, "7194": [32, 34], "7192": 32, "7190": 32, "rgs21": 33, "spend": 33, "synthet": 33, "ahead": 33, "itertool": 33, "product": 33, "tnx": 33, "networkx": 33, "nx": 33, "random_split": 33, "spatial": 33, "delaunai": 33, "distanc": 33, "scone_lay": 33, "sconelay": [33, 34], "seed": 33, "lt": 33, "_c": 33, "0x15d64d0b0": 33, "less": 33, "uniformli": 33, "point": 33, "triangul": 33, "cloud": 33, "disk": 33, "insid": 33, "remov": 33, "centroid": 33, "generate_complex": 33, "delet": 33, "uniform": 33, "sort": 33, "coordin": 33, "argsort": 33, "tri": 33, "disk_cent": 33, "disk_radiu": 33, "indices_includ": 33, "cdist": 33, "idx_dict": 33, "coord": 33, "instanc": 33, "euclidean": 33, "shortest": 33, "path": 33, "plot_complex": 33, "plane": 33, "idx": 33, "poli": 33, "polygon": 33, "color": 33, "green": 33, "gca": 33, "add_patch": 33, "vstack": 33, "i_1": 33, "i_2": 33, "ldot": 33, "i_m": 33, "i_j": 33, "i_": 33, "neighbour": 33, "ground": 33, "truth": 33, "supervis": 33, "setup": 33, "subsect": 33, "randomli": 33, "pick": 33, "triplet": 33, "corner": 33, "around": 33, "middl": 33, "anti": 33, "diagon": 33, "n_max": 33, "determin": 33, "generate_trajectori": 33, "mid": 33, "region": 33, "start_nod": 33, "mid_nod": 33, "end_nod": 33, "all_triplet": 33, "increas": 33, "underli": 33, "distance_matrix": 33, "squareform": 33, "pdist": 33, "toarrai": 33, "from_numpy_arrai": 33, "path_1": 33, "shortest_path": 33, "path_2": 33, "plot_path": 33, "red": 33, "arrow": 33, "quiver": 33, "scale_unit": 33, "angl": [33, 34], "scale": 33, "yield": 33, "vectorized_trajectori": 33, "neigbors_mask": 33, "last_nod": 33, "turn": 33, "a_1": 33, "a_2": 33, "a_j": 33, "i_n": 33, "later": [33, 34], "trajectoriesdataset": 33, "lookup": 33, "speed": 33, "edge_lookup_t": 33, "__getitem__": 33, "vectorize_path": 33, "discard": 33, "neighbors_mask": 33, "__len__": 33, "c0": 33, "batch": 33, "loader": 33, "batch_siz": 33, "val_siz": 33, "train_siz": 33, "train_d": 33, "val_d": 33, "test_d": 33, "train_dl": 33, "val_dl": 33, "test_dl": 33, "c_1": 33, "chain": 33, "partial_1": 33, "c_0": 33, "That": 33, "hat": 33, "_m": 33, "hidden_dim": 33, "init": 33, "xavier_uniform_": 33, "hidden_dimens": 33, "inf": 33, "log_softmax": 33, "neg": 33, "likelihood": 33, "penal": 33, "weight_decai": 33, "5e": 33, "loss_funct": 33, "nllloss": 33, "nll": 33, "training_histori": 33, "training_loss": 33, "traj": 33, "06": 33, "quick": 33, "confirm": 33, "everyth": 33, "reason": 33, "ax": 33, "ncol": 33, "figsiz": 33, "better": 33, "guess": 33, "3f": 33, "constructor": 33, "affect": 33, "capabl": 33, "revers": 33, "Or": 33, "ocean": 33, "drifter": 33, "scone_layer_bi": 34, "pyt": 34, "area": 34, "up_lap1": 34, "gather": 34, "pair": 34, "train_indic": 34, "test_indic": 34, "sconenn": 34, "iden": 34, "OF": 34, "7211": 34, "7185": 34, "5484": 34, "7205": 34, "7210": 34, "ajbr": 34, "appdata": 34, "temp": 34, "ipykernel_492": 34, "1152818844": 34, "recommend": 34, "sourcetensor": 34, "detach": 34, "requires_grad_": 34}, "objects": {"topomodelx.base": [[0, 0, 0, "-", "aggregation"], [0, 0, 0, "-", "conv"], [0, 0, 0, "-", "message_passing"]], "topomodelx.base.aggregation": [[0, 1, 1, "", "Aggregation"]], "topomodelx.base.aggregation.Aggregation": [[0, 2, 1, "", "forward"], [0, 2, 1, "", "update"]], "topomodelx.base.conv": [[0, 1, 1, "", "Conv"]], "topomodelx.base.conv.Conv": [[0, 2, 1, "", "forward"], [0, 2, 1, "", "update"]], "topomodelx.base.message_passing": [[0, 1, 1, "", "MessagePassing"]], "topomodelx.base.message_passing.MessagePassing": [[0, 2, 1, "", "aggregate"], [0, 2, 1, "", "attention"], [0, 2, 1, "", "forward"], [0, 2, 1, "", "message"], [0, 2, 1, "", "reset_parameters"]], "topomodelx.nn.cell": [[2, 0, 0, "-", "ccxn_layer"]], "topomodelx.nn.cell.ccxn_layer": [[2, 1, 1, "", "CCXNLayer"]], "topomodelx.nn.cell.ccxn_layer.CCXNLayer": [[2, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph": [[2, 0, 0, "-", "template_layer"]], "topomodelx.nn.hypergraph.template_layer": [[2, 1, 1, "", "TemplateLayer"]], "topomodelx.nn.hypergraph.template_layer.TemplateLayer": [[2, 2, 1, "", "forward"], [2, 2, 1, "", "reset_parameters"]], "topomodelx.nn.simplicial": [[2, 0, 0, "-", "hsn_layer"]], "topomodelx.nn.simplicial.hsn_layer": [[2, 1, 1, "", "HSNLayer"]], "topomodelx.nn.simplicial.hsn_layer.HSNLayer": [[2, 2, 1, "", "forward"], [2, 2, 1, "", "reset_parameters"]], "topomodelx.utils": [[3, 0, 0, "-", "scatter"]], "topomodelx.utils.scatter": [[3, 3, 1, "", "broadcast"], [3, 3, 1, "", "scatter"], [3, 3, 1, "", "scatter_add"], [3, 3, 1, "", "scatter_mean"], [3, 3, 1, "", "scatter_sum"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"]}, "titleterms": {"base": 0, "api": 1, "refer": [1, 6, 31], "packag": 1, "modul": 1, "neural": [2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "network": [2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "hypergraph": [2, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21], "simplici": [2, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34], "complex": [2, 9, 27, 28, 29, 30, 33, 34], "cell": [2, 7, 9], "util": 3, "scatter": 3, "icml": 4, "2023": 4, "topolog": 4, "deep": 4, "learn": 4, "challeng": 4, "descript": 4, "public": 4, "outcom": 4, "particip": 4, "deadlin": 4, "how": 4, "submit": 4, "guidelin": 4, "submiss": 4, "requir": 4, "evalu": [4, 33], "question": 4, "contribut": 5, "make": 5, "chang": 5, "write": 5, "test": [5, 27, 30, 32, 33, 34], "run": 5, "document": 5, "intro": 5, "docstr": 5, "The": [5, 7, 8, 9, 10, 26], "anatomi": 5, "exampl": 5, "topomodelx": 6, "tmx": 6, "get": 6, "start": 6, "train": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "attent": [7, 8, 9, 26], "can": [7, 8], "abstract": [7, 26], "task": [7, 8, 9, 10, 26], "set": [7, 8, 9, 10], "up": [7, 8, 9, 10], "pre": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "process": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34], "creat": [7, 8, 9, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "cellular": 8, "convolut": [9, 28, 29, 30, 31, 32], "ccxn": 9, "cw": 10, "cwn": 10, "addit": [11, 12, 18], "theoret": [11, 12, 18], "clarif": [11, 12, 18], "defin": [12, 13, 15, 17, 18, 19, 24, 25, 28, 29, 30, 31, 32, 34], "import": [13, 15, 17, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34], "data": [13, 17, 19, 20, 21, 22, 23, 27, 30, 33], "neighborhood": [13, 15, 17, 19, 24, 25, 28, 29, 31, 32, 34], "structur": [13, 15, 17, 19, 24, 25, 28, 30, 31, 34], "lift": [13, 17, 19], "domain": [13, 17, 19], "messag": [14, 27], "pass": [14, 27], "hmpnn": 14, "hyperedg": [15, 16], "neuron": [15, 16], "hnhn": [15, 16], "dataset": [15, 24, 25, 28, 29, 30, 31, 32, 33, 34], "signal": [15, 24, 25, 28, 29, 32], "us": 21, "unigcnii": 21, "layer": 21, "load": 21, "homologi": 24, "local": 24, "dist2cycl": 24, "binari": [24, 25, 28, 29, 32], "label": [24, 25, 28, 29, 32, 34], "featur": 24, "high": 25, "skip": 25, "hsn": 25, "san": 26, "autoencod": 27, "sca": 27, "coadjac": 27, "scheme": 27, "cmp": 27, "prepar": [27, 30, 32, 34], "input": [27, 34], "each": 27, "split": [27, 32, 34], "model": [27, 29, 32, 33], "sccn": 28, "sccnn": 29, "we": [29, 32], "perform": [29, 32], "1": [29, 32], "classif": [29, 32], "shrec": 29, "strcture": [29, 32], "2": [29, 30, 31, 32], "node": [29, 32], "scconv": 30, "helper": 30, "function": 30, "neighbourhood": 30, "simplex": 31, "scn": 31, "rank": 31, "scnn": 32, "compl": 32, "karat": 32, "weight": 32, "hodg": 32, "laplacian": 32, "net": 33, "scone": [33, 34], "tabl": 33, "content": 33, "gener": 33, "trajectori": 33, "pytorch": 33, "dataload": 33, "suggest": 33, "further": 33, "experiment": 33, "tutori": 35}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.viewcode": 1, "sphinx": 60}, "alltitles": {"Base": [[0, "module-topomodelx.base.message_passing"]], "API Reference": [[1, "api-reference"]], "Packages & Modules": [[1, null]], "Neural Networks": [[2, "neural-networks"]], "Hypergraph Neural Networks": [[2, "module-topomodelx.nn.hypergraph.template_layer"]], "Simplicial Complex Neural Networks": [[2, "module-topomodelx.nn.simplicial.hsn_layer"]], "Cell Complex Neural Networks": [[2, "module-topomodelx.nn.cell.ccxn_layer"]], "Utils": [[3, "utils"]], "Scatter": [[3, "module-topomodelx.utils.scatter"]], "ICML 2023 Topological Deep Learning Challenge": [[4, "icml-2023-topological-deep-learning-challenge"]], "Description of the Challenge": [[4, "description-of-the-challenge"]], "\u2b50\ufe0f Publication Outcomes for Participants \u2b50\ufe0f": [[4, "publication-outcomes-for-participants"]], "Deadline": [[4, "deadline"]], "How to Submit": [[4, "how-to-submit"]], "Guidelines": [[4, "guidelines"]], "Submission Requirements": [[4, "submission-requirements"]], "Evaluation": [[4, "evaluation"]], "Questions": [[4, "questions"]], "Contributing": [[5, "contributing"]], "Making Changes": [[5, "making-changes"]], "Write Tests": [[5, "write-tests"]], "Run Tests": [[5, "run-tests"]], "Write Documentation": [[5, "write-documentation"]], "Intro to Docstrings": [[5, "intro-to-docstrings"]], "The Anatomy of a Docstring": [[5, "the-anatomy-of-a-docstring"]], "Docstring Examples": [[5, "docstring-examples"]], "\ud83c\udf10 TopoModelX (TMX) \ud83c\udf69": [[6, "topomodelx-tmx"]], "\ud83d\udd0d References": [[6, "references"]], "\ud83e\uddbe Getting Started": [[6, "getting-started"]], "Train a Cell Attention Network (CAN)": [[7, "Train-a-Cell-Attention-Network-(CAN)"]], "Abstract:": [[7, "Abstract:"]], "The Neural Network:": [[7, "The-Neural-Network:"], [8, "The-Neural-Network:"], [9, "The-Neural-Network:"], [10, "The-Neural-Network:"]], "The Task:": [[7, "The-Task:"], [8, "The-Task:"], [9, "The-Task:"], [10, "The-Task:"], [26, "The-Task:"]], "Set-up": [[7, "Set-up"], [8, "Set-up"], [9, "Set-up"], [10, "Set-up"]], "Pre-processing": [[7, "Pre-processing"], [8, "Pre-processing"], [9, "Pre-processing"], [10, "Pre-processing"], [11, "Pre-processing"], [12, "Pre-processing"], [13, "Pre-processing"], [14, "Pre-processing"], [15, "Pre-processing"], [16, "Pre-processing"], [17, "Pre-processing"], [18, "Pre-processing"], [19, "Pre-processing"], [20, "Pre-processing"], [22, "Pre-processing"], [23, "Pre-processing"], [24, "Pre-processing"], [25, "Pre-processing"], [26, "Pre-processing"], [27, "Pre-processing"], [28, "Pre-processing"], [29, "Pre-processing"], [30, "Pre-processing"], [31, "Pre-processing"], [32, "Pre-processing"], [34, "Pre-processing"]], "Create the Neural Network": [[7, "Create-the-Neural-Network"], [8, "Create-the-Neural-Network"], [9, "Create-the-Neural-Network"], [10, "Create-the-Neural-Network"], [11, "Create-the-Neural-Network"], [13, "Create-the-Neural-Network"], [14, "Create-the-Neural-Network"], [15, "Create-the-Neural-Network"], [16, "Create-the-Neural-Network"], [19, "Create-the-Neural-Network"], [20, "Create-the-Neural-Network"], [22, "Create-the-Neural-Network"], [23, "Create-the-Neural-Network"], [24, "Create-the-Neural-Network"], [25, "Create-the-Neural-Network"], [26, "Create-the-Neural-Network"], [28, "Create-the-Neural-Network"], [30, "Create-the-Neural-Network"], [31, "Create-the-Neural-Network"]], "Train the Neural Network": [[7, "Train-the-Neural-Network"], [8, "Train-the-Neural-Network"], [9, "Train-the-Neural-Network"], [10, "Train-the-Neural-Network"], [11, "Train-the-Neural-Network"], [12, "Train-the-Neural-Network"], [13, "Train-the-Neural-Network"], [14, "Train-the-Neural-Network"], [15, "Train-the-Neural-Network"], [16, "Train-the-Neural-Network"], [17, "Train-the-Neural-Network"], [18, "Train-the-Neural-Network"], [19, "Train-the-Neural-Network"], [20, "Train-the-Neural-Network"], [22, "Train-the-Neural-Network"], [23, "Train-the-Neural-Network"], [24, "Train-the-Neural-Network"], [25, "Train-the-Neural-Network"], [26, "Train-the-Neural-Network"], [28, "Train-the-Neural-Network"], [29, "Train-the-Neural-Network"], [29, "id3"], [30, "Train-the-Neural-Network"], [31, "Train-the-Neural-Network"], [32, "Train-the-Neural-Network"]], "Train a Cellular Attention Network (CAN)": [[8, "Train-a-Cellular-Attention-Network-(CAN)"]], "Train the Neural Network with Attention": [[8, "Train-the-Neural-Network-with-Attention"], [9, "Train-the-Neural-Network-with-Attention"]], "Train a Convolutional Cell Complex Network (CCXN)": [[9, "Train-a-Convolutional-Cell-Complex-Network-(CCXN)"]], "Train a CW Network (CWN)": [[10, "Train-a-CW-Network-(CWN)"]], "Train a Hypergraph Neural Network": [[11, "Train-a-Hypergraph-Neural-Network"], [12, "Train-a-Hypergraph-Neural-Network"], [13, "Train-a-Hypergraph-Neural-Network"], [17, "Train-a-Hypergraph-Neural-Network"], [18, "Train-a-Hypergraph-Neural-Network"], [19, "Train-a-Hypergraph-Neural-Network"]], "Additional theoretical clarifications": [[11, "Additional-theoretical-clarifications"], [12, "Additional-theoretical-clarifications"], [18, "Additional-theoretical-clarifications"]], "Define the Neural Network": [[12, "Define-the-Neural-Network"], [17, "Define-the-Neural-Network"], [18, "Define-the-Neural-Network"]], "Import data": [[13, "Import-data"], [17, "Import-data"], [19, "Import-data"], [20, "Import-data"], [22, "Import-data"], [23, "Import-data"], [27, "Import-data"]], "Define neighborhood structures and lift into hypergraph domain.": [[13, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."], [17, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."], [19, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."]], "Train a Hypergraph Message Passing Neural Network (HMPNN)": [[14, "Train-a-Hypergraph-Message-Passing-Neural-Network-(HMPNN)"]], "Train a Hypergraph Networks with Hyperedge Neurons (HNHN)": [[15, "Train-a-Hypergraph-Networks-with-Hyperedge-Neurons-(HNHN)"]], "Import dataset": [[15, "Import-dataset"], [24, "Import-dataset"], [25, "Import-dataset"], [28, "Import-dataset"], [30, "Import-dataset"], [31, "Import-dataset"], [34, "Import-dataset"]], "Define neighborhood structures.": [[15, "Define-neighborhood-structures."], [24, "Define-neighborhood-structures."], [25, "Define-neighborhood-structures."], [28, "Define-neighborhood-structures."], [31, "Define-neighborhood-structures."]], "Import signal": [[15, "Import-signal"], [24, "Import-signal"], [25, "Import-signal"], [28, "Import-signal"], [29, "Import-signal"]], "Train a Hypergraph Network with Hyperedge Neurons (HNHN)": [[16, "Train-a-Hypergraph-Network-with-Hyperedge-Neurons-(HNHN)"]], "Train a hypergraph neural network using UniGCNII layers": [[21, "Train-a-hypergraph-neural-network-using-UniGCNII-layers"]], "Loading the data": [[21, "Loading-the-data"]], "Creating a neural network": [[21, "Creating-a-neural-network"]], "Training the neural network": [[21, "Training-the-neural-network"]], "Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)": [[24, "Train-a-Simplicial-Neural-Network-for-Homology-Localization-(Dist2Cycle)"]], "Define binary labels": [[24, "Define-binary-labels"], [25, "Define-binary-labels"], [28, "Define-binary-labels"], [29, "Define-binary-labels"]], "Create Features": [[24, "Create-Features"]], "Train a Simplicial High-Skip Network (HSN)": [[25, "Train-a-Simplicial-High-Skip-Network-(HSN)"]], "Train a Simplicial Attention Network (SAN)": [[26, "Train-a-Simplicial-Attention-Network-(SAN)"]], "Abstract": [[26, "Abstract"]], "The Neural Network": [[26, "The-Neural-Network"]], "Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)": [[27, "Train-a-Simplicial-Complex-Autoencoder-(SCA)-with-Coadjacency-Message-Passing-Scheme-(CMPS)"]], "Preparing the inputs to test each message passing scheme:": [[27, "Preparing-the-inputs-to-test-each-message-passing-scheme:"]], "Coadjacency Message Passing Scheme (CMPS):": [[27, "Coadjacency-Message-Passing-Scheme-(CMPS):"]], "Create the Neural Networks": [[27, "Create-the-Neural-Networks"]], "Train and Test Split": [[27, "Train-and-Test-Split"]], "Training and Testing Model": [[27, "Training-and-Testing-Model"]], "Train a Simplicial Complex Convolutional Network (SCCN)": [[28, "Train-a-Simplicial-Complex-Convolutional-Network-(SCCN)"]], "Train a SCCNN": [[29, "Train-a-SCCNN"]], "We train the model to perform:": [[29, "We-train-the-model-to-perform:"], [32, "We-train-the-model-to-perform:"]], "Simplicial Complex Convolutional Neural Networks [SCCNN]": [[29, "Simplicial-Complex-Convolutional-Neural-Networks-[SCCNN]"]], "1. Complex Classification": [[29, "1.-Complex-Classification"]], "Import shrec dataset": [[29, "Import-shrec-dataset"]], "Define Neighborhood Strctures": [[29, "Define-Neighborhood-Strctures"], [29, "id1"], [32, "Define-Neighborhood-Strctures"], [32, "id1"]], "Create the SCCNN": [[29, "Create-the-SCCNN"], [29, "id2"]], "2. Node Classification": [[29, "2.-Node-Classification"], [32, "2.-Node-Classification"]], "Train a Simplicial 2-complex convolutional neural network (SCConv)": [[30, "Train-a-Simplicial-2-complex-convolutional-neural-network-(SCConv)"]], "Helper functions": [[30, "Helper-functions"]], "Define Neighbourhood Structures": [[30, "Define-Neighbourhood-Structures"]], "prepare training and test data": [[30, "prepare-training-and-test-data"]], "Train a Simplex Convolutional Network (SCN) of Rank 2": [[31, "Train-a-Simplex-Convolutional-Network-(SCN)-of-Rank-2"]], "References": [[31, "References"]], "Train a Simplicial Convolutional Neural Network (SCNN)": [[32, "Train-a-Simplicial-Convolutional-Neural-Network-(SCNN)"]], "Simplicial Convolutional Neural Networks [SCNN]": [[32, "Simplicial-Convolutional-Neural-Networks-[SCNN]"]], "1. Comples Classification": [[32, "1.-Comples-Classification"]], "Create the SCNN": [[32, "Create-the-SCNN"]], "Import Karate dataset": [[32, "Import-Karate-dataset"]], "Weighted Hodge Laplacians": [[32, "Weighted-Hodge-Laplacians"]], "Import signals": [[32, "Import-signals"]], "Define binary labels and Prepare the training-testing split": [[32, "Define-binary-labels-and-Prepare-the-training-testing-split"]], "Create the SCNN for node classification": [[32, "Create-the-SCNN-for-node-classification"]], "Train the SCNN": [[32, "Train-the-SCNN"]], "Train a Simplicial Complex Net (SCoNe)": [[33, "Train-a-Simplicial-Complex-Net-(SCoNe)"]], "Table of contents": [[33, "Table-of-contents"]], "Dataset generation": [[33, "Dataset-generation"]], "Generating trajectories": [[33, "Generating-trajectories"]], "Creating PyTorch dataloaders": [[33, "Creating-PyTorch-dataloaders"]], "Creating the Neural Network": [[33, "Creating-the-Neural-Network"]], "Training the Neural Network": [[33, "Training-the-Neural-Network"], [34, "Training-the-Neural-Network"]], "Evaluating the model on test data": [[33, "Evaluating-the-model-on-test-data"]], "Suggestions for further experimentation": [[33, "Suggestions-for-further-experimentation"]], "Train a Simplicial Complex Network (SCoNe)": [[34, "Train-a-Simplicial-Complex-Network-(SCoNe)"]], "Define Neighborhood Structures": [[34, "Define-Neighborhood-Structures"]], "Defining Labels and Preparing Input": [[34, "Defining-Labels-and-Preparing-Input"]], "Train/Test Split": [[34, "Train/Test-Split"]], "Creating Neural Network": [[34, "Creating-Neural-Network"]], "Tutorials": [[35, "tutorials"]]}, "indexentries": {"aggregation (class in topomodelx.base.aggregation)": [[0, "topomodelx.base.aggregation.Aggregation"]], "conv (class in topomodelx.base.conv)": [[0, "topomodelx.base.conv.Conv"]], "messagepassing (class in topomodelx.base.message_passing)": [[0, "topomodelx.base.message_passing.MessagePassing"]], "aggregate() (topomodelx.base.message_passing.messagepassing method)": [[0, "topomodelx.base.message_passing.MessagePassing.aggregate"]], "attention() (topomodelx.base.message_passing.messagepassing method)": [[0, "topomodelx.base.message_passing.MessagePassing.attention"]], "forward() (topomodelx.base.aggregation.aggregation method)": [[0, "topomodelx.base.aggregation.Aggregation.forward"]], "forward() (topomodelx.base.conv.conv method)": [[0, "topomodelx.base.conv.Conv.forward"]], "forward() (topomodelx.base.message_passing.messagepassing method)": [[0, "topomodelx.base.message_passing.MessagePassing.forward"]], "message() (topomodelx.base.message_passing.messagepassing method)": [[0, "topomodelx.base.message_passing.MessagePassing.message"]], "module": [[0, "module-topomodelx.base.aggregation"], [0, "module-topomodelx.base.conv"], [0, "module-topomodelx.base.message_passing"], [2, "module-topomodelx.nn.cell.ccxn_layer"], [2, "module-topomodelx.nn.hypergraph.template_layer"], [2, "module-topomodelx.nn.simplicial.hsn_layer"], [3, "module-topomodelx.utils.scatter"]], "reset_parameters() (topomodelx.base.message_passing.messagepassing method)": [[0, "topomodelx.base.message_passing.MessagePassing.reset_parameters"]], "topomodelx.base.aggregation": [[0, "module-topomodelx.base.aggregation"]], "topomodelx.base.conv": [[0, "module-topomodelx.base.conv"]], "topomodelx.base.message_passing": [[0, "module-topomodelx.base.message_passing"]], "update() (topomodelx.base.aggregation.aggregation method)": [[0, "topomodelx.base.aggregation.Aggregation.update"]], "update() (topomodelx.base.conv.conv method)": [[0, "topomodelx.base.conv.Conv.update"]], "ccxnlayer (class in topomodelx.nn.cell.ccxn_layer)": [[2, "topomodelx.nn.cell.ccxn_layer.CCXNLayer"]], "hsnlayer (class in topomodelx.nn.simplicial.hsn_layer)": [[2, "topomodelx.nn.simplicial.hsn_layer.HSNLayer"]], "templatelayer (class in topomodelx.nn.hypergraph.template_layer)": [[2, "topomodelx.nn.hypergraph.template_layer.TemplateLayer"]], "forward() (topomodelx.nn.cell.ccxn_layer.ccxnlayer method)": [[2, "topomodelx.nn.cell.ccxn_layer.CCXNLayer.forward"]], "forward() (topomodelx.nn.hypergraph.template_layer.templatelayer method)": [[2, "topomodelx.nn.hypergraph.template_layer.TemplateLayer.forward"]], "forward() (topomodelx.nn.simplicial.hsn_layer.hsnlayer method)": [[2, "topomodelx.nn.simplicial.hsn_layer.HSNLayer.forward"]], "reset_parameters() (topomodelx.nn.hypergraph.template_layer.templatelayer method)": [[2, "topomodelx.nn.hypergraph.template_layer.TemplateLayer.reset_parameters"]], "reset_parameters() (topomodelx.nn.simplicial.hsn_layer.hsnlayer method)": [[2, "topomodelx.nn.simplicial.hsn_layer.HSNLayer.reset_parameters"]], "topomodelx.nn.cell.ccxn_layer": [[2, "module-topomodelx.nn.cell.ccxn_layer"]], "topomodelx.nn.hypergraph.template_layer": [[2, "module-topomodelx.nn.hypergraph.template_layer"]], "topomodelx.nn.simplicial.hsn_layer": [[2, "module-topomodelx.nn.simplicial.hsn_layer"]], "broadcast() (in module topomodelx.utils.scatter)": [[3, "topomodelx.utils.scatter.broadcast"]], "scatter() (in module topomodelx.utils.scatter)": [[3, "topomodelx.utils.scatter.scatter"]], "scatter_add() (in module topomodelx.utils.scatter)": [[3, "topomodelx.utils.scatter.scatter_add"]], "scatter_mean() (in module topomodelx.utils.scatter)": [[3, "topomodelx.utils.scatter.scatter_mean"]], "scatter_sum() (in module topomodelx.utils.scatter)": [[3, "topomodelx.utils.scatter.scatter_sum"]], "topomodelx.utils.scatter": [[3, "module-topomodelx.utils.scatter"]]}})