Search.setIndex({"docnames": ["api/base", "api/index", "api/nn", "api/utils", "challenge/index", "contributing/index", "index", "notebooks/cell/can_train", "notebooks/cell/ccxn_train", "notebooks/cell/cwn_train", "notebooks/hypergraph/allsettransformer_train", "notebooks/hypergraph/dhgcn_train", "notebooks/hypergraph/hmpnn_train", "notebooks/hypergraph/hnhn_train", "notebooks/hypergraph/hnhn_train_bis", "notebooks/hypergraph/hypergat_train", "notebooks/hypergraph/hypersage_train", "notebooks/hypergraph/template_train", "notebooks/hypergraph/unigcnii_train", "notebooks/hypergraph/unigin_train", "notebooks/hypergraph/unisage_train", "notebooks/simplicial/dist2cycle_train", "notebooks/simplicial/hsn_train", "notebooks/simplicial/san_train", "notebooks/simplicial/sca_cmps_train", "notebooks/simplicial/sccnn_train", "notebooks/simplicial/scconv_train", "notebooks/simplicial/scn2_train", "notebooks/simplicial/scn_train", "notebooks/simplicial/scnn_train", "notebooks/simplicial/scone_train", "notebooks/simplicial/scone_train_bis", "tutorials/index"], "filenames": ["api/base.rst", "api/index.rst", "api/nn.rst", "api/utils.rst", "challenge/index.rst", "contributing/index.rst", "index.rst", "notebooks/cell/can_train.ipynb", "notebooks/cell/ccxn_train.ipynb", "notebooks/cell/cwn_train.ipynb", "notebooks/hypergraph/allsettransformer_train.ipynb", "notebooks/hypergraph/dhgcn_train.ipynb", "notebooks/hypergraph/hmpnn_train.ipynb", "notebooks/hypergraph/hnhn_train.ipynb", "notebooks/hypergraph/hnhn_train_bis.ipynb", "notebooks/hypergraph/hypergat_train.ipynb", "notebooks/hypergraph/hypersage_train.ipynb", "notebooks/hypergraph/template_train.ipynb", "notebooks/hypergraph/unigcnii_train.ipynb", "notebooks/hypergraph/unigin_train.ipynb", "notebooks/hypergraph/unisage_train.ipynb", "notebooks/simplicial/dist2cycle_train.ipynb", "notebooks/simplicial/hsn_train.ipynb", "notebooks/simplicial/san_train.ipynb", "notebooks/simplicial/sca_cmps_train.ipynb", "notebooks/simplicial/sccnn_train.ipynb", "notebooks/simplicial/scconv_train.ipynb", "notebooks/simplicial/scn2_train.ipynb", "notebooks/simplicial/scn_train.ipynb", "notebooks/simplicial/scnn_train.ipynb", "notebooks/simplicial/scone_train.ipynb", "notebooks/simplicial/scone_train_bis.ipynb", "tutorials/index.rst"], "titles": ["Base", "API Reference", "Neural Networks", "Utils", "ICML 2023 Topological Deep Learning Challenge", "Contributing", "\ud83c\udf10 TopoModelX (TMX) \ud83c\udf69", "Train a Cellular Attention Network (CAN)", "Train a Convolutional Cell Complex Network (CCXN)", "Train a CW Network (CWN)", "Train a Hypergraph Neural Network", "Train a Hypergraph Neural Network", "Train a Hypergraph Message Passing Neural Network (HMPNN)", "Train a Hypergraph Networks with Hyperedge Neurons (HNHN)", "Train a Hypergraph Network with Hyperedge Neurons (HNHN)", "Train a Hypergraph Neural Network", "Train a Hypergraph Neural Network", "Train a Hypergraph Neural Network", "Train a hypergraph neural network using UniGCNII layers", "Pre-processing", "Pre-processing", "Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)", "Train a Simplicial High-Skip Network (HSN)", "Train a Simplicial Attention Network (SAN)", "Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)", "Train a SCCNN", "Train a Simplicial 2-complex convolutional neural network (SCConv)", "Train a Simplicial Convolutional Network (SCN) of Rank 2", "Train a Simplicial Convolutional Network (SCN)", "Train a Simplicial Convolutional Neural Network (SCNN)", "Train a Simplicial Complex Net (SCoNe)", "Train a Simplicial Complex Network (SCoNe)", "Tutorials"], "terms": {"The": [1, 4, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31], "give": [1, 10, 23], "an": [1, 4, 5, 7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31], "overview": 1, "topomodelx": [1, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "which": [1, 4, 5, 7, 10, 12, 14, 15, 18, 21, 22, 23, 24, 25, 28, 29, 30], "consist": [1, 4, 5, 18, 30], "sever": [1, 4], "base": [1, 4, 10, 24, 25, 26, 29, 30, 31], "implement": [1, 4, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "core": 1, "mathemat": 1, "concept": 1, "messag": [1, 4, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 31, 32], "pass": [1, 4, 7, 8, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32], "nn": [1, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "neural": [1, 4, 6, 32], "network": [1, 4, 6, 32], "layer": [1, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "organ": [1, 4, 28], "topolog": [1, 6, 7, 8, 9, 13, 21, 22, 23, 24, 26, 28, 29, 30, 31], "domain": [1, 4, 6, 7, 8, 9, 10, 12, 13, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "util": [1, 7, 10, 18, 19, 20, 23, 30], "comput": [1, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "spars": [1, 5, 10, 12, 13, 14, 15, 16, 18, 21, 23, 26, 28], "tensor": [1, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "hypergraph": [1, 4, 19, 20, 32], "simplici": [1, 4, 7, 8, 9, 10, 11, 13, 15, 16, 17, 32], "complex": [1, 4, 5, 7, 9, 10, 11, 15, 16, 17, 19, 20, 21, 22, 23, 27, 28, 29, 32], "cell": [1, 4, 7, 9, 10, 11, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32], "scatter": [1, 14, 30], "welcom": [4, 5], "host": 4, "second": [4, 10, 24, 31], "annual": 4, "topologi": [4, 11, 23], "geometri": 4, "tag": 4, "machin": [4, 29], "workshop": 4, "review": [4, 5, 6], "contributor": [4, 5], "mathild": [4, 6], "papillon": [4, 6, 7, 8, 9, 13, 21, 22, 23, 24, 26, 28, 29, 30, 31], "mustafa": [4, 6], "hajij": [4, 6, 8, 22, 23, 31], "nina": [4, 6], "miolan": [4, 6], "florian": 4, "frantzen": 4, "ghada": [4, 6], "alzamzmi": 4, "theodor": [4, 6], "papamark": [4, 6], "michael": [4, 6], "schaub": [4, 6], "scholkemp": 4, "josef": 4, "hopp": 4, "karthikeyan": [4, 6], "natesan": [4, 6], "ramamurthi": [4, 6], "johan": 4, "math": [4, 5, 7, 10, 15, 16, 26, 28, 29, 30], "audun": 4, "myer": 4, "helen": 4, "jenn": 4, "tim": 4, "doster": 4, "tegan": 4, "emerson": 4, "henri": 4, "kving": 4, "bastian": 4, "rieck": 4, "sophia": [4, 6], "sanborn": [4, 6], "jan": 4, "meissner": 4, "paul": [4, 6], "rosen": [4, 6], "tolga": [4, 6], "birdal": [4, 6], "vincent": 4, "grand": 4, "aldo": [4, 6], "guzm\u00e1n": [4, 6], "s\u00e1enz": [4, 6], "tamal": [4, 6], "dei": [4, 6], "soham": [4, 6], "mukherje": [4, 6], "shreya": [4, 6], "n": [4, 5, 6, 9, 15, 16, 23, 24, 30], "samaga": [4, 6], "neal": [4, 6], "livesai": [4, 6], "robin": [4, 6], "walter": [4, 6], "edit": [4, 5], "i": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "now": [4, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 27, 30, 31], "over": [4, 10, 11, 12, 14, 16, 17, 20, 21, 22, 23, 26, 27, 28, 30, 31], "thank": 4, "you": [4, 5, 18, 31], "all": [4, 5, 10, 11, 15, 16, 17, 18, 21, 22, 23, 25, 28, 29, 30, 31], "stellar": 4, "contirbut": 4, "foster": 4, "reproduc": [4, 6], "open": [4, 18], "sourc": 4, "research": 4, "winner": 4, "announc": 4, "here": [4, 5, 11, 12, 14, 18, 21, 22, 25, 28, 30], "luca": 4, "scofano": 4, "claudio": 4, "battiloro": [4, 23], "guillermo": 4, "bernardez": 4, "simon": 4, "fiorellino": 4, "indro": 4, "spinelli": 4, "scardapan": 4, "lev": 4, "telyatninkov": 4, "olga": 4, "zaghen": 4, "allsettransform": [4, 10], "chien": [4, 10], "et": [4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "al": [4, 6, 7, 8, 9, 10, 13, 14, 15, 16, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "2022": [4, 7, 12, 21, 22, 23, 28, 29, 31], "sadrodin": 4, "barikbin": [4, 14], "hmpnn": [4, 32], "heydari": [4, 12], "attent": [4, 10, 15, 24, 32], "san": [4, 32], "giusti": [4, 7, 23], "odin": 4, "hoff": 4, "gardaa": 4, "net": [4, 31, 32], "scone": [4, 32], "roddenberri": [4, 29, 30], "2021": [4, 9, 10, 29, 30], "cellular": [4, 9, 32], "can": [4, 5, 6, 15, 16, 18, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32], "dmitrii": 4, "gavrilev": 4, "gleb": 4, "bazhenov": 4, "suraj": 4, "singh": 4, "cw": [4, 32], "cwn": [4, 32], "bodnar": [4, 9], "combinatori": 4, "rub\u00e9n": 4, "ballest": 4, "manuel": 4, "lecha": 4, "sergio": 4, "escalera": 4, "higher": [4, 22, 28, 29, 31], "order": [4, 22, 23, 25, 28, 29, 30, 31], "hoan": 4, "aiden": 4, "brent": 4, "honor": 4, "mention": 4, "jen": 4, "agerberg": 4, "georg": [4, 28], "b\u00f6kman": 4, "pavlo": 4, "melnyk": 4, "convolut": [4, 7, 9, 23, 32], "sccn": 4, "yang": [4, 25, 28, 29], "autoencod": [4, 32], "sca": [4, 32], "alessandro": 4, "salatiello": 4, "hyperedg": [4, 10, 11, 12, 15, 16, 17, 32], "neuron": [4, 32], "hnhn": [4, 32], "dong": [4, 13, 14], "2020": [4, 8, 12, 13, 15, 16, 26], "alexand": 4, "nikitin": 4, "unigcn": 4, "huang": 4, "purpos": [4, 5, 7, 8, 9, 10, 11, 12, 14, 16, 17, 20, 21, 22, 23, 25, 28], "thi": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "crowdsourc": 4, "ar": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "ask": 4, "contribut": [4, 15, 25], "code": [4, 5, 30], "previous": 4, "exist": 4, "tnn": [4, 6, 10, 16], "train": [4, 32], "benchmark": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31], "dataset": [4, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 23, 24, 32], "built": [4, 5], "us": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "python": [4, 5, 6], "packag": [4, 6, 7, 8, 14, 18, 21, 25, 26, 28, 29], "each": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 28, 30], "take": [4, 7, 8, 9, 23, 25, 27, 30], "form": [4, 10, 21, 22, 25, 28, 30], "pull": [4, 5], "request": [4, 5, 18, 30], "contain": [4, 10, 12, 14, 18, 25, 30], "necessari": [4, 23], "from": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "literatur": [4, 6, 18], "leverag": [4, 23], "infrastructur": 4, "build": [4, 5, 30], "block": 4, "note": [4, 5, 10, 11, 15, 16, 17, 21, 22, 25, 29, 30], "we": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31], "invit": 4, "file": [4, 5], "regularli": 4, "detail": [4, 5, 10, 23], "ad": [4, 5], "when": [4, 5, 23, 30], "everi": [4, 18, 19], "respect": [4, 9, 10, 15, 16, 23, 24, 25, 29, 30], "includ": [4, 5, 30], "white": 4, "paper": [4, 12, 13, 14, 21, 22, 23, 25, 26, 27, 29, 30, 31], "summar": 4, "find": [4, 30], "publish": 4, "through": [4, 7, 8, 9, 11, 12, 14, 15, 16, 17, 18, 19, 20, 24, 25, 29, 30], "qualifi": 4, "have": [4, 5, 7, 8, 10, 11, 13, 15, 16, 17, 21, 22, 25, 28, 30], "opportun": 4, "co": [4, 18], "author": [4, 6, 14, 30], "top": [4, 25], "8": [4, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 27, 28, 30, 31], "best": [4, 10], "addit": 4, "softwar": [4, 5], "journal": 4, "receiv": 4, "special": 4, "recognit": 4, "final": [4, 12, 13, 14, 18, 23, 29, 30], "date": 4, "time": [4, 10, 11, 12, 13, 14, 15, 16, 17, 21, 22, 23, 25, 28, 29, 30, 31], "must": [4, 10, 11, 13, 15, 16, 17, 21, 22, 23, 25, 28, 29], "place": [4, 5, 10], "befor": [4, 5, 18, 30], "juli": 4, "13": [4, 7, 8, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 26, 28, 30], "16": [4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30], "59": [4, 7, 12, 13, 21, 28], "pacif": 4, "standard": [4, 5, 18, 23], "modifi": [4, 5, 24], "until": 4, "everyon": [4, 5], "free": [4, 30], "It": [4, 12, 14, 18], "suffici": 4, "send": [4, 7, 8, 9, 10, 11, 13, 15, 16, 17, 21, 22, 23, 27, 31], "accept": 4, "automat": [4, 23], "subscrib": 4, "team": [4, 31], "encourag": 4, "start": [4, 5, 18, 24, 30], "earli": 4, "help": [4, 5], "debug": 4, "fail": 4, "test": [4, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 28, 32], "address": 4, "potenti": 4, "issu": [4, 18], "In": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "case": [4, 7, 8, 9, 10, 11, 13, 15, 16, 17, 21, 22, 23, 27, 30, 31], "multipl": [4, 5, 10, 30], "similar": [4, 28], "qualiti": 4, "same": [4, 5, 7, 8, 23, 24, 25, 30], "earlier": [4, 28], "given": [4, 7, 8, 9, 10, 13, 15, 16, 18, 21, 22, 23, 25, 26, 28, 29, 30, 31], "prioriti": 4, "consider": 4, "restrict": 4, "number": [4, 7, 8, 9, 10, 12, 13, 14, 18, 21, 22, 23, 24, 26, 27, 28, 30, 31], "member": 4, "A": [4, 5, 6, 7, 8, 9, 10, 12, 13, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "should": [4, 5, 30], "more": [4, 5, 6, 21, 28, 30], "than": [4, 29, 30, 31], "one": [4, 5, 7, 8, 13, 18, 21, 22, 23, 24, 25, 26, 28, 30, 31], "model": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 31, 32], "There": [4, 5, 12, 13, 14, 21, 22, 23, 28, 29], "amount": [4, 8, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20, 21, 22, 25, 27, 31], "per": [4, 5], "princip": 4, "develop": [4, 5], "allow": [4, 28], "pre": [4, 30, 32], "fig": [4, 30], "11": [4, 7, 8, 9, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31], "architectur": [4, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 21, 22, 23, 24, 26, 28, 29, 30, 31], "survei": [4, 6, 7, 8, 9, 13, 21, 22, 23, 24, 26, 28, 29, 30, 31], "compli": 4, "": [4, 5, 7, 8, 9, 10, 11, 12, 14, 17, 18, 21, 22, 24, 25, 28, 30], "github": [4, 10, 14, 16, 18], "action": 4, "workflow": 4, "successfulli": 4, "lint": 4, "format": [4, 5, 18], "e": [4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 21, 22, 23, 25, 27, 29, 30, 31], "black": [4, 30], "isort": 4, "flake8": 4, "three": [4, 5, 18], "new": [4, 5, 7, 8], "name": [4, 5, 10, 12, 19, 20], "_layer": 4, "py": [4, 5, 7, 8, 14, 18, 21, 26, 28, 31], "ex": 4, "hsn_layer": [4, 22], "store": [4, 13], "directori": [4, 5], "where": [4, 5, 7, 8, 9, 10, 13, 15, 16, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "class": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "hsnlayer": [4, 22, 28], "primit": 4, "One": [4, 21, 22, 23, 25, 27, 28, 29, 30, 31], "equival": [4, 5], "depict": 4, "diagram": 4, "represent": [4, 10, 12, 13, 14, 15, 28, 30], "exampl": [4, 23, 25, 29, 30], "check": [4, 5, 6, 13, 21, 22, 31], "out": [4, 5, 6, 11, 13, 14, 17, 24, 28, 30, 31], "_train": 4, "ipynb": 4, "hsn_train": 4, "tutori": [4, 6, 18], "follow": [4, 5, 6, 7, 10, 11, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "step": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "process": [4, 5, 18, 32], "import": [4, 5, 7, 8, 9, 10, 12, 14, 16, 18, 23, 30], "well": [4, 5], "load": [4, 7, 8, 9, 10, 11, 14, 15, 16, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29], "featur": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "face": [4, 7, 8, 9, 10, 11, 15, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "rank": [4, 7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32], "2": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 30, 31, 32], "neighborhood": [4, 7, 8, 9, 10, 16, 23, 24, 30, 32], "matric": [4, 7, 8, 9, 10, 11, 13, 15, 16, 17, 21, 22, 23, 24, 25, 27, 28, 29, 31], "toponetx": [4, 7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "either": [4, 5, 23, 30], "shrec16": [4, 7, 8, 9, 10, 11, 15, 16, 17, 24, 25, 29, 31], "suitabl": [4, 13], "level": [4, 10, 11, 13, 15, 16, 17, 18, 21, 22, 23, 24, 25, 28, 29], "classif": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 31, 32], "see": [4, 5, 6, 14, 30], "template_lay": [4, 17], "karat": [4, 13, 21, 22, 23, 25, 28], "club": [4, 13, 21, 22, 23, 25, 28], "node": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32], "onli": [4, 5, 11, 18, 23, 25, 30], "edg": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "0": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "1": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32], "abov": [4, 5, 29, 30], "torch": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "geometr": 4, "graph": [4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31], "lift": [4, 7, 8, 9, 10, 13, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29], "choic": [4, 7, 8, 9, 10, 11, 15, 16, 17, 19, 20, 24], "creat": [4, 5, 10, 15, 16, 32], "defin": [4, 5, 7, 8, 9, 18, 23, 24, 30, 32], "hsn": [4, 32], "inherit": 4, "modul": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "along": [4, 7, 23], "linear": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "task": [4, 10, 12, 13, 14, 18, 21, 22, 25, 28, 29, 30], "simpl": [4, 29], "loop": [4, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 23, 26, 27, 28, 30, 31], "depend": 4, "output": [4, 5, 10, 11, 15, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31], "perform": [4, 5, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 20, 21, 22, 23, 26, 27, 28, 30, 31], "rather": [4, 5, 31], "accuraci": [4, 13, 14, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31], "provid": [4, 5, 7, 24, 25, 29], "test_": [4, 5], "name_of_model": 4, "test_hsn_lay": 4, "testhsnlay": 4, "unit": [4, 5, 30], "function": [4, 5, 9, 10, 16, 18, 21, 22, 23, 25, 28, 29, 30, 31], "pleas": [4, 5, 7, 8, 14, 18, 23], "pytest": [4, 5], "unittest": 4, "further": [4, 23, 32], "manipul": 4, "mai": 4, "modif": 4, "singl": [4, 9], "accompani": 4, "appropri": [4, 5], "locat": [4, 5, 18], "With": [4, 15], "being": [4, 23, 24], "said": 4, "highli": 4, "make": [4, 7, 8, 9, 10, 11, 12, 14, 17, 18, 24, 30, 31], "most": [4, 5, 23, 28], "resort": 4, "option": [4, 5, 8, 10, 23], "absolut": 4, "aggreg": [4, 15, 16, 23, 24, 26, 28, 29], "method": [4, 5, 12, 14], "condorcet": 4, "decid": [4, 23], "criteria": 4, "doe": [4, 5, 25, 29, 30], "chosen": [4, 28], "correctli": 4, "specif": [4, 5, 9, 13, 15, 18], "term": [4, 23], "its": [4, 5, 12, 14, 15, 31], "scheme": [4, 7, 8, 23, 32], "do": [4, 12, 14, 21, 22, 28, 30], "need": [4, 7, 8, 9, 10, 11, 13, 15, 16, 17, 21, 22, 23, 27, 30, 31], "match": 4, "origin": [4, 5, 7, 8, 9, 18, 23, 25, 27, 28, 29, 30], "readabl": [4, 5], "clean": 4, "api": [4, 5], "written": 4, "docstr": 4, "clearli": 4, "explain": 4, "robust": 4, "reward": 4, "nor": 4, "goal": 4, "accur": 4, "our": [4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31], "field": 4, "select": [4, 28, 29], "maintain": 4, "collabor": 4, "whose": [4, 5], "vote": 4, "onc": [4, 10, 11, 15, 16, 17], "googl": [4, 5], "express": [4, 15], "prefer": [4, 5], "get": [4, 23, 25, 29, 30], "even": 4, "link": [4, 5], "record": [4, 5, 10, 11, 15, 16, 17], "while": [4, 5, 23], "email": 4, "identifi": 4, "voter": 4, "ident": [4, 10, 21, 22, 25], "remain": [4, 30], "secret": 4, "share": 4, "feel": [4, 30], "contact": 4, "u": [4, 8, 9, 10, 15, 24, 30], "repositori": [4, 5], "slack": 4, "altern": 4, "ucsb": 4, "edu": 4, "guid": 5, "aim": [5, 23], "eas": 5, "both": [5, 23, 30], "novic": 5, "experienc": 5, "commun": 5, "effort": 5, "wai": [5, 23], "fork": 5, "upstream": 5, "submit": [5, 18], "pr": 5, "synchron": 5, "your": 5, "main": [5, 18], "branch": 5, "git": 5, "checkout": 5, "hold": 5, "b": [5, 7, 9, 10, 13, 15, 16, 24, 25, 26, 28], "sure": [5, 31], "next": [5, 13, 15, 18, 30], "section": [5, 30], "re": [5, 21, 30], "done": [5, 7, 8, 9, 10, 11, 15, 16, 17, 20, 24, 25, 26, 27, 29, 30], "add": [5, 18], "commit": 5, "modified_fil": 5, "m": [5, 7, 8, 15, 21, 24, 26, 29, 30, 31], "my": [5, 24], "Then": [5, 7, 8, 9], "push": 5, "toponextx": 5, "instruct": 5, "repeat": 5, "3": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "4": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "folder": 5, "valid": [5, 18, 19, 20, 30], "filenam": 5, "For": [5, 6, 7, 13, 16, 21, 22, 25, 29, 30, 31], "test_add": 5, "def": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "x": [5, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "y": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "return": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "test_capital_cas": 5, "assert": [5, 28, 30], "5": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "9": [5, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 27, 28, 30, 31], "statement": 5, "under": 5, "correct": [5, 19, 20, 30], "instal": 5, "tool": 5, "pip": 5, "dev": 5, "verifi": 5, "break": 5, "requir": [5, 7, 24], "doc": 5, "descript": [5, 30], "usag": 5, "other": [5, 30], "inform": [5, 10, 12, 15, 16, 29], "differ": [5, 7, 8, 13, 21, 22, 23, 25, 28, 30], "markdown": 5, "languag": 5, "common": 5, "restructuredtext": 5, "numpi": [5, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "style": 5, "up": [5, 21, 22, 23, 28, 30, 32], "understand": 5, "role": 5, "syntax": 5, "also": [5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 27, 29, 31], "autom": 5, "pars": 5, "inclus": 5, "gener": [5, 10, 18, 22, 23, 25, 31, 32], "refer": [5, 16, 23], "look": [5, 30], "ani": [5, 7, 8, 16, 25, 30], "object": 5, "print": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "__doc__": 5, "attribut": 5, "try": [5, 7, 8, 23, 30], "np": [5, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "arrai": [5, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "mean": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "good": [5, 27], "These": 5, "some": [5, 28, 30], "element": [5, 10], "ones": [5, 12, 14], "d": [5, 15, 21, 26], "like": [5, 7, 8, 23, 28], "summari": 5, "line": 5, "79": [5, 7, 11, 12, 13, 28], "char": 5, "begin": [5, 23], "immedi": 5, "after": [5, 14, 19], "first": [5, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "capit": 5, "letter": 5, "end": [5, 21, 22, 23, 28, 30, 31], "period": 5, "If": [5, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 23, 24, 25, 27, 28], "describ": [5, 10], "verb": 5, "imper": 5, "mood": 5, "g": [5, 10, 15, 23, 29, 30], "v": [5, 10, 13, 15, 16, 18, 21, 22, 23, 25, 28, 29, 31], "possibl": [5, 18], "default": [5, 10, 14, 16, 18, 23], "uncertain": 5, "oppos": 5, "calcul": [5, 23, 31], "evalu": [5, 12, 13, 14, 18, 19, 32], "multi": [5, 10], "separ": 5, "blank": 5, "paramet": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "list": [5, 10, 11, 18, 24, 30], "argument": [5, 10, 23], "type": 5, "On": 5, "state": [5, 16, 18], "shape": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "rest": 5, "space": [5, 25, 30], "side": 5, "default_valu": 5, "indent": 5, "esp": 5, "would": [5, 21, 22], "want": [5, 18, 30], "mani": 5, "veri": [5, 18], "rais": [5, 25, 29], "etc": [5, 18, 24], "within": [5, 12, 14, 23], "latex": 5, "cite": [5, 18], "text": [5, 10, 11, 12, 13, 14, 15, 16, 17, 21, 22, 23, 24, 25, 28, 31], "id": 5, "templat": [5, 15, 17], "my_method": 5, "self": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "my_param_1": 5, "my_param_2": 5, "vector": [5, 10, 12, 14, 15, 30], "r": [5, 8, 9, 10, 15, 23, 24, 28, 30], "big": 5, "o": [5, 10, 13, 23], "left": [5, 9, 15, 16, 30], "right": [5, 9, 15, 16, 30], "dim": [5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31], "short": 5, "str": [5, 26, 28], "matrix": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "my_result": 5, "result": [5, 7, 8, 10, 13], "relev": 5, "equat": [5, 6, 7, 8, 9, 13, 21, 22, 23, 26, 28, 30, 31], "snippet": 5, "show": [5, 13, 21, 22, 30, 31], "how": [5, 10, 21, 22, 23], "script": 5, "associ": [5, 7, 8, 9, 10, 11, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 28], "pdf": 5, "wikipedia": 5, "page": 5, "And": 5, "fill": 5, "scikit": 5, "learn": [5, 6, 7, 8, 9, 13, 14, 15, 16, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "project": [5, 9, 23, 24, 29], "fit_predict": 5, "none": [5, 25, 29, 30], "sample_weight": 5, "cluster": [5, 24], "center": [5, 30], "predict": [5, 10, 12, 13, 14, 29, 30], "index": [5, 28, 30], "sampl": [5, 13, 30], "conveni": 5, "call": [5, 10, 30], "fit": 5, "sparse_matrix": 5, "n_featur": 5, "data": [5, 6, 12, 14, 23, 28, 31, 32], "transform": [5, 14, 18, 23], "ignor": [5, 20], "Not": 5, "present": 5, "convent": 5, "weight": [5, 10, 15, 23, 25, 28, 30], "observ": 5, "assign": [5, 7, 8, 9, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "equal": [5, 15, 30], "label": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 26, 27, 30, 32], "belong": [5, 13, 21, 22, 23, 25, 28], "labels_": 5, "mind": 5, "bool": [5, 7, 8, 10, 24], "instead": [5, 18], "boolean": 5, "vari": 5, "notat": [5, 7, 8, 9, 13, 21, 22, 23, 24, 26, 28, 29, 30, 31], "dimens": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "axi": [5, 30], "string": [5, 16], "bracket": 5, "input": [5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32], "log": [5, 28, 30], "squar": [5, 30], "multinomi": 5, "1d": [5, 7, 8, 9, 25, 27], "2d": [5, 7, 8, 9, 25, 27], "subset": [5, 12, 14], "ndarrai": [5, 30], "datafram": 5, "explicitli": 5, "relat": [5, 12], "colon": 5, "explan": 5, "_weight_boost": 5, "adaboost": 5, "ha": [5, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "great": 5, "ve": 5, "discuss": 5, "Of": 5, "cours": [5, 25], "verbos": 5, "thei": [5, 7, 8, 9, 10, 21, 22, 23, 25, 27, 28], "compon": [5, 23], "rst": 5, "keep": [5, 7, 8, 9, 10, 11, 12, 14, 16, 17, 20, 21, 22, 23, 25, 28, 31], "length": [5, 12, 14, 18, 28], "80": [5, 7, 11, 12, 13, 24, 28], "charact": 5, "except": [5, 23], "tabl": [5, 32], "deep": [6, 7, 8, 9, 10, 13, 21, 22, 23, 24, 26, 28, 29, 30, 31], "tdl": 6, "blue": 6, "laid": 6, "2023": [6, 7, 8, 9, 13, 18, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "go": [6, 9, 23, 30], "beyond": [6, 23], "extend": [6, 25], "graphic": 6, "avail": [6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 23, 24], "awesom": [6, 10, 16], "To": [6, 13, 20, 21, 22, 29, 30, 31], "about": 6, "blueprint": 6, "zamzmi": 6, "k": [6, 9, 10, 13, 15, 21, 22, 23, 24, 26, 28, 29, 30, 31], "t": [6, 7, 8, 9, 10, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "misc": 6, "hajij2023topolog": 6, "titl": [6, 13], "year": 6, "eprint": 6, "2206": [6, 21], "00606": 6, "archiveprefix": 6, "arxiv": 6, "primaryclass": 6, "c": [6, 7, 8, 10, 13, 14, 15, 16, 21, 22, 26, 28, 30, 31], "lg": 6, "papillon2023architectur": 6, "2304": [6, 13], "10031": 6, "down": [7, 23, 24, 25, 26, 31], "laplacian": [7, 23, 24, 25, 27, 28, 31], "propos": [7, 8, 9, 13, 16, 21, 22, 23, 25, 26, 29, 30, 31], "rodenberri": 7, "signal": [7, 8, 9, 10, 11, 15, 16, 17, 19, 20, 23, 24], "mechan": [7, 8, 10, 15, 23], "without": [7, 8], "quad": [7, 8, 9, 10, 13, 15, 16, 21, 22, 23, 24, 26, 28, 29, 30, 31], "m_": [7, 8, 9, 10, 13, 15, 16, 21, 22, 23, 24, 26, 28, 29, 30, 31], "rightarrow": [7, 8, 9, 10, 13, 15, 16, 21, 22, 23, 24, 26, 28, 29, 30, 31], "z": [7, 8, 9, 10, 15, 16, 22, 29, 30, 31], "l_": [7, 23, 24, 29, 30, 31], "downarrow": [7, 21, 23, 24, 25, 26, 28, 29, 30, 31], "cdot": [7, 13, 15, 16, 21, 22, 23, 26, 28, 29, 30, 31], "h_y": [7, 8, 9, 10, 13, 16, 22, 23, 26, 29, 30], "theta": [7, 8, 10, 13, 15, 16, 21, 22, 24, 25, 26, 28, 29, 30, 31], "uparrow": [7, 8, 9, 21, 22, 23, 25, 26, 28, 29, 30, 31], "h_x": [7, 8, 9, 10, 13, 15, 16, 21, 22, 23, 24, 28, 29, 30, 31], "m_x": [7, 8, 9, 13, 15, 16, 21, 22, 24, 26, 28, 29, 30, 31], "sum_": [7, 13, 15, 16, 21, 22, 25, 26, 28, 29, 30, 31], "mathcal": [7, 8, 9, 10, 13, 15, 16, 21, 22, 23, 24, 26, 28, 29, 30, 31], "sigma": [7, 13, 15, 16, 21, 22, 25, 26, 28, 29, 30, 31], "mask": [7, 12, 23, 30], "nbsphinx": [7, 10, 15, 16, 29], "odot": [7, 15, 21], "att": [7, 8, 15, 24], "h_": [7, 8, 15, 21, 24, 28], "l": [7, 8, 9, 15, 16, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "_": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "xy": [7, 13, 21, 22, 26, 28, 29, 30, 31], "epsilon": [7, 23], "theta_": 7, "entir": [7, 8, 9], "small": [7, 8, 9, 10, 11, 15, 16, 17, 24, 25, 26, 27, 28, 29], "version": [7, 8, 9, 25, 29], "random": [7, 14, 30], "sklearn": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 24, 25, 27, 29, 31], "model_select": [7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 24, 25, 27, 29, 31], "train_test_split": [7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 24, 25, 27, 29, 31], "cellcomplex": 7, "can_lay": 7, "canlay": 7, "gpu": [7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 24], "them": [7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 23, 24, 25, 27, 28], "otherwis": [7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 24, 30], "run": [7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 28, 30], "cpu": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 26, 27, 31], "devic": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 26, 27, 31], "cuda": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 26, 27, 31], "is_avail": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 26, 27, 31], "els": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 25, 26, 27, 29, 31], "3d": [7, 8, 9, 10, 11, 15, 16, 17, 24, 26, 27], "mesh": [7, 8, 9, 10, 11, 15, 16, 17, 24, 25, 26, 27, 29], "retriev": [7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31], "x_0": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "x_1": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "x_2": [7, 8, 9, 10, 11, 15, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29], "binari": [7, 12, 13, 14, 19, 20, 23, 26, 27, 31], "shrec": [7, 8, 9, 10, 11, 15, 16, 17, 24, 26, 27, 29], "shrec_16": [7, 8, 9, 10, 11, 15, 16, 17, 24, 25, 26, 27, 29], "size": [7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "kei": [7, 8, 9, 10, 11, 15, 16, 17, 24, 25, 26, 27, 29], "valu": [7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 21, 23, 24, 25, 26, 27, 29, 30], "item": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "node_feat": [7, 8, 9, 10, 11, 13, 15, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29], "edge_feat": [7, 8, 9, 10, 11, 13, 15, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "face_feat": [7, 8, 9, 10, 11, 15, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29], "simplex": [7, 8, 9, 10, 11, 15, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "i_complex": [7, 8, 9, 10, 11, 15, 16, 17, 24, 26, 27], "6": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "f": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "th": [7, 8, 9, 10, 11, 15, 16, 17, 23, 24, 26, 27], "6th": [7, 8, 9, 10, 11, 15, 16, 17, 24, 27], "252": [7, 8, 9, 10, 11, 13, 15, 16, 17, 24, 26, 27], "750": [7, 8, 9, 10, 11, 13, 15, 16, 17, 24, 26, 27], "10": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "500": [7, 8, 9, 10, 11, 13, 15, 16, 17, 24, 26, 27], "7": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "structur": [7, 8, 9, 10, 16, 23, 25, 29, 32], "repres": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 27, 30, 31], "taht": 7, "act": [7, 31], "denot": [7, 10, 15, 16, 29, 30], "cc_list": [7, 8, 9], "down_laplacian_list": 7, "up_laplacian_list": 7, "cell_complex": [7, 8, 9], "to_cell_complex": [7, 8, 9], "append": [7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "down_laplacian": 7, "down_laplacian_matrix": [7, 21, 23, 24, 25, 26, 29, 31], "up_laplacian": 7, "up_laplacian_matrix": [7, 23, 25, 26, 29, 31], "from_numpi": [7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "todens": [7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "to_spars": [7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "thu": [7, 23, 27], "i_cc": 7, "appli": [7, 10, 12, 15, 23, 26, 30], "in_channels_0": [7, 8, 9, 25, 27, 29], "in_channels_1": [7, 8, 9, 25, 27, 29], "in_channels_2": [7, 8, 9, 25, 27, 29], "int": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "num_class": [7, 8, 9, 12, 14, 18, 24, 25, 27], "n_layer": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "whether": [7, 8, 10, 24], "__init__": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "fals": [7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 24, 25, 26, 27, 29], "super": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "rang": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "channel": [7, 18, 21, 22, 23, 25, 26, 27, 28, 29, 31], "lin_0": [7, 8, 9, 27], "lin_1": [7, 8, 9, 27], "lin_2": [7, 8, 9, 27], "forward": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "avg": [7, 8, 24], "pool": [7, 8, 9, 11, 15, 16, 17, 19, 20, 24], "n_node": [7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31], "n_edg": [7, 8, 9, 13, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 29, 31], "n_face": [7, 8, 9, 25, 26], "whole": [7, 8, 9, 11, 15, 16, 17, 19, 20, 24, 25, 26], "averag": [7, 8, 9, 11, 25, 27, 29, 30], "0d": [7, 8, 9, 25, 27], "nan": [7, 8, 9, 13, 25, 26, 27], "convert": [7, 8, 9, 13, 19, 20, 21, 22, 23, 25, 27, 31], "two_dimensional_cells_mean": [7, 8, 9, 24, 25, 27], "nanmean": [7, 8, 9, 24, 25, 26, 27, 29], "isnan": [7, 8, 9, 24, 25, 26, 27, 29], "one_dimensional_cells_mean": [7, 8, 9, 24, 25, 27, 29], "zero_dimensional_cells_mean": [7, 8, 9, 24, 25, 27], "sum": [7, 8, 9, 13, 15, 23, 25, 26, 27, 28, 30], "specifi": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 27, 28, 29], "initi": [7, 8, 10, 12, 13, 14, 16, 23, 25, 26, 29, 30], "loss": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "optim": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "crit": [7, 8, 19, 20], "crossentropyloss": [7, 8, 12, 13, 14, 18, 19], "opt": [7, 8, 10, 11, 15, 16, 17, 24, 26], "adam": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "lr": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "loss_fn": [7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 24, 25, 26, 27, 29], "mseloss": [7, 8, 9, 10, 11, 15, 16, 17, 24, 25, 26, 27, 29], "split": [7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 26, 30, 32], "test_siz": [7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 24, 25, 27, 29, 30, 31], "x_0_train": [7, 8, 9, 10, 11, 14, 15, 16, 24, 25, 26], "x_0_test": [7, 8, 9, 10, 11, 14, 15, 16, 24, 25], "shuffl": [7, 8, 9, 10, 11, 15, 16, 17, 19, 20, 24, 25, 27, 29, 30, 31], "x_1_train": [7, 8, 9, 17, 19, 20, 24, 25, 26], "x_1_test": [7, 8, 9, 17, 19, 20, 24, 25], "x_2_train": [7, 9, 24, 25, 26], "x_2_test": [7, 9, 24, 25], "up_laplacian_train": 7, "up_laplacian_test": 7, "down_laplacian_train": 7, "down_laplacian_test": 7, "y_train": [7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31], "y_test": [7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31], "epoch": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "minim": [7, 8, 9, 10, 11, 12, 14, 16, 17, 20, 25], "rapid": [7, 8, 9, 10, 11, 12, 14, 16, 17, 20, 25], "12": [7, 8, 12, 13, 14, 15, 18, 19, 20, 21, 22, 27, 28, 30], "test_interv": [7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "num_epoch": [7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "epoch_i": [7, 8, 9, 10, 11, 13, 15, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29], "epoch_loss": [7, 8, 9, 10, 11, 15, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "zip": [7, 8, 9, 10, 11, 15, 16, 17, 19, 20, 24, 25, 26, 27, 29], "float": [7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "zero_grad": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "y_hat": [7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "backward": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "4f": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 21, 22, 23, 25, 27, 28, 29, 31], "flush": [7, 8, 9, 10, 11, 13, 15, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "true": [7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "no_grad": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "up_laplcian": 7, "test_loss": [7, 8, 9, 10, 11, 12, 15, 16, 17, 24, 25, 26, 27, 29], "user": [7, 8, 21, 31], "abrah": 7, "anaconda3": [7, 8, 21, 26, 28], "env": [7, 8, 21, 26, 28], "topological_2": 7, "lib": [7, 8, 14, 21, 26, 28], "site": [7, 8, 14, 21, 26, 28], "536": [7, 8, 13], "userwarn": [7, 8, 18, 26, 31], "target": [7, 8], "lead": [7, 8], "incorrect": [7, 8], "due": [7, 8, 28], "broadcast": [7, 8], "ensur": [7, 8], "mse_loss": [7, 8], "reduct": [7, 8, 25], "89": [7, 12, 13, 14, 28], "3527": 7, "81": [7, 11, 12, 13, 28], "9469": 7, "5947": 7, "1082": [7, 13], "3476": 7, "55": [7, 12, 13, 21, 28, 29], "3188": 7, "6493": 7, "0137": [7, 12], "51": [7, 9, 12, 13, 14, 18, 21, 28, 29], "6529": 7, "78": [7, 11, 12, 13, 21, 22, 23, 25, 28, 29, 31], "4377": 7, "77": [7, 11, 12, 13, 21, 24, 28], "9167": 7, "48": [7, 12, 13, 14, 19, 20, 21, 28, 29], "4984": 7, "4454": 7, "0191": 7, "45": [7, 12, 13, 14, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 31], "7851": 7, "14": [7, 12, 13, 14, 15, 18, 19, 20, 21, 25, 28, 30], "96": [7, 8, 12, 13, 14, 25, 28], "6442": [7, 13], "76": [7, 11, 12, 13, 21, 27, 28], "8734": 7, "52": [7, 12, 13, 18, 21, 28, 29], "6675": [7, 13], "2222": 7, "75": [7, 11, 12, 13, 18, 19, 20, 21, 24, 28], "4701": 7, "46": [7, 12, 13, 14, 19, 20, 21, 28, 29], "0780": [7, 13], "74": [7, 12, 13, 21, 28], "7502": 7, "0797": [7, 13], "40": [7, 11, 12, 13, 14, 18, 19, 20, 21, 25, 28, 29], "4300": 7, "73": [7, 12, 13, 21, 28], "4617": 7, "72": [7, 12, 13, 21, 28], "8948": 7, "35": [7, 12, 13, 14, 18, 19, 20, 21, 28], "5483": 7, "3760": 7, "71": [7, 12, 13, 21, 28], "9013": 7, "31": [7, 12, 13, 14, 19, 20, 21, 28], "3371": 7, "simplifi": 8, "adjac": [8, 9, 12, 21, 22, 23, 25, 26, 28, 30], "amp": [8, 24], "agg_": [8, 9, 10, 24], "cohomologi": 8, "t_": [8, 16], "ccxn_layer": 8, "ccxnlayer": 8, "scalar": [8, 9, 24, 30], "messg": [8, 10, 15, 16, 17, 21, 22, 27, 31], "a_": [8, 9, 15, 21, 22, 23], "coboundari": [8, 9], "b_2": [8, 23, 26], "incidence_2_t_list": 8, "adjacency_0_list": 8, "incidence_2_t": 8, "incidence_matrix": [8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30], "adjacency_0": [8, 21, 22], "adjacency_matrix": [8, 9, 21, 22, 25, 26, 28, 30], "stack": [8, 9, 11, 12, 13, 14, 17, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31], "modulelist": [8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24, 25, 26, 27, 28, 29, 30], "neighborhood_0_to_0": 8, "neighborhood_1_to_2": 8, "transpos": [8, 24, 26], "boundari": [8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 22, 28, 30], "between": [8, 23, 28], "incidence_2_t_train": 8, "incidence_2_t_test": 8, "adjacency_0_train": 8, "adjacency_0_test": 8, "low": [8, 9, 10, 11, 12, 14, 16, 17, 20, 21, 22, 23, 25, 26, 27, 28, 31], "4544": 8, "ninamiolan": 8, "tmxtest": 8, "python3": [8, 14, 26, 28], "82": [8, 11, 12, 13, 18, 28], "0496": [8, 13], "36": [8, 12, 13, 14, 19, 20, 21, 28], "4422": [8, 13], "83": [8, 11, 12, 13, 14, 28], "8916": 8, "9388": 8, "49": [8, 12, 13, 14, 19, 20, 21, 28, 29], "7630": 8, "99": [8, 12, 13, 14, 18, 25, 26, 28, 30], "6948": [8, 23], "84": [8, 9, 11, 12, 13, 28], "4177": 8, "39": [8, 12, 13, 14, 18, 19, 20, 21, 26, 28, 29], "5379": [8, 21], "85": [8, 9, 11, 12, 13, 14, 28], "5503": 8, "8946": 8, "6596": 8, "weisfeil": 9, "lehman": 9, "h_z": [9, 10], "_k": [9, 23, 24], "cwn_layer": 9, "cwnlayer": 9, "upper": [9, 23, 25, 26, 28, 29, 30, 31], "b_r": [9, 28], "interc": 9, "b_": [9, 24, 28], "incidence_2_list": [9, 25, 26, 29], "adjacency_1_list": 9, "incidence_1_t_list": 9, "incidence_2": [9, 25, 26, 29, 30], "adjacency_1": [9, 26], "incidence_1_t": 9, "hid_channel": 9, "hidden": [9, 10, 12, 14, 15, 23, 30], "proj_0": 9, "proj_1": 9, "proj_2": 9, "out_channel": [9, 10, 11, 15, 16, 17, 19, 20, 23, 25, 29], "neighborhood_1_to_1": 9, "neighborhood_2_to_1": 9, "neighborhood_0_to_1": 9, "elu": 9, "instanti": 9, "05": [9, 30], "criterion": [9, 13], "adjacency_1_train": 9, "adjacency_1_test": 9, "incidence_2_train": [9, 25], "incidence_2_test": [9, 25], "incidence_1_t_train": 9, "incidence_1_t_test": 9, "106": [9, 13, 25, 28], "5665": 9, "4893": [9, 12], "54": [9, 12, 13, 18, 21, 28, 29], "3770": 9, "0177": 9, "6247": 9, "4964": 9, "notebook": [10, 11, 12, 13, 14, 15, 16, 17, 21, 22, 23, 25, 26, 29, 30, 31], "two": [10, 11, 13, 15, 16, 17, 21, 22, 23, 25, 28, 29, 30, 31], "collect": [10, 11, 12, 14, 15, 16, 17, 29], "repo": [10, 14, 16], "ln": 10, "mlp": [10, 19, 25], "vertex": [10, 30], "let": [10, 15, 16, 30], "textbf": [10, 16, 23], "mathbb": [10, 15, 30], "addition": [10, 28], "v_": [10, 15], "multiset": 10, "e_": 10, "set": [10, 11, 13, 16, 17, 18, 19, 20, 23, 28, 30, 31, 32], "updat": [10, 14, 23, 30], "rule": 10, "allset": 10, "framework": 10, "put": [10, 28], "f_": 10, "permut": 10, "invari": 10, "zero": [10, 18, 21, 22, 23, 25, 29, 30], "practic": 10, "parametr": 10, "learnt": 10, "achiev": [10, 28, 30], "rise": 10, "so": [10, 21, 22, 23, 25, 28, 29, 30, 31], "dive": 10, "iter": 10, "Their": 10, "correspond": [10, 12, 14, 18], "dimension": [10, 30], "h": [10, 15, 16, 18, 22, 23, 25, 26, 28, 29, 31], "omega": 10, "overset": [10, 23], "delta": 10, "mathbin": 10, "vert": [10, 16, 30], "mh": 10, "oper": [10, 15, 23, 25, 28, 30], "normal": [10, 26, 27, 28, 31], "ba": 10, "2016": 10, "concaten": [10, 15, 30], "hf_": 10, "learnabl": [10, 23, 29], "multihead": 10, "head": 10, "activ": [10, 26, 28], "vaswani": 10, "2017": [10, 21], "perceptron": 10, "row": 10, "wise": [10, 11, 15, 16, 17], "independ": 10, "allsettransformer_lay": 10, "allsettransformerlay": 10, "load_ext": [10, 20, 23], "autoreload": [10, 20, 23], "what": [10, 11, 15, 16, 17, 19, 20, 28, 31], "feed": [10, 11, 15, 16, 17, 19, 20, 30], "incid": [10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 28, 29], "b_1": [10, 11, 12, 13, 14, 15, 16, 17, 21, 22, 23, 26, 29], "n_": [10, 11, 12, 13, 14, 15, 16, 17, 21, 22, 23, 25, 28, 29, 31], "amtric": [10, 11, 15, 16, 17], "unsign": [10, 11, 15, 16, 17], "pairwis": [10, 11, 15, 16, 17, 30], "becom": [10, 11, 15, 16, 17, 23], "simplciial": [10, 11, 15, 16, 17], "hg_list": [10, 11, 15, 16, 17, 19, 20], "incidence_1_list": [10, 11, 15, 16, 17, 19, 20, 25, 26, 29], "incidence_1": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 29, 30], "sign": [10, 11, 13, 15, 16, 17, 26, 30, 31], "hg": [10, 11, 15, 16, 17, 19, 20], "to_hypergraph": [10, 11, 13, 15, 16, 17, 19, 20], "extract": [10, 15, 16, 20], "1250": [10, 13, 15, 16], "allsettransformermodel": 10, "combin": 10, "in_dim": 10, "hid_dim": 10, "out_dim": [10, 15, 19], "dropout": [10, 12, 14], "probabl": [10, 25], "input_dropout": 10, "mlp_num_lay": 10, "mlp_input_norm": 10, "in_channel": [10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 28, 29], "hidden_channel": [10, 23], "mlp_dropout": 10, "edge_index": [10, 12, 15, 16], "pooled_x": [10, 11, 15, 16, 17, 20], "max": [10, 15, 16, 17, 19, 20, 28], "sigmoid": [10, 15, 16, 17, 19, 20, 23, 24, 25, 26, 28, 30], "64": [10, 12, 13, 21, 28], "q_n": 10, "incidence_1_train": [10, 15, 16, 17, 19, 20, 25], "incidence_1_test": [10, 15, 16, 17, 19, 20, 25], "dtype": [10, 11, 12, 13, 14, 15, 16, 17, 18, 25, 29, 31], "to_edge_index": [10, 15, 16], "274": [10, 13, 16, 17], "9018": 10, "529": [10, 13, 15, 16, 17], "0000": [10, 13, 15, 16, 21, 22, 25, 28, 29], "6125": [10, 16], "dhgcn_layer": 11, "dhgcnlayer": 11, "100": [11, 12, 13, 14, 18, 19, 20, 24, 25, 26, 27, 28, 30], "dir": 11, "templatelay": [11, 17], "channels_edg": [11, 13, 15, 16, 17, 20], "channels_nod": [11, 13, 15, 16, 17, 20, 21, 22, 23, 25, 28, 29], "dhgcn": 11, "dynam": 11, "intermediate_channel": [11, 17, 19, 29], "global": [11, 15, 16, 17, 19, 20], "node_channel": [11, 26], "86": [11, 12, 13, 14, 24, 28], "87": [11, 12, 13, 28], "88": [11, 12, 13, 25, 28], "8821578": 11, "6946": 11, "36521": 11, "6562": 11, "17477": 11, "7685": 11, "212": [11, 13], "8590": 11, "152": [11, 13, 28], "9723": 11, "0999": 11, "177": [11, 13, 28], "0583": [11, 13], "163": [11, 13, 28], "9508": 11, "202": [11, 13], "9814": 11, "22": [11, 12, 13, 14, 19, 20, 21, 28], "2991": 11, "introduc": [12, 14, 15, 23], "livi": 12, "cora": [12, 18], "2708": 12, "academ": [12, 14], "5429": 12, "citat": [12, 18], "categori": [12, 14], "case_bas": 12, "genetic_algorithm": 12, "neural_network": 12, "probabilistic_method": 12, "reinforcement_learn": 12, "rule_learn": 12, "theori": 12, "document": [12, 14, 18, 23], "1433": [12, 13], "stand": [12, 14], "uniqu": [12, 13, 14, 26], "word": [12, 14], "presenc": [12, 14], "25": [12, 13, 14, 18, 19, 20, 21, 28, 30], "torch_geometr": [12, 14, 19, 20, 23], "planetoid": 12, "metric": [12, 13, 14], "accuracy_scor": [12, 14], "hmpnn_layer": 12, "hmpnnlayer": 12, "24": [12, 13, 14, 19, 20, 21, 28], "download": [12, 14, 18, 20], "val": [12, 19, 20, 30], "26": [12, 13, 14, 19, 20, 21, 28], "below": [12, 19, 30], "construct": [12, 14, 18, 30, 31], "27": [12, 13, 14, 19, 20, 21, 26, 28], "sparse_coo_tensor": [12, 14], "long": [12, 14, 28], "28": [12, 13, 14, 19, 20, 21, 28], "in_featur": [12, 14, 18, 25, 29], "hidden_featur": [12, 14], "tupl": [12, 25, 30], "gradual": 12, "reduc": 12, "last": [12, 28, 29, 30], "adjacency_dropout_r": 12, "rate": [12, 14], "regular_dropout_r": 12, "regular": 12, "to_hidden_linear": [12, 14], "sequenti": [12, 14, 19], "len": [12, 13, 14, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30], "adjacency_dropout": 12, "updating_dropout": 12, "to_categories_linear": [12, 14], "n_hyperedg": [12, 14], "b1": [12, 13, 21, 22, 25, 26, 28, 29], "y_pred": [12, 14, 18, 21, 22, 23, 25, 28, 29, 31], "logit": [12, 13, 14, 18, 21, 22, 25, 28, 29, 30], "hyperparamet": [12, 14, 18], "29": [12, 13, 14, 19, 20, 21, 28], "manual_se": [12, 30], "41": [12, 13, 14, 19, 20, 21, 28, 29], "256": [12, 13], "01": [12, 18, 21, 25, 29, 30], "30": [12, 13, 14, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30], "train_y_tru": [12, 14], "train_mask": [12, 14], "val_y_tru": 12, "val_mask": 12, "initial_x_1": 12, "zeros_lik": 12, "y_pred_logit": [12, 14], "train_loss": [12, 30], "argmax": [12, 13, 14, 18, 19, 30], "train_acc": [12, 13, 18, 21, 22, 23, 25, 28, 29, 30, 31], "eval": [12, 14, 18, 19, 20, 30], "val_loss": [12, 30], "val_acc": [12, 30], "acc": [12, 14], "2f": [12, 14], "1079": [12, 13], "1436": [12, 13], "0234": 12, "15": [12, 13, 14, 17, 18, 19, 20, 21, 24, 28, 30], "1016": [12, 13], "9800": 12, "0681": [12, 13], "9504": 12, "18": [12, 13, 14, 18, 19, 20, 21, 27, 28], "0389": [12, 13], "9194": 12, "21": [12, 13, 14, 19, 20, 21, 25, 28], "9241": 12, "19": [12, 13, 14, 19, 20, 21, 26, 28, 30], "9917": 12, "8917": 12, "9729": 12, "8710": 12, "23": [12, 13, 14, 19, 20, 21, 28], "9556": 12, "8574": 12, "9402": 12, "17": [12, 13, 14, 19, 20, 21, 28], "8646": 12, "9265": 12, "8540": 12, "33": [12, 13, 14, 19, 20, 21, 28, 31], "9136": 12, "8430": 12, "9012": 12, "8336": 12, "38": [12, 13, 14, 19, 20, 21, 28], "8886": 12, "8405": 12, "34": [12, 13, 14, 19, 20, 21, 22, 23, 25, 26, 28, 29, 31], "8775": 12, "8264": 12, "8668": 12, "8065": 12, "8562": 12, "37": [12, 13, 14, 18, 19, 20, 21, 28], "8158": 12, "8456": 12, "7957": 12, "44": [12, 13, 14, 19, 20, 21, 28, 29], "8346": 12, "8028": 12, "8249": 12, "20": [12, 13, 14, 18, 19, 20, 21, 25, 28, 30], "7882": 12, "8156": 12, "42": [12, 13, 14, 19, 20, 21, 28, 29], "7912": 12, "8070": 12, "7610": 12, "7987": 12, "7617": 12, "47": [12, 13, 14, 19, 20, 21, 28, 29], "7905": 12, "7596": 12, "7830": 12, "7391": 12, "7740": 12, "7315": 12, "7655": 12, "7365": 12, "7565": 12, "43": [12, 13, 14, 19, 20, 21, 26, 28, 29], "7184": 12, "7459": 12, "7085": 12, "7367": 12, "6815": [12, 13], "7279": 12, "6673": 12, "50": [12, 13, 14, 18, 19, 20, 21, 28, 29], "7178": 12, "32": [12, 13, 14, 15, 19, 20, 21, 28, 30], "6846": 12, "7077": 12, "6483": 12, "7000": [12, 28], "6436": 12, "6971": 12, "6353": 12, "6991": 12, "6336": 12, "6982": 12, "5938": 12, "60": [12, 13, 21, 28, 30], "6980": 12, "5886": 12, "56": [12, 13, 21, 28, 29], "6979": 12, "5974": 12, "6881": [12, 13], "5600": 12, "6694": 12, "5445": 12, "6513": 12, "5501": 12, "6308": 12, "5397": [12, 21], "6141": 12, "5096": 12, "6020": 12, "4992": 12, "5915": [12, 13], "5020": 12, "58": [12, 13, 21, 28], "5829": 12, "4710": 12, "5747": 12, "4608": 12, "67": [12, 13, 14, 21, 28], "5703": 12, "4341": 12, "62": [12, 13, 21, 28], "5632": 12, "4428": 12, "66": [12, 13, 14, 21, 28], "5630": 12, "4209": 12, "5502": 12, "4151": 12, "63": [12, 13, 28], "5303": 12, "53": [12, 13, 18, 21, 28, 29], "4090": 12, "5051": 12, "4021": 12, "3847": 12, "65": [12, 13, 21, 28], "4842": 12, "3907": 12, "61": [12, 13, 21, 25, 28], "4849": 12, "57": [12, 13, 14, 21, 28, 29], "3434": 12, "70": [12, 13, 21, 28], "4866": 12, "3253": 12, "69": [12, 13, 21, 28], "4864": 12, "3380": 12, "4896": 12, "2933": 12, "4921": 12, "3124": 12, "68": [12, 13, 21, 28], "4948": 12, "3091": 12, "4931": 12, "2768": 12, "4881": 12, "2749": 12, "4827": [12, 13], "2740": 12, "4833": 12, "2773": 12, "4744": 12, "2430": 12, "4646": 12, "4648": 12, "1958": [12, 13], "4734": 12, "1895": [12, 13], "4748": 12, "2008": 12, "4760": 12, "1573": [12, 13], "4385": 12, "1751": [12, 13], "4242": 12, "1889": [12, 13], "4183": 12, "1762": [12, 13], "4250": 12, "1737": [12, 13], "4471": 12, "1242": [12, 13], "4559": 12, "0648": [12, 13], "4498": 12, "0717": [12, 13], "4506": 12, "0568": [12, 13, 14], "4410": 12, "0650": [12, 13, 21], "4375": [12, 31], "0475": [12, 13], "4441": 12, "0293": 12, "4450": 12, "0494": [12, 13], "4622": 12, "0200": 12, "4609": 12, "0358": [12, 13], "4645": 12, "9877": 12, "0173": 12, "4788": 12, "9744": 12, "4970": 12, "90": [12, 13, 25, 28], "9497": 12, "4981": 12, "91": [12, 13, 14, 25, 28], "9345": 12, "4736": 12, "92": [12, 13, 25, 28], "9636": 12, "4339": 12, "93": [12, 13, 14, 18, 25, 26, 28], "9197": 12, "4162": 12, "94": [12, 13, 14, 25, 27, 28, 29], "8984": 12, "3813": 12, "95": [12, 13, 14, 25, 28], "8895": 12, "3547": 12, "9048": 12, "3499": 12, "97": [12, 13, 14, 25, 26, 28], "8737": 12, "3502": [12, 14], "98": [12, 13, 14, 24, 25, 28], "9479": 12, "3518": 12, "8906": 12, "3639": 12, "8589": 12, "3789": 12, "against": [12, 14], "test_y_tru": [12, 14], "test_mask": [12, 14], "test_acc": [12, 13, 18, 21, 22, 23, 25, 28, 29, 31], "2982": 12, "karateclub": [13, 21, 22, 23, 25, 28, 31], "w": [13, 15, 23], "hnhn_layer": 13, "hnhnlayer": [13, 14], "matplotlib": [13, 14, 30], "pyplot": [13, 14, 30], "plt": [13, 14, 30], "http": [13, 14, 18, 20, 21, 22, 23, 25, 28], "www": [13, 20, 21, 22, 23, 25, 28], "jstor": [13, 21, 22, 23, 25, 28], "org": [13, 21, 22, 23, 25, 28], "stabl": [13, 14, 21, 22, 23, 25, 28], "3629752": [13, 21, 22, 23, 25, 28], "singular": [13, 21, 22, 23, 25, 28], "social": [13, 21, 22, 23, 25, 28], "group": [13, 21, 22, 23, 25, 28], "dataset_sim": 13, "karate_club": [13, 21, 22, 23, 25, 28, 29, 31], "complex_typ": [13, 21, 22, 23, 25, 28, 29, 31], "dataset_hyp": 13, "santii": [13, 21, 22, 31], "classifi": [13, 14, 18], "channels_": 13, "hot": [13, 21, 22, 23, 25, 27, 31], "encod": [13, 21, 22, 23, 25, 30], "get_simplex_attribut": [13, 21, 22, 23, 25, 28, 29, 31], "n_class": [13, 26, 28], "y_1h": 13, "ey": [13, 18, 21, 23, 28, 31], "astyp": 13, "stratifi": 13, "ind_train": 13, "ind_test": 13, "arang": [13, 31], "random_st": 13, "float32": [13, 17, 18], "int32": 13, "fraction": 13, "hnhnnetwork": 13, "multiclass": 13, "map": [13, 25, 26, 28, 30], "hypernod": 13, "softmax": [13, 18, 21, 22, 23, 29, 30, 31], "made": [13, 21, 22, 23, 25, 27, 28, 29], "1e": [13, 20, 23, 30], "2000": 13, "get_accuraci": 13, "lambda": 13, "yhat": 13, "ytrue": 13, "full": 13, "y_hat_cl": 13, "nloss": 13, "ntrain_acc": 13, "7157": 13, "5000": [13, 25], "7135": 13, "7113": 13, "7093": 13, "7074": 13, "7056": 13, "7039": [13, 22], "7024": 13, "7010": 13, "6997": 13, "6985": 13, "6975": 13, "6966": 13, "6958": 13, "6951": 13, "6945": 13, "6940": 13, "6936": 13, "6933": 13, "6931": 13, "6930": 13, "6929": 13, "6928": 13, "6932": 13, "6927": 13, "6926": 13, "6925": 13, "6924": 13, "6429": 13, "6923": 13, "6922": 13, "6921": 13, "6920": 13, "6919": 13, "8571": 13, "9643": 13, "6918": 13, "7500": [13, 21, 25, 28], "6917": 13, "5714": 13, "5357": 13, "6916": 13, "6915": 13, "6914": 13, "6913": 13, "6912": 13, "6911": 13, "6910": 13, "6909": 13, "6908": 13, "6667": [13, 25, 28], "101": [13, 25, 28, 29], "6907": 13, "102": [13, 25, 28], "103": [13, 25, 26, 28], "6906": 13, "104": [13, 25, 26, 28], "105": [13, 25, 26, 28, 29], "6905": 13, "107": [13, 25, 28], "6904": 13, "108": [13, 18, 25, 28], "109": [13, 18, 28], "6903": 13, "110": [13, 18, 28], "6902": 13, "111": [13, 18, 28], "112": [13, 28], "6901": 13, "113": [13, 26, 28], "114": [13, 28], "6900": 13, "115": [13, 28], "6899": 13, "116": [13, 28], "117": [13, 24, 28], "6898": 13, "118": [13, 28], "6897": 13, "119": [13, 28], "120": [13, 28], "6896": 13, "121": [13, 18, 28], "6895": 13, "122": [13, 28], "6894": 13, "123": [13, 28, 29], "124": [13, 24, 28], "6893": 13, "125": [13, 28], "6892": 13, "126": [13, 28], "6891": 13, "127": [13, 28], "128": [13, 28], "6890": 13, "129": [13, 28], "6889": 13, "130": [13, 28], "6888": 13, "131": [13, 24, 28], "6887": 13, "132": [13, 24, 28], "6886": 13, "133": [13, 18, 24, 28], "134": [13, 24, 28], "6885": 13, "135": [13, 24, 28], "6884": 13, "136": [13, 24, 28], "6883": 13, "137": [13, 24, 28], "6882": 13, "138": [13, 24, 28], "139": [13, 24, 25, 28], "6880": 13, "140": [13, 18, 28], "6879": [13, 21], "141": [13, 28], "6878": 13, "142": [13, 24, 28], "6877": 13, "143": [13, 21, 24, 28], "6876": 13, "144": [13, 28], "6875": 13, "145": [13, 28], "6874": 13, "146": [13, 28], "6873": 13, "147": [13, 28], "6871": 13, "148": [13, 28], "6870": 13, "149": [13, 28], "6869": 13, "150": [13, 28, 30], "6868": 13, "151": [13, 28], "6867": 13, "6865": 13, "153": [13, 28], "6864": 13, "154": [13, 28], "6863": 13, "155": [13, 28], "6861": 13, "156": [13, 28], "6860": 13, "157": [13, 28], "6859": 13, "158": [13, 28], "6857": 13, "159": [13, 28], "6856": 13, "160": [13, 28], "6855": 13, "161": [13, 28], "6853": 13, "162": [13, 28], "6852": 13, "6850": 13, "164": [13, 25, 28], "6849": 13, "165": [13, 28], "6847": 13, "166": [13, 28], "6845": 13, "167": [13, 28], "6844": 13, "168": [13, 28], "6842": 13, "169": [13, 28], "6840": 13, "170": [13, 28], "6839": 13, "171": [13, 28], "6837": 13, "172": [13, 28], "6835": 13, "173": [13, 28], "6833": 13, "174": [13, 28], "6831": 13, "175": [13, 28], "6829": [13, 23], "176": [13, 28], "6827": 13, "6825": 13, "178": [13, 28], "6823": 13, "179": [13, 28], "6821": 13, "180": [13, 28, 29], "6819": 13, "181": [13, 28], "6817": 13, "182": [13, 24, 28], "183": [13, 28], "6813": 13, "184": [13, 28], "6810": 13, "185": [13, 18, 28], "6808": 13, "186": [13, 28], "6806": 13, "187": [13, 28], "6803": 13, "188": [13, 28], "6801": 13, "189": [13, 28], "6799": 13, "190": [13, 28], "6796": 13, "191": [13, 28], "6793": 13, "192": [13, 28], "6791": 13, "193": [13, 28], "6788": 13, "194": [13, 28], "6785": 13, "195": [13, 28], "6783": 13, "196": [13, 28], "6780": 13, "197": [13, 28], "6777": 13, "198": [13, 28], "6774": 13, "199": [13, 18, 28], "6771": 13, "200": [13, 14, 18, 28], "6768": 13, "201": 13, "6765": 13, "6762": 13, "203": 13, "6758": 13, "204": 13, "6755": 13, "205": 13, "6752": 13, "206": 13, "6748": 13, "207": 13, "6745": 13, "208": 13, "6741": 13, "209": 13, "6738": 13, "210": [13, 24, 25], "6734": 13, "211": 13, "6730": 13, "6726": 13, "213": 13, "6723": 13, "214": 13, "6719": 13, "215": 13, "6715": 13, "216": 13, "6710": 13, "217": 13, "6706": 13, "218": 13, "6702": 13, "6786": 13, "219": 13, "6698": [13, 23], "220": 13, "6693": 13, "221": 13, "6689": 13, "222": 13, "6684": 13, "223": 13, "6679": 13, "224": 13, "225": 13, "6670": 13, "226": 13, "6665": 13, "227": 13, "6660": 13, "228": 13, "6655": 13, "229": 13, "6649": 13, "230": 13, "6644": 13, "231": 13, "6639": 13, "232": 13, "6633": 13, "233": 13, "6628": 13, "234": 13, "6622": 13, "235": 13, "6616": 13, "236": 13, "6610": 13, "237": 13, "6604": 13, "238": 13, "6598": 13, "239": 13, "6592": 13, "240": 13, "6585": 13, "7143": 13, "241": 13, "6579": 13, "242": 13, "6572": 13, "243": 13, "6566": 13, "244": 13, "6559": 13, "245": 13, "6552": 13, "246": 13, "6545": 13, "247": 13, "6538": 13, "248": 13, "6531": 13, "249": 13, "6523": 13, "250": 13, "6516": 13, "8214": 13, "251": 13, "6508": 13, "6500": 13, "253": 13, "6492": 13, "254": 13, "6484": 13, "255": 13, "6476": 13, "6468": 13, "257": 13, "6459": 13, "258": 13, "6451": 13, "259": 13, "260": 13, "6433": 13, "261": 13, "6424": 13, "262": 13, "6415": 13, "263": 13, "6406": 13, "264": 13, "6397": 13, "265": 13, "6387": 13, "266": 13, "6378": 13, "267": 13, "6368": 13, "268": 13, "6358": 13, "269": 13, "6348": 13, "270": [13, 21], "6337": 13, "271": 13, "6327": 13, "272": 13, "6317": 13, "273": 13, "6306": 13, "6295": 13, "275": [13, 16], "6284": 13, "276": 13, "6273": [13, 28], "277": 13, "6262": 13, "278": [13, 15], "6250": 13, "279": 13, "6239": 13, "280": 13, "6227": 13, "281": [13, 15], "6215": 13, "282": [13, 15], "6203": 13, "283": 13, "6191": 13, "284": 13, "6178": 13, "285": 13, "6166": 13, "286": 13, "6153": 13, "287": 13, "6140": 13, "288": 13, "6127": 13, "289": 13, "6114": 13, "290": 13, "6101": 13, "291": 13, "6088": 13, "292": 13, "6074": 13, "293": 13, "6060": 13, "294": 13, "6046": [13, 14], "295": 13, "6032": 13, "296": [13, 25], "6018": 13, "297": 13, "6004": 13, "298": 13, "5989": 13, "299": 13, "5975": 13, "300": 13, "5960": 13, "301": 13, "5945": 13, "302": [13, 18], "5930": 13, "303": 13, "304": 13, "5900": 13, "305": 13, "5884": 13, "306": 13, "5868": 13, "307": 13, "5853": 13, "308": 13, "5837": 13, "309": 13, "5821": [13, 28], "310": [13, 24], "5805": [13, 21], "311": 13, "5788": 13, "312": 13, "5772": 13, "313": 13, "5755": 13, "314": 13, "5739": 13, "315": 13, "5722": 13, "316": 13, "5705": 13, "317": 13, "5688": 13, "318": 13, "5671": [13, 27], "319": 13, "5653": 13, "320": 13, "5636": 13, "321": 13, "5618": 13, "322": 13, "5601": 13, "323": 13, "5583": 13, "324": 13, "5565": 13, "325": 13, "5547": 13, "326": 13, "5529": 13, "327": 13, "5511": 13, "328": 13, "5492": 13, "329": 13, "5474": 13, "330": 13, "5455": 13, "331": 13, "5437": 13, "332": 13, "5418": 13, "333": 13, "5399": 13, "334": 13, "5381": 13, "335": 13, "5362": [13, 21], "336": 13, "5343": 13, "337": 13, "5323": [13, 31], "338": 13, "5304": 13, "339": 13, "5285": 13, "340": 13, "5266": 13, "8929": 13, "341": 13, "5246": [13, 21], "342": 13, "5227": 13, "343": 13, "5207": 13, "344": 13, "5188": [13, 21], "345": 13, "5168": 13, "346": 13, "5148": 13, "347": 13, "5129": 13, "348": 13, "5109": 13, "349": 13, "5089": 13, "350": 13, "5069": 13, "9286": 13, "351": 13, "5049": 13, "352": 13, "5029": 13, "353": 13, "5009": 13, "354": 13, "4989": 13, "355": 13, "4969": 13, "356": 13, "4949": 13, "357": 13, "4928": 13, "358": 13, "4908": 13, "359": 13, "4888": 13, "360": 13, "4868": 13, "361": 13, "4847": 13, "362": 13, "363": 13, "4807": 13, "364": 13, "4787": 13, "365": 13, "4766": 13, "366": 13, "4746": 13, "367": 13, "4726": 13, "368": 13, "4705": 13, "369": 13, "4685": 13, "370": 13, "4665": 13, "371": 13, "4644": 13, "372": 13, "4624": 13, "373": 13, "4604": 13, "374": 13, "4583": 13, "375": 13, "4563": 13, "376": 13, "4543": 13, "377": 13, "4523": 13, "378": 13, "4503": 13, "379": 13, "4482": 13, "380": 13, "4462": 13, "381": 13, "4442": 13, "382": 13, "383": 13, "4402": 13, "384": 13, "4382": 13, "385": 13, "4362": 13, "386": 13, "4342": 13, "387": 13, "4322": 13, "388": 13, "4302": 13, "389": 13, "4282": 13, "390": 13, "4262": 13, "391": 13, "4243": 13, "392": 13, "4223": 13, "393": 13, "4203": 13, "394": 13, "4184": 13, "395": [13, 18], "4164": 13, "396": 13, "4145": 13, "397": 13, "4125": 13, "398": 13, "4106": 13, "399": 13, "4086": 13, "400": [13, 14], "4067": 13, "401": 13, "4048": 13, "402": 13, "4029": 13, "403": 13, "4010": 13, "404": 13, "3991": 13, "405": 13, "3972": 13, "406": 13, "3953": 13, "407": 13, "3934": 13, "408": 13, "3915": 13, "409": 13, "3897": 13, "410": 13, "3878": 13, "411": [13, 29], "3859": 13, "412": 13, "3841": 13, "413": 13, "3823": 13, "414": 13, "3804": 13, "415": 13, "3786": 13, "416": 13, "3768": 13, "417": 13, "3750": [13, 15, 31], "418": 13, "3732": 13, "419": 13, "3714": 13, "420": 13, "3696": 13, "421": 13, "3678": 13, "422": 13, "3661": 13, "423": 13, "3643": 13, "424": 13, "3626": 13, "425": 13, "3608": 13, "426": 13, "3591": 13, "427": 13, "3573": 13, "428": 13, "3556": 13, "429": 13, "3539": 13, "430": 13, "3522": 13, "431": 13, "3505": 13, "432": 13, "3488": 13, "433": 13, "3472": 13, "434": 13, "3455": 13, "435": 13, "3438": 13, "436": 13, "3422": 13, "437": 13, "3406": 13, "438": 13, "3389": 13, "439": 13, "3373": 13, "440": 13, "3357": 13, "441": 13, "3341": 13, "442": 13, "3325": 13, "443": [13, 18], "3309": 13, "444": 13, "3293": 13, "445": 13, "3278": 13, "446": 13, "3262": 13, "447": 13, "3247": 13, "448": 13, "3231": 13, "449": 13, "3216": 13, "450": 13, "3201": 13, "451": 13, "3185": 13, "452": 13, "3170": 13, "453": 13, "3155": 13, "454": 13, "3140": 13, "455": 13, "3126": 13, "456": 13, "3111": 13, "457": 13, "3096": 13, "458": 13, "3082": 13, "459": 13, "3067": 13, "460": 13, "3053": 13, "461": 13, "3039": [13, 29], "462": 13, "3025": 13, "463": 13, "3011": 13, "464": 13, "2997": 13, "465": 13, "2983": 13, "466": 13, "2969": 13, "467": 13, "2955": 13, "468": 13, "2941": 13, "469": 13, "2928": 13, "470": 13, "2914": [13, 14], "471": 13, "2901": 13, "472": 13, "2888": 13, "473": 13, "2874": 13, "474": 13, "2861": 13, "475": 13, "2848": 13, "476": 13, "2835": 13, "477": 13, "2822": 13, "478": 13, "2810": 13, "479": 13, "2797": 13, "480": 13, "2784": 13, "481": 13, "2772": 13, "482": 13, "2759": 13, "483": 13, "2747": 13, "484": 13, "2735": 13, "485": 13, "2722": 13, "486": 13, "2710": 13, "487": 13, "2698": 13, "488": 13, "2686": 13, "489": 13, "2674": 13, "490": 13, "2662": 13, "491": 13, "2651": 13, "492": 13, "2639": 13, "493": 13, "2627": 13, "494": 13, "2616": 13, "495": 13, "2604": 13, "496": 13, "2593": 13, "497": 13, "2582": 13, "498": 13, "2571": 13, "499": 13, "2559": 13, "2548": 13, "501": 13, "2537": 13, "502": 13, "2526": 13, "503": 13, "2516": 13, "504": 13, "2505": 13, "505": 13, "2494": 13, "506": 13, "2484": 13, "507": 13, "2473": 13, "508": 13, "2463": 13, "509": 13, "2452": [13, 14], "510": 13, "2442": 13, "511": 13, "2432": 13, "512": 13, "2421": 13, "513": 13, "2411": 13, "514": 13, "2401": 13, "515": 13, "2391": 13, "516": 13, "2381": 13, "517": 13, "2371": 13, "518": 13, "2362": 13, "519": 13, "2352": 13, "520": 13, "2342": 13, "521": 13, "2333": 13, "522": 13, "2323": 13, "523": 13, "2314": 13, "524": 13, "525": 13, "2295": 13, "526": 13, "2286": 13, "527": 13, "2276": 13, "528": 13, "2267": 13, "2258": 13, "530": 13, "2249": 13, "531": 13, "2240": 13, "532": 13, "2231": [13, 14], "533": 13, "2223": 13, "534": 13, "2214": 13, "535": 13, "2205": 13, "2196": 13, "537": 13, "2188": 13, "538": 13, "2179": 13, "539": 13, "2171": 13, "540": 13, "2162": 13, "541": 13, "2154": 13, "542": 13, "2146": 13, "543": 13, "2137": 13, "544": 13, "2129": 13, "545": 13, "2121": 13, "546": [13, 26], "2113": 13, "547": 13, "2105": 13, "548": 13, "2097": 13, "549": 13, "2089": 13, "550": 13, "2081": 13, "551": 13, "2073": 13, "552": 13, "2066": 13, "553": 13, "2058": 13, "554": 13, "2050": 13, "555": 13, "2043": 13, "556": 13, "2035": 13, "557": 13, "2028": 13, "558": 13, "559": 13, "2013": 13, "560": 13, "2005": 13, "561": 13, "1998": 13, "562": 13, "1991": 13, "563": 13, "1983": [13, 28], "564": 13, "1976": 13, "565": 13, "1969": 13, "566": 13, "1962": [13, 21], "567": 13, "1955": 13, "568": 13, "1948": 13, "569": 13, "1941": 13, "570": 13, "1934": 13, "571": 13, "1927": 13, "572": 13, "1921": 13, "573": 13, "1914": 13, "574": 13, "1907": 13, "575": 13, "1900": 13, "576": 13, "1894": 13, "577": 13, "1887": 13, "578": 13, "1881": 13, "579": 13, "1874": 13, "580": 13, "1868": 13, "581": 13, "1861": 13, "582": 13, "1855": 13, "583": 13, "1849": 13, "584": 13, "1842": 13, "585": 13, "1836": [13, 21], "586": 13, "1830": 13, "587": 13, "1824": 13, "588": 13, "1818": 13, "589": 13, "1811": 13, "590": 13, "1805": 13, "591": 13, "1799": 13, "592": 13, "1793": 13, "593": 13, "1788": 13, "594": 13, "1782": 13, "595": 13, "1776": 13, "596": 13, "1770": 13, "597": 13, "1764": 13, "598": 13, "1758": 13, "599": 13, "1753": 13, "600": 13, "1747": 13, "601": 13, "1741": 13, "602": 13, "1736": 13, "603": 13, "1730": [13, 21], "604": 13, "1725": [13, 21], "605": 13, "1719": 13, "606": 13, "1714": 13, "607": 13, "1708": 13, "608": 13, "1703": 13, "609": 13, "1697": 13, "610": 13, "1692": 13, "611": 13, "1687": 13, "612": 13, "1682": 13, "613": [13, 30], "1676": 13, "614": 13, "1671": 13, "615": 13, "1666": 13, "616": 13, "1661": 13, "617": 13, "1656": 13, "618": 13, "1651": 13, "619": 13, "1646": 13, "620": 13, "1640": 13, "621": 13, "1636": 13, "622": 13, "1631": 13, "623": 13, "1626": 13, "624": 13, "1621": 13, "625": 13, "1616": 13, "626": 13, "1611": 13, "627": 13, "1606": 13, "628": 13, "1601": 13, "629": 13, "1597": 13, "630": 13, "1592": 13, "631": 13, "1587": 13, "632": 13, "1583": [13, 25], "633": 13, "1578": 13, "634": 13, "635": 13, "1569": 13, "636": 13, "1564": 13, "637": 13, "1560": [13, 21], "638": 13, "1555": 13, "639": 13, "1551": 13, "640": 13, "1546": 13, "641": 13, "1542": 13, "642": 13, "1537": 13, "643": 13, "1533": 13, "644": 13, "1529": 13, "645": 13, "1524": 13, "646": 13, "1520": 13, "647": 13, "1516": 13, "648": 13, "1511": [13, 21], "649": 13, "1507": 13, "650": 13, "1503": 13, "651": 13, "1499": 13, "652": 13, "1495": [13, 21], "653": 13, "1491": 13, "654": 13, "1487": [13, 21], "655": 13, "1482": 13, "656": 13, "1478": 13, "657": 13, "1474": [13, 21], "658": 13, "1470": 13, "659": 13, "1466": 13, "660": 13, "1462": 13, "661": 13, "1458": 13, "662": 13, "1454": 13, "663": 13, "1451": 13, "664": 13, "1447": 13, "665": 13, "1443": 13, "666": 13, "1439": 13, "667": 13, "1435": 13, "668": 13, "1431": 13, "669": 13, "1428": 13, "670": 13, "1424": 13, "671": 13, "1420": 13, "672": 13, "1416": 13, "673": 13, "1413": 13, "674": 13, "1409": 13, "675": 13, "1405": 13, "676": 13, "1402": 13, "677": 13, "1398": 13, "678": 13, "1395": 13, "679": 13, "1391": 13, "680": 13, "1387": 13, "681": 13, "1384": 13, "682": 13, "1380": [13, 21, 29], "683": 13, "1377": 13, "684": 13, "1373": 13, "685": 13, "1370": 13, "686": 13, "1367": 13, "687": 13, "1363": 13, "688": 13, "1360": 13, "689": 13, "1356": [13, 21], "690": 13, "1353": 13, "691": 13, "1350": 13, "692": 13, "1346": 13, "693": 13, "1343": [13, 21], "694": 13, "1340": 13, "695": 13, "1336": 13, "696": 13, "1333": 13, "697": 13, "1330": 13, "698": 13, "1327": 13, "699": 13, "1323": 13, "700": 13, "1320": 13, "701": 13, "1317": 13, "702": 13, "1314": 13, "703": 13, "1311": 13, "704": 13, "1308": 13, "705": 13, "1304": 13, "706": 13, "1301": 13, "707": 13, "1298": 13, "708": 13, "1295": 13, "709": 13, "1292": 13, "710": 13, "1289": 13, "711": 13, "1286": 13, "712": 13, "1283": 13, "713": 13, "1280": 13, "714": 13, "1277": 13, "715": 13, "1274": 13, "716": 13, "1271": 13, "717": 13, "1268": 13, "718": 13, "1265": 13, "719": 13, "1263": 13, "720": 13, "1260": 13, "721": 13, "1257": 13, "722": 13, "1254": 13, "723": 13, "1251": 13, "724": 13, "1248": 13, "725": 13, "1245": 13, "726": 13, "1243": 13, "727": 13, "1240": 13, "728": 13, "1237": 13, "729": 13, "1234": 13, "730": 13, "1232": 13, "731": 13, "1229": 13, "732": 13, "1226": 13, "733": 13, "1223": 13, "734": 13, "1221": 13, "735": 13, "1218": 13, "736": 13, "1215": 13, "737": 13, "1213": 13, "738": 13, "1210": 13, "739": 13, "1207": 13, "740": 13, "1205": 13, "741": 13, "1202": 13, "742": 13, "1200": [13, 30], "743": 13, "1197": 13, "744": 13, "1194": 13, "745": 13, "1192": 13, "746": 13, "1189": 13, "747": 13, "1187": 13, "748": 13, "1184": 13, "749": 13, "1182": 13, "1179": [13, 21], "751": 13, "1177": 13, "752": 13, "1174": 13, "753": 13, "1172": 13, "754": 13, "1169": 13, "755": 13, "1167": 13, "756": 13, "1165": 13, "757": 13, "1162": 13, "758": 13, "1160": 13, "759": 13, "1157": 13, "760": 13, "1155": 13, "761": 13, "1153": 13, "762": 13, "1150": [13, 28], "763": 13, "1148": 13, "764": 13, "1146": 13, "765": 13, "1143": 13, "766": 13, "1141": 13, "767": 13, "1139": [13, 14], "768": 13, "1136": 13, "769": 13, "1134": 13, "770": 13, "1132": 13, "771": 13, "1130": 13, "772": 13, "1127": 13, "773": 13, "1125": 13, "774": 13, "1123": 13, "775": 13, "1121": 13, "776": 13, "1118": 13, "777": 13, "1116": 13, "778": 13, "1114": 13, "779": 13, "1112": 13, "780": 13, "1110": 13, "781": 13, "1107": [13, 14], "782": 13, "1105": 13, "783": 13, "1103": 13, "784": 13, "1101": 13, "785": 13, "1099": 13, "786": 13, "1097": 13, "787": 13, "1095": 13, "788": 13, "1093": 13, "789": 13, "1090": 13, "790": 13, "1088": 13, "791": 13, "1086": 13, "792": 13, "1084": 13, "793": 13, "794": 13, "1080": [13, 21], "795": [13, 14], "1078": 13, "796": 13, "1076": 13, "797": 13, "1074": 13, "798": 13, "1072": 13, "799": 13, "1070": 13, "800": 13, "1068": 13, "801": 13, "1066": 13, "802": 13, "1064": 13, "803": 13, "1062": 13, "804": 13, "1060": 13, "805": [13, 14], "1058": 13, "806": 13, "1056": 13, "807": 13, "1054": 13, "808": 13, "1052": 13, "809": 13, "1050": 13, "810": 13, "1049": 13, "811": 13, "1047": 13, "812": 13, "1045": 13, "813": 13, "1043": 13, "814": 13, "1041": 13, "815": 13, "1039": 13, "816": 13, "1037": 13, "817": 13, "1035": 13, "818": 13, "1033": 13, "819": 13, "1032": 13, "820": 13, "1030": 13, "821": 13, "1028": 13, "822": 13, "1026": 13, "823": 13, "1024": 13, "824": 13, "1023": [13, 21], "825": 13, "1021": 13, "826": 13, "1019": [13, 21], "827": 13, "1017": 13, "828": 13, "1015": 13, "829": 13, "1014": 13, "830": 13, "1012": [13, 21], "831": 13, "1010": 13, "832": 13, "1008": 13, "833": 13, "1007": 13, "834": 13, "1005": 13, "835": 13, "1003": 13, "836": 13, "1001": 13, "837": 13, "1000": [13, 30], "838": 13, "0998": [13, 21], "839": 13, "0996": [13, 21], "840": 13, "0995": 13, "841": 13, "0993": 13, "842": 13, "0991": 13, "843": 13, "0990": 13, "844": 13, "0988": 13, "845": 13, "0986": 13, "846": 13, "0985": 13, "847": 13, "0983": 13, "848": 13, "0981": 13, "849": 13, "0980": 13, "850": 13, "0978": 13, "851": 13, "0976": 13, "852": 13, "0975": 13, "853": 13, "0973": 13, "854": 13, "0972": 13, "855": 13, "0970": 13, "856": 13, "0968": [13, 21], "857": 13, "0967": 13, "858": 13, "0965": 13, "859": 13, "0964": 13, "860": 13, "0962": 13, "861": 13, "0961": 13, "862": 13, "0959": [13, 21], "863": 13, "0957": 13, "864": 13, "0956": 13, "865": 13, "0954": [13, 21], "866": 13, "0953": 13, "867": 13, "0951": 13, "868": 13, "0950": 13, "869": 13, "0948": [13, 21], "870": 13, "0947": 13, "871": 13, "0945": 13, "872": 13, "0944": 13, "873": 13, "0942": 13, "874": 13, "0941": 13, "875": 13, "0939": 13, "876": 13, "0938": 13, "877": 13, "0936": 13, "878": 13, "0935": 13, "879": 13, "0933": 13, "880": 13, "0932": 13, "881": 13, "0930": [13, 21], "882": 13, "0929": 13, "883": 13, "0928": 13, "884": 13, "0926": 13, "885": 13, "0925": 13, "886": 13, "0923": [13, 21], "887": 13, "0922": 13, "888": 13, "0920": [13, 21], "889": 13, "0919": 13, "890": 13, "0918": 13, "891": 13, "0916": 13, "892": 13, "0915": 13, "893": 13, "0913": 13, "894": 13, "0912": [13, 28], "895": 13, "0911": 13, "896": 13, "0909": 13, "897": 13, "0908": 13, "898": 13, "0907": 13, "899": 13, "0905": 13, "900": 13, "0904": 13, "901": 13, "0902": 13, "902": 13, "0901": 13, "903": 13, "0900": 13, "904": 13, "0898": 13, "905": 13, "0897": [13, 21], "906": 13, "0896": 13, "907": 13, "0894": 13, "908": 13, "0893": 13, "909": 13, "0892": [13, 21], "910": 13, "0891": [13, 21], "911": 13, "0889": 13, "912": 13, "0888": 13, "913": 13, "0887": 13, "914": 13, "0885": 13, "915": 13, "0884": 13, "916": 13, "0883": 13, "917": 13, "0881": 13, "918": 13, "0880": 13, "919": 13, "0879": 13, "920": 13, "0878": 13, "921": 13, "0876": 13, "922": 13, "0875": 13, "923": 13, "0874": 13, "924": 13, "0873": 13, "925": 13, "0871": 13, "926": 13, "0870": 13, "927": 13, "0869": 13, "928": 13, "0868": 13, "929": 13, "0866": 13, "930": 13, "0865": 13, "931": 13, "0864": [13, 21], "932": 13, "0863": 13, "933": 13, "0862": 13, "934": 13, "0860": 13, "935": 13, "0859": 13, "936": 13, "0858": 13, "937": 13, "0857": 13, "938": 13, "0856": 13, "939": 13, "0854": 13, "940": 13, "0853": 13, "941": 13, "0852": 13, "942": 13, "0851": 13, "943": 13, "0850": 13, "944": 13, "0848": 13, "945": 13, "0847": 13, "946": 13, "0846": 13, "947": 13, "0845": 13, "948": 13, "0844": 13, "949": 13, "0843": 13, "950": 13, "0842": 13, "951": 13, "0840": 13, "952": 13, "0839": 13, "953": 13, "0838": 13, "954": 13, "0837": 13, "955": 13, "0836": 13, "956": 13, "0835": 13, "957": 13, "0834": 13, "958": 13, "0833": 13, "959": 13, "0831": 13, "960": 13, "0830": 13, "961": 13, "0829": 13, "962": 13, "0828": 13, "963": 13, "0827": 13, "964": 13, "0826": 13, "965": 13, "0825": 13, "966": 13, "0824": 13, "967": 13, "0823": 13, "968": 13, "0822": 13, "969": 13, "0820": 13, "970": 13, "0819": [13, 21], "971": 13, "0818": 13, "972": 13, "0817": 13, "973": 13, "0816": 13, "974": 13, "0815": 13, "975": 13, "0814": 13, "976": 13, "0813": 13, "977": 13, "0812": 13, "978": 13, "0811": 13, "979": 13, "0810": 13, "980": 13, "0809": 13, "981": 13, "0808": 13, "982": 13, "0807": 13, "983": 13, "0806": 13, "984": 13, "0805": [13, 28], "985": 13, "0804": [13, 21], "986": 13, "0803": [13, 21], "987": 13, "0802": 13, "988": 13, "0800": 13, "989": 13, "0799": 13, "990": 13, "0798": 13, "991": 13, "992": 13, "0796": 13, "993": 13, "0795": 13, "994": 13, "0794": 13, "995": 13, "0793": 13, "996": 13, "0792": 13, "997": 13, "0791": 13, "998": 13, "0790": 13, "999": 13, "0789": [13, 21], "0788": 13, "0787": 13, "1002": 13, "0786": [13, 14], "1004": 13, "0785": 13, "0784": 13, "1006": [13, 21], "0783": 13, "0782": 13, "0781": 13, "1009": [13, 21], "0779": 13, "1011": 13, "0778": 13, "0777": 13, "1013": 13, "0776": 13, "0775": 13, "0774": 13, "0773": 13, "0772": 13, "1018": 13, "0771": 13, "0770": 13, "1020": 13, "0769": 13, "0768": 13, "1022": 13, "0767": 13, "0766": 13, "1025": 13, "0765": 13, "0764": 13, "1027": 13, "0763": 13, "0762": [13, 21], "1029": 13, "0761": 13, "0760": 13, "1031": 13, "0759": [13, 21], "0758": 13, "1034": 13, "0757": 13, "0756": 13, "1036": 13, "0755": 13, "0754": [13, 21], "1038": 13, "0753": 13, "0752": 13, "1040": 13, "0751": 13, "0750": 13, "1042": 13, "0749": [13, 21], "1044": 13, "0748": 13, "0747": 13, "1046": [13, 21], "0746": [13, 21], "0745": 13, "1048": 13, "0744": 13, "0743": 13, "1051": 13, "0742": 13, "0741": 13, "1053": 13, "0740": 13, "0739": 13, "1055": 13, "0738": 13, "1057": 13, "0737": 13, "0736": 13, "1059": 13, "0735": 13, "0734": 13, "1061": 13, "0733": 13, "1063": 13, "0732": 13, "0731": [13, 21], "1065": 13, "0730": 13, "0729": 13, "1067": [13, 28], "0728": 13, "1069": 13, "0727": 13, "0726": 13, "1071": 13, "0725": [13, 21], "0724": [13, 21], "1073": 13, "0723": 13, "1075": 13, "0722": [13, 28], "0721": [13, 21], "1077": 13, "0720": [13, 21], "0719": 13, "0718": 13, "1081": 13, "0716": 13, "1083": 13, "0715": 13, "1085": 13, "0714": 13, "0713": 13, "1087": 13, "0712": 13, "1089": 13, "0711": 13, "0710": 13, "1091": 13, "0709": 13, "1092": 13, "0708": 13, "1094": 13, "0707": 13, "0706": 13, "1096": 13, "0705": 13, "1098": 13, "0704": 13, "0703": 13, "1100": 13, "0702": 13, "1102": 13, "0701": [13, 21], "0700": 13, "1104": 13, "0699": [13, 21], "1106": [13, 21], "0698": 13, "0697": 13, "1108": 13, "1109": 13, "0696": 13, "0695": 13, "1111": 13, "0694": 13, "1113": 13, "0693": [13, 21], "0692": 13, "1115": 13, "0691": 13, "1117": 13, "0690": 13, "0689": 13, "1119": 13, "1120": 13, "0688": 13, "0687": [13, 21], "1122": 13, "0686": 13, "1124": 13, "0685": [13, 21], "0684": 13, "1126": 13, "0683": 13, "1128": 13, "0682": 13, "1129": 13, "1131": 13, "0680": 13, "0679": 13, "1133": 13, "0678": 13, "1135": 13, "0677": 13, "1137": 13, "0676": 13, "1138": 13, "0675": 13, "0674": 13, "1140": 13, "0673": 13, "1142": 13, "0672": 13, "1144": 13, "0671": 13, "1145": 13, "0670": 13, "1147": 13, "0669": 13, "0668": 13, "1149": 13, "0667": 13, "1151": 13, "0666": 13, "1152": 13, "0665": 13, "1154": 13, "0664": 13, "1156": 13, "0663": [13, 21], "0662": 13, "1158": 13, "1159": 13, "0661": 13, "0660": 13, "1161": 13, "0659": 13, "1163": 13, "0658": 13, "1164": 13, "0657": 13, "1166": 13, "0656": 13, "1168": 13, "0655": 13, "1170": 13, "0654": 13, "1171": 13, "0653": 13, "1173": 13, "0652": 13, "0651": 13, "1175": 13, "1176": 13, "1178": 13, "0649": 13, "1180": 13, "1181": 13, "0647": 13, "0646": 13, "1183": 13, "0645": 13, "1185": 13, "1186": 13, "0644": 13, "0643": 13, "1188": 13, "0642": 13, "1190": 13, "0641": 13, "1191": 13, "0640": 13, "1193": 13, "0639": 13, "1195": 13, "0638": 13, "1196": 13, "0637": 13, "1198": 13, "1199": 13, "0636": 13, "0635": 13, "1201": 13, "0634": 13, "1203": 13, "1204": 13, "0633": 13, "0632": 13, "1206": 13, "0631": 13, "1208": 13, "1209": 13, "0630": 13, "0629": 13, "1211": 13, "1212": 13, "0628": 13, "1214": 13, "0627": 13, "1216": 13, "0626": 13, "1217": 13, "0625": 13, "1219": 13, "0624": 13, "1220": 13, "0623": 13, "1222": 13, "0622": 13, "1224": 13, "0621": 13, "1225": 13, "0620": 13, "1227": 13, "1228": 13, "0619": 13, "1230": 13, "0618": 13, "1231": 13, "0617": 13, "1233": 13, "0616": 13, "1235": 13, "0615": 13, "1236": 13, "0614": 13, "1238": 13, "0613": 13, "1239": 13, "0612": 13, "1241": 13, "0611": 13, "1244": 13, "0610": 13, "1246": 13, "0609": 13, "1247": 13, "0608": 13, "1249": 13, "0607": [13, 21], "0606": 13, "1252": 13, "1253": 13, "0605": 13, "1255": [13, 21], "0604": 13, "1256": 13, "0603": 13, "1258": 13, "1259": 13, "0602": 13, "1261": 13, "0601": [13, 28], "1262": 13, "0600": 13, "1264": 13, "0599": 13, "1266": 13, "0598": 13, "1267": 13, "0597": 13, "1269": 13, "1270": 13, "0596": 13, "1272": 13, "0595": 13, "1273": 13, "0594": 13, "1275": 13, "1276": 13, "0593": 13, "1278": 13, "0592": 13, "1279": 13, "0591": 13, "1281": 13, "1282": 13, "0590": 13, "1284": 13, "0589": 13, "1285": 13, "0588": 13, "1287": 13, "0587": 13, "1288": [13, 21], "0586": 13, "1290": 13, "1291": 13, "0585": 13, "1293": [13, 21, 28], "0584": 13, "1294": [13, 21], "1296": 13, "1297": 13, "0582": 13, "1299": 13, "0581": 13, "1300": 13, "0580": [13, 21], "1302": 13, "1303": 13, "0579": 13, "1305": 13, "1306": 13, "0578": 13, "1307": 13, "0577": 13, "1309": 13, "1310": 13, "0576": [13, 21], "1312": [13, 25], "0575": 13, "1313": 13, "0574": 13, "1315": 13, "1316": [13, 21], "0573": 13, "1318": 13, "0572": 13, "1319": 13, "0571": 13, "1321": 13, "1322": 13, "0570": 13, "1324": 13, "0569": 13, "1325": 13, "1326": 13, "1328": 13, "0567": 13, "1329": 13, "1331": 13, "0566": 13, "1332": [13, 21], "0565": 13, "1334": 13, "1335": 13, "0564": 13, "1337": 13, "0563": 13, "1338": 13, "1339": 13, "0562": 13, "1341": 13, "0561": [13, 14], "1342": 13, "1344": 13, "0560": [13, 14], "1345": 13, "0559": [13, 14], "1347": [13, 29], "1348": 13, "0558": 13, "1349": 13, "0557": 13, "1351": 13, "1352": 13, "0556": 13, "1354": 13, "1355": 13, "0555": 13, "1357": 13, "0554": 13, "1358": 13, "1359": 13, "0553": [13, 21], "1361": 13, "0552": 13, "1362": 13, "0551": 13, "1364": 13, "1365": 13, "1366": 13, "0550": 13, "1368": 13, "0549": 13, "1369": 13, "0548": 13, "1371": 13, "1372": 13, "0547": 13, "1374": 13, "1375": 13, "0546": [13, 21], "1376": 13, "0545": 13, "1378": 13, "1379": 13, "0544": 13, "1381": 13, "1382": 13, "0543": 13, "1383": 13, "0542": 13, "1385": 13, "1386": 13, "0541": 13, "1388": 13, "1389": 13, "0540": 13, "1390": 13, "0539": 13, "1392": 13, "1393": 13, "1394": 13, "0538": 13, "1396": 13, "0537": [13, 21], "1397": 13, "0536": 13, "1399": 13, "1400": 13, "1401": 13, "0535": 13, "1403": 13, "0534": 13, "1404": 13, "0533": 13, "1406": 13, "1407": 13, "1408": 13, "0532": 13, "1410": 13, "0531": 13, "1411": 13, "1412": 13, "0530": 13, "1414": 13, "1415": 13, "0529": 13, "1417": 13, "1418": 13, "0528": 13, "1419": 13, "0527": 13, "1421": 13, "1422": 13, "1423": 13, "0526": 13, "1425": 13, "0525": 13, "1426": [13, 21], "1427": 13, "0524": 13, "1429": [13, 21], "1430": 13, "0523": 13, "1432": 13, "0522": 13, "1434": 13, "0521": 13, "1437": 13, "1438": 13, "0520": 13, "1440": 13, "0519": 13, "1441": 13, "1442": 13, "0518": 13, "1444": 13, "1445": 13, "0517": 13, "1446": 13, "1448": 13, "0516": 13, "1449": [13, 28], "1450": 13, "0515": 13, "1452": 13, "1453": 13, "0514": [13, 25], "1455": 13, "0513": 13, "1456": 13, "1457": [13, 21], "0512": 13, "1459": 13, "1460": 13, "1461": 13, "0511": 13, "1463": 13, "0510": 13, "1464": 13, "1465": 13, "0509": 13, "1467": 13, "1468": 13, "1469": 13, "0508": 13, "1471": 13, "0507": 13, "1472": 13, "1473": [13, 21], "0506": 13, "1475": [13, 21], "1476": 13, "0505": 13, "1477": 13, "1479": 13, "0504": 13, "1480": 13, "1481": 13, "0503": 13, "1483": 13, "1484": [13, 21], "1485": 13, "0502": 13, "1486": 13, "0501": 13, "1488": 13, "1489": 13, "1490": 13, "0500": 13, "1492": 13, "1493": 13, "0499": 13, "1494": 13, "0498": 13, "1496": 13, "1497": 13, "1498": [13, 14], "0497": 13, "1500": 13, "1501": 13, "1502": 13, "1504": 13, "0495": 13, "1505": 13, "1506": 13, "1508": 13, "1509": 13, "0493": 13, "1510": 13, "1512": 13, "0492": 13, "1513": 13, "1514": 13, "1515": 13, "0491": 13, "1517": 13, "1518": [13, 21], "0490": 13, "1519": [13, 21], "0489": 13, "1521": 13, "1522": 13, "1523": 13, "0488": 13, "1525": 13, "1526": 13, "0487": 13, "1527": 13, "1528": 13, "0486": 13, "1530": 13, "1531": 13, "1532": 13, "0485": 13, "1534": 13, "1535": 13, "0484": 13, "1536": 13, "1538": 13, "0483": 13, "1539": 13, "1540": 13, "1541": 13, "0482": 13, "1543": 13, "1544": 13, "0481": 13, "1545": [13, 21], "0480": 13, "1547": 13, "1548": 13, "1549": 13, "0479": 13, "1550": 13, "1552": 13, "0478": 13, "1553": 13, "1554": 13, "0477": 13, "1556": 13, "1557": 13, "1558": 13, "0476": 13, "1559": 13, "1561": 13, "1562": 13, "1563": 13, "0474": 13, "1565": 13, "1566": 13, "1567": 13, "0473": 13, "1568": 13, "1570": 13, "0472": 13, "1571": 13, "1572": 13, "0471": 13, "1574": 13, "1575": [13, 21], "1576": 13, "0470": 13, "1577": 13, "1579": 13, "0469": 13, "1580": 13, "1581": 13, "1582": 13, "0468": 13, "1584": 13, "1585": 13, "1586": 13, "0467": 13, "1588": [13, 28], "1589": 13, "0466": 13, "1590": 13, "1591": 13, "0465": 13, "1593": 13, "1594": 13, "1595": 13, "0464": 13, "1596": 13, "1598": 13, "0463": 13, "1599": 13, "1600": 13, "0462": 13, "1602": 13, "1603": 13, "1604": 13, "0461": 13, "1605": 13, "1607": 13, "0460": 13, "1608": 13, "1609": 13, "1610": 13, "0459": 13, "1612": 13, "1613": 13, "1614": 13, "0458": 13, "1615": 13, "1617": 13, "0457": 13, "1618": 13, "1619": 13, "1620": 13, "0456": 13, "1622": 13, "1623": 13, "0455": 13, "1624": 13, "1625": 13, "0454": 13, "1627": 13, "1628": [13, 21, 28], "1629": 13, "1630": 13, "0453": 13, "1632": 13, "1633": 13, "0452": 13, "1634": 13, "1635": 13, "0451": 13, "1637": 13, "1638": [13, 28], "1639": 13, "0450": 13, "1641": 13, "1642": 13, "1643": 13, "0449": 13, "1644": 13, "1645": 13, "0448": 13, "1647": 13, "1648": 13, "1649": 13, "0447": [13, 14], "1650": 13, "1652": 13, "0446": 13, "1653": 13, "1654": [13, 21], "1655": 13, "0445": 13, "1657": 13, "1658": 13, "1659": 13, "0444": 13, "1660": 13, "1662": 13, "1663": 13, "0443": 13, "1664": 13, "1665": 13, "0442": 13, "1667": 13, "1668": 13, "1669": 13, "0441": 13, "1670": 13, "1672": 13, "1673": 13, "0440": 13, "1674": 13, "1675": 13, "0439": 13, "1677": 13, "1678": 13, "1679": 13, "0438": 13, "1680": 13, "1681": 13, "1683": 13, "0437": 13, "1684": 13, "1685": 13, "1686": 13, "0436": 13, "1688": 13, "1689": 13, "1690": 13, "0435": 13, "1691": 13, "1693": 13, "0434": 13, "1694": 13, "1695": 13, "1696": 13, "0433": 13, "1698": 13, "1699": 13, "1700": 13, "0432": 13, "1701": 13, "1702": 13, "1704": 13, "0431": [13, 28], "1705": 13, "1706": 13, "1707": 13, "0430": 13, "1709": 13, "1710": 13, "1711": 13, "0429": 13, "1712": 13, "1713": 13, "0428": 13, "1715": 13, "1716": 13, "1717": 13, "1718": 13, "0427": 13, "1720": 13, "1721": 13, "0426": 13, "1722": 13, "1723": 13, "1724": [13, 21], "0425": 13, "1726": 13, "1727": 13, "1728": 13, "0424": 13, "1729": 13, "1731": 13, "1732": 13, "0423": 13, "1733": 13, "1734": [13, 21], "1735": 13, "0422": 13, "1738": [13, 21], "1739": 13, "0421": 13, "1740": 13, "1742": 13, "1743": 13, "0420": 13, "1744": 13, "1745": 13, "1746": 13, "0419": 13, "1748": 13, "1749": 13, "1750": 13, "0418": 13, "1752": 13, "1754": 13, "0417": 13, "1755": 13, "1756": 13, "1757": 13, "0416": 13, "1759": 13, "1760": 13, "1761": 13, "0415": 13, "1763": [13, 21], "1765": 13, "0414": 13, "1766": 13, "1767": 13, "1768": 13, "1769": 13, "0413": 13, "1771": 13, "1772": 13, "0412": [13, 28], "1773": 13, "1774": 13, "1775": 13, "0411": 13, "1777": 13, "1778": 13, "1779": 13, "1780": [13, 21], "0410": 13, "1781": [13, 28], "1783": 13, "1784": 13, "0409": 13, "1785": 13, "1786": 13, "1787": 13, "0408": 13, "1789": 13, "1790": 13, "1791": 13, "0407": 13, "1792": 13, "1794": 13, "1795": 13, "0406": [13, 14], "1796": 13, "1797": 13, "1798": 13, "0405": 13, "1800": 13, "1801": 13, "1802": 13, "1803": 13, "0404": 13, "1804": [13, 21], "1806": 13, "1807": 13, "0403": 13, "1808": 13, "1809": 13, "1810": 13, "0402": 13, "1812": [13, 21], "1813": 13, "1814": 13, "0401": 13, "1815": 13, "1816": 13, "1817": 13, "0400": 13, "1819": 13, "1820": 13, "1821": [13, 21], "1822": 13, "0399": 13, "1823": 13, "1825": 13, "1826": 13, "0398": 13, "1827": 13, "1828": 13, "1829": 13, "0397": 13, "1831": [13, 21], "1832": 13, "1833": 13, "1834": 13, "0396": [13, 14], "1835": 13, "1837": 13, "1838": 13, "0395": 13, "1839": 13, "1840": 13, "1841": 13, "0394": 13, "1843": 13, "1844": 13, "1845": 13, "1846": 13, "0393": 13, "1847": 13, "1848": 13, "1850": 13, "0392": 13, "1851": [13, 21], "1852": 13, "1853": 13, "1854": 13, "0391": 13, "1856": 13, "1857": 13, "1858": 13, "0390": 13, "1859": 13, "1860": 13, "1862": 13, "1863": 13, "1864": 13, "1865": 13, "1866": 13, "0388": 13, "1867": 13, "1869": 13, "1870": 13, "0387": 13, "1871": 13, "1872": 13, "1873": 13, "0386": 13, "1875": 13, "1876": 13, "1877": 13, "1878": 13, "0385": 13, "1879": 13, "1880": 13, "1882": 13, "0384": 13, "1883": 13, "1884": 13, "1885": 13, "1886": 13, "0383": 13, "1888": 13, "1890": 13, "1891": 13, "0382": [13, 28], "1892": 13, "1893": 13, "0381": 13, "1896": 13, "1897": 13, "1898": 13, "1899": 13, "0380": 13, "1901": 13, "1902": 13, "1903": 13, "0379": 13, "1904": 13, "1905": 13, "1906": 13, "0378": 13, "1908": 13, "1909": 13, "1910": 13, "1911": 13, "1912": 13, "0377": 13, "1913": 13, "1915": 13, "1916": 13, "0376": 13, "1917": 13, "1918": 13, "1919": 13, "1920": 13, "0375": 13, "1922": 13, "1923": 13, "1924": 13, "0374": 13, "1925": 13, "1926": 13, "1928": 13, "1929": 13, "0373": 13, "1930": 13, "1931": 13, "1932": 13, "1933": 13, "0372": 13, "1935": 13, "1936": 13, "1937": 13, "0371": 13, "1938": 13, "1939": 13, "1940": 13, "1942": 13, "0370": 13, "1943": 13, "1944": 13, "1945": 13, "1946": 13, "0369": 13, "1947": 13, "1949": 13, "1950": 13, "0368": 13, "1951": 13, "1952": 13, "1953": 13, "1954": 13, "0367": 13, "1956": 13, "1957": 13, "1959": 13, "0366": 13, "1960": 13, "1961": 13, "1963": 13, "0365": 13, "1964": 13, "1965": 13, "1966": 13, "1967": 13, "1968": 13, "0364": 13, "1970": 13, "1971": 13, "1972": 13, "0363": 13, "1973": 13, "1974": 13, "1975": 13, "1977": 13, "0362": 13, "1978": 13, "1979": 13, "1980": 13, "1981": 13, "0361": 13, "1982": 13, "1984": 13, "1985": 13, "0360": 13, "1986": 13, "1987": 13, "1988": 13, "1989": 13, "1990": 13, "0359": 13, "1992": 13, "1993": 13, "1994": 13, "1995": 13, "1996": 13, "1997": 13, "1999": 13, "0357": 13, "plot": [13, 30], "figur": 13, "dpi": 13, "test_epoch": 13, "isfinit": 13, "linestyl": 13, "marker": 13, "legend": [13, 30], "xlabel": 13, "cites": 14, "3703": 14, "manifold": 14, "tsne": 14, "hnhn_layer_bi": 14, "randomnodesplit": 14, "home": [14, 26, 28], "sadra": 14, "local": [14, 31, 32], "tqdm": [14, 30], "auto": 14, "tqdmwarn": 14, "iprogress": 14, "found": [14, 18], "jupyt": 14, "ipywidget": 14, "readthedoc": 14, "io": 14, "en": 14, "user_instal": 14, "html": 14, "autonotebook": 14, "notebook_tqdm": 14, "offici": 14, "accord": [14, 27], "wget": [14, 18], "com": [14, 18, 20], "twistedcub": 14, "raw": [14, 18], "master": [14, 18], "citeseer6cls3703": 14, "pt": [14, 30], "paper_x": 14, "indic": [14, 21, 22, 23, 25, 28, 30, 31], "longtensor": [14, 18], "paper_author": 14, "train_test_splitt": 14, "num_test": 14, "num_val": 14, "dropout_r": 14, "normalization_param_alpha": 14, "normalization_param_beta": 14, "enumer": [14, 18, 30], "schedul": 14, "initial_lr": 14, "04": [14, 21, 30], "lr_schedul": 14, "steplr": 14, "gamma": 14, "7889": 14, "6347": 14, "6458": 14, "9118": 14, "5491": 14, "7203": 14, "5956": 14, "4068": 14, "4721": 14, "7964": 14, "3431": 14, "5075": 14, "0124": 14, "9682": 14, "2804": 14, "2483": 14, "2004": 14, "2019": 14, "0248": [14, 28], "0219": 14, "0217": 14, "0328": 14, "0180": 14, "0220": 14, "0232": 14, "0241": 14, "0130": 14, "0239": 14, "0240": 14, "0284": 14, "0295": 14, "0163": 14, "0195": 14, "0323": 14, "8441": 14, "worth": 14, "visual": [14, 30], "n_compon": 14, "fit_transform": 14, "ax1": 14, "ax2": 14, "subplot": [14, 30], "suptitl": 14, "set_titl": [14, 30], "_t_sne": 14, "futurewarn": 14, "chang": [14, 21, 28, 30], "pca": 14, "warn": [14, 20, 26], "hypergat": 15, "ding": 15, "t_1": 15, "zy": [15, 16, 22], "m_z": [15, 16], "xz": [15, 16, 22], "rightarrow0": [15, 26], "connect": [15, 18, 22, 25, 30, 31], "As": 15, "j": [15, 16, 21, 26, 28, 30], "highlight": 15, "those": [15, 23], "formal": [15, 23], "alpha_": 15, "jk": 15, "nonlinear": [15, 29], "relu": [15, 19, 30], "trainabl": 15, "coeffici": 15, "frac": [15, 16], "operatornam": 15, "exp": 15, "u_": 15, "limits_": 15, "p": [15, 16, 23], "context": 15, "foral": [15, 23], "again": [15, 23, 24], "vi": [15, 16], "beta_": 15, "ij": 15, "leakyrelu": [15, 23], "anoth": 15, "measur": 15, "hypergat_lay": 15, "hypergatlay": 15, "7875": 15, "9625": 15, "hypersag": 16, "arya": 16, "strategi": 16, "w_y": 16, "w_z": 16, "lvert": 16, "rvert": 16, "interpret": 16, "propag": 16, "problem": [16, 18], "divid": 16, "intra": 16, "neighbor": [16, 29, 30], "inter": [16, 25], "leftarrow": 16, "alpha": [16, 18, 23, 30], "obtain": [16, 18, 23, 25, 29, 30], "hypersage_lay": 16, "hypersagelay": 16, "hypersagemodel": 16, "kwarg": 16, "features_nod": 16, "xavier_uniform": 16, "2431": 16, "templatenn": 17, "6126": 17, "0002": 17, "0001": 17, "cicitationcora": 18, "hgnn": 18, "utlil": 18, "neccessari": 18, "pickl": 18, "scipi": [18, 21, 26, 28, 30], "sp": 18, "unigcnii_lay": 18, "unigcniilay": 18, "directli": 18, "howev": [18, 25, 29], "computation": 18, "expens": [18, 21, 28], "malllabiisc": 18, "hypergcn": 18, "cocit": 18, "07": [18, 21, 30], "ca": 18, "certif": 18, "ssl": 18, "cert": 18, "crt": 18, "resolv": 18, "sent": 18, "await": 18, "respons": 18, "githubusercont": 18, "ok": 18, "404937": 18, "395k": 18, "applic": 18, "octet": 18, "stream": 18, "save": 18, "gt": [18, 30], "45k": 18, "kb": 18, "mb": 18, "101905": 18, "100k": 18, "52k": 18, "02": [18, 21, 30], "5436": 18, "3k": 18, "31k": 18, "51582": 18, "50k": 18, "37k": 18, "rb": 18, "handl": 18, "tmp": [18, 19, 20], "ipykernel_14655": 18, "121206761": 18, "deprecationwarn": 18, "csr_matrix": [18, 21, 28], "namespac": 18, "csr": 18, "deprec": 18, "pytorch": 18, "floattensor": 18, "num": 18, "hyper": [18, 30], "expect": [18, 26, 28], "gcnii": 18, "h2": [18, 28], "hstack": 18, "to_sparse_csr": [18, 20], "2226475299": 18, "support": [18, 23, 25, 29], "beta": [18, 30], "miss": 18, "trigger": 18, "intern": [18, 29], "aten": 18, "src": 18, "sparsecsrtensorimpl": 18, "cpp": 18, "predefin": 18, "train_idx": 18, "test_idx": 18, "unigcniimodel": 18, "num_lay": [18, 25, 29], "num_featur": 18, "num_nod": 18, "num_edg": 18, "copi": [18, 31], "skip": [18, 21, 30, 31, 32], "x_0_skip": 18, "clone": [18, 31], "ommit": 18, "cross": 18, "entropi": 18, "current": [18, 23, 25, 29], "readi": [18, 30], "mode": 18, "7071428298950195": 18, "39291277527809143": 18, "4376946985721588": 18, "9357143044471741": 18, "6137071847915649": 18, "8714285492897034": 18, "45210281014442444": 18, "9071428775787354": 18, "5502336621284485": 18, "9785714149475098": 18, "5463395714759827": 18, "5747663378715515": 18, "9857142567634583": 18, "5673676133155823": 18, "9428571462631226": 18, "552570104598999": 18, "9571428298950195": 18, "5607476830482483": 18, "tudataset": [19, 20], "to_networkx": [19, 20, 23], "simplicial_complex": [19, 20, 30], "simplicialcomplex": [19, 20, 23, 30], "unigin_lay": 19, "uniginlay": 19, "mutag": [19, 20], "root": [19, 20], "use_edge_attr": [19, 20], "x_1_list": [19, 20], "y_list": [19, 20], "unigin_nn": 19, "unigin": 19, "in_channels_nod": 19, "inp_emb": 19, "out_decod": 19, "pooled_x_0": 19, "node_dim": 19, "001": [19, 27], "x_1_val": [19, 20], "incidence_1_v": [19, 20], "y_val": [19, 20], "seper": 19, "unsqueez": [19, 30], "pred": [19, 20, 30], "3916015625": 19, "5625": [19, 20], "91788864135742": 19, "573387145996094": 19, "32501220703125": 19, "29070281982422": 19, "48554229736328": 19, "905006408691406": 19, "502838134765625": 19, "23980712890625": 19, "084415435791016": 19, "003536224365234": 19, "96804428100586": 19, "95846939086914": 19, "9611930847168": 19, "96879196166992": 19, "977806091308594": 19, "98638916015625": 19, "99394989013672": 19, "00029754638672": 19, "00556945800781": 19, "00981521606445": 19, "01326370239258": 19, "01602554321289": 19, "018226623535156": 19, "01999282836914": 19, "0213737487793": 19, "02241897583008": 19, "02317810058594": 19, "023704528808594": 19, "02401351928711": 19, "02414321899414": 19, "024078369140625": 19, "023826599121094": 19, "02338790893555": 19, "02278137207031": 19, "021995544433594": 19, "02100372314453": 19, "019805908203125": 19, "018394470214844": 19, "01671600341797": 19, "0147590637207": 19, "01249313354492": 19, "00986862182617": 19, "0068359375": 19, "003334045410156": 19, "999298095703125": 19, "99464416503906": 19, "98926544189453": 19, "98302459716797": 19, "975791931152344": 19, "unisage_lay": 20, "unisagelay": 20, "filterwarn": 20, "extens": 20, "alreadi": 20, "reload": 20, "reload_ext": 20, "chrsmrr": 20, "graphkerneldataset": 20, "unisagenn": 20, "unisag": 20, "bceloss": 20, "38711929321289": 20, "50642013549805": 20, "88081741333008": 20, "313419342041016": 20, "208885192871094": 20, "00963592529297": 20, "59610366821289": 20, "292537689208984": 20, "19595718383789": 20, "106815338134766": 20, "913330078125": 20, "710723876953125": 20, "6346549987793": 20, "63870620727539": 20, "57096481323242": 20, "44948196411133": 20, "391658782958984": 20, "39373779296875": 20, "34821319580078": 20, "241302490234375": 20, "159812927246094": 20, "131492614746094": 20, "08507537841797": 20, "99526023864746": 20, "924638748168945": 20, "894010543823242": 20, "868173599243164": 20, "829978942871094": 20, "808109283447266": 20, "807811737060547": 20, "785655975341797": 20, "746475219726562": 20, "724843978881836": 20, "700727462768555": 20, "660417556762695": 20, "624387741088867": 20, "606855392456055": 20, "585779190063477": 20, "568805694580078": 20, "556062698364258": 20, "53620147705078": 20, "51841163635254": 20, "507102966308594": 20, "491756439208984": 20, "478620529174805": 20, "475711822509766": 20, "467418670654297": 20, "449710845947266": 20, "429576873779297": 20, "42317771911621": 20, "alexandro": 21, "kero": 21, "_x": [21, 23, 26], "dist2cycle_lay": 21, "dist2cyclelay": 21, "linalg": [21, 23], "npla": 21, "a0": [21, 22], "sinc": [21, 22, 25, 28, 30], "becaus": [21, 22, 24, 25, 29], "serv": [21, 22], "simpli": [21, 22, 30], "demonstr": [21, 22], "similarli": [21, 22, 28], "emerg": [21, 22, 23, 25, 28], "part": [21, 22, 23, 25, 28], "four": [21, 22, 23, 25, 28], "y_true": [21, 22, 23, 25, 29], "ld": [21, 23], "l_tilde_pinv": 21, "pinv": 21, "invers": 21, "linv": 21, "x_1e": 21, "0971": 21, "0937": 21, "2140": 21, "2069": 21, "2927": 21, "3018": 21, "2309": 21, "0992": 21, "0943": 21, "0927": 21, "2678": [21, 28], "3090": 21, "0960": 21, "2077": 21, "2056": 21, "2813": 21, "nnz": 21, "layout": 21, "sparse_coo": 21, "56771909e": 21, "49643084e": 21, "13434650e": 21, "60154799e": 21, "03": [21, 30], "73820292e": 21, "65885226e": 21, "04038181e": 21, "08": [21, 30], "51925802e": 21, "09": [21, 30], "73643677e": 21, "95577741e": 21, "09312067e": 21, "39698386e": 21, "11006736e": 21, "25540316e": 21, "87149896e": 21, "65674657e": 21, "43987098e": 21, "79396772e": 21, "00662204e": 21, "45058060e": 21, "36910174e": 21, "82942520e": 21, "24798042e": 21, "85055751e": 21, "78386103e": 21, "24821486e": 21, "81510593e": 21, "07917011e": 21, "30485535e": 21, "19925834e": 21, "56662779e": 21, "25658545e": 21, "29514395e": 21, "73054542e": 21, "57650283e": 21, "87089108e": 21, "31973699e": 21, "45874534e": 21, "78385898e": 21, "24821523e": 21, "38282800e": 21, "29527006e": 21, "24821542e": 21, "45585343e": 21, "20149602e": 21, "39614227e": 21, "52603984e": 21, "02427802e": 21, "38569428e": 21, "20058507e": 21, "89658767e": 21, "67997003e": 21, "90682733e": 21, "88636552e": 21, "61071175e": 21, "75768661e": 21, "22418800e": 21, "07488209e": 21, "26928225e": 21, "52925774e": 21, "50903371e": 21, "71863856e": 21, "40345353e": 21, "36909867e": 21, "82943824e": 21, "90223058e": 21, "08467136e": 21, "43380561e": 21, "27135092e": 21, "31898531e": 21, "01219751e": 21, "78963115e": 21, "97890193e": 21, "49229891e": 21, "67953214e": 21, "75078206e": 21, "75904313e": 21, "03583546e": 21, "12457962e": 21, "10897127e": 21, "18870673e": 21, "28672193e": 21, "61245163e": 21, "48166016e": 21, "75217551e": 21, "67996958e": 21, "90682673e": 21, "44834775e": 21, "90006804e": 21, "59747154e": 21, "69860917e": 21, "59747209e": 21, "69862127e": 21, "59747284e": 21, "69861429e": 21, "59747191e": 21, "59747247e": 21, "69860823e": 21, "59747135e": 21, "11979373e": 21, "90869734e": 21, "59747228e": 21, "69860637e": 21, "59747303e": 21, "69861010e": 21, "59747116e": 21, "17587730e": 21, "43268425e": 21, "43105909e": 21, "32787512e": 21, "03376685e": 21, "44168448e": 21, "62169540e": 21, "41996737e": 21, "73246880e": 21, "97727704e": 21, "03496753e": 21, "71378374e": 21, "92902595e": 21, "15740368e": 21, "94057676e": 21, "48602486e": 21, "40909785e": 21, "14646482e": 21, "38315065e": 21, "76777497e": 21, "38311899e": 21, "76780128e": 21, "37373477e": 21, "49392605e": 21, "30545244e": 21, "10224779e": 21, "69429579e": 21, "59057510e": 21, "11831834e": 21, "86165255e": 21, "07662510e": 21, "53556532e": 21, "82225195e": 21, "76254632e": 21, "62731223e": 21, "63466549e": 21, "16528196e": 21, "62805045e": 21, "36022410e": 21, "48832843e": 21, "19494419e": 21, "13972221e": 21, "zia003": 21, "topox2": 21, "_index": [21, 28], "sparseefficiencywarn": [21, 28], "sparsiti": [21, 28], "lil_matrix": [21, 28], "effici": [21, 28], "_set_arrayxarrai": [21, 28], "produc": [21, 22, 23, 28, 29, 31], "compar": [21, 22, 23, 28, 29, 31], "high": [21, 31, 32], "binary_cross_entropy_with_logit": [21, 22, 23, 28, 29, 31], "y_hat_test": [21, 22, 23, 25, 28, 29, 31], "y_pred_test": [21, 22, 23, 25, 28, 29, 31], "test_accuraci": [21, 22, 23, 25, 28, 29, 31], "eq": [21, 22, 23, 25, 29, 31], "7231": 21, "6000": 21, "6989": 21, "5667": [21, 22, 25, 28, 29], "2500": [21, 23, 25, 28], "6737": 21, "6564": 21, "6434": 21, "6362": 21, "6290": 21, "4333": [21, 23], "6199": 21, "6117": 21, "6057": 21, "6011": 21, "5964": 21, "5911": 21, "5855": 21, "5764": 21, "4000": [21, 25], "5730": 21, "5696": 21, "5660": 21, "5624": 21, "5593": 21, "5567": 21, "5544": 21, "5520": 21, "5496": 21, "5472": 21, "5451": 21, "5432": 21, "5414": 21, "5346": 21, "5333": 21, "5320": 21, "5308": 21, "5295": 21, "5284": 21, "5273": 21, "5264": 21, "5255": 21, "5238": 21, "5230": 21, "5223": 21, "5216": 21, "5210": 21, "5204": 21, "5198": 21, "5193": 21, "5183": 21, "5178": 21, "5174": 21, "5170": 21, "5166": 21, "5163": 21, "5159": 21, "5156": 21, "_y": [22, 28, 31], "7216": 22, "7169": 22, "7151": 22, "7109": 22, "didact": 23, "clear": 23, "technic": 23, "work": 23, "novel": 23, "hing": 23, "proper": [23, 31], "abl": [23, 31], "triangl": [23, 25, 30], "lower": [23, 24, 25, 28, 29, 30, 31], "total": 23, "orient": 23, "fashion": 23, "remark": 23, "custom": 23, "symbol": 23, "involv": 23, "n_1": 23, "n_2": 23, "2p": 23, "q_r": 23, "kernel": 23, "hodg": [23, 25, 28], "l_r": 23, "phi": 23, "bigg": [23, 25, 29], "bigotimes_": 23, "bigoplus_": 23, "widetild": 23, "hy": 23, "alpha_k": 23, "neq": [23, 30], "affin": 23, "entri": [23, 25], "therefor": 23, "hop": [23, 29], "align": [23, 29], "textrm": 23, "a_k": [23, 30], "psi_k": 23, "n_k": 23, "gat": 23, "suppos": 23, "_j": 23, "underset": 23, "w_": 23, "q_": 23, "san_lay": 23, "sanlay": 23, "consid": [23, 25, 29], "tb_1": 23, "b_2b_2": 23, "notic": 23, "non": [23, 30], "pattern": 23, "simplic": [23, 25, 28, 29, 30], "just": [23, 28, 30], "maxium": 23, "simplex_order_k": 23, "ldown": 23, "valueerror": [23, 25, 29], "lup": 23, "gradient": 23, "tx_0": 23, "estim": 23, "multipli": 23, "diverg": 23, "deriv": 23, "could": [23, 28], "seen": 23, "incidence_0_1": 23, "plu": 23, "onto": 23, "accordingli": 23, "mm": 23, "henc": 23, "num_filters_j": 23, "approxim": [23, 30], "filter": [23, 25], "j_har": 23, "harmon": 23, "epsilon_har": 23, "compute_projection_matrix": 23, "matrix_pow": 23, "channels_in": 23, "y_hat_edg": 23, "fn": 23, "y_hat_edge_test": 23, "_pred_test": 23, "ge": 23, "7240": 23, "7114": 23, "7333": [23, 28], "6760": 23, "6721": 23, "6685": 23, "6677": 23, "6672": 23, "qquad": 24, "agg": 24, "sca_cmps_lay": 24, "scacmpslay": 24, "sc": [24, 25, 29, 30], "down_lap1_list": 24, "down_lap2_list": 24, "incidence1_t_list": 24, "incidence2_t_list": 24, "down_lap1": [24, 31], "down_lap2": 24, "incidence_1t": 24, "incidence_2t": 24, "channels_list": 24, "complex_dim": 24, "ampssca": 24, "tetahedron": 24, "complex_dimens": 24, "highest": [24, 30], "embed": 24, "lin0": 24, "lin1": 24, "lin2": 24, "aggr": [24, 26], "aggr_func": [24, 26], "update_func": [24, 25, 26, 28, 29, 30], "x_list": 24, "down_lap_list": 24, "incidencet_list": 24, "x_2f": 24, "flatten": [24, 26], "x_1f": 24, "x_0f": 24, "down_lap1_train": 24, "down_lap1_test": 24, "down_lap2_train": 24, "down_lap2_test": 24, "incidence1_t_train": 24, "incidence1_t_test": 24, "incidence2_t_train": 24, "incidence2_t_test": 24, "hzpmc22": 24, "wa": [24, 29], "did": 24, "incidence_t_list": 24, "correct_count": [24, 26], "round": [24, 26], "15074526998214": 24, "42108154296875": 24, "16418675570749": 24, "73768615722656": 24, "16661446671351": 24, "76749420166016": 24, "8968961050734": 24, "735595703125": 24, "84987897076644": 24, "7345199584961": 24, "18321903655306": 24, "809326171875": 24, "scnn": [25, 32], "account": 25, "At": [25, 29], "mathbf": [25, 29], "_t": [25, 29], "p_d": [25, 29], "p_u": [25, 29], "likewis": 25, "essenti": 25, "sccnn_layer": 25, "sccnnlayer": 25, "in_channels_al": 25, "_1": [25, 26, 29], "_2": [25, 26], "_0": 25, "yet": [25, 29], "max_rank": [25, 28, 29], "laplacian_0_list": [25, 29], "laplacian_down_1_list": [25, 29], "laplacian_up_1_list": [25, 29], "laplacian_2_list": [25, 29], "laplacian_0": [25, 29], "hodge_laplacian_matrix": [25, 29], "laplacian_down_1": [25, 29], "laplacian_up_1": [25, 29], "laplacian_2": [25, 29], "amend": 25, "readout": 25, "intermediate_channels_al": 25, "intermedi": [25, 29], "out_channels_al": 25, "conv_ord": 25, "sc_order": 25, "numer": [25, 29], "aggr_norm": [25, 29], "in_linear_0": 25, "in_linear_1": 25, "in_linear_2": 25, "out_channels_0": 25, "out_channels_1": 25, "out_channels_2": 25, "out_linear_0": 25, "out_linear_1": 25, "out_linear_2": 25, "x_all": 25, "laplacian_al": 25, "incidence_al": 25, "n_simplic": [25, 29], "l0": 25, "l1_d": 25, "l1_u": 25, "l2": 25, "pf": 25, "b2": [25, 26, 28, 29], "in_x_0": 25, "in_x_1": 25, "in_x_2": 25, "size_averag": 25, "out_featur": [25, 29], "bia": [25, 29], "laplacian_0_train": 25, "laplacian_0_test": 25, "laplacian_down_1_train": 25, "laplacian_down_1_test": 25, "laplacian_up_1_train": 25, "laplacian_up_1_test": 25, "laplacian_2_train": 25, "laplacian_2_test": 25, "288238": 25, "2517": 25, "7562": 25, "7251": 25, "7232": 25, "9496": 25, "2592": 25, "7179": 25, "8378": 25, "7978": 25, "laplacian_down_2": [25, 29], "laplacian_up_2": [25, 29], "coadjacency_matrix": [25, 28], "get_simplicial_featur": [25, 29], "which_feat": [25, 29], "elif": [25, 29], "binary_cross_entropi": 25, "0333": 25, "6766": 25, "3667": 25, "6162": 25, "6333": 25, "bunch": 26, "tild": 26, "rightarrow1": 26, "coo_matrix": 26, "diag": 26, "scconv_lay": 26, "scconvlay": 26, "return_count": 26, "0th": 26, "normalize_higher_order_adj": 26, "a_opt": 26, "arg": 26, "cochain": 26, "num_of_k_simplic": 26, "num_of_j_simplic": 26, "rowsum": 26, "ab": 26, "r_inv_sqrt": 26, "power": 26, "isinf": 26, "r_mat_inv_sqrt": 26, "a_opt_to": 26, "dot": 26, "neigborood": 26, "ssconv": 26, "incidence_1_norm": 26, "incidence_2_norm": 26, "adjacency_up_0_norm": 26, "adjacency_up_1_norm": 26, "adjacency_down_1_norm": 26, "adjacency_down_2_norm": 26, "get_neighborhood": 26, "incidence_1_norm_list": 26, "incidence_2_norm_list": 26, "adjacency_up_0_norm_list": 26, "adjacency_up_1_norm_list": 26, "adjacency_down_1_norm_list": 26, "adjacency_down_2_norm_list": 26, "up_laplacian_1_list": 26, "up_laplacian_2_list": 26, "down_laplacian_1_list": 26, "down_laplacian_2_list": 26, "up_laplacian_1": 26, "up_laplacian_2": 26, "down_laplacian_1": 26, "down_laplacian_2": 26, "edge_channel": [26, 31], "face_channel": 26, "linear_x0": 26, "linear_x1": 26, "linear_x2": 26, "node_mean": 26, "edge_mean": 26, "face_mean": 26, "todo": 26, "kha053": 26, "nvml": 26, "incid1": 26, "incid1_norm": 26, "incid2": 26, "incid2_norm": 26, "adj0_up_norm": 26, "adj1_up_norm": 26, "adj1_down_norm": 26, "adj2_down_norm": 26, "x_0t": 26, "x_1t": 26, "x_2t": 26, "incid1t": 26, "incid1_normt": 26, "incid2t": 26, "incid2_normt": 26, "adj0_up_normt": 26, "adj1_up_normt": 26, "adj1_down_normt": 26, "adj2_down_normt": 26, "yt": 26, "scn2_layer": 27, "scn2layer": 27, "chose": 27, "reshap": 27, "a_0": 27, "a_1": [27, 30], "a_2": [27, 30], "normalized_laplacian_matrix": 27, "scn2": 27, "x_0s_train": 27, "x_0s_test": 27, "x_1s_train": 27, "x_1s_test": 27, "x_2s_train": 27, "x_2s_test": 27, "a_0s_train": 27, "a_0s_test": 27, "a_1s_train": 27, "a_1s_test": 27, "a_2s_train": 27, "a_2s_test": 27, "6313": 27, "5828": 27, "7222": 27, "5361": 27, "4920": 27, "4495": 27, "4081": 27, "4065": 27, "3676": 27, "3283": 27, "2507": 27, "la": 28, "r_": 28, "mathrm": 28, "leq": [28, 30], "bigcup": 28, "scn_layer": 28, "scnlayer": 28, "feat_dim": 28, "arbitrari": 28, "maximum": [28, 30], "choos": [28, 30], "dictionari": 28, "tha": 28, "arbitrarili": 28, "formul": 28, "quit": 28, "close": 28, "h_r": 28, "2i": 28, "themselv": 28, "usual": 28, "suggest": [28, 32], "refrain": 28, "tetrahedron": 28, "sparse_to_torch": 28, "rank_": 28, "rank_0": 28, "h0": 28, "h1": 28, "h3": 28, "b3": 28, "program": 28, "recent": 28, "x_3": 28, "tetrahedron_feat": 28, "track": 28, "rank_1": 28, "rank_2": 28, "rank_3": 28, "dict": 28, "n_rank_r_cel": 28, "n_rank_r_minus_1_cel": 28, "via": [28, 29], "squeez": [28, 30], "typic": 28, "6779": 28, "7667": 28, "6076": 28, "5566": 28, "5347": 28, "5144": 28, "4904": 28, "4728": 28, "4449": 28, "8000": 28, "3994": 28, "8333": 28, "4043": 28, "3834": 28, "3222": 28, "3318": 28, "9000": 28, "2878": 28, "2527": 28, "2272": 28, "2147": 28, "9667": 28, "9333": 28, "0336": 28, "0182": 28, "0147": 28, "0132": 28, "0121": 28, "0114": 28, "0106": 28, "0093": 28, "0080": 28, "0070": 28, "0062": 28, "0057": 28, "0056": 28, "0053": 28, "0047": 28, "0040": 28, "0033": 28, "0029": 28, "0027": 28, "0026": 28, "0025": 28, "0023": 28, "0022": 28, "0021": 28, "0020": 28, "0019": 28, "0018": 28, "0017": 28, "0016": 28, "0015": 28, "0014": 28, "0013": 28, "0012": 28, "0011": 28, "0010": 28, "0009": 28, "0008": 28, "0007": 28, "0006": 28, "0005": 28, "0004": 28, "definit": 29, "itself": 29, "scnn_layer": 29, "scnnlayer": 29, "simplci": 29, "challeng": 29, "conv_order_down": 29, "conv_order_up": 29, "inter_channel": 29, "laplacian_down": 29, "laplacian_up": 29, "larger": 29, "x_train": 29, "x_test": 29, "laplacian_down_train": 29, "laplacian_down_test": 29, "laplacian_up_train": 29, "laplacian_up_test": 29, "simplex_order_select": 29, "8446": 29, "4423": 29, "6270": 29, "9483": 29, "9201": 29, "3076": 29, "6582": 29, "2524": 29, "maxim": 29, "chennel_edg": 29, "channel_fac": 29, "certain": 29, "classm": 29, "rm": 29, "mitchel": 29, "nichola": 29, "glaze": 29, "santiago": 29, "segarra": 29, "principl": [29, 30], "trajectori": 29, "confer": 29, "channels_x": 29, "7199": 29, "7196": 29, "7194": [29, 31], "7192": 29, "7190": 29, "rgs21": 30, "spend": 30, "synthet": 30, "ahead": 30, "itertool": 30, "product": 30, "tnx": 30, "networkx": 30, "nx": 30, "random_split": 30, "spatial": 30, "delaunai": 30, "distanc": 30, "scone_lay": 30, "sconelay": [30, 31], "seed": 30, "lt": 30, "_c": 30, "0x15d64d0b0": 30, "less": 30, "uniformli": 30, "point": 30, "triangul": 30, "cloud": 30, "disk": 30, "insid": 30, "remov": 30, "centroid": 30, "generate_complex": 30, "delet": 30, "uniform": 30, "sort": 30, "coordin": 30, "argsort": 30, "tri": 30, "disk_cent": 30, "disk_radiu": 30, "indices_includ": 30, "cdist": 30, "vertic": 30, "idx_dict": 30, "coord": 30, "instanc": 30, "euclidean": 30, "shortest": 30, "path": 30, "plot_complex": 30, "plane": 30, "idx": 30, "skeleton": 30, "poli": 30, "polygon": 30, "color": 30, "green": 30, "gca": 30, "add_patch": 30, "vstack": 30, "i_1": 30, "i_2": 30, "ldot": 30, "i_m": 30, "i_j": 30, "i_": 30, "neighbour": 30, "ground": 30, "truth": 30, "supervis": 30, "setup": 30, "subsect": 30, "randomli": 30, "pick": 30, "triplet": 30, "corner": 30, "around": 30, "middl": 30, "anti": 30, "diagon": 30, "n_max": 30, "determin": 30, "generate_trajectori": 30, "mid": 30, "region": 30, "start_nod": 30, "mid_nod": 30, "end_nod": 30, "all_triplet": 30, "increas": 30, "underli": 30, "distance_matrix": 30, "squareform": 30, "pdist": 30, "toarrai": 30, "from_numpy_arrai": 30, "path_1": 30, "shortest_path": 30, "path_2": 30, "plot_path": 30, "red": 30, "arrow": 30, "quiver": 30, "scale_unit": 30, "angl": [30, 31], "scale": 30, "yield": 30, "vectorized_trajectori": 30, "neigbors_mask": 30, "last_nod": 30, "turn": 30, "a_j": 30, "i_n": 30, "later": [30, 31], "trajectoriesdataset": 30, "lookup": 30, "speed": 30, "edge_lookup_t": 30, "__getitem__": 30, "vectorize_path": 30, "discard": 30, "neighbors_mask": 30, "__len__": 30, "c0": 30, "batch": 30, "loader": 30, "batch_siz": 30, "val_siz": 30, "train_siz": 30, "train_d": 30, "val_d": 30, "test_d": 30, "train_dl": 30, "val_dl": 30, "test_dl": 30, "c_1": 30, "chain": 30, "partial_1": 30, "c_0": 30, "That": 30, "score": 30, "hat": 30, "_m": 30, "hidden_dim": 30, "init": 30, "xavier_uniform_": 30, "hidden_dimens": 30, "reset_paramet": 30, "inf": 30, "log_softmax": 30, "neg": 30, "likelihood": 30, "penal": 30, "weight_decai": 30, "5e": 30, "loss_funct": 30, "nllloss": 30, "nll": 30, "training_histori": 30, "training_loss": 30, "traj": 30, "06": 30, "quick": 30, "confirm": 30, "everyth": 30, "reason": 30, "ax": 30, "ncol": 30, "figsiz": 30, "better": 30, "guess": 30, "3f": 30, "constructor": 30, "affect": 30, "capabl": 30, "revers": 30, "Or": 30, "real": 30, "world": 30, "ocean": 30, "drifter": 30, "scone_layer_bi": 31, "pyt": 31, "area": 31, "up_lap1": 31, "gather": 31, "pair": 31, "train_indic": 31, "test_indic": 31, "sconenn": 31, "iden": 31, "OF": 31, "7211": 31, "7185": 31, "5484": 31, "7205": 31, "7210": 31, "ajbr": 31, "appdata": 31, "temp": 31, "ipykernel_492": 31, "1152818844": 31, "recommend": 31, "sourcetensor": 31, "detach": 31, "requires_grad_": 31, "ccxn": 32, "unigcnii": 32, "homologi": 32, "dist2cycl": 32, "coadjac": 32, "cmp": 32, "sccnn": 32, "scconv": 32, "neighbourhood": 32, "scn": 32, "compl": 32, "content": 32, "experiment": 32, "prepar": 32}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"base": 0, "api": 1, "refer": [1, 6], "packag": 1, "modul": 1, "neural": [2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "network": [2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "hypergraph": [2, 10, 11, 12, 13, 14, 15, 16, 17, 18], "simplici": [2, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "complex": [2, 8, 24, 25, 26, 30, 31], "cell": [2, 8], "util": 3, "scatter": 3, "icml": 4, "2023": 4, "topolog": 4, "deep": 4, "learn": 4, "challeng": 4, "descript": 4, "public": 4, "outcom": 4, "particip": 4, "deadlin": 4, "how": 4, "submit": 4, "guidelin": 4, "submiss": 4, "requir": 4, "evalu": [4, 30], "question": 4, "contribut": 5, "make": 5, "chang": 5, "write": 5, "test": [5, 24, 26, 29, 30, 31], "run": 5, "document": 5, "intro": 5, "docstr": 5, "The": [5, 7, 8, 9, 23], "anatomi": 5, "exampl": 5, "topomodelx": 6, "tmx": 6, "get": 6, "start": 6, "train": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "cellular": 7, "attent": [7, 8, 23], "can": 7, "task": [7, 8, 9, 23], "set": [7, 8, 9], "up": [7, 8, 9], "pre": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "process": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "creat": [7, 8, 9, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "convolut": [8, 25, 26, 27, 28, 29], "ccxn": 8, "cw": 9, "cwn": 9, "addit": [10, 16], "theoret": [10, 16], "clarif": [10, 16], "defin": [10, 11, 13, 15, 16, 17, 21, 22, 25, 26, 27, 28, 29, 31], "import": [11, 13, 15, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31], "data": [11, 15, 17, 18, 19, 20, 24, 26, 30], "neighborhood": [11, 13, 15, 17, 21, 22, 25, 27, 28, 29, 31], "structur": [11, 13, 15, 17, 21, 22, 26, 27, 28, 31], "lift": [11, 15, 17], "domain": [11, 15, 17], "messag": [12, 24], "pass": [12, 24], "hmpnn": 12, "hyperedg": [13, 14], "neuron": [13, 14], "hnhn": [13, 14], "dataset": [13, 21, 22, 25, 26, 27, 28, 29, 30, 31], "signal": [13, 21, 22, 25, 28, 29], "us": 18, "unigcnii": 18, "layer": 18, "load": 18, "homologi": 21, "local": 21, "dist2cycl": 21, "binari": [21, 22, 25, 28, 29], "label": [21, 22, 25, 28, 29, 31], "featur": 21, "high": 22, "skip": 22, "hsn": 22, "san": 23, "abstract": 23, "autoencod": 24, "sca": 24, "coadjac": 24, "scheme": 24, "cmp": 24, "prepar": [24, 26, 29, 31], "input": [24, 31], "each": 24, "split": [24, 29, 31], "model": [24, 25, 29, 30], "sccnn": 25, "we": [25, 29], "perform": [25, 29], "1": [25, 29], "classif": [25, 29], "shrec": 25, "strcture": [25, 29], "2": [25, 26, 27, 29], "node": [25, 29], "scconv": 26, "helper": 26, "function": 26, "neighbourhood": 26, "scn": [27, 28], "rank": 27, "scnn": 29, "compl": 29, "karat": 29, "weight": 29, "hodg": 29, "laplacian": 29, "net": 30, "scone": [30, 31], "tabl": 30, "content": 30, "gener": 30, "trajectori": 30, "pytorch": 30, "dataload": 30, "suggest": 30, "further": 30, "experiment": 30, "tutori": 32}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.viewcode": 1, "sphinx": 60}, "alltitles": {"Base": [[0, "base"]], "API Reference": [[1, "api-reference"]], "Packages & Modules": [[1, null]], "Neural Networks": [[2, "neural-networks"]], "Hypergraph Neural Networks": [[2, "hypergraph-neural-networks"]], "Simplicial Complex Neural Networks": [[2, "simplicial-complex-neural-networks"]], "Cell Complex Neural Networks": [[2, "cell-complex-neural-networks"]], "Utils": [[3, "utils"]], "Scatter": [[3, "scatter"]], "ICML 2023 Topological Deep Learning Challenge": [[4, "icml-2023-topological-deep-learning-challenge"]], "Description of the Challenge": [[4, "description-of-the-challenge"]], "\u2b50\ufe0f Publication Outcomes for Participants \u2b50\ufe0f": [[4, "publication-outcomes-for-participants"]], "Deadline": [[4, "deadline"]], "How to Submit": [[4, "how-to-submit"]], "Guidelines": [[4, "guidelines"]], "Submission Requirements": [[4, "submission-requirements"]], "Evaluation": [[4, "evaluation"]], "Questions": [[4, "questions"]], "Contributing": [[5, "contributing"]], "Making Changes": [[5, "making-changes"]], "Write Tests": [[5, "write-tests"]], "Run Tests": [[5, "run-tests"]], "Write Documentation": [[5, "write-documentation"]], "Intro to Docstrings": [[5, "intro-to-docstrings"]], "The Anatomy of a Docstring": [[5, "the-anatomy-of-a-docstring"]], "Docstring Examples": [[5, "docstring-examples"]], "\ud83c\udf10 TopoModelX (TMX) \ud83c\udf69": [[6, "topomodelx-tmx"]], "\ud83d\udd0d References": [[6, "references"]], "\ud83e\uddbe Getting Started": [[6, "getting-started"]], "Train a Cellular Attention Network (CAN)": [[7, "Train-a-Cellular-Attention-Network-(CAN)"]], "The Neural Network:": [[7, "The-Neural-Network:"], [8, "The-Neural-Network:"], [9, "The-Neural-Network:"]], "The Task:": [[7, "The-Task:"], [8, "The-Task:"], [9, "The-Task:"], [23, "The-Task:"]], "Set-up": [[7, "Set-up"], [8, "Set-up"], [9, "Set-up"]], "Pre-processing": [[7, "Pre-processing"], [8, "Pre-processing"], [9, "Pre-processing"], [10, "Pre-processing"], [11, "Pre-processing"], [12, "Pre-processing"], [13, "Pre-processing"], [14, "Pre-processing"], [15, "Pre-processing"], [16, "Pre-processing"], [17, "Pre-processing"], [19, "Pre-processing"], [20, "Pre-processing"], [21, "Pre-processing"], [22, "Pre-processing"], [23, "Pre-processing"], [24, "Pre-processing"], [25, "Pre-processing"], [26, "Pre-processing"], [27, "Pre-processing"], [28, "Pre-processing"], [29, "Pre-processing"], [31, "Pre-processing"]], "Create the Neural Network": [[7, "Create-the-Neural-Network"], [8, "Create-the-Neural-Network"], [9, "Create-the-Neural-Network"], [11, "Create-the-Neural-Network"], [12, "Create-the-Neural-Network"], [13, "Create-the-Neural-Network"], [14, "Create-the-Neural-Network"], [17, "Create-the-Neural-Network"], [19, "Create-the-Neural-Network"], [20, "Create-the-Neural-Network"], [21, "Create-the-Neural-Network"], [22, "Create-the-Neural-Network"], [23, "Create-the-Neural-Network"], [26, "Create-the-Neural-Network"], [27, "Create-the-Neural-Network"], [28, "Create-the-Neural-Network"]], "Train the Neural Network": [[7, "Train-the-Neural-Network"], [8, "Train-the-Neural-Network"], [9, "Train-the-Neural-Network"], [10, "Train-the-Neural-Network"], [11, "Train-the-Neural-Network"], [12, "Train-the-Neural-Network"], [13, "Train-the-Neural-Network"], [14, "Train-the-Neural-Network"], [15, "Train-the-Neural-Network"], [16, "Train-the-Neural-Network"], [17, "Train-the-Neural-Network"], [19, "Train-the-Neural-Network"], [20, "Train-the-Neural-Network"], [21, "Train-the-Neural-Network"], [22, "Train-the-Neural-Network"], [23, "Train-the-Neural-Network"], [25, "Train-the-Neural-Network"], [25, "id3"], [26, "Train-the-Neural-Network"], [27, "Train-the-Neural-Network"], [28, "Train-the-Neural-Network"], [29, "Train-the-Neural-Network"]], "Train the Neural Network with Attention": [[7, "Train-the-Neural-Network-with-Attention"], [8, "Train-the-Neural-Network-with-Attention"]], "Train a Convolutional Cell Complex Network (CCXN)": [[8, "Train-a-Convolutional-Cell-Complex-Network-(CCXN)"]], "Train a CW Network (CWN)": [[9, "Train-a-CW-Network-(CWN)"]], "Train a Hypergraph Neural Network": [[10, "Train-a-Hypergraph-Neural-Network"], [11, "Train-a-Hypergraph-Neural-Network"], [15, "Train-a-Hypergraph-Neural-Network"], [16, "Train-a-Hypergraph-Neural-Network"], [17, "Train-a-Hypergraph-Neural-Network"]], "Additional theoretical clarifications": [[10, "Additional-theoretical-clarifications"], [16, "Additional-theoretical-clarifications"]], "Define the Neural Network": [[10, "Define-the-Neural-Network"], [15, "Define-the-Neural-Network"], [16, "Define-the-Neural-Network"]], "Import data": [[11, "Import-data"], [15, "Import-data"], [17, "Import-data"], [19, "Import-data"], [20, "Import-data"], [24, "Import-data"]], "Define neighborhood structures and lift into hypergraph domain.": [[11, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."], [15, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."], [17, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."]], "Train a Hypergraph Message Passing Neural Network (HMPNN)": [[12, "Train-a-Hypergraph-Message-Passing-Neural-Network-(HMPNN)"]], "Train a Hypergraph Networks with Hyperedge Neurons (HNHN)": [[13, "Train-a-Hypergraph-Networks-with-Hyperedge-Neurons-(HNHN)"]], "Import dataset": [[13, "Import-dataset"], [21, "Import-dataset"], [22, "Import-dataset"], [26, "Import-dataset"], [27, "Import-dataset"], [28, "Import-dataset"], [31, "Import-dataset"]], "Define neighborhood structures.": [[13, "Define-neighborhood-structures."], [21, "Define-neighborhood-structures."], [22, "Define-neighborhood-structures."], [27, "Define-neighborhood-structures."], [28, "Define-neighborhood-structures."]], "Import signal": [[13, "Import-signal"], [21, "Import-signal"], [22, "Import-signal"], [25, "Import-signal"], [28, "Import-signal"]], "Train a Hypergraph Network with Hyperedge Neurons (HNHN)": [[14, "Train-a-Hypergraph-Network-with-Hyperedge-Neurons-(HNHN)"]], "Train a hypergraph neural network using UniGCNII layers": [[18, "Train-a-hypergraph-neural-network-using-UniGCNII-layers"]], "Loading the data": [[18, "Loading-the-data"]], "Creating a neural network": [[18, "Creating-a-neural-network"]], "Training the neural network": [[18, "Training-the-neural-network"]], "Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)": [[21, "Train-a-Simplicial-Neural-Network-for-Homology-Localization-(Dist2Cycle)"]], "Define binary labels": [[21, "Define-binary-labels"], [22, "Define-binary-labels"], [25, "Define-binary-labels"], [28, "Define-binary-labels"]], "Create Features": [[21, "Create-Features"]], "Train a Simplicial High-Skip Network (HSN)": [[22, "Train-a-Simplicial-High-Skip-Network-(HSN)"]], "Train a Simplicial Attention Network (SAN)": [[23, "Train-a-Simplicial-Attention-Network-(SAN)"]], "Abstract": [[23, "Abstract"]], "The Neural Network": [[23, "The-Neural-Network"]], "Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)": [[24, "Train-a-Simplicial-Complex-Autoencoder-(SCA)-with-Coadjacency-Message-Passing-Scheme-(CMPS)"]], "Preparing the inputs to test each message passing scheme:": [[24, "Preparing-the-inputs-to-test-each-message-passing-scheme:"]], "Coadjacency Message Passing Scheme (CMPS):": [[24, "Coadjacency-Message-Passing-Scheme-(CMPS):"]], "Create the Neural Networks": [[24, "Create-the-Neural-Networks"]], "Train and Test Split": [[24, "Train-and-Test-Split"]], "Training and Testing Model": [[24, "Training-and-Testing-Model"]], "Train a SCCNN": [[25, "Train-a-SCCNN"]], "We train the model to perform:": [[25, "We-train-the-model-to-perform:"], [29, "We-train-the-model-to-perform:"]], "Simplicial Complex Convolutional Neural Networks [SCCNN]": [[25, "Simplicial-Complex-Convolutional-Neural-Networks-[SCCNN]"]], "1. Complex Classification": [[25, "1.-Complex-Classification"]], "Import shrec dataset": [[25, "Import-shrec-dataset"]], "Define Neighborhood Strctures": [[25, "Define-Neighborhood-Strctures"], [25, "id1"], [29, "Define-Neighborhood-Strctures"], [29, "id1"]], "Create the SCCNN": [[25, "Create-the-SCCNN"], [25, "id2"]], "2. Node Classification": [[25, "2.-Node-Classification"], [29, "2.-Node-Classification"]], "Train a Simplicial 2-complex convolutional neural network (SCConv)": [[26, "Train-a-Simplicial-2-complex-convolutional-neural-network-(SCConv)"]], "Helper functions": [[26, "Helper-functions"]], "Define Neighbourhood Structures": [[26, "Define-Neighbourhood-Structures"]], "prepare training and test data": [[26, "prepare-training-and-test-data"]], "Train a Simplicial Convolutional Network (SCN) of Rank 2": [[27, "Train-a-Simplicial-Convolutional-Network-(SCN)-of-Rank-2"]], "Train a Simplicial Convolutional Network (SCN)": [[28, "Train-a-Simplicial-Convolutional-Network-(SCN)"]], "Train a Simplicial Convolutional Neural Network (SCNN)": [[29, "Train-a-Simplicial-Convolutional-Neural-Network-(SCNN)"]], "Simplicial Convolutional Neural Networks [SCNN]": [[29, "Simplicial-Convolutional-Neural-Networks-[SCNN]"]], "1. Comples Classification": [[29, "1.-Comples-Classification"]], "Create the SCNN": [[29, "Create-the-SCNN"]], "Import Karate dataset": [[29, "Import-Karate-dataset"]], "Weighted Hodge Laplacians": [[29, "Weighted-Hodge-Laplacians"]], "Import signals": [[29, "Import-signals"]], "Define binary labels and Prepare the training-testing split": [[29, "Define-binary-labels-and-Prepare-the-training-testing-split"]], "Create the SCNN for node classification": [[29, "Create-the-SCNN-for-node-classification"]], "Train the SCNN": [[29, "Train-the-SCNN"]], "Train a Simplicial Complex Net (SCoNe)": [[30, "Train-a-Simplicial-Complex-Net-(SCoNe)"]], "Table of contents": [[30, "Table-of-contents"]], "Dataset generation": [[30, "Dataset-generation"]], "Generating trajectories": [[30, "Generating-trajectories"]], "Creating PyTorch dataloaders": [[30, "Creating-PyTorch-dataloaders"]], "Creating the Neural Network": [[30, "Creating-the-Neural-Network"]], "Training the Neural Network": [[30, "Training-the-Neural-Network"], [31, "Training-the-Neural-Network"]], "Evaluating the model on test data": [[30, "Evaluating-the-model-on-test-data"]], "Suggestions for further experimentation": [[30, "Suggestions-for-further-experimentation"]], "Train a Simplicial Complex Network (SCoNe)": [[31, "Train-a-Simplicial-Complex-Network-(SCoNe)"]], "Define Neighborhood Structures": [[31, "Define-Neighborhood-Structures"]], "Defining Labels and Preparing Input": [[31, "Defining-Labels-and-Preparing-Input"]], "Train/Test Split": [[31, "Train/Test-Split"]], "Creating Neural Network": [[31, "Creating-Neural-Network"]], "Tutorials": [[32, "tutorials"]]}, "indexentries": {}})