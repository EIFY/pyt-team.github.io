Search.setIndex({"docnames": ["api/base", "api/index", "api/nn", "api/utils", "challenge/index", "contributing/index", "index", "notebooks/cell/can_train", "notebooks/cell/ccxn_train", "notebooks/cell/cwn_train", "notebooks/hypergraph/allset_train", "notebooks/hypergraph/allset_transformer_train", "notebooks/hypergraph/dhgcn_train", "notebooks/hypergraph/hmpnn_train", "notebooks/hypergraph/hnhn_train", "notebooks/hypergraph/hnhn_train_bis", "notebooks/hypergraph/hypergat_train", "notebooks/hypergraph/hypersage_train", "notebooks/hypergraph/template_train", "notebooks/hypergraph/unigcnii_train", "notebooks/hypergraph/unigin_train", "notebooks/hypergraph/unisage_train", "notebooks/simplicial/dist2cycle_train", "notebooks/simplicial/hsn_train", "notebooks/simplicial/san_train", "notebooks/simplicial/sca_cmps_train", "notebooks/simplicial/sccnn_train", "notebooks/simplicial/scconv_train", "notebooks/simplicial/scn2_train", "notebooks/simplicial/scn_train", "notebooks/simplicial/scnn_train", "notebooks/simplicial/scone_train", "notebooks/simplicial/scone_train_bis", "tutorials/index"], "filenames": ["api/base.rst", "api/index.rst", "api/nn.rst", "api/utils.rst", "challenge/index.rst", "contributing/index.rst", "index.rst", "notebooks/cell/can_train.ipynb", "notebooks/cell/ccxn_train.ipynb", "notebooks/cell/cwn_train.ipynb", "notebooks/hypergraph/allset_train.ipynb", "notebooks/hypergraph/allset_transformer_train.ipynb", "notebooks/hypergraph/dhgcn_train.ipynb", "notebooks/hypergraph/hmpnn_train.ipynb", "notebooks/hypergraph/hnhn_train.ipynb", "notebooks/hypergraph/hnhn_train_bis.ipynb", "notebooks/hypergraph/hypergat_train.ipynb", "notebooks/hypergraph/hypersage_train.ipynb", "notebooks/hypergraph/template_train.ipynb", "notebooks/hypergraph/unigcnii_train.ipynb", "notebooks/hypergraph/unigin_train.ipynb", "notebooks/hypergraph/unisage_train.ipynb", "notebooks/simplicial/dist2cycle_train.ipynb", "notebooks/simplicial/hsn_train.ipynb", "notebooks/simplicial/san_train.ipynb", "notebooks/simplicial/sca_cmps_train.ipynb", "notebooks/simplicial/sccnn_train.ipynb", "notebooks/simplicial/scconv_train.ipynb", "notebooks/simplicial/scn2_train.ipynb", "notebooks/simplicial/scn_train.ipynb", "notebooks/simplicial/scnn_train.ipynb", "notebooks/simplicial/scone_train.ipynb", "notebooks/simplicial/scone_train_bis.ipynb", "tutorials/index.rst"], "titles": ["Base", "API Reference", "Neural Networks", "Utils", "ICML 2023 Topological Deep Learning Challenge", "Contributing", "\ud83c\udf10 TopoModelX (TMX) \ud83c\udf69", "Train a Cellular Attention Network (CAN)", "Train a Convolutional Cell Complex Network (CCXN)", "Train a CW Network (CWN)", "Train a Hypergraph Neural Network", "Train a Hypergraph Neural Network", "Train a Hypergraph Neural Network", "Train a Hypergraph Message Passing Neural Network (HMPNN)", "Train a Hypergraph Networks with Hyperedge Neurons (HNHN)", "Train a Hypergraph Network with Hyperedge Neurons (HNHN)", "Train a Hypergraph Neural Network", "Train a Hypergraph Neural Network", "Train a Hypergraph Neural Network", "Train a hypergraph neural network using UniGCNII layers", "Pre-processing", "Pre-processing", "Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)", "Train a Simplicial High-Skip Network (HSN)", "Train a Simplicial Attention Network (SAN)", "Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)", "Train a SCCNN", "Train a Simplicial 2-complex convolutional neural network (SCConv)", "Train a Simplicial Convolutional Network (SCN) of Rank 2", "Train a Simplicial Convolutional Network (SCN)", "Train a Simplicial Convolutional Neural Network (SCNN)", "Train a Simplicial Complex Net (SCoNe)", "Train a Simplicial Complex Network (SCoNe)", "Tutorials"], "terms": {"The": [1, 4, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32], "give": [1, 11, 24], "an": [1, 4, 5, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32], "overview": 1, "topomodelx": [1, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "which": [1, 4, 5, 7, 10, 11, 13, 15, 16, 19, 22, 23, 24, 25, 26, 29, 30, 31], "consist": [1, 4, 5, 19, 31], "sever": [1, 4], "base": [1, 4, 11, 25, 26, 27, 30, 31, 32], "implement": [1, 4, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "core": 1, "mathemat": 1, "concept": 1, "messag": [1, 4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 32, 33], "pass": [1, 4, 7, 8, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33], "nn": [1, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "neural": [1, 4, 6, 33], "network": [1, 4, 6, 33], "layer": [1, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], "organ": [1, 4, 29], "topolog": [1, 6, 7, 8, 9, 14, 22, 23, 24, 25, 27, 29, 30, 31, 32], "domain": [1, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "util": [1, 7, 10, 11, 19, 20, 21, 24, 31], "comput": [1, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "spars": [1, 5, 10, 11, 13, 14, 15, 16, 17, 19, 22, 24, 27, 29], "tensor": [1, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "hypergraph": [1, 4, 20, 21, 33], "simplici": [1, 4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 33], "complex": [1, 4, 5, 7, 9, 10, 11, 12, 16, 17, 18, 20, 21, 22, 23, 24, 28, 29, 30, 33], "cell": [1, 4, 7, 9, 10, 11, 12, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33], "scatter": [1, 15, 31], "welcom": [4, 5], "host": 4, "second": [4, 10, 11, 25, 32], "annual": 4, "topologi": [4, 12, 24], "geometri": 4, "tag": 4, "machin": [4, 30], "workshop": 4, "review": [4, 5, 6], "contributor": [4, 5], "mathild": [4, 6], "papillon": [4, 6, 7, 8, 9, 14, 22, 23, 24, 25, 27, 29, 30, 31, 32], "mustafa": [4, 6], "hajij": [4, 6, 8, 23, 24, 32], "nina": [4, 6], "miolan": [4, 6], "florian": 4, "frantzen": 4, "ghada": [4, 6], "alzamzmi": 4, "theodor": [4, 6], "papamark": [4, 6], "michael": [4, 6], "schaub": [4, 6], "scholkemp": 4, "josef": 4, "hopp": 4, "karthikeyan": [4, 6], "natesan": [4, 6], "ramamurthi": [4, 6], "johan": 4, "math": [4, 5, 7, 11, 16, 17, 27, 29, 30, 31], "audun": 4, "myer": 4, "helen": 4, "jenn": 4, "tim": 4, "doster": 4, "tegan": 4, "emerson": 4, "henri": 4, "kving": 4, "bastian": 4, "rieck": 4, "sophia": [4, 6], "sanborn": [4, 6], "jan": 4, "meissner": 4, "paul": [4, 6], "rosen": [4, 6], "tolga": [4, 6], "birdal": [4, 6], "vincent": 4, "grand": 4, "aldo": [4, 6], "guzm\u00e1n": [4, 6], "s\u00e1enz": [4, 6], "tamal": [4, 6], "dei": [4, 6], "soham": [4, 6], "mukherje": [4, 6], "shreya": [4, 6], "n": [4, 5, 6, 9, 16, 17, 24, 25, 31], "samaga": [4, 6], "neal": [4, 6], "livesai": [4, 6], "robin": [4, 6], "walter": [4, 6], "edit": [4, 5], "i": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "now": [4, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 28, 31, 32], "over": [4, 10, 11, 12, 13, 15, 17, 18, 21, 22, 23, 24, 27, 28, 29, 31, 32], "thank": 4, "you": [4, 5, 19, 32], "all": [4, 5, 10, 11, 12, 16, 17, 18, 19, 22, 23, 24, 26, 29, 30, 31, 32], "stellar": 4, "contirbut": 4, "foster": 4, "reproduc": [4, 6], "open": [4, 19], "sourc": 4, "research": 4, "winner": 4, "announc": 4, "here": [4, 5, 12, 13, 15, 19, 22, 23, 26, 29, 31], "luca": 4, "scofano": 4, "claudio": 4, "battiloro": [4, 24], "guillermo": 4, "bernardez": 4, "simon": 4, "fiorellino": 4, "indro": 4, "spinelli": 4, "scardapan": 4, "lev": 4, "telyatninkov": 4, "olga": 4, "zaghen": 4, "allsettransform": [4, 11], "chien": [4, 10, 11], "et": [4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "al": [4, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "2022": [4, 7, 13, 22, 23, 24, 29, 30, 32], "sadrodin": 4, "barikbin": [4, 15], "hmpnn": [4, 33], "heydari": [4, 13], "attent": [4, 11, 16, 25, 33], "san": [4, 33], "giusti": [4, 7, 24], "odin": 4, "hoff": 4, "gardaa": 4, "net": [4, 32, 33], "scone": [4, 33], "roddenberri": [4, 30, 31], "2021": [4, 9, 10, 11, 30, 31], "cellular": [4, 9, 33], "can": [4, 5, 6, 16, 17, 19, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33], "dmitrii": 4, "gavrilev": 4, "gleb": 4, "bazhenov": 4, "suraj": 4, "singh": 4, "cw": [4, 33], "cwn": [4, 33], "bodnar": [4, 9], "combinatori": 4, "rub\u00e9n": 4, "ballest": 4, "manuel": 4, "lecha": 4, "sergio": 4, "escalera": 4, "higher": [4, 23, 29, 30, 32], "order": [4, 23, 24, 26, 29, 30, 31, 32], "hoan": 4, "aiden": 4, "brent": 4, "honor": 4, "mention": 4, "jen": 4, "agerberg": 4, "georg": [4, 29], "b\u00f6kman": 4, "pavlo": 4, "melnyk": 4, "convolut": [4, 7, 9, 24, 33], "sccn": 4, "yang": [4, 26, 29, 30], "autoencod": [4, 33], "sca": [4, 33], "alessandro": 4, "salatiello": 4, "hyperedg": [4, 10, 11, 12, 13, 16, 17, 18, 33], "neuron": [4, 33], "hnhn": [4, 33], "dong": [4, 14, 15], "2020": [4, 8, 13, 14, 16, 17, 27], "alexand": 4, "nikitin": 4, "unigcn": 4, "huang": 4, "purpos": [4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 21, 22, 23, 24, 26, 29], "thi": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "crowdsourc": 4, "ar": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "ask": 4, "contribut": [4, 16, 26], "code": [4, 5, 31], "previous": 4, "exist": 4, "tnn": [4, 6, 11, 17], "train": [4, 33], "benchmark": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 32], "dataset": [4, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 24, 25, 33], "built": [4, 5], "us": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], "python": [4, 5, 6], "packag": [4, 6, 7, 8, 15, 19, 22, 26, 27, 29, 30], "each": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 29, 31], "take": [4, 7, 8, 9, 24, 26, 28, 31], "form": [4, 10, 11, 22, 23, 26, 29, 31], "pull": [4, 5], "request": [4, 5, 19, 31], "contain": [4, 10, 11, 13, 15, 19, 26, 31], "necessari": [4, 24], "from": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "literatur": [4, 6, 19], "leverag": [4, 24], "infrastructur": 4, "build": [4, 5, 31], "block": 4, "note": [4, 5, 10, 11, 12, 16, 17, 18, 22, 23, 26, 30, 31], "we": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32], "invit": 4, "file": [4, 5], "regularli": 4, "detail": [4, 5, 11, 24], "ad": [4, 5], "when": [4, 5, 24, 31], "everi": [4, 19, 20], "respect": [4, 9, 10, 11, 16, 17, 24, 25, 26, 30, 31], "includ": [4, 5, 31], "white": 4, "paper": [4, 13, 14, 15, 22, 23, 24, 26, 27, 28, 30, 31, 32], "summar": 4, "find": [4, 31], "publish": 4, "through": [4, 7, 8, 9, 12, 13, 15, 16, 17, 18, 19, 20, 21, 25, 26, 30, 31], "qualifi": 4, "have": [4, 5, 7, 8, 10, 11, 12, 14, 16, 17, 18, 22, 23, 26, 29, 31], "opportun": 4, "co": [4, 19], "author": [4, 6, 15, 31], "top": [4, 26], "8": [4, 7, 8, 9, 11, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 31, 32], "best": [4, 11], "addit": 4, "softwar": [4, 5], "journal": 4, "receiv": 4, "special": 4, "recognit": 4, "final": [4, 13, 14, 15, 19, 24, 30, 31], "date": 4, "time": [4, 10, 11, 12, 13, 14, 15, 16, 17, 18, 22, 23, 24, 26, 29, 30, 31, 32], "must": [4, 10, 11, 12, 14, 16, 17, 18, 22, 23, 24, 26, 29, 30], "place": [4, 5, 10, 11], "befor": [4, 5, 19, 31], "juli": 4, "13": [4, 7, 8, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 27, 29, 31], "16": [4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31], "59": [4, 7, 13, 14, 22, 29], "pacif": 4, "standard": [4, 5, 19, 24], "modifi": [4, 5, 25], "until": 4, "everyon": [4, 5], "free": [4, 31], "It": [4, 13, 15, 19], "suffici": 4, "send": [4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 22, 23, 24, 28, 32], "accept": 4, "automat": [4, 24], "subscrib": 4, "team": [4, 32], "encourag": 4, "start": [4, 5, 19, 25, 31], "earli": 4, "help": [4, 5], "debug": 4, "fail": 4, "test": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26, 29, 33], "address": 4, "potenti": 4, "issu": [4, 19], "In": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "case": [4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 22, 23, 24, 28, 31, 32], "multipl": [4, 5, 10, 11, 31], "similar": [4, 29], "qualiti": 4, "same": [4, 5, 7, 8, 24, 25, 26, 31], "earlier": [4, 29], "given": [4, 7, 8, 9, 10, 11, 14, 16, 17, 19, 22, 23, 24, 26, 27, 29, 30, 31, 32], "prioriti": 4, "consider": 4, "restrict": 4, "number": [4, 7, 8, 9, 10, 11, 13, 14, 15, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32], "member": 4, "A": [4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "should": [4, 5, 31], "more": [4, 5, 6, 22, 29, 31], "than": [4, 30, 31, 32], "one": [4, 5, 7, 8, 14, 19, 22, 23, 24, 25, 26, 27, 29, 31, 32], "model": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 32, 33], "There": [4, 5, 13, 14, 15, 22, 23, 24, 29, 30], "amount": [4, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 26, 28, 32], "per": [4, 5], "princip": 4, "develop": [4, 5], "allow": [4, 29], "pre": [4, 31, 33], "fig": [4, 31], "11": [4, 7, 8, 9, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32], "architectur": [4, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 22, 23, 24, 25, 27, 29, 30, 31, 32], "survei": [4, 6, 7, 8, 9, 14, 22, 23, 24, 25, 27, 29, 30, 31, 32], "compli": 4, "": [4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 18, 19, 22, 23, 25, 26, 29, 31], "github": [4, 11, 15, 17, 19], "action": 4, "workflow": 4, "successfulli": 4, "lint": 4, "format": [4, 5, 19], "e": [4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 22, 23, 24, 26, 28, 30, 31, 32], "black": [4, 31], "isort": 4, "flake8": 4, "three": [4, 5, 19], "new": [4, 5, 7, 8], "name": [4, 5, 10, 11, 13, 20, 21], "_layer": 4, "py": [4, 5, 7, 8, 15, 19, 22, 27, 29, 32], "ex": 4, "hsn_layer": [4, 23], "store": [4, 14], "directori": [4, 5], "where": [4, 5, 7, 8, 9, 11, 14, 16, 17, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "class": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "hsnlayer": [4, 23, 29], "primit": 4, "One": [4, 22, 23, 24, 26, 28, 29, 30, 31, 32], "equival": [4, 5], "depict": 4, "diagram": 4, "represent": [4, 10, 11, 13, 14, 15, 16, 29, 31], "exampl": [4, 24, 26, 30, 31], "check": [4, 5, 6, 14, 22, 23, 32], "out": [4, 5, 6, 12, 14, 15, 18, 25, 29, 31, 32], "_train": 4, "ipynb": 4, "hsn_train": 4, "tutori": [4, 6, 19], "follow": [4, 5, 6, 7, 10, 11, 12, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "step": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "process": [4, 5, 19, 33], "import": [4, 5, 7, 8, 9, 10, 11, 13, 15, 17, 19, 24, 31], "well": [4, 5], "load": [4, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30], "featur": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], "face": [4, 7, 8, 9, 10, 11, 12, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "rank": [4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33], "2": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 31, 32, 33], "neighborhood": [4, 7, 8, 9, 10, 11, 17, 24, 25, 31, 33], "matric": [4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 22, 23, 24, 25, 26, 28, 29, 30, 32], "toponetx": [4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "either": [4, 5, 24, 31], "shrec16": [4, 7, 8, 9, 10, 11, 12, 16, 17, 18, 25, 26, 30, 32], "suitabl": [4, 14], "level": [4, 10, 11, 12, 14, 16, 17, 18, 19, 22, 23, 24, 25, 26, 29, 30], "classif": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33], "see": [4, 5, 6, 15, 31], "template_lay": [4, 18], "karat": [4, 14, 22, 23, 24, 26, 29], "club": [4, 14, 22, 23, 24, 26, 29], "node": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33], "onli": [4, 5, 12, 19, 24, 26, 31], "edg": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "0": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "1": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33], "abov": [4, 5, 30, 31], "torch": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "geometr": 4, "graph": [4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32], "lift": [4, 7, 8, 9, 10, 11, 14, 17, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30], "choic": [4, 7, 8, 9, 10, 11, 12, 16, 17, 18, 20, 21, 25], "creat": [4, 5, 11, 16, 17, 33], "defin": [4, 5, 7, 8, 9, 10, 19, 24, 25, 31, 33], "hsn": [4, 33], "inherit": 4, "modul": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "along": [4, 7, 24], "linear": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "task": [4, 10, 11, 13, 14, 15, 19, 22, 23, 26, 29, 30, 31], "simpl": [4, 30], "loop": [4, 10, 11, 12, 13, 15, 17, 18, 19, 21, 22, 23, 24, 27, 28, 29, 31, 32], "depend": 4, "output": [4, 5, 10, 11, 12, 16, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32], "perform": [4, 5, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 21, 22, 23, 24, 27, 28, 29, 31, 32], "rather": [4, 5, 32], "accuraci": [4, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32], "provid": [4, 5, 7, 25, 26, 30], "test_": [4, 5], "name_of_model": 4, "test_hsn_lay": 4, "testhsnlay": 4, "unit": [4, 5, 31], "function": [4, 5, 9, 10, 11, 17, 19, 22, 23, 24, 26, 29, 30, 31, 32], "pleas": [4, 5, 7, 8, 15, 19, 24], "pytest": [4, 5], "unittest": 4, "further": [4, 24, 33], "manipul": 4, "mai": 4, "modif": 4, "singl": [4, 9], "accompani": 4, "appropri": [4, 5], "locat": [4, 5, 19], "With": [4, 16], "being": [4, 24, 25], "said": 4, "highli": 4, "make": [4, 7, 8, 9, 10, 11, 12, 13, 15, 18, 19, 25, 31, 32], "most": [4, 5, 24, 29], "resort": 4, "option": [4, 5, 8, 10, 11, 24], "absolut": 4, "aggreg": [4, 16, 17, 24, 25, 27, 29, 30], "method": [4, 5, 13, 15], "condorcet": 4, "decid": [4, 24], "criteria": 4, "doe": [4, 5, 26, 30, 31], "chosen": [4, 29], "correctli": 4, "specif": [4, 5, 9, 14, 16, 19], "term": [4, 24], "its": [4, 5, 13, 15, 16, 32], "scheme": [4, 7, 8, 24, 33], "do": [4, 13, 15, 22, 23, 29, 31], "need": [4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 22, 23, 24, 28, 31, 32], "match": 4, "origin": [4, 5, 7, 8, 9, 19, 24, 26, 28, 29, 30, 31], "readabl": [4, 5], "clean": 4, "api": [4, 5], "written": 4, "docstr": 4, "clearli": 4, "explain": 4, "robust": 4, "reward": 4, "nor": 4, "goal": 4, "accur": 4, "our": [4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "field": 4, "select": [4, 29, 30], "maintain": 4, "collabor": 4, "whose": [4, 5], "vote": 4, "onc": [4, 10, 11, 12, 16, 17, 18], "googl": [4, 5], "express": [4, 16], "prefer": [4, 5], "get": [4, 24, 26, 30, 31], "even": 4, "link": [4, 5], "record": [4, 5, 10, 11, 12, 16, 17, 18], "while": [4, 5, 24], "email": 4, "identifi": 4, "voter": 4, "ident": [4, 11, 22, 23, 26], "remain": [4, 31], "secret": 4, "share": 4, "feel": [4, 31], "contact": 4, "u": [4, 8, 9, 10, 11, 16, 25, 31], "repositori": [4, 5], "slack": 4, "altern": 4, "ucsb": 4, "edu": 4, "guid": 5, "aim": [5, 24], "eas": 5, "both": [5, 24, 31], "novic": 5, "experienc": 5, "commun": 5, "effort": 5, "wai": [5, 24], "fork": 5, "upstream": 5, "submit": [5, 19], "pr": 5, "synchron": 5, "your": 5, "main": [5, 19], "branch": 5, "git": 5, "checkout": 5, "hold": 5, "b": [5, 7, 9, 10, 11, 14, 16, 17, 25, 26, 27, 29], "sure": [5, 32], "next": [5, 14, 16, 19, 31], "section": [5, 31], "re": [5, 22, 31], "done": [5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 21, 25, 26, 27, 28, 30, 31], "add": [5, 19], "commit": 5, "modified_fil": 5, "m": [5, 7, 8, 16, 22, 25, 27, 30, 31, 32], "my": [5, 25], "Then": [5, 7, 8, 9], "push": 5, "toponextx": 5, "instruct": 5, "repeat": 5, "3": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "4": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "folder": 5, "valid": [5, 19, 20, 21, 31], "filenam": 5, "For": [5, 6, 7, 14, 17, 22, 23, 26, 30, 31, 32], "test_add": 5, "def": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "x": [5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "y": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "return": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "test_capital_cas": 5, "assert": [5, 29, 31], "5": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "9": [5, 7, 8, 9, 11, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 31, 32], "statement": 5, "under": 5, "correct": [5, 20, 21, 31], "instal": 5, "tool": 5, "pip": 5, "dev": 5, "verifi": 5, "break": 5, "requir": [5, 7, 25], "doc": 5, "descript": [5, 31], "usag": 5, "other": [5, 31], "inform": [5, 10, 11, 13, 16, 17, 30], "differ": [5, 7, 8, 14, 22, 23, 24, 26, 29, 31], "markdown": 5, "languag": 5, "common": 5, "restructuredtext": 5, "numpi": [5, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "style": 5, "up": [5, 22, 23, 24, 29, 31, 33], "understand": 5, "role": 5, "syntax": 5, "also": [5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 28, 30, 32], "autom": 5, "pars": 5, "inclus": 5, "gener": [5, 10, 11, 19, 23, 24, 26, 32, 33], "refer": [5, 17, 24], "look": [5, 31], "ani": [5, 7, 8, 17, 26, 31], "object": 5, "print": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "__doc__": 5, "attribut": 5, "try": [5, 7, 8, 24, 31], "np": [5, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "arrai": [5, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "mean": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "good": [5, 28], "These": 5, "some": [5, 29, 31], "element": [5, 11], "ones": [5, 13, 15], "d": [5, 16, 22, 27], "like": [5, 7, 8, 24, 29], "summari": 5, "line": 5, "79": [5, 7, 12, 13, 14, 29], "char": 5, "begin": [5, 24], "immedi": 5, "after": [5, 15, 20], "first": [5, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "capit": 5, "letter": 5, "end": [5, 22, 23, 24, 29, 31, 32], "period": 5, "If": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 24, 25, 26, 28, 29], "describ": [5, 11], "verb": 5, "imper": 5, "mood": 5, "g": [5, 10, 11, 16, 24, 30, 31], "v": [5, 10, 11, 14, 16, 17, 19, 22, 23, 24, 26, 29, 30, 32], "possibl": [5, 19], "default": [5, 10, 11, 15, 17, 19, 24], "uncertain": 5, "oppos": 5, "calcul": [5, 24, 32], "evalu": [5, 13, 14, 15, 19, 20, 33], "multi": [5, 11], "separ": 5, "blank": 5, "paramet": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "list": [5, 10, 11, 12, 19, 25, 31], "argument": [5, 10, 11, 24], "type": 5, "On": 5, "state": [5, 17, 19], "shape": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "rest": 5, "space": [5, 26, 31], "side": 5, "default_valu": 5, "indent": 5, "esp": 5, "would": [5, 22, 23], "want": [5, 19, 31], "mani": 5, "veri": [5, 19], "rais": [5, 26, 30], "etc": [5, 19, 25], "within": [5, 13, 15, 24], "latex": 5, "cite": [5, 19], "text": [5, 10, 11, 12, 13, 14, 15, 16, 17, 18, 22, 23, 24, 25, 26, 29, 32], "id": 5, "templat": [5, 16, 18], "my_method": 5, "self": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "my_param_1": 5, "my_param_2": 5, "vector": [5, 11, 13, 15, 16, 31], "r": [5, 8, 9, 10, 11, 16, 24, 25, 29, 31], "big": 5, "o": [5, 11, 14, 24], "left": [5, 9, 16, 17, 31], "right": [5, 9, 16, 17, 31], "dim": [5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32], "short": 5, "str": [5, 27, 29], "matrix": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "my_result": 5, "result": [5, 7, 8, 11, 14], "relev": 5, "equat": [5, 6, 7, 8, 9, 14, 22, 23, 24, 27, 29, 31, 32], "snippet": 5, "show": [5, 14, 22, 23, 31, 32], "how": [5, 11, 22, 23, 24], "script": 5, "associ": [5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 29], "pdf": 5, "wikipedia": 5, "page": 5, "And": 5, "fill": 5, "scikit": 5, "learn": [5, 6, 7, 8, 9, 14, 15, 16, 17, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "project": [5, 9, 24, 25, 30], "fit_predict": 5, "none": [5, 10, 26, 30, 31], "sample_weight": 5, "cluster": [5, 25], "center": [5, 31], "predict": [5, 10, 11, 13, 14, 15, 30, 31], "index": [5, 29, 31], "sampl": [5, 14, 31], "conveni": 5, "call": [5, 11, 31], "fit": 5, "sparse_matrix": 5, "n_featur": 5, "data": [5, 6, 13, 15, 24, 29, 32, 33], "transform": [5, 15, 19, 24], "ignor": [5, 21], "Not": 5, "present": 5, "convent": 5, "weight": [5, 11, 16, 24, 26, 29, 31], "observ": 5, "assign": [5, 7, 8, 9, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "equal": [5, 16, 31], "label": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 27, 28, 31, 33], "belong": [5, 14, 22, 23, 24, 26, 29], "labels_": 5, "mind": 5, "bool": [5, 7, 8, 10, 11, 25], "instead": [5, 19], "boolean": 5, "vari": 5, "notat": [5, 7, 8, 9, 14, 22, 23, 24, 25, 27, 29, 30, 31, 32], "dimens": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "axi": [5, 31], "string": [5, 17], "bracket": 5, "input": [5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 33], "log": [5, 29, 31], "squar": [5, 31], "multinomi": 5, "1d": [5, 7, 8, 9, 26, 28], "2d": [5, 7, 8, 9, 26, 28], "subset": [5, 13, 15], "ndarrai": [5, 31], "datafram": 5, "explicitli": 5, "relat": [5, 13], "colon": 5, "explan": 5, "_weight_boost": 5, "adaboost": 5, "ha": [5, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "great": 5, "ve": 5, "discuss": 5, "Of": 5, "cours": [5, 26], "verbos": 5, "thei": [5, 7, 8, 9, 10, 11, 22, 23, 24, 26, 28, 29], "compon": [5, 24], "rst": 5, "keep": [5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 21, 22, 23, 24, 26, 29, 32], "length": [5, 13, 15, 19, 29], "80": [5, 7, 12, 13, 14, 25, 29], "charact": 5, "except": [5, 24], "tabl": [5, 33], "deep": [6, 7, 8, 9, 11, 14, 22, 23, 24, 25, 27, 29, 30, 31, 32], "tdl": 6, "blue": 6, "laid": 6, "2023": [6, 7, 8, 9, 14, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "go": [6, 9, 24, 31], "beyond": [6, 24], "extend": [6, 26], "graphic": 6, "avail": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 24, 25], "awesom": [6, 11, 17], "To": [6, 10, 14, 21, 22, 23, 30, 31, 32], "about": 6, "blueprint": 6, "zamzmi": 6, "k": [6, 9, 11, 14, 16, 22, 23, 24, 25, 27, 29, 30, 31, 32], "t": [6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "misc": 6, "hajij2023topolog": 6, "titl": [6, 14], "year": 6, "eprint": 6, "2206": [6, 22], "00606": 6, "archiveprefix": 6, "arxiv": 6, "primaryclass": 6, "c": [6, 7, 8, 10, 11, 14, 15, 16, 17, 22, 23, 27, 29, 31, 32], "lg": 6, "papillon2023architectur": 6, "2304": [6, 14], "10031": 6, "down": [7, 24, 25, 26, 27, 32], "laplacian": [7, 24, 25, 26, 28, 29, 32], "propos": [7, 8, 9, 14, 17, 22, 23, 24, 26, 27, 30, 31, 32], "rodenberri": 7, "signal": [7, 8, 9, 10, 11, 12, 16, 17, 18, 20, 21, 24, 25], "mechan": [7, 8, 11, 16, 24], "without": [7, 8], "quad": [7, 8, 9, 10, 11, 14, 16, 17, 22, 23, 24, 25, 27, 29, 30, 31, 32], "m_": [7, 8, 9, 10, 11, 14, 16, 17, 22, 23, 24, 25, 27, 29, 30, 31, 32], "rightarrow": [7, 8, 9, 10, 11, 14, 16, 17, 22, 23, 24, 25, 27, 29, 30, 31, 32], "z": [7, 8, 9, 10, 11, 16, 17, 23, 30, 31, 32], "l_": [7, 24, 25, 30, 31, 32], "downarrow": [7, 22, 24, 25, 26, 27, 29, 30, 31, 32], "cdot": [7, 14, 16, 17, 22, 23, 24, 27, 29, 30, 31, 32], "h_y": [7, 8, 9, 10, 11, 14, 17, 23, 24, 27, 30, 31], "theta": [7, 8, 11, 14, 16, 17, 22, 23, 25, 26, 27, 29, 30, 31, 32], "uparrow": [7, 8, 9, 22, 23, 24, 26, 27, 29, 30, 31, 32], "h_x": [7, 8, 9, 10, 11, 14, 16, 17, 22, 23, 24, 25, 29, 30, 31, 32], "m_x": [7, 8, 9, 14, 16, 17, 22, 23, 25, 27, 29, 30, 31, 32], "sum_": [7, 14, 16, 17, 22, 23, 26, 27, 29, 30, 31, 32], "mathcal": [7, 8, 9, 10, 11, 14, 16, 17, 22, 23, 24, 25, 27, 29, 30, 31, 32], "sigma": [7, 10, 14, 16, 17, 22, 23, 26, 27, 29, 30, 31, 32], "mask": [7, 13, 24, 31], "nbsphinx": [7, 11, 16, 17, 30], "odot": [7, 16, 22], "att": [7, 8, 16, 25], "h_": [7, 8, 16, 22, 25, 29], "l": [7, 8, 9, 16, 17, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "_": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "xy": [7, 14, 22, 23, 27, 29, 30, 31, 32], "epsilon": [7, 24], "theta_": 7, "entir": [7, 8, 9], "small": [7, 8, 9, 10, 11, 12, 16, 17, 18, 25, 26, 27, 28, 29, 30], "version": [7, 8, 9, 26, 30], "random": [7, 15, 31], "sklearn": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 25, 26, 28, 30, 32], "model_select": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 25, 26, 28, 30, 32], "train_test_split": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 25, 26, 28, 30, 32], "cellcomplex": 7, "can_lay": 7, "canlay": 7, "gpu": [7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 25], "them": [7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 24, 25, 26, 28, 29], "otherwis": [7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 25, 31], "run": [7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 29, 31], "cpu": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 32], "devic": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 32], "cuda": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 32], "is_avail": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 32], "els": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 26, 27, 28, 30, 32], "3d": [7, 8, 9, 10, 11, 12, 16, 17, 18, 25, 27, 28], "mesh": [7, 8, 9, 10, 11, 12, 16, 17, 18, 25, 26, 27, 28, 30], "retriev": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32], "x_0": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "x_1": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "x_2": [7, 8, 9, 10, 11, 12, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30], "binari": [7, 13, 14, 15, 20, 21, 24, 27, 28, 32], "shrec": [7, 8, 9, 10, 11, 12, 16, 17, 18, 25, 27, 28, 30], "shrec_16": [7, 8, 9, 10, 11, 12, 16, 17, 18, 25, 26, 27, 28, 30], "size": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "kei": [7, 8, 9, 10, 11, 12, 16, 17, 18, 25, 26, 27, 28, 30], "valu": [7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 22, 24, 25, 26, 27, 28, 30, 31], "item": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "node_feat": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30], "edge_feat": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "face_feat": [7, 8, 9, 10, 11, 12, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30], "simplex": [7, 8, 9, 10, 11, 12, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "i_complex": [7, 8, 9, 10, 11, 12, 16, 17, 18, 25, 27, 28], "6": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "f": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "th": [7, 8, 9, 10, 11, 12, 16, 17, 18, 24, 25, 27, 28], "6th": [7, 8, 9, 10, 11, 12, 16, 17, 18, 25, 28], "252": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 25, 27, 28], "750": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 25, 27, 28], "10": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "500": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 25, 27, 28], "7": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "structur": [7, 8, 9, 10, 11, 17, 24, 26, 30, 33], "repres": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 28, 31, 32], "taht": 7, "act": [7, 32], "denot": [7, 10, 11, 16, 17, 30, 31], "cc_list": [7, 8, 9], "down_laplacian_list": 7, "up_laplacian_list": 7, "cell_complex": [7, 8, 9], "to_cell_complex": [7, 8, 9], "append": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "down_laplacian": 7, "down_laplacian_matrix": [7, 22, 24, 25, 26, 27, 30, 32], "up_laplacian": 7, "up_laplacian_matrix": [7, 24, 26, 27, 30, 32], "from_numpi": [7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "todens": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "to_spars": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "thu": [7, 24, 28], "i_cc": 7, "appli": [7, 10, 11, 13, 16, 24, 27, 31], "in_channels_0": [7, 8, 9, 26, 28, 30], "in_channels_1": [7, 8, 9, 26, 28, 30], "in_channels_2": [7, 8, 9, 26, 28, 30], "int": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "num_class": [7, 8, 9, 13, 15, 19, 25, 26, 28], "n_layer": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "whether": [7, 8, 10, 11, 25], "__init__": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "fals": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 25, 26, 27, 28, 30], "super": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "rang": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "channel": [7, 19, 22, 23, 24, 26, 27, 28, 29, 30, 32], "lin_0": [7, 8, 9, 28], "lin_1": [7, 8, 9, 28], "lin_2": [7, 8, 9, 28], "forward": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "avg": [7, 8, 25], "pool": [7, 8, 9, 12, 16, 17, 18, 20, 21, 25], "n_node": [7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32], "n_edg": [7, 8, 9, 14, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 30, 32], "n_face": [7, 8, 9, 26, 27], "whole": [7, 8, 9, 12, 16, 17, 18, 20, 21, 25, 26, 27], "averag": [7, 8, 9, 12, 26, 28, 30, 31], "0d": [7, 8, 9, 26, 28], "nan": [7, 8, 9, 14, 26, 27, 28], "convert": [7, 8, 9, 14, 20, 21, 22, 23, 24, 26, 28, 32], "two_dimensional_cells_mean": [7, 8, 9, 25, 26, 28], "nanmean": [7, 8, 9, 25, 26, 27, 28, 30], "isnan": [7, 8, 9, 25, 26, 27, 28, 30], "one_dimensional_cells_mean": [7, 8, 9, 25, 26, 28, 30], "zero_dimensional_cells_mean": [7, 8, 9, 25, 26, 28], "sum": [7, 8, 9, 14, 16, 24, 26, 27, 28, 29, 31], "specifi": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 28, 29, 30], "initi": [7, 8, 10, 11, 13, 14, 15, 17, 24, 26, 27, 30, 31], "loss": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "optim": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "crit": [7, 8, 20, 21], "crossentropyloss": [7, 8, 13, 14, 15, 19, 20], "opt": [7, 8, 10, 11, 12, 16, 17, 18, 25, 27], "adam": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "lr": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "loss_fn": [7, 8, 10, 11, 12, 13, 15, 16, 17, 18, 19, 25, 26, 27, 28, 30], "mseloss": [7, 8, 9, 10, 11, 12, 16, 17, 18, 25, 26, 27, 28, 30], "split": [7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 27, 31, 33], "test_siz": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 25, 26, 28, 30, 31, 32], "x_0_train": [7, 8, 9, 10, 11, 12, 15, 16, 17, 25, 26, 27], "x_0_test": [7, 8, 9, 10, 11, 12, 15, 16, 17, 25, 26], "shuffl": [7, 8, 9, 10, 11, 12, 16, 17, 18, 20, 21, 25, 26, 28, 30, 31, 32], "x_1_train": [7, 8, 9, 18, 20, 21, 25, 26, 27], "x_1_test": [7, 8, 9, 18, 20, 21, 25, 26], "x_2_train": [7, 9, 25, 26, 27], "x_2_test": [7, 9, 25, 26], "up_laplacian_train": 7, "up_laplacian_test": 7, "down_laplacian_train": 7, "down_laplacian_test": 7, "y_train": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32], "y_test": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32], "epoch": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "minim": [7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 21, 26], "rapid": [7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 21, 26], "12": [7, 8, 13, 14, 15, 16, 19, 20, 21, 22, 23, 28, 29, 31], "test_interv": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "num_epoch": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "epoch_i": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30], "epoch_loss": [7, 8, 9, 10, 11, 12, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "zip": [7, 8, 9, 10, 11, 12, 16, 17, 18, 20, 21, 25, 26, 27, 28, 30], "float": [7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "zero_grad": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "y_hat": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "backward": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "4f": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 22, 23, 24, 26, 28, 29, 30, 32], "flush": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "true": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "no_grad": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "up_laplcian": 7, "test_loss": [7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 25, 26, 27, 28, 30], "user": [7, 8, 22, 32], "abrah": 7, "anaconda3": [7, 8, 22, 27, 29], "env": [7, 8, 22, 27, 29], "topological_2": 7, "lib": [7, 8, 15, 22, 27, 29], "site": [7, 8, 15, 22, 27, 29], "536": [7, 8, 14], "userwarn": [7, 8, 19, 27, 32], "target": [7, 8], "lead": [7, 8], "incorrect": [7, 8], "due": [7, 8, 29], "broadcast": [7, 8], "ensur": [7, 8], "mse_loss": [7, 8], "reduct": [7, 8, 26], "89": [7, 13, 14, 15, 29], "3527": 7, "81": [7, 12, 13, 14, 29], "9469": 7, "5947": 7, "1082": [7, 14], "3476": 7, "55": [7, 13, 14, 22, 29, 30], "3188": 7, "6493": 7, "0137": [7, 13], "51": [7, 9, 13, 14, 15, 19, 22, 29, 30], "6529": 7, "78": [7, 12, 13, 14, 22, 23, 24, 26, 29, 30, 32], "4377": 7, "77": [7, 12, 13, 14, 22, 25, 29], "9167": 7, "48": [7, 13, 14, 15, 20, 21, 22, 29, 30], "4984": 7, "4454": 7, "0191": 7, "45": [7, 13, 14, 15, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 32], "7851": 7, "14": [7, 13, 14, 15, 16, 19, 20, 21, 22, 26, 29, 31], "96": [7, 8, 13, 14, 15, 26, 29], "6442": [7, 14], "76": [7, 12, 13, 14, 22, 28, 29], "8734": 7, "52": [7, 13, 14, 19, 22, 29, 30], "6675": [7, 14], "2222": 7, "75": [7, 12, 13, 14, 19, 20, 21, 22, 25, 29], "4701": 7, "46": [7, 13, 14, 15, 20, 21, 22, 29, 30], "0780": [7, 14], "74": [7, 13, 14, 22, 29], "7502": 7, "0797": [7, 14], "40": [7, 12, 13, 14, 15, 19, 20, 21, 22, 26, 29, 30], "4300": 7, "73": [7, 13, 14, 22, 29], "4617": 7, "72": [7, 13, 14, 22, 29], "8948": 7, "35": [7, 10, 13, 14, 15, 19, 20, 21, 22, 29], "5483": 7, "3760": 7, "71": [7, 13, 14, 22, 29], "9013": 7, "31": [7, 10, 13, 14, 15, 20, 21, 22, 29], "3371": 7, "simplifi": 8, "adjac": [8, 9, 13, 22, 23, 24, 26, 27, 29, 31], "amp": [8, 25], "agg_": [8, 9, 10, 11, 25], "cohomologi": 8, "t_": [8, 17], "ccxn_layer": 8, "ccxnlayer": 8, "scalar": [8, 9, 25, 31], "messg": [8, 10, 11, 16, 17, 18, 22, 23, 28, 32], "a_": [8, 9, 16, 22, 23, 24], "coboundari": [8, 9], "b_2": [8, 24, 27], "incidence_2_t_list": 8, "adjacency_0_list": 8, "incidence_2_t": 8, "incidence_matrix": [8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31], "adjacency_0": [8, 22, 23], "adjacency_matrix": [8, 9, 22, 23, 26, 27, 29, 31], "stack": [8, 9, 10, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32], "modulelist": [8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 31], "neighborhood_0_to_0": 8, "neighborhood_1_to_2": 8, "transpos": [8, 25, 27], "boundari": [8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 23, 29, 31], "between": [8, 24, 29], "incidence_2_t_train": 8, "incidence_2_t_test": 8, "adjacency_0_train": 8, "adjacency_0_test": 8, "low": [8, 9, 10, 11, 12, 13, 15, 17, 18, 21, 22, 23, 24, 26, 27, 28, 29, 32], "4544": 8, "ninamiolan": 8, "tmxtest": 8, "python3": [8, 15, 27, 29], "82": [8, 12, 13, 14, 19, 29], "0496": [8, 14], "36": [8, 13, 14, 15, 20, 21, 22, 29], "4422": [8, 14], "83": [8, 12, 13, 14, 15, 29], "8916": 8, "9388": 8, "49": [8, 13, 14, 15, 20, 21, 22, 29, 30], "7630": 8, "99": [8, 13, 14, 15, 19, 26, 27, 29, 31], "6948": [8, 24], "84": [8, 9, 12, 13, 14, 29], "4177": 8, "39": [8, 13, 14, 15, 19, 20, 21, 22, 27, 29, 30], "5379": [8, 22], "85": [8, 9, 12, 13, 14, 15, 29], "5503": 8, "8946": 8, "6596": 8, "weisfeil": 9, "lehman": 9, "h_z": [9, 10, 11], "_k": [9, 24, 25], "cwn_layer": 9, "cwnlayer": 9, "upper": [9, 24, 26, 27, 29, 30, 31, 32], "b_r": [9, 29], "interc": 9, "b_": [9, 25, 29], "incidence_2_list": [9, 26, 27, 30], "adjacency_1_list": 9, "incidence_1_t_list": 9, "incidence_2": [9, 26, 27, 30, 31], "adjacency_1": [9, 27], "incidence_1_t": 9, "hid_channel": 9, "hidden": [9, 10, 11, 13, 15, 16, 24, 31], "proj_0": 9, "proj_1": 9, "proj_2": 9, "out_channel": [9, 10, 11, 12, 16, 17, 18, 20, 21, 24, 26, 30], "neighborhood_1_to_1": 9, "neighborhood_2_to_1": 9, "neighborhood_0_to_1": 9, "elu": 9, "instanti": 9, "05": [9, 31], "criterion": [9, 14], "adjacency_1_train": 9, "adjacency_1_test": 9, "incidence_2_train": [9, 26], "incidence_2_test": [9, 26], "incidence_1_t_train": 9, "incidence_1_t_test": 9, "106": [9, 14, 26, 29], "5665": 9, "4893": [9, 13], "54": [9, 13, 14, 19, 22, 29, 30], "3770": 9, "0177": 9, "6247": 9, "4964": 9, "notebook": [10, 11, 12, 13, 14, 15, 16, 17, 18, 22, 23, 24, 26, 27, 30, 31, 32], "two": [10, 11, 12, 14, 16, 17, 18, 22, 23, 24, 26, 29, 30, 31, 32], "allset": [10, 11], "collect": [10, 11, 12, 13, 15, 16, 17, 18, 30], "vertex": [10, 11, 31], "let": [10, 11, 16, 17, 31], "textbf": [10, 11, 17, 24], "mathbb": [10, 11, 16, 31], "addition": [10, 11, 29], "v_": [10, 11, 16], "multiset": [10, 11], "e_": [10, 11], "set": [10, 11, 12, 14, 17, 18, 19, 20, 21, 24, 29, 31, 32, 33], "updat": [10, 11, 15, 24, 31], "rule": [10, 11], "framework": [10, 11], "put": [10, 11, 29], "f_": [10, 11], "permut": [10, 11], "invari": [10, 11], "zero": [10, 11, 19, 22, 23, 24, 26, 30, 31], "practic": [10, 11], "parametr": [10, 11], "learnt": [10, 11], "25": [10, 13, 14, 15, 19, 20, 21, 22, 29, 31], "allset_lay": 10, "allsetlay": 10, "load_ext": [10, 11, 21, 24], "autoreload": [10, 11, 21, 24], "extens": [10, 21], "alreadi": [10, 21], "reload": [10, 21], "reload_ext": [10, 21], "26": [10, 13, 14, 15, 20, 21, 22, 29], "what": [10, 11, 12, 16, 17, 18, 20, 21, 29, 32], "feed": [10, 11, 12, 16, 17, 18, 20, 21, 31], "27": [10, 13, 14, 15, 20, 21, 22, 27, 29], "28": [10, 13, 14, 15, 20, 21, 22, 29], "incid": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 29, 30], "b_1": [10, 11, 12, 13, 14, 15, 16, 17, 18, 22, 23, 24, 27, 30], "n_": [10, 11, 12, 13, 14, 15, 16, 17, 18, 22, 23, 24, 26, 29, 30, 32], "amtric": [10, 11, 12, 16, 17, 18], "unsign": [10, 11, 12, 16, 17, 18], "pairwis": [10, 11, 12, 16, 17, 18, 31], "becom": [10, 11, 12, 16, 17, 18, 24], "simplciial": [10, 11, 12, 16, 17, 18], "wise": [10, 11, 12, 16, 17, 18], "29": [10, 13, 14, 15, 20, 21, 22, 29], "hg_list": [10, 11, 12, 16, 17, 18, 20, 21], "incidence_1_list": [10, 11, 12, 16, 17, 18, 20, 21, 26, 27, 30], "incidence_1": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 30, 31], "sign": [10, 11, 12, 14, 16, 17, 18, 27, 31, 32], "hg": [10, 11, 12, 16, 17, 18, 20, 21], "to_hypergraph": [10, 11, 12, 14, 16, 17, 18, 20, 21], "extract": [10, 11, 16, 17, 21], "30": [10, 13, 14, 15, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31], "1250": [10, 11, 14, 16, 17], "templatelay": [10, 12, 18], "channels_edg": [10, 12, 14, 16, 17, 18, 21], "channels_nod": [10, 12, 14, 16, 17, 18, 21, 22, 23, 24, 26, 29, 30], "32": [10, 13, 14, 15, 16, 20, 21, 22, 29, 31], "allsetnn": 10, "combin": [10, 11], "in_dim": [10, 11], "hid_dim": [10, 11], "out_dim": [10, 11, 16, 20], "dropout": [10, 11, 13, 15], "probabl": [10, 11, 26], "input_dropout": [10, 11], "mlp_num_lay": [10, 11], "mlp": [10, 11, 20, 26], "mlp_norm": [10, 11], "normal": [10, 11, 27, 28, 29, 32], "in_channel": [10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 29, 30], "hidden_channel": [10, 11, 24], "mlp_activ": 10, "mlp_dropout": [10, 11], "edge_index": [10, 11, 13, 16, 17], "cidx": 10, "min": 10, "reversed_edge_index": 10, "pooled_x": [10, 11, 12, 16, 17, 18, 21], "max": [10, 11, 16, 17, 18, 20, 21, 29], "sigmoid": [10, 11, 16, 17, 18, 20, 21, 24, 25, 26, 27, 29, 31], "33": [10, 13, 14, 15, 20, 21, 22, 29, 32], "64": [10, 11, 13, 14, 22, 29], "34": [10, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 29, 30, 32], "incidence_1_train": [10, 11, 16, 17, 18, 20, 21, 26], "incidence_1_test": [10, 11, 16, 17, 18, 20, 21, 26], "dtype": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 26, 30, 32], "to_edge_index": [10, 11, 16, 17], "274": [10, 11, 14, 17, 18], "8233": 10, "529": [10, 11, 14, 16, 17, 18], "0000": [10, 11, 14, 16, 17, 22, 23, 26, 29, 30], "6125": [10, 11, 17], "repo": [11, 15, 17], "ln": 11, "achiev": [11, 29, 31], "rise": 11, "so": [11, 22, 23, 24, 26, 29, 30, 31, 32], "dive": 11, "iter": 11, "Their": 11, "correspond": [11, 13, 15, 19], "dimension": [11, 31], "h": [11, 16, 17, 19, 23, 24, 26, 27, 29, 30, 32], "omega": 11, "overset": [11, 24], "delta": 11, "mathbin": 11, "vert": [11, 17, 31], "mh": 11, "oper": [11, 16, 24, 26, 29, 31], "ba": 11, "2016": 11, "concaten": [11, 16, 31], "hf_": 11, "learnabl": [11, 24, 30], "multihead": 11, "head": 11, "activ": [11, 27, 29], "vaswani": 11, "2017": [11, 22], "perceptron": 11, "row": 11, "independ": 11, "allset_transformer_lay": 11, "allsettransformerlay": 11, "q_n": 11, "9018": 11, "dhgcn_layer": 12, "dhgcnlayer": 12, "100": [12, 13, 14, 15, 19, 20, 21, 25, 26, 27, 28, 29, 31], "dir": 12, "dhgcn": 12, "dynam": 12, "intermediate_channel": [12, 18, 20, 30], "global": [12, 16, 17, 18, 20, 21], "node_channel": [12, 27], "86": [12, 13, 14, 15, 25, 29], "87": [12, 13, 14, 29], "88": [12, 13, 14, 26, 29], "8821578": 12, "6946": 12, "36521": 12, "6562": 12, "17477": 12, "7685": 12, "212": [12, 14], "8590": 12, "152": [12, 14, 29], "9723": 12, "0999": 12, "177": [12, 14, 29], "0583": [12, 14], "163": [12, 14, 29], "9508": 12, "202": [12, 14], "9814": 12, "22": [12, 13, 14, 15, 20, 21, 22, 29], "2991": 12, "introduc": [13, 15, 16, 24], "livi": 13, "cora": [13, 19], "2708": 13, "academ": [13, 15], "5429": 13, "citat": [13, 19], "categori": [13, 15], "case_bas": 13, "genetic_algorithm": 13, "neural_network": 13, "probabilistic_method": 13, "reinforcement_learn": 13, "rule_learn": 13, "theori": 13, "document": [13, 15, 19, 24], "1433": [13, 14], "stand": [13, 15], "uniqu": [13, 14, 15, 27], "word": [13, 15], "presenc": [13, 15], "torch_geometr": [13, 15, 20, 21, 24], "planetoid": 13, "metric": [13, 14, 15], "accuracy_scor": [13, 15], "hmpnn_layer": 13, "hmpnnlayer": 13, "24": [13, 14, 15, 20, 21, 22, 29], "download": [13, 15, 19, 21], "val": [13, 20, 21, 31], "below": [13, 20, 31], "construct": [13, 15, 19, 31, 32], "sparse_coo_tensor": [13, 15], "long": [13, 15, 29], "in_featur": [13, 15, 19, 26, 30], "hidden_featur": [13, 15], "tupl": [13, 26, 31], "gradual": 13, "reduc": 13, "last": [13, 29, 30, 31], "adjacency_dropout_r": 13, "rate": [13, 15], "regular_dropout_r": 13, "regular": 13, "to_hidden_linear": [13, 15], "sequenti": [13, 15, 20], "len": [13, 14, 15, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31], "adjacency_dropout": 13, "updating_dropout": 13, "to_categories_linear": [13, 15], "n_hyperedg": [13, 15], "b1": [13, 14, 22, 23, 26, 27, 29, 30], "y_pred": [13, 15, 19, 22, 23, 24, 26, 29, 30, 32], "logit": [13, 14, 15, 19, 22, 23, 26, 29, 30, 31], "hyperparamet": [13, 15, 19], "manual_se": [13, 31], "41": [13, 14, 15, 20, 21, 22, 29, 30], "256": [13, 14], "01": [13, 19, 22, 26, 30, 31], "train_y_tru": [13, 15], "train_mask": [13, 15], "val_y_tru": 13, "val_mask": 13, "initial_x_1": 13, "zeros_lik": 13, "y_pred_logit": [13, 15], "train_loss": [13, 31], "argmax": [13, 14, 15, 19, 20, 31], "train_acc": [13, 14, 19, 22, 23, 24, 26, 29, 30, 31, 32], "eval": [13, 15, 19, 20, 21, 31], "val_loss": [13, 31], "val_acc": [13, 31], "acc": [13, 15], "2f": [13, 15], "1079": [13, 14], "1436": [13, 14], "0234": 13, "15": [13, 14, 15, 18, 19, 20, 21, 22, 25, 29, 31], "1016": [13, 14], "9800": 13, "0681": [13, 14], "9504": 13, "18": [13, 14, 15, 19, 20, 21, 22, 28, 29], "0389": [13, 14], "9194": 13, "21": [13, 14, 15, 20, 21, 22, 26, 29], "9241": 13, "19": [13, 14, 15, 20, 21, 22, 27, 29, 31], "9917": 13, "8917": 13, "9729": 13, "8710": 13, "23": [13, 14, 15, 20, 21, 22, 29], "9556": 13, "8574": 13, "9402": 13, "17": [13, 14, 15, 20, 21, 22, 29], "8646": 13, "9265": 13, "8540": 13, "9136": 13, "8430": 13, "9012": 13, "8336": 13, "38": [13, 14, 15, 20, 21, 22, 29], "8886": 13, "8405": 13, "8775": 13, "8264": 13, "8668": 13, "8065": 13, "8562": 13, "37": [13, 14, 15, 19, 20, 21, 22, 29], "8158": 13, "8456": 13, "7957": 13, "44": [13, 14, 15, 20, 21, 22, 29, 30], "8346": 13, "8028": 13, "8249": 13, "20": [13, 14, 15, 19, 20, 21, 22, 26, 29, 31], "7882": 13, "8156": 13, "42": [13, 14, 15, 20, 21, 22, 29, 30], "7912": 13, "8070": 13, "7610": 13, "7987": 13, "7617": 13, "47": [13, 14, 15, 20, 21, 22, 29, 30], "7905": 13, "7596": 13, "7830": 13, "7391": 13, "7740": 13, "7315": 13, "7655": 13, "7365": 13, "7565": 13, "43": [13, 14, 15, 20, 21, 22, 27, 29, 30], "7184": 13, "7459": 13, "7085": 13, "7367": 13, "6815": [13, 14], "7279": 13, "6673": 13, "50": [13, 14, 15, 19, 20, 21, 22, 29, 30], "7178": 13, "6846": 13, "7077": 13, "6483": 13, "7000": [13, 29], "6436": 13, "6971": 13, "6353": 13, "6991": 13, "6336": 13, "6982": 13, "5938": 13, "60": [13, 14, 22, 29, 31], "6980": 13, "5886": 13, "56": [13, 14, 22, 29, 30], "6979": 13, "5974": 13, "6881": [13, 14], "5600": 13, "6694": 13, "5445": 13, "6513": 13, "5501": 13, "6308": 13, "5397": [13, 22], "6141": 13, "5096": 13, "6020": 13, "4992": 13, "5915": [13, 14], "5020": 13, "58": [13, 14, 22, 29], "5829": 13, "4710": 13, "5747": 13, "4608": 13, "67": [13, 14, 15, 22, 29], "5703": 13, "4341": 13, "62": [13, 14, 22, 29], "5632": 13, "4428": 13, "66": [13, 14, 15, 22, 29], "5630": 13, "4209": 13, "5502": 13, "4151": 13, "63": [13, 14, 29], "5303": 13, "53": [13, 14, 19, 22, 29, 30], "4090": 13, "5051": 13, "4021": 13, "3847": 13, "65": [13, 14, 22, 29], "4842": 13, "3907": 13, "61": [13, 14, 22, 26, 29], "4849": 13, "57": [13, 14, 15, 22, 29, 30], "3434": 13, "70": [13, 14, 22, 29], "4866": 13, "3253": 13, "69": [13, 14, 22, 29], "4864": 13, "3380": 13, "4896": 13, "2933": 13, "4921": 13, "3124": 13, "68": [13, 14, 22, 29], "4948": 13, "3091": 13, "4931": 13, "2768": 13, "4881": 13, "2749": 13, "4827": [13, 14], "2740": 13, "4833": 13, "2773": 13, "4744": 13, "2430": 13, "4646": 13, "4648": 13, "1958": [13, 14], "4734": 13, "1895": [13, 14], "4748": 13, "2008": 13, "4760": 13, "1573": [13, 14], "4385": 13, "1751": [13, 14], "4242": 13, "1889": [13, 14], "4183": 13, "1762": [13, 14], "4250": 13, "1737": [13, 14], "4471": 13, "1242": [13, 14], "4559": 13, "0648": [13, 14], "4498": 13, "0717": [13, 14], "4506": 13, "0568": [13, 14, 15], "4410": 13, "0650": [13, 14, 22], "4375": [13, 32], "0475": [13, 14], "4441": 13, "0293": 13, "4450": 13, "0494": [13, 14], "4622": 13, "0200": 13, "4609": 13, "0358": [13, 14], "4645": 13, "9877": 13, "0173": 13, "4788": 13, "9744": 13, "4970": 13, "90": [13, 14, 26, 29], "9497": 13, "4981": 13, "91": [13, 14, 15, 26, 29], "9345": 13, "4736": 13, "92": [13, 14, 26, 29], "9636": 13, "4339": 13, "93": [13, 14, 15, 19, 26, 27, 29], "9197": 13, "4162": 13, "94": [13, 14, 15, 26, 28, 29, 30], "8984": 13, "3813": 13, "95": [13, 14, 15, 26, 29], "8895": 13, "3547": 13, "9048": 13, "3499": 13, "97": [13, 14, 15, 26, 27, 29], "8737": 13, "3502": [13, 15], "98": [13, 14, 15, 25, 26, 29], "9479": 13, "3518": 13, "8906": 13, "3639": 13, "8589": 13, "3789": 13, "against": [13, 15], "test_y_tru": [13, 15], "test_mask": [13, 15], "test_acc": [13, 14, 19, 22, 23, 24, 26, 29, 30, 32], "2982": 13, "karateclub": [14, 22, 23, 24, 26, 29, 32], "w": [14, 16, 24], "hnhn_layer": 14, "hnhnlayer": [14, 15], "matplotlib": [14, 15, 31], "pyplot": [14, 15, 31], "plt": [14, 15, 31], "http": [14, 15, 19, 21, 22, 23, 24, 26, 29], "www": [14, 21, 22, 23, 24, 26, 29], "jstor": [14, 22, 23, 24, 26, 29], "org": [14, 22, 23, 24, 26, 29], "stabl": [14, 15, 22, 23, 24, 26, 29], "3629752": [14, 22, 23, 24, 26, 29], "singular": [14, 22, 23, 24, 26, 29], "social": [14, 22, 23, 24, 26, 29], "group": [14, 22, 23, 24, 26, 29], "dataset_sim": 14, "karate_club": [14, 22, 23, 24, 26, 29, 30, 32], "complex_typ": [14, 22, 23, 24, 26, 29, 30, 32], "dataset_hyp": 14, "santii": [14, 22, 23, 32], "classifi": [14, 15, 19], "channels_": 14, "hot": [14, 22, 23, 24, 26, 28, 32], "encod": [14, 22, 23, 24, 26, 31], "get_simplex_attribut": [14, 22, 23, 24, 26, 29, 30, 32], "n_class": [14, 27, 29], "y_1h": 14, "ey": [14, 19, 22, 24, 29, 32], "astyp": 14, "stratifi": 14, "ind_train": 14, "ind_test": 14, "arang": [14, 32], "random_st": 14, "float32": [14, 18, 19], "int32": 14, "fraction": 14, "hnhnnetwork": 14, "multiclass": 14, "map": [14, 26, 27, 29, 31], "hypernod": 14, "softmax": [14, 19, 22, 23, 24, 30, 31, 32], "made": [14, 22, 23, 24, 26, 28, 29, 30], "1e": [14, 21, 24, 31], "2000": 14, "get_accuraci": 14, "lambda": 14, "yhat": 14, "ytrue": 14, "full": 14, "y_hat_cl": 14, "nloss": 14, "ntrain_acc": 14, "7157": 14, "5000": [14, 26], "7135": 14, "7113": 14, "7093": 14, "7074": 14, "7056": 14, "7039": [14, 23], "7024": 14, "7010": 14, "6997": 14, "6985": 14, "6975": 14, "6966": 14, "6958": 14, "6951": 14, "6945": 14, "6940": 14, "6936": 14, "6933": 14, "6931": 14, "6930": 14, "6929": 14, "6928": 14, "6932": 14, "6927": 14, "6926": 14, "6925": 14, "6924": 14, "6429": 14, "6923": 14, "6922": 14, "6921": 14, "6920": 14, "6919": 14, "8571": 14, "9643": 14, "6918": 14, "7500": [14, 22, 26, 29], "6917": 14, "5714": 14, "5357": 14, "6916": 14, "6915": 14, "6914": 14, "6913": 14, "6912": 14, "6911": 14, "6910": 14, "6909": 14, "6908": 14, "6667": [14, 26, 29], "101": [14, 26, 29, 30], "6907": 14, "102": [14, 26, 29], "103": [14, 26, 27, 29], "6906": 14, "104": [14, 26, 27, 29], "105": [14, 26, 27, 29, 30], "6905": 14, "107": [14, 26, 29], "6904": 14, "108": [14, 19, 26, 29], "109": [14, 19, 29], "6903": 14, "110": [14, 19, 29], "6902": 14, "111": [14, 19, 29], "112": [14, 29], "6901": 14, "113": [14, 27, 29], "114": [14, 29], "6900": 14, "115": [14, 29], "6899": 14, "116": [14, 29], "117": [14, 25, 29], "6898": 14, "118": [14, 29], "6897": 14, "119": [14, 29], "120": [14, 29], "6896": 14, "121": [14, 19, 29], "6895": 14, "122": [14, 29], "6894": 14, "123": [14, 29, 30], "124": [14, 25, 29], "6893": 14, "125": [14, 29], "6892": 14, "126": [14, 29], "6891": 14, "127": [14, 29], "128": [14, 29], "6890": 14, "129": [14, 29], "6889": 14, "130": [14, 29], "6888": 14, "131": [14, 25, 29], "6887": 14, "132": [14, 25, 29], "6886": 14, "133": [14, 19, 25, 29], "134": [14, 25, 29], "6885": 14, "135": [14, 25, 29], "6884": 14, "136": [14, 25, 29], "6883": 14, "137": [14, 25, 29], "6882": 14, "138": [14, 25, 29], "139": [14, 25, 26, 29], "6880": 14, "140": [14, 19, 29], "6879": [14, 22], "141": [14, 29], "6878": 14, "142": [14, 25, 29], "6877": 14, "143": [14, 22, 25, 29], "6876": 14, "144": [14, 29], "6875": 14, "145": [14, 29], "6874": 14, "146": [14, 29], "6873": 14, "147": [14, 29], "6871": 14, "148": [14, 29], "6870": 14, "149": [14, 29], "6869": 14, "150": [14, 29, 31], "6868": 14, "151": [14, 29], "6867": 14, "6865": 14, "153": [14, 29], "6864": 14, "154": [14, 29], "6863": 14, "155": [14, 29], "6861": 14, "156": [14, 29], "6860": 14, "157": [14, 29], "6859": 14, "158": [14, 29], "6857": 14, "159": [14, 29], "6856": 14, "160": [14, 29], "6855": 14, "161": [14, 29], "6853": 14, "162": [14, 29], "6852": 14, "6850": 14, "164": [14, 26, 29], "6849": 14, "165": [14, 29], "6847": 14, "166": [14, 29], "6845": 14, "167": [14, 29], "6844": 14, "168": [14, 29], "6842": 14, "169": [14, 29], "6840": 14, "170": [14, 29], "6839": 14, "171": [14, 29], "6837": 14, "172": [14, 29], "6835": 14, "173": [14, 29], "6833": 14, "174": [14, 29], "6831": 14, "175": [14, 29], "6829": [14, 24], "176": [14, 29], "6827": 14, "6825": 14, "178": [14, 29], "6823": 14, "179": [14, 29], "6821": 14, "180": [14, 29, 30], "6819": 14, "181": [14, 29], "6817": 14, "182": [14, 25, 29], "183": [14, 29], "6813": 14, "184": [14, 29], "6810": 14, "185": [14, 19, 29], "6808": 14, "186": [14, 29], "6806": 14, "187": [14, 29], "6803": 14, "188": [14, 29], "6801": 14, "189": [14, 29], "6799": 14, "190": [14, 29], "6796": 14, "191": [14, 29], "6793": 14, "192": [14, 29], "6791": 14, "193": [14, 29], "6788": 14, "194": [14, 29], "6785": 14, "195": [14, 29], "6783": 14, "196": [14, 29], "6780": 14, "197": [14, 29], "6777": 14, "198": [14, 29], "6774": 14, "199": [14, 19, 29], "6771": 14, "200": [14, 15, 19, 29], "6768": 14, "201": 14, "6765": 14, "6762": 14, "203": 14, "6758": 14, "204": 14, "6755": 14, "205": 14, "6752": 14, "206": 14, "6748": 14, "207": 14, "6745": 14, "208": 14, "6741": 14, "209": 14, "6738": 14, "210": [14, 25, 26], "6734": 14, "211": 14, "6730": 14, "6726": 14, "213": 14, "6723": 14, "214": 14, "6719": 14, "215": 14, "6715": 14, "216": 14, "6710": 14, "217": 14, "6706": 14, "218": 14, "6702": 14, "6786": 14, "219": 14, "6698": [14, 24], "220": 14, "6693": 14, "221": 14, "6689": 14, "222": 14, "6684": 14, "223": 14, "6679": 14, "224": 14, "225": 14, "6670": 14, "226": 14, "6665": 14, "227": 14, "6660": 14, "228": 14, "6655": 14, "229": 14, "6649": 14, "230": 14, "6644": 14, "231": 14, "6639": 14, "232": 14, "6633": 14, "233": 14, "6628": 14, "234": 14, "6622": 14, "235": 14, "6616": 14, "236": 14, "6610": 14, "237": 14, "6604": 14, "238": 14, "6598": 14, "239": 14, "6592": 14, "240": 14, "6585": 14, "7143": 14, "241": 14, "6579": 14, "242": 14, "6572": 14, "243": 14, "6566": 14, "244": 14, "6559": 14, "245": 14, "6552": 14, "246": 14, "6545": 14, "247": 14, "6538": 14, "248": 14, "6531": 14, "249": 14, "6523": 14, "250": 14, "6516": 14, "8214": 14, "251": 14, "6508": 14, "6500": 14, "253": 14, "6492": 14, "254": 14, "6484": 14, "255": 14, "6476": 14, "6468": 14, "257": 14, "6459": 14, "258": 14, "6451": 14, "259": 14, "260": 14, "6433": 14, "261": 14, "6424": 14, "262": 14, "6415": 14, "263": 14, "6406": 14, "264": 14, "6397": 14, "265": 14, "6387": 14, "266": 14, "6378": 14, "267": 14, "6368": 14, "268": 14, "6358": 14, "269": 14, "6348": 14, "270": [14, 22], "6337": 14, "271": 14, "6327": 14, "272": 14, "6317": 14, "273": 14, "6306": 14, "6295": 14, "275": [14, 17], "6284": 14, "276": 14, "6273": [14, 29], "277": 14, "6262": 14, "278": [14, 16], "6250": 14, "279": 14, "6239": 14, "280": 14, "6227": 14, "281": [14, 16], "6215": 14, "282": [14, 16], "6203": 14, "283": 14, "6191": 14, "284": 14, "6178": 14, "285": 14, "6166": 14, "286": 14, "6153": 14, "287": 14, "6140": 14, "288": 14, "6127": 14, "289": 14, "6114": 14, "290": 14, "6101": 14, "291": 14, "6088": 14, "292": 14, "6074": 14, "293": 14, "6060": 14, "294": 14, "6046": [14, 15], "295": 14, "6032": 14, "296": [14, 26], "6018": 14, "297": 14, "6004": 14, "298": 14, "5989": 14, "299": 14, "5975": 14, "300": 14, "5960": 14, "301": 14, "5945": 14, "302": [14, 19], "5930": 14, "303": 14, "304": 14, "5900": 14, "305": 14, "5884": 14, "306": 14, "5868": 14, "307": 14, "5853": 14, "308": 14, "5837": 14, "309": 14, "5821": [14, 29], "310": [14, 25], "5805": [14, 22], "311": 14, "5788": 14, "312": 14, "5772": 14, "313": 14, "5755": 14, "314": 14, "5739": 14, "315": 14, "5722": 14, "316": 14, "5705": 14, "317": 14, "5688": 14, "318": 14, "5671": [14, 28], "319": 14, "5653": 14, "320": 14, "5636": 14, "321": 14, "5618": 14, "322": 14, "5601": 14, "323": 14, "5583": 14, "324": 14, "5565": 14, "325": 14, "5547": 14, "326": 14, "5529": 14, "327": 14, "5511": 14, "328": 14, "5492": 14, "329": 14, "5474": 14, "330": 14, "5455": 14, "331": 14, "5437": 14, "332": 14, "5418": 14, "333": 14, "5399": 14, "334": 14, "5381": 14, "335": 14, "5362": [14, 22], "336": 14, "5343": 14, "337": 14, "5323": [14, 32], "338": 14, "5304": 14, "339": 14, "5285": 14, "340": 14, "5266": 14, "8929": 14, "341": 14, "5246": [14, 22], "342": 14, "5227": 14, "343": 14, "5207": 14, "344": 14, "5188": [14, 22], "345": 14, "5168": 14, "346": 14, "5148": 14, "347": 14, "5129": 14, "348": 14, "5109": 14, "349": 14, "5089": 14, "350": 14, "5069": 14, "9286": 14, "351": 14, "5049": 14, "352": 14, "5029": 14, "353": 14, "5009": 14, "354": 14, "4989": 14, "355": 14, "4969": 14, "356": 14, "4949": 14, "357": 14, "4928": 14, "358": 14, "4908": 14, "359": 14, "4888": 14, "360": 14, "4868": 14, "361": 14, "4847": 14, "362": 14, "363": 14, "4807": 14, "364": 14, "4787": 14, "365": 14, "4766": 14, "366": 14, "4746": 14, "367": 14, "4726": 14, "368": 14, "4705": 14, "369": 14, "4685": 14, "370": 14, "4665": 14, "371": 14, "4644": 14, "372": 14, "4624": 14, "373": 14, "4604": 14, "374": 14, "4583": 14, "375": 14, "4563": 14, "376": 14, "4543": 14, "377": 14, "4523": 14, "378": 14, "4503": 14, "379": 14, "4482": 14, "380": 14, "4462": 14, "381": 14, "4442": 14, "382": 14, "383": 14, "4402": 14, "384": 14, "4382": 14, "385": 14, "4362": 14, "386": 14, "4342": 14, "387": 14, "4322": 14, "388": 14, "4302": 14, "389": 14, "4282": 14, "390": 14, "4262": 14, "391": 14, "4243": 14, "392": 14, "4223": 14, "393": 14, "4203": 14, "394": 14, "4184": 14, "395": [14, 19], "4164": 14, "396": 14, "4145": 14, "397": 14, "4125": 14, "398": 14, "4106": 14, "399": 14, "4086": 14, "400": [14, 15], "4067": 14, "401": 14, "4048": 14, "402": 14, "4029": 14, "403": 14, "4010": 14, "404": 14, "3991": 14, "405": 14, "3972": 14, "406": 14, "3953": 14, "407": 14, "3934": 14, "408": 14, "3915": 14, "409": 14, "3897": 14, "410": 14, "3878": 14, "411": [14, 30], "3859": 14, "412": 14, "3841": 14, "413": 14, "3823": 14, "414": 14, "3804": 14, "415": 14, "3786": 14, "416": 14, "3768": 14, "417": 14, "3750": [14, 16, 32], "418": 14, "3732": 14, "419": 14, "3714": 14, "420": 14, "3696": 14, "421": 14, "3678": 14, "422": 14, "3661": 14, "423": 14, "3643": 14, "424": 14, "3626": 14, "425": 14, "3608": 14, "426": 14, "3591": 14, "427": 14, "3573": 14, "428": 14, "3556": 14, "429": 14, "3539": 14, "430": 14, "3522": 14, "431": 14, "3505": 14, "432": 14, "3488": 14, "433": 14, "3472": 14, "434": 14, "3455": 14, "435": 14, "3438": 14, "436": 14, "3422": 14, "437": 14, "3406": 14, "438": 14, "3389": 14, "439": 14, "3373": 14, "440": 14, "3357": 14, "441": 14, "3341": 14, "442": 14, "3325": 14, "443": [14, 19], "3309": 14, "444": 14, "3293": 14, "445": 14, "3278": 14, "446": 14, "3262": 14, "447": 14, "3247": 14, "448": 14, "3231": 14, "449": 14, "3216": 14, "450": 14, "3201": 14, "451": 14, "3185": 14, "452": 14, "3170": 14, "453": 14, "3155": 14, "454": 14, "3140": 14, "455": 14, "3126": 14, "456": 14, "3111": 14, "457": 14, "3096": 14, "458": 14, "3082": 14, "459": 14, "3067": 14, "460": 14, "3053": 14, "461": 14, "3039": [14, 30], "462": 14, "3025": 14, "463": 14, "3011": 14, "464": 14, "2997": 14, "465": 14, "2983": 14, "466": 14, "2969": 14, "467": 14, "2955": 14, "468": 14, "2941": 14, "469": 14, "2928": 14, "470": 14, "2914": [14, 15], "471": 14, "2901": 14, "472": 14, "2888": 14, "473": 14, "2874": 14, "474": 14, "2861": 14, "475": 14, "2848": 14, "476": 14, "2835": 14, "477": 14, "2822": 14, "478": 14, "2810": 14, "479": 14, "2797": 14, "480": 14, "2784": 14, "481": 14, "2772": 14, "482": 14, "2759": 14, "483": 14, "2747": 14, "484": 14, "2735": 14, "485": 14, "2722": 14, "486": 14, "2710": 14, "487": 14, "2698": 14, "488": 14, "2686": 14, "489": 14, "2674": 14, "490": 14, "2662": 14, "491": 14, "2651": 14, "492": 14, "2639": 14, "493": 14, "2627": 14, "494": 14, "2616": 14, "495": 14, "2604": 14, "496": 14, "2593": 14, "497": 14, "2582": 14, "498": 14, "2571": 14, "499": 14, "2559": 14, "2548": 14, "501": 14, "2537": 14, "502": 14, "2526": 14, "503": 14, "2516": 14, "504": 14, "2505": 14, "505": 14, "2494": 14, "506": 14, "2484": 14, "507": 14, "2473": 14, "508": 14, "2463": 14, "509": 14, "2452": [14, 15], "510": 14, "2442": 14, "511": 14, "2432": 14, "512": 14, "2421": 14, "513": 14, "2411": 14, "514": 14, "2401": 14, "515": 14, "2391": 14, "516": 14, "2381": 14, "517": 14, "2371": 14, "518": 14, "2362": 14, "519": 14, "2352": 14, "520": 14, "2342": 14, "521": 14, "2333": 14, "522": 14, "2323": 14, "523": 14, "2314": 14, "524": 14, "525": 14, "2295": 14, "526": 14, "2286": 14, "527": 14, "2276": 14, "528": 14, "2267": 14, "2258": 14, "530": 14, "2249": 14, "531": 14, "2240": 14, "532": 14, "2231": [14, 15], "533": 14, "2223": 14, "534": 14, "2214": 14, "535": 14, "2205": 14, "2196": 14, "537": 14, "2188": 14, "538": 14, "2179": 14, "539": 14, "2171": 14, "540": 14, "2162": 14, "541": 14, "2154": 14, "542": 14, "2146": 14, "543": 14, "2137": 14, "544": 14, "2129": 14, "545": 14, "2121": 14, "546": [14, 27], "2113": 14, "547": 14, "2105": 14, "548": 14, "2097": 14, "549": 14, "2089": 14, "550": 14, "2081": 14, "551": 14, "2073": 14, "552": 14, "2066": 14, "553": 14, "2058": 14, "554": 14, "2050": 14, "555": 14, "2043": 14, "556": 14, "2035": 14, "557": 14, "2028": 14, "558": 14, "559": 14, "2013": 14, "560": 14, "2005": 14, "561": 14, "1998": 14, "562": 14, "1991": 14, "563": 14, "1983": [14, 29], "564": 14, "1976": 14, "565": 14, "1969": 14, "566": 14, "1962": [14, 22], "567": 14, "1955": 14, "568": 14, "1948": 14, "569": 14, "1941": 14, "570": 14, "1934": 14, "571": 14, "1927": 14, "572": 14, "1921": 14, "573": 14, "1914": 14, "574": 14, "1907": 14, "575": 14, "1900": 14, "576": 14, "1894": 14, "577": 14, "1887": 14, "578": 14, "1881": 14, "579": 14, "1874": 14, "580": 14, "1868": 14, "581": 14, "1861": 14, "582": 14, "1855": 14, "583": 14, "1849": 14, "584": 14, "1842": 14, "585": 14, "1836": [14, 22], "586": 14, "1830": 14, "587": 14, "1824": 14, "588": 14, "1818": 14, "589": 14, "1811": 14, "590": 14, "1805": 14, "591": 14, "1799": 14, "592": 14, "1793": 14, "593": 14, "1788": 14, "594": 14, "1782": 14, "595": 14, "1776": 14, "596": 14, "1770": 14, "597": 14, "1764": 14, "598": 14, "1758": 14, "599": 14, "1753": 14, "600": 14, "1747": 14, "601": 14, "1741": 14, "602": 14, "1736": 14, "603": 14, "1730": [14, 22], "604": 14, "1725": [14, 22], "605": 14, "1719": 14, "606": 14, "1714": 14, "607": 14, "1708": 14, "608": 14, "1703": 14, "609": 14, "1697": 14, "610": 14, "1692": 14, "611": 14, "1687": 14, "612": 14, "1682": 14, "613": [14, 31], "1676": 14, "614": 14, "1671": 14, "615": 14, "1666": 14, "616": 14, "1661": 14, "617": 14, "1656": 14, "618": 14, "1651": 14, "619": 14, "1646": 14, "620": 14, "1640": 14, "621": 14, "1636": 14, "622": 14, "1631": 14, "623": 14, "1626": 14, "624": 14, "1621": 14, "625": 14, "1616": 14, "626": 14, "1611": 14, "627": 14, "1606": 14, "628": 14, "1601": 14, "629": 14, "1597": 14, "630": 14, "1592": 14, "631": 14, "1587": 14, "632": 14, "1583": [14, 26], "633": 14, "1578": 14, "634": 14, "635": 14, "1569": 14, "636": 14, "1564": 14, "637": 14, "1560": [14, 22], "638": 14, "1555": 14, "639": 14, "1551": 14, "640": 14, "1546": 14, "641": 14, "1542": 14, "642": 14, "1537": 14, "643": 14, "1533": 14, "644": 14, "1529": 14, "645": 14, "1524": 14, "646": 14, "1520": 14, "647": 14, "1516": 14, "648": 14, "1511": [14, 22], "649": 14, "1507": 14, "650": 14, "1503": 14, "651": 14, "1499": 14, "652": 14, "1495": [14, 22], "653": 14, "1491": 14, "654": 14, "1487": [14, 22], "655": 14, "1482": 14, "656": 14, "1478": 14, "657": 14, "1474": [14, 22], "658": 14, "1470": 14, "659": 14, "1466": 14, "660": 14, "1462": 14, "661": 14, "1458": 14, "662": 14, "1454": 14, "663": 14, "1451": 14, "664": 14, "1447": 14, "665": 14, "1443": 14, "666": 14, "1439": 14, "667": 14, "1435": 14, "668": 14, "1431": 14, "669": 14, "1428": 14, "670": 14, "1424": 14, "671": 14, "1420": 14, "672": 14, "1416": 14, "673": 14, "1413": 14, "674": 14, "1409": 14, "675": 14, "1405": 14, "676": 14, "1402": 14, "677": 14, "1398": 14, "678": 14, "1395": 14, "679": 14, "1391": 14, "680": 14, "1387": 14, "681": 14, "1384": 14, "682": 14, "1380": [14, 22, 30], "683": 14, "1377": 14, "684": 14, "1373": 14, "685": 14, "1370": 14, "686": 14, "1367": 14, "687": 14, "1363": 14, "688": 14, "1360": 14, "689": 14, "1356": [14, 22], "690": 14, "1353": 14, "691": 14, "1350": 14, "692": 14, "1346": 14, "693": 14, "1343": [14, 22], "694": 14, "1340": 14, "695": 14, "1336": 14, "696": 14, "1333": 14, "697": 14, "1330": 14, "698": 14, "1327": 14, "699": 14, "1323": 14, "700": 14, "1320": 14, "701": 14, "1317": 14, "702": 14, "1314": 14, "703": 14, "1311": 14, "704": 14, "1308": 14, "705": 14, "1304": 14, "706": 14, "1301": 14, "707": 14, "1298": 14, "708": 14, "1295": 14, "709": 14, "1292": 14, "710": 14, "1289": 14, "711": 14, "1286": 14, "712": 14, "1283": 14, "713": 14, "1280": 14, "714": 14, "1277": 14, "715": 14, "1274": 14, "716": 14, "1271": 14, "717": 14, "1268": 14, "718": 14, "1265": 14, "719": 14, "1263": 14, "720": 14, "1260": 14, "721": 14, "1257": 14, "722": 14, "1254": 14, "723": 14, "1251": 14, "724": 14, "1248": 14, "725": 14, "1245": 14, "726": 14, "1243": 14, "727": 14, "1240": 14, "728": 14, "1237": 14, "729": 14, "1234": 14, "730": 14, "1232": 14, "731": 14, "1229": 14, "732": 14, "1226": 14, "733": 14, "1223": 14, "734": 14, "1221": 14, "735": 14, "1218": 14, "736": 14, "1215": 14, "737": 14, "1213": 14, "738": 14, "1210": 14, "739": 14, "1207": 14, "740": 14, "1205": 14, "741": 14, "1202": 14, "742": 14, "1200": [14, 31], "743": 14, "1197": 14, "744": 14, "1194": 14, "745": 14, "1192": 14, "746": 14, "1189": 14, "747": 14, "1187": 14, "748": 14, "1184": 14, "749": 14, "1182": 14, "1179": [14, 22], "751": 14, "1177": 14, "752": 14, "1174": 14, "753": 14, "1172": 14, "754": 14, "1169": 14, "755": 14, "1167": 14, "756": 14, "1165": 14, "757": 14, "1162": 14, "758": 14, "1160": 14, "759": 14, "1157": 14, "760": 14, "1155": 14, "761": 14, "1153": 14, "762": 14, "1150": [14, 29], "763": 14, "1148": 14, "764": 14, "1146": 14, "765": 14, "1143": 14, "766": 14, "1141": 14, "767": 14, "1139": [14, 15], "768": 14, "1136": 14, "769": 14, "1134": 14, "770": 14, "1132": 14, "771": 14, "1130": 14, "772": 14, "1127": 14, "773": 14, "1125": 14, "774": 14, "1123": 14, "775": 14, "1121": 14, "776": 14, "1118": 14, "777": 14, "1116": 14, "778": 14, "1114": 14, "779": 14, "1112": 14, "780": 14, "1110": 14, "781": 14, "1107": [14, 15], "782": 14, "1105": 14, "783": 14, "1103": 14, "784": 14, "1101": 14, "785": 14, "1099": 14, "786": 14, "1097": 14, "787": 14, "1095": 14, "788": 14, "1093": 14, "789": 14, "1090": 14, "790": 14, "1088": 14, "791": 14, "1086": 14, "792": 14, "1084": 14, "793": 14, "794": 14, "1080": [14, 22], "795": [14, 15], "1078": 14, "796": 14, "1076": 14, "797": 14, "1074": 14, "798": 14, "1072": 14, "799": 14, "1070": 14, "800": 14, "1068": 14, "801": 14, "1066": 14, "802": 14, "1064": 14, "803": 14, "1062": 14, "804": 14, "1060": 14, "805": [14, 15], "1058": 14, "806": 14, "1056": 14, "807": 14, "1054": 14, "808": 14, "1052": 14, "809": 14, "1050": 14, "810": 14, "1049": 14, "811": 14, "1047": 14, "812": 14, "1045": 14, "813": 14, "1043": 14, "814": 14, "1041": 14, "815": 14, "1039": 14, "816": 14, "1037": 14, "817": 14, "1035": 14, "818": 14, "1033": 14, "819": 14, "1032": 14, "820": 14, "1030": 14, "821": 14, "1028": 14, "822": 14, "1026": 14, "823": 14, "1024": 14, "824": 14, "1023": [14, 22], "825": 14, "1021": 14, "826": 14, "1019": [14, 22], "827": 14, "1017": 14, "828": 14, "1015": 14, "829": 14, "1014": 14, "830": 14, "1012": [14, 22], "831": 14, "1010": 14, "832": 14, "1008": 14, "833": 14, "1007": 14, "834": 14, "1005": 14, "835": 14, "1003": 14, "836": 14, "1001": 14, "837": 14, "1000": [14, 31], "838": 14, "0998": [14, 22], "839": 14, "0996": [14, 22], "840": 14, "0995": 14, "841": 14, "0993": 14, "842": 14, "0991": 14, "843": 14, "0990": 14, "844": 14, "0988": 14, "845": 14, "0986": 14, "846": 14, "0985": 14, "847": 14, "0983": 14, "848": 14, "0981": 14, "849": 14, "0980": 14, "850": 14, "0978": 14, "851": 14, "0976": 14, "852": 14, "0975": 14, "853": 14, "0973": 14, "854": 14, "0972": 14, "855": 14, "0970": 14, "856": 14, "0968": [14, 22], "857": 14, "0967": 14, "858": 14, "0965": 14, "859": 14, "0964": 14, "860": 14, "0962": 14, "861": 14, "0961": 14, "862": 14, "0959": [14, 22], "863": 14, "0957": 14, "864": 14, "0956": 14, "865": 14, "0954": [14, 22], "866": 14, "0953": 14, "867": 14, "0951": 14, "868": 14, "0950": 14, "869": 14, "0948": [14, 22], "870": 14, "0947": 14, "871": 14, "0945": 14, "872": 14, "0944": 14, "873": 14, "0942": 14, "874": 14, "0941": 14, "875": 14, "0939": 14, "876": 14, "0938": 14, "877": 14, "0936": 14, "878": 14, "0935": 14, "879": 14, "0933": 14, "880": 14, "0932": 14, "881": 14, "0930": [14, 22], "882": 14, "0929": 14, "883": 14, "0928": 14, "884": 14, "0926": 14, "885": 14, "0925": 14, "886": 14, "0923": [14, 22], "887": 14, "0922": 14, "888": 14, "0920": [14, 22], "889": 14, "0919": 14, "890": 14, "0918": 14, "891": 14, "0916": 14, "892": 14, "0915": 14, "893": 14, "0913": 14, "894": 14, "0912": [14, 29], "895": 14, "0911": 14, "896": 14, "0909": 14, "897": 14, "0908": 14, "898": 14, "0907": 14, "899": 14, "0905": 14, "900": 14, "0904": 14, "901": 14, "0902": 14, "902": 14, "0901": 14, "903": 14, "0900": 14, "904": 14, "0898": 14, "905": 14, "0897": [14, 22], "906": 14, "0896": 14, "907": 14, "0894": 14, "908": 14, "0893": 14, "909": 14, "0892": [14, 22], "910": 14, "0891": [14, 22], "911": 14, "0889": 14, "912": 14, "0888": 14, "913": 14, "0887": 14, "914": 14, "0885": 14, "915": 14, "0884": 14, "916": 14, "0883": 14, "917": 14, "0881": 14, "918": 14, "0880": 14, "919": 14, "0879": 14, "920": 14, "0878": 14, "921": 14, "0876": 14, "922": 14, "0875": 14, "923": 14, "0874": 14, "924": 14, "0873": 14, "925": 14, "0871": 14, "926": 14, "0870": 14, "927": 14, "0869": 14, "928": 14, "0868": 14, "929": 14, "0866": 14, "930": 14, "0865": 14, "931": 14, "0864": [14, 22], "932": 14, "0863": 14, "933": 14, "0862": 14, "934": 14, "0860": 14, "935": 14, "0859": 14, "936": 14, "0858": 14, "937": 14, "0857": 14, "938": 14, "0856": 14, "939": 14, "0854": 14, "940": 14, "0853": 14, "941": 14, "0852": 14, "942": 14, "0851": 14, "943": 14, "0850": 14, "944": 14, "0848": 14, "945": 14, "0847": 14, "946": 14, "0846": 14, "947": 14, "0845": 14, "948": 14, "0844": 14, "949": 14, "0843": 14, "950": 14, "0842": 14, "951": 14, "0840": 14, "952": 14, "0839": 14, "953": 14, "0838": 14, "954": 14, "0837": 14, "955": 14, "0836": 14, "956": 14, "0835": 14, "957": 14, "0834": 14, "958": 14, "0833": 14, "959": 14, "0831": 14, "960": 14, "0830": 14, "961": 14, "0829": 14, "962": 14, "0828": 14, "963": 14, "0827": 14, "964": 14, "0826": 14, "965": 14, "0825": 14, "966": 14, "0824": 14, "967": 14, "0823": 14, "968": 14, "0822": 14, "969": 14, "0820": 14, "970": 14, "0819": [14, 22], "971": 14, "0818": 14, "972": 14, "0817": 14, "973": 14, "0816": 14, "974": 14, "0815": 14, "975": 14, "0814": 14, "976": 14, "0813": 14, "977": 14, "0812": 14, "978": 14, "0811": 14, "979": 14, "0810": 14, "980": 14, "0809": 14, "981": 14, "0808": 14, "982": 14, "0807": 14, "983": 14, "0806": 14, "984": 14, "0805": [14, 29], "985": 14, "0804": [14, 22], "986": 14, "0803": [14, 22], "987": 14, "0802": 14, "988": 14, "0800": 14, "989": 14, "0799": 14, "990": 14, "0798": 14, "991": 14, "992": 14, "0796": 14, "993": 14, "0795": 14, "994": 14, "0794": 14, "995": 14, "0793": 14, "996": 14, "0792": 14, "997": 14, "0791": 14, "998": 14, "0790": 14, "999": 14, "0789": [14, 22], "0788": 14, "0787": 14, "1002": 14, "0786": [14, 15], "1004": 14, "0785": 14, "0784": 14, "1006": [14, 22], "0783": 14, "0782": 14, "0781": 14, "1009": [14, 22], "0779": 14, "1011": 14, "0778": 14, "0777": 14, "1013": 14, "0776": 14, "0775": 14, "0774": 14, "0773": 14, "0772": 14, "1018": 14, "0771": 14, "0770": 14, "1020": 14, "0769": 14, "0768": 14, "1022": 14, "0767": 14, "0766": 14, "1025": 14, "0765": 14, "0764": 14, "1027": 14, "0763": 14, "0762": [14, 22], "1029": 14, "0761": 14, "0760": 14, "1031": 14, "0759": [14, 22], "0758": 14, "1034": 14, "0757": 14, "0756": 14, "1036": 14, "0755": 14, "0754": [14, 22], "1038": 14, "0753": 14, "0752": 14, "1040": 14, "0751": 14, "0750": 14, "1042": 14, "0749": [14, 22], "1044": 14, "0748": 14, "0747": 14, "1046": [14, 22], "0746": [14, 22], "0745": 14, "1048": 14, "0744": 14, "0743": 14, "1051": 14, "0742": 14, "0741": 14, "1053": 14, "0740": 14, "0739": 14, "1055": 14, "0738": 14, "1057": 14, "0737": 14, "0736": 14, "1059": 14, "0735": 14, "0734": 14, "1061": 14, "0733": 14, "1063": 14, "0732": 14, "0731": [14, 22], "1065": 14, "0730": 14, "0729": 14, "1067": [14, 29], "0728": 14, "1069": 14, "0727": 14, "0726": 14, "1071": 14, "0725": [14, 22], "0724": [14, 22], "1073": 14, "0723": 14, "1075": 14, "0722": [14, 29], "0721": [14, 22], "1077": 14, "0720": [14, 22], "0719": 14, "0718": 14, "1081": 14, "0716": 14, "1083": 14, "0715": 14, "1085": 14, "0714": 14, "0713": 14, "1087": 14, "0712": 14, "1089": 14, "0711": 14, "0710": 14, "1091": 14, "0709": 14, "1092": 14, "0708": 14, "1094": 14, "0707": 14, "0706": 14, "1096": 14, "0705": 14, "1098": 14, "0704": 14, "0703": 14, "1100": 14, "0702": 14, "1102": 14, "0701": [14, 22], "0700": 14, "1104": 14, "0699": [14, 22], "1106": [14, 22], "0698": 14, "0697": 14, "1108": 14, "1109": 14, "0696": 14, "0695": 14, "1111": 14, "0694": 14, "1113": 14, "0693": [14, 22], "0692": 14, "1115": 14, "0691": 14, "1117": 14, "0690": 14, "0689": 14, "1119": 14, "1120": 14, "0688": 14, "0687": [14, 22], "1122": 14, "0686": 14, "1124": 14, "0685": [14, 22], "0684": 14, "1126": 14, "0683": 14, "1128": 14, "0682": 14, "1129": 14, "1131": 14, "0680": 14, "0679": 14, "1133": 14, "0678": 14, "1135": 14, "0677": 14, "1137": 14, "0676": 14, "1138": 14, "0675": 14, "0674": 14, "1140": 14, "0673": 14, "1142": 14, "0672": 14, "1144": 14, "0671": 14, "1145": 14, "0670": 14, "1147": 14, "0669": 14, "0668": 14, "1149": 14, "0667": 14, "1151": 14, "0666": 14, "1152": 14, "0665": 14, "1154": 14, "0664": 14, "1156": 14, "0663": [14, 22], "0662": 14, "1158": 14, "1159": 14, "0661": 14, "0660": 14, "1161": 14, "0659": 14, "1163": 14, "0658": 14, "1164": 14, "0657": 14, "1166": 14, "0656": 14, "1168": 14, "0655": 14, "1170": 14, "0654": 14, "1171": 14, "0653": 14, "1173": 14, "0652": 14, "0651": 14, "1175": 14, "1176": 14, "1178": 14, "0649": 14, "1180": 14, "1181": 14, "0647": 14, "0646": 14, "1183": 14, "0645": 14, "1185": 14, "1186": 14, "0644": 14, "0643": 14, "1188": 14, "0642": 14, "1190": 14, "0641": 14, "1191": 14, "0640": 14, "1193": 14, "0639": 14, "1195": 14, "0638": 14, "1196": 14, "0637": 14, "1198": 14, "1199": 14, "0636": 14, "0635": 14, "1201": 14, "0634": 14, "1203": 14, "1204": 14, "0633": 14, "0632": 14, "1206": 14, "0631": 14, "1208": 14, "1209": 14, "0630": 14, "0629": 14, "1211": 14, "1212": 14, "0628": 14, "1214": 14, "0627": 14, "1216": 14, "0626": 14, "1217": 14, "0625": 14, "1219": 14, "0624": 14, "1220": 14, "0623": 14, "1222": 14, "0622": 14, "1224": 14, "0621": 14, "1225": 14, "0620": 14, "1227": 14, "1228": 14, "0619": 14, "1230": 14, "0618": 14, "1231": 14, "0617": 14, "1233": 14, "0616": 14, "1235": 14, "0615": 14, "1236": 14, "0614": 14, "1238": 14, "0613": 14, "1239": 14, "0612": 14, "1241": 14, "0611": 14, "1244": 14, "0610": 14, "1246": 14, "0609": 14, "1247": 14, "0608": 14, "1249": 14, "0607": [14, 22], "0606": 14, "1252": 14, "1253": 14, "0605": 14, "1255": [14, 22], "0604": 14, "1256": 14, "0603": 14, "1258": 14, "1259": 14, "0602": 14, "1261": 14, "0601": [14, 29], "1262": 14, "0600": 14, "1264": 14, "0599": 14, "1266": 14, "0598": 14, "1267": 14, "0597": 14, "1269": 14, "1270": 14, "0596": 14, "1272": 14, "0595": 14, "1273": 14, "0594": 14, "1275": 14, "1276": 14, "0593": 14, "1278": 14, "0592": 14, "1279": 14, "0591": 14, "1281": 14, "1282": 14, "0590": 14, "1284": 14, "0589": 14, "1285": 14, "0588": 14, "1287": 14, "0587": 14, "1288": [14, 22], "0586": 14, "1290": 14, "1291": 14, "0585": 14, "1293": [14, 22, 29], "0584": 14, "1294": [14, 22], "1296": 14, "1297": 14, "0582": 14, "1299": 14, "0581": 14, "1300": 14, "0580": [14, 22], "1302": 14, "1303": 14, "0579": 14, "1305": 14, "1306": 14, "0578": 14, "1307": 14, "0577": 14, "1309": 14, "1310": 14, "0576": [14, 22], "1312": [14, 26], "0575": 14, "1313": 14, "0574": 14, "1315": 14, "1316": [14, 22], "0573": 14, "1318": 14, "0572": 14, "1319": 14, "0571": 14, "1321": 14, "1322": 14, "0570": 14, "1324": 14, "0569": 14, "1325": 14, "1326": 14, "1328": 14, "0567": 14, "1329": 14, "1331": 14, "0566": 14, "1332": [14, 22], "0565": 14, "1334": 14, "1335": 14, "0564": 14, "1337": 14, "0563": 14, "1338": 14, "1339": 14, "0562": 14, "1341": 14, "0561": [14, 15], "1342": 14, "1344": 14, "0560": [14, 15], "1345": 14, "0559": [14, 15], "1347": [14, 30], "1348": 14, "0558": 14, "1349": 14, "0557": 14, "1351": 14, "1352": 14, "0556": 14, "1354": 14, "1355": 14, "0555": 14, "1357": 14, "0554": 14, "1358": 14, "1359": 14, "0553": [14, 22], "1361": 14, "0552": 14, "1362": 14, "0551": 14, "1364": 14, "1365": 14, "1366": 14, "0550": 14, "1368": 14, "0549": 14, "1369": 14, "0548": 14, "1371": 14, "1372": 14, "0547": 14, "1374": 14, "1375": 14, "0546": [14, 22], "1376": 14, "0545": 14, "1378": 14, "1379": 14, "0544": 14, "1381": 14, "1382": 14, "0543": 14, "1383": 14, "0542": 14, "1385": 14, "1386": 14, "0541": 14, "1388": 14, "1389": 14, "0540": 14, "1390": 14, "0539": 14, "1392": 14, "1393": 14, "1394": 14, "0538": 14, "1396": 14, "0537": [14, 22], "1397": 14, "0536": 14, "1399": 14, "1400": 14, "1401": 14, "0535": 14, "1403": 14, "0534": 14, "1404": 14, "0533": 14, "1406": 14, "1407": 14, "1408": 14, "0532": 14, "1410": 14, "0531": 14, "1411": 14, "1412": 14, "0530": 14, "1414": 14, "1415": 14, "0529": 14, "1417": 14, "1418": 14, "0528": 14, "1419": 14, "0527": 14, "1421": 14, "1422": 14, "1423": 14, "0526": 14, "1425": 14, "0525": 14, "1426": [14, 22], "1427": 14, "0524": 14, "1429": [14, 22], "1430": 14, "0523": 14, "1432": 14, "0522": 14, "1434": 14, "0521": 14, "1437": 14, "1438": 14, "0520": 14, "1440": 14, "0519": 14, "1441": 14, "1442": 14, "0518": 14, "1444": 14, "1445": 14, "0517": 14, "1446": 14, "1448": 14, "0516": 14, "1449": [14, 29], "1450": 14, "0515": 14, "1452": 14, "1453": 14, "0514": [14, 26], "1455": 14, "0513": 14, "1456": 14, "1457": [14, 22], "0512": 14, "1459": 14, "1460": 14, "1461": 14, "0511": 14, "1463": 14, "0510": 14, "1464": 14, "1465": 14, "0509": 14, "1467": 14, "1468": 14, "1469": 14, "0508": 14, "1471": 14, "0507": 14, "1472": 14, "1473": [14, 22], "0506": 14, "1475": [14, 22], "1476": 14, "0505": 14, "1477": 14, "1479": 14, "0504": 14, "1480": 14, "1481": 14, "0503": 14, "1483": 14, "1484": [14, 22], "1485": 14, "0502": 14, "1486": 14, "0501": 14, "1488": 14, "1489": 14, "1490": 14, "0500": 14, "1492": 14, "1493": 14, "0499": 14, "1494": 14, "0498": 14, "1496": 14, "1497": 14, "1498": [14, 15], "0497": 14, "1500": 14, "1501": 14, "1502": 14, "1504": 14, "0495": 14, "1505": 14, "1506": 14, "1508": 14, "1509": 14, "0493": 14, "1510": 14, "1512": 14, "0492": 14, "1513": 14, "1514": 14, "1515": 14, "0491": 14, "1517": 14, "1518": [14, 22], "0490": 14, "1519": [14, 22], "0489": 14, "1521": 14, "1522": 14, "1523": 14, "0488": 14, "1525": 14, "1526": 14, "0487": 14, "1527": 14, "1528": 14, "0486": 14, "1530": 14, "1531": 14, "1532": 14, "0485": 14, "1534": 14, "1535": 14, "0484": 14, "1536": 14, "1538": 14, "0483": 14, "1539": 14, "1540": 14, "1541": 14, "0482": 14, "1543": 14, "1544": 14, "0481": 14, "1545": [14, 22], "0480": 14, "1547": 14, "1548": 14, "1549": 14, "0479": 14, "1550": 14, "1552": 14, "0478": 14, "1553": 14, "1554": 14, "0477": 14, "1556": 14, "1557": 14, "1558": 14, "0476": 14, "1559": 14, "1561": 14, "1562": 14, "1563": 14, "0474": 14, "1565": 14, "1566": 14, "1567": 14, "0473": 14, "1568": 14, "1570": 14, "0472": 14, "1571": 14, "1572": 14, "0471": 14, "1574": 14, "1575": [14, 22], "1576": 14, "0470": 14, "1577": 14, "1579": 14, "0469": 14, "1580": 14, "1581": 14, "1582": 14, "0468": 14, "1584": 14, "1585": 14, "1586": 14, "0467": 14, "1588": [14, 29], "1589": 14, "0466": 14, "1590": 14, "1591": 14, "0465": 14, "1593": 14, "1594": 14, "1595": 14, "0464": 14, "1596": 14, "1598": 14, "0463": 14, "1599": 14, "1600": 14, "0462": 14, "1602": 14, "1603": 14, "1604": 14, "0461": 14, "1605": 14, "1607": 14, "0460": 14, "1608": 14, "1609": 14, "1610": 14, "0459": 14, "1612": 14, "1613": 14, "1614": 14, "0458": 14, "1615": 14, "1617": 14, "0457": 14, "1618": 14, "1619": 14, "1620": 14, "0456": 14, "1622": 14, "1623": 14, "0455": 14, "1624": 14, "1625": 14, "0454": 14, "1627": 14, "1628": [14, 22, 29], "1629": 14, "1630": 14, "0453": 14, "1632": 14, "1633": 14, "0452": 14, "1634": 14, "1635": 14, "0451": 14, "1637": 14, "1638": [14, 29], "1639": 14, "0450": 14, "1641": 14, "1642": 14, "1643": 14, "0449": 14, "1644": 14, "1645": 14, "0448": 14, "1647": 14, "1648": 14, "1649": 14, "0447": [14, 15], "1650": 14, "1652": 14, "0446": 14, "1653": 14, "1654": [14, 22], "1655": 14, "0445": 14, "1657": 14, "1658": 14, "1659": 14, "0444": 14, "1660": 14, "1662": 14, "1663": 14, "0443": 14, "1664": 14, "1665": 14, "0442": 14, "1667": 14, "1668": 14, "1669": 14, "0441": 14, "1670": 14, "1672": 14, "1673": 14, "0440": 14, "1674": 14, "1675": 14, "0439": 14, "1677": 14, "1678": 14, "1679": 14, "0438": 14, "1680": 14, "1681": 14, "1683": 14, "0437": 14, "1684": 14, "1685": 14, "1686": 14, "0436": 14, "1688": 14, "1689": 14, "1690": 14, "0435": 14, "1691": 14, "1693": 14, "0434": 14, "1694": 14, "1695": 14, "1696": 14, "0433": 14, "1698": 14, "1699": 14, "1700": 14, "0432": 14, "1701": 14, "1702": 14, "1704": 14, "0431": [14, 29], "1705": 14, "1706": 14, "1707": 14, "0430": 14, "1709": 14, "1710": 14, "1711": 14, "0429": 14, "1712": 14, "1713": 14, "0428": 14, "1715": 14, "1716": 14, "1717": 14, "1718": 14, "0427": 14, "1720": 14, "1721": 14, "0426": 14, "1722": 14, "1723": 14, "1724": [14, 22], "0425": 14, "1726": 14, "1727": 14, "1728": 14, "0424": 14, "1729": 14, "1731": 14, "1732": 14, "0423": 14, "1733": 14, "1734": [14, 22], "1735": 14, "0422": 14, "1738": [14, 22], "1739": 14, "0421": 14, "1740": 14, "1742": 14, "1743": 14, "0420": 14, "1744": 14, "1745": 14, "1746": 14, "0419": 14, "1748": 14, "1749": 14, "1750": 14, "0418": 14, "1752": 14, "1754": 14, "0417": 14, "1755": 14, "1756": 14, "1757": 14, "0416": 14, "1759": 14, "1760": 14, "1761": 14, "0415": 14, "1763": [14, 22], "1765": 14, "0414": 14, "1766": 14, "1767": 14, "1768": 14, "1769": 14, "0413": 14, "1771": 14, "1772": 14, "0412": [14, 29], "1773": 14, "1774": 14, "1775": 14, "0411": 14, "1777": 14, "1778": 14, "1779": 14, "1780": [14, 22], "0410": 14, "1781": [14, 29], "1783": 14, "1784": 14, "0409": 14, "1785": 14, "1786": 14, "1787": 14, "0408": 14, "1789": 14, "1790": 14, "1791": 14, "0407": 14, "1792": 14, "1794": 14, "1795": 14, "0406": [14, 15], "1796": 14, "1797": 14, "1798": 14, "0405": 14, "1800": 14, "1801": 14, "1802": 14, "1803": 14, "0404": 14, "1804": [14, 22], "1806": 14, "1807": 14, "0403": 14, "1808": 14, "1809": 14, "1810": 14, "0402": 14, "1812": [14, 22], "1813": 14, "1814": 14, "0401": 14, "1815": 14, "1816": 14, "1817": 14, "0400": 14, "1819": 14, "1820": 14, "1821": [14, 22], "1822": 14, "0399": 14, "1823": 14, "1825": 14, "1826": 14, "0398": 14, "1827": 14, "1828": 14, "1829": 14, "0397": 14, "1831": [14, 22], "1832": 14, "1833": 14, "1834": 14, "0396": [14, 15], "1835": 14, "1837": 14, "1838": 14, "0395": 14, "1839": 14, "1840": 14, "1841": 14, "0394": 14, "1843": 14, "1844": 14, "1845": 14, "1846": 14, "0393": 14, "1847": 14, "1848": 14, "1850": 14, "0392": 14, "1851": [14, 22], "1852": 14, "1853": 14, "1854": 14, "0391": 14, "1856": 14, "1857": 14, "1858": 14, "0390": 14, "1859": 14, "1860": 14, "1862": 14, "1863": 14, "1864": 14, "1865": 14, "1866": 14, "0388": 14, "1867": 14, "1869": 14, "1870": 14, "0387": 14, "1871": 14, "1872": 14, "1873": 14, "0386": 14, "1875": 14, "1876": 14, "1877": 14, "1878": 14, "0385": 14, "1879": 14, "1880": 14, "1882": 14, "0384": 14, "1883": 14, "1884": 14, "1885": 14, "1886": 14, "0383": 14, "1888": 14, "1890": 14, "1891": 14, "0382": [14, 29], "1892": 14, "1893": 14, "0381": 14, "1896": 14, "1897": 14, "1898": 14, "1899": 14, "0380": 14, "1901": 14, "1902": 14, "1903": 14, "0379": 14, "1904": 14, "1905": 14, "1906": 14, "0378": 14, "1908": 14, "1909": 14, "1910": 14, "1911": 14, "1912": 14, "0377": 14, "1913": 14, "1915": 14, "1916": 14, "0376": 14, "1917": 14, "1918": 14, "1919": 14, "1920": 14, "0375": 14, "1922": 14, "1923": 14, "1924": 14, "0374": 14, "1925": 14, "1926": 14, "1928": 14, "1929": 14, "0373": 14, "1930": 14, "1931": 14, "1932": 14, "1933": 14, "0372": 14, "1935": 14, "1936": 14, "1937": 14, "0371": 14, "1938": 14, "1939": 14, "1940": 14, "1942": 14, "0370": 14, "1943": 14, "1944": 14, "1945": 14, "1946": 14, "0369": 14, "1947": 14, "1949": 14, "1950": 14, "0368": 14, "1951": 14, "1952": 14, "1953": 14, "1954": 14, "0367": 14, "1956": 14, "1957": 14, "1959": 14, "0366": 14, "1960": 14, "1961": 14, "1963": 14, "0365": 14, "1964": 14, "1965": 14, "1966": 14, "1967": 14, "1968": 14, "0364": 14, "1970": 14, "1971": 14, "1972": 14, "0363": 14, "1973": 14, "1974": 14, "1975": 14, "1977": 14, "0362": 14, "1978": 14, "1979": 14, "1980": 14, "1981": 14, "0361": 14, "1982": 14, "1984": 14, "1985": 14, "0360": 14, "1986": 14, "1987": 14, "1988": 14, "1989": 14, "1990": 14, "0359": 14, "1992": 14, "1993": 14, "1994": 14, "1995": 14, "1996": 14, "1997": 14, "1999": 14, "0357": 14, "plot": [14, 31], "figur": 14, "dpi": 14, "test_epoch": 14, "isfinit": 14, "linestyl": 14, "marker": 14, "legend": [14, 31], "xlabel": 14, "cites": 15, "3703": 15, "manifold": 15, "tsne": 15, "hnhn_layer_bi": 15, "randomnodesplit": 15, "home": [15, 27, 29], "sadra": 15, "local": [15, 32, 33], "tqdm": [15, 31], "auto": 15, "tqdmwarn": 15, "iprogress": 15, "found": [15, 19], "jupyt": 15, "ipywidget": 15, "readthedoc": 15, "io": 15, "en": 15, "user_instal": 15, "html": 15, "autonotebook": 15, "notebook_tqdm": 15, "offici": 15, "accord": [15, 28], "wget": [15, 19], "com": [15, 19, 21], "twistedcub": 15, "raw": [15, 19], "master": [15, 19], "citeseer6cls3703": 15, "pt": [15, 31], "paper_x": 15, "indic": [15, 22, 23, 24, 26, 29, 31, 32], "longtensor": [15, 19], "paper_author": 15, "train_test_splitt": 15, "num_test": 15, "num_val": 15, "dropout_r": 15, "normalization_param_alpha": 15, "normalization_param_beta": 15, "enumer": [15, 19, 31], "schedul": 15, "initial_lr": 15, "04": [15, 22, 31], "lr_schedul": 15, "steplr": 15, "gamma": 15, "7889": 15, "6347": 15, "6458": 15, "9118": 15, "5491": 15, "7203": 15, "5956": 15, "4068": 15, "4721": 15, "7964": 15, "3431": 15, "5075": 15, "0124": 15, "9682": 15, "2804": 15, "2483": 15, "2004": 15, "2019": 15, "0248": [15, 29], "0219": 15, "0217": 15, "0328": 15, "0180": 15, "0220": 15, "0232": 15, "0241": 15, "0130": 15, "0239": 15, "0240": 15, "0284": 15, "0295": 15, "0163": 15, "0195": 15, "0323": 15, "8441": 15, "worth": 15, "visual": [15, 31], "n_compon": 15, "fit_transform": 15, "ax1": 15, "ax2": 15, "subplot": [15, 31], "suptitl": 15, "set_titl": [15, 31], "_t_sne": 15, "futurewarn": 15, "chang": [15, 22, 29, 31], "pca": 15, "warn": [15, 21, 27], "hypergat": 16, "ding": 16, "t_1": 16, "zy": [16, 17, 23], "m_z": [16, 17], "xz": [16, 17, 23], "rightarrow0": [16, 27], "connect": [16, 19, 23, 26, 31, 32], "As": 16, "j": [16, 17, 22, 27, 29, 31], "highlight": 16, "those": [16, 24], "formal": [16, 24], "alpha_": 16, "jk": 16, "nonlinear": [16, 30], "relu": [16, 20, 31], "trainabl": 16, "coeffici": 16, "frac": [16, 17], "operatornam": 16, "exp": 16, "u_": 16, "limits_": 16, "p": [16, 17, 24], "context": 16, "foral": [16, 24], "again": [16, 24, 25], "vi": [16, 17], "beta_": 16, "ij": 16, "leakyrelu": [16, 24], "anoth": 16, "measur": 16, "hypergat_lay": 16, "hypergatlay": 16, "7875": 16, "9625": 16, "hypersag": 17, "arya": 17, "strategi": 17, "w_y": 17, "w_z": 17, "lvert": 17, "rvert": 17, "interpret": 17, "propag": 17, "problem": [17, 19], "divid": 17, "intra": 17, "neighbor": [17, 30, 31], "inter": [17, 26], "leftarrow": 17, "alpha": [17, 19, 24, 31], "obtain": [17, 19, 24, 26, 30, 31], "hypersage_lay": 17, "hypersagelay": 17, "hypersagemodel": 17, "kwarg": 17, "features_nod": 17, "xavier_uniform": 17, "2431": 17, "templatenn": 18, "6126": 18, "0002": 18, "0001": 18, "cicitationcora": 19, "hgnn": 19, "utlil": 19, "neccessari": 19, "pickl": 19, "scipi": [19, 22, 27, 29, 31], "sp": 19, "unigcnii_lay": 19, "unigcniilay": 19, "directli": 19, "howev": [19, 26, 30], "computation": 19, "expens": [19, 22, 29], "malllabiisc": 19, "hypergcn": 19, "cocit": 19, "07": [19, 22, 31], "ca": 19, "certif": 19, "ssl": 19, "cert": 19, "crt": 19, "resolv": 19, "sent": 19, "await": 19, "respons": 19, "githubusercont": 19, "ok": 19, "404937": 19, "395k": 19, "applic": 19, "octet": 19, "stream": 19, "save": 19, "gt": [19, 31], "45k": 19, "kb": 19, "mb": 19, "101905": 19, "100k": 19, "52k": 19, "02": [19, 22, 31], "5436": 19, "3k": 19, "31k": 19, "51582": 19, "50k": 19, "37k": 19, "rb": 19, "handl": 19, "tmp": [19, 20, 21], "ipykernel_14655": 19, "121206761": 19, "deprecationwarn": 19, "csr_matrix": [19, 22, 29], "namespac": 19, "csr": 19, "deprec": 19, "pytorch": 19, "floattensor": 19, "num": 19, "hyper": [19, 31], "expect": [19, 27, 29], "gcnii": 19, "h2": [19, 29], "hstack": 19, "to_sparse_csr": [19, 21], "2226475299": 19, "support": [19, 24, 26, 30], "beta": [19, 31], "miss": 19, "trigger": 19, "intern": [19, 30], "aten": 19, "src": 19, "sparsecsrtensorimpl": 19, "cpp": 19, "predefin": 19, "train_idx": 19, "test_idx": 19, "unigcniimodel": 19, "num_lay": [19, 26, 30], "num_featur": 19, "num_nod": 19, "num_edg": 19, "copi": [19, 32], "skip": [19, 22, 31, 32, 33], "x_0_skip": 19, "clone": [19, 32], "ommit": 19, "cross": 19, "entropi": 19, "current": [19, 24, 26, 30], "readi": [19, 31], "mode": 19, "7071428298950195": 19, "39291277527809143": 19, "4376946985721588": 19, "9357143044471741": 19, "6137071847915649": 19, "8714285492897034": 19, "45210281014442444": 19, "9071428775787354": 19, "5502336621284485": 19, "9785714149475098": 19, "5463395714759827": 19, "5747663378715515": 19, "9857142567634583": 19, "5673676133155823": 19, "9428571462631226": 19, "552570104598999": 19, "9571428298950195": 19, "5607476830482483": 19, "tudataset": [20, 21], "to_networkx": [20, 21, 24], "simplicial_complex": [20, 21, 31], "simplicialcomplex": [20, 21, 24, 31], "unigin_lay": 20, "uniginlay": 20, "mutag": [20, 21], "root": [20, 21], "use_edge_attr": [20, 21], "x_1_list": [20, 21], "y_list": [20, 21], "unigin_nn": 20, "unigin": 20, "in_channels_nod": 20, "inp_emb": 20, "out_decod": 20, "pooled_x_0": 20, "node_dim": 20, "001": [20, 28], "x_1_val": [20, 21], "incidence_1_v": [20, 21], "y_val": [20, 21], "seper": 20, "unsqueez": [20, 31], "pred": [20, 21, 31], "3916015625": 20, "5625": [20, 21], "91788864135742": 20, "573387145996094": 20, "32501220703125": 20, "29070281982422": 20, "48554229736328": 20, "905006408691406": 20, "502838134765625": 20, "23980712890625": 20, "084415435791016": 20, "003536224365234": 20, "96804428100586": 20, "95846939086914": 20, "9611930847168": 20, "96879196166992": 20, "977806091308594": 20, "98638916015625": 20, "99394989013672": 20, "00029754638672": 20, "00556945800781": 20, "00981521606445": 20, "01326370239258": 20, "01602554321289": 20, "018226623535156": 20, "01999282836914": 20, "0213737487793": 20, "02241897583008": 20, "02317810058594": 20, "023704528808594": 20, "02401351928711": 20, "02414321899414": 20, "024078369140625": 20, "023826599121094": 20, "02338790893555": 20, "02278137207031": 20, "021995544433594": 20, "02100372314453": 20, "019805908203125": 20, "018394470214844": 20, "01671600341797": 20, "0147590637207": 20, "01249313354492": 20, "00986862182617": 20, "0068359375": 20, "003334045410156": 20, "999298095703125": 20, "99464416503906": 20, "98926544189453": 20, "98302459716797": 20, "975791931152344": 20, "unisage_lay": 21, "unisagelay": 21, "filterwarn": 21, "chrsmrr": 21, "graphkerneldataset": 21, "unisagenn": 21, "unisag": 21, "bceloss": 21, "38711929321289": 21, "50642013549805": 21, "88081741333008": 21, "313419342041016": 21, "208885192871094": 21, "00963592529297": 21, "59610366821289": 21, "292537689208984": 21, "19595718383789": 21, "106815338134766": 21, "913330078125": 21, "710723876953125": 21, "6346549987793": 21, "63870620727539": 21, "57096481323242": 21, "44948196411133": 21, "391658782958984": 21, "39373779296875": 21, "34821319580078": 21, "241302490234375": 21, "159812927246094": 21, "131492614746094": 21, "08507537841797": 21, "99526023864746": 21, "924638748168945": 21, "894010543823242": 21, "868173599243164": 21, "829978942871094": 21, "808109283447266": 21, "807811737060547": 21, "785655975341797": 21, "746475219726562": 21, "724843978881836": 21, "700727462768555": 21, "660417556762695": 21, "624387741088867": 21, "606855392456055": 21, "585779190063477": 21, "568805694580078": 21, "556062698364258": 21, "53620147705078": 21, "51841163635254": 21, "507102966308594": 21, "491756439208984": 21, "478620529174805": 21, "475711822509766": 21, "467418670654297": 21, "449710845947266": 21, "429576873779297": 21, "42317771911621": 21, "alexandro": 22, "kero": 22, "_x": [22, 24, 27], "dist2cycle_lay": 22, "dist2cyclelay": 22, "linalg": [22, 24], "npla": 22, "a0": [22, 23], "sinc": [22, 23, 26, 29, 31], "becaus": [22, 23, 25, 26, 30], "serv": [22, 23], "simpli": [22, 23, 31], "demonstr": [22, 23], "similarli": [22, 23, 29], "emerg": [22, 23, 24, 26, 29], "part": [22, 23, 24, 26, 29], "four": [22, 23, 24, 26, 29], "y_true": [22, 23, 24, 26, 30], "ld": [22, 24], "l_tilde_pinv": 22, "pinv": 22, "invers": 22, "linv": 22, "x_1e": 22, "0971": 22, "0937": 22, "2140": 22, "2069": 22, "2927": 22, "3018": 22, "2309": 22, "0992": 22, "0943": 22, "0927": 22, "2678": [22, 29], "3090": 22, "0960": 22, "2077": 22, "2056": 22, "2813": 22, "nnz": 22, "layout": 22, "sparse_coo": 22, "56771909e": 22, "49643084e": 22, "13434650e": 22, "60154799e": 22, "03": [22, 31], "73820292e": 22, "65885226e": 22, "04038181e": 22, "08": [22, 31], "51925802e": 22, "09": [22, 31], "73643677e": 22, "95577741e": 22, "09312067e": 22, "39698386e": 22, "11006736e": 22, "25540316e": 22, "87149896e": 22, "65674657e": 22, "43987098e": 22, "79396772e": 22, "00662204e": 22, "45058060e": 22, "36910174e": 22, "82942520e": 22, "24798042e": 22, "85055751e": 22, "78386103e": 22, "24821486e": 22, "81510593e": 22, "07917011e": 22, "30485535e": 22, "19925834e": 22, "56662779e": 22, "25658545e": 22, "29514395e": 22, "73054542e": 22, "57650283e": 22, "87089108e": 22, "31973699e": 22, "45874534e": 22, "78385898e": 22, "24821523e": 22, "38282800e": 22, "29527006e": 22, "24821542e": 22, "45585343e": 22, "20149602e": 22, "39614227e": 22, "52603984e": 22, "02427802e": 22, "38569428e": 22, "20058507e": 22, "89658767e": 22, "67997003e": 22, "90682733e": 22, "88636552e": 22, "61071175e": 22, "75768661e": 22, "22418800e": 22, "07488209e": 22, "26928225e": 22, "52925774e": 22, "50903371e": 22, "71863856e": 22, "40345353e": 22, "36909867e": 22, "82943824e": 22, "90223058e": 22, "08467136e": 22, "43380561e": 22, "27135092e": 22, "31898531e": 22, "01219751e": 22, "78963115e": 22, "97890193e": 22, "49229891e": 22, "67953214e": 22, "75078206e": 22, "75904313e": 22, "03583546e": 22, "12457962e": 22, "10897127e": 22, "18870673e": 22, "28672193e": 22, "61245163e": 22, "48166016e": 22, "75217551e": 22, "67996958e": 22, "90682673e": 22, "44834775e": 22, "90006804e": 22, "59747154e": 22, "69860917e": 22, "59747209e": 22, "69862127e": 22, "59747284e": 22, "69861429e": 22, "59747191e": 22, "59747247e": 22, "69860823e": 22, "59747135e": 22, "11979373e": 22, "90869734e": 22, "59747228e": 22, "69860637e": 22, "59747303e": 22, "69861010e": 22, "59747116e": 22, "17587730e": 22, "43268425e": 22, "43105909e": 22, "32787512e": 22, "03376685e": 22, "44168448e": 22, "62169540e": 22, "41996737e": 22, "73246880e": 22, "97727704e": 22, "03496753e": 22, "71378374e": 22, "92902595e": 22, "15740368e": 22, "94057676e": 22, "48602486e": 22, "40909785e": 22, "14646482e": 22, "38315065e": 22, "76777497e": 22, "38311899e": 22, "76780128e": 22, "37373477e": 22, "49392605e": 22, "30545244e": 22, "10224779e": 22, "69429579e": 22, "59057510e": 22, "11831834e": 22, "86165255e": 22, "07662510e": 22, "53556532e": 22, "82225195e": 22, "76254632e": 22, "62731223e": 22, "63466549e": 22, "16528196e": 22, "62805045e": 22, "36022410e": 22, "48832843e": 22, "19494419e": 22, "13972221e": 22, "zia003": 22, "topox2": 22, "_index": [22, 29], "sparseefficiencywarn": [22, 29], "sparsiti": [22, 29], "lil_matrix": [22, 29], "effici": [22, 29], "_set_arrayxarrai": [22, 29], "produc": [22, 23, 24, 29, 30, 32], "compar": [22, 23, 24, 29, 30, 32], "high": [22, 32, 33], "binary_cross_entropy_with_logit": [22, 23, 24, 29, 30, 32], "y_hat_test": [22, 23, 24, 26, 29, 30, 32], "y_pred_test": [22, 23, 24, 26, 29, 30, 32], "test_accuraci": [22, 23, 24, 26, 29, 30, 32], "eq": [22, 23, 24, 26, 30, 32], "7231": 22, "6000": 22, "6989": 22, "5667": [22, 23, 26, 29, 30], "2500": [22, 24, 26, 29], "6737": 22, "6564": 22, "6434": 22, "6362": 22, "6290": 22, "4333": [22, 24], "6199": 22, "6117": 22, "6057": 22, "6011": 22, "5964": 22, "5911": 22, "5855": 22, "5764": 22, "4000": [22, 26], "5730": 22, "5696": 22, "5660": 22, "5624": 22, "5593": 22, "5567": 22, "5544": 22, "5520": 22, "5496": 22, "5472": 22, "5451": 22, "5432": 22, "5414": 22, "5346": 22, "5333": 22, "5320": 22, "5308": 22, "5295": 22, "5284": 22, "5273": 22, "5264": 22, "5255": 22, "5238": 22, "5230": 22, "5223": 22, "5216": 22, "5210": 22, "5204": 22, "5198": 22, "5193": 22, "5183": 22, "5178": 22, "5174": 22, "5170": 22, "5166": 22, "5163": 22, "5159": 22, "5156": 22, "_y": [23, 29, 32], "7216": 23, "7169": 23, "7151": 23, "7109": 23, "didact": 24, "clear": 24, "technic": 24, "work": 24, "novel": 24, "hing": 24, "proper": [24, 32], "abl": [24, 32], "triangl": [24, 26, 31], "lower": [24, 25, 26, 29, 30, 31, 32], "total": 24, "orient": 24, "fashion": 24, "remark": 24, "custom": 24, "symbol": 24, "involv": 24, "n_1": 24, "n_2": 24, "2p": 24, "q_r": 24, "kernel": 24, "hodg": [24, 26, 29], "l_r": 24, "phi": 24, "bigg": [24, 26, 30], "bigotimes_": 24, "bigoplus_": 24, "widetild": 24, "hy": 24, "alpha_k": 24, "neq": [24, 31], "affin": 24, "entri": [24, 26], "therefor": 24, "hop": [24, 30], "align": [24, 30], "textrm": 24, "a_k": [24, 31], "psi_k": 24, "n_k": 24, "gat": 24, "suppos": 24, "_j": 24, "underset": 24, "w_": 24, "q_": 24, "san_lay": 24, "sanlay": 24, "consid": [24, 26, 30], "tb_1": 24, "b_2b_2": 24, "notic": 24, "non": [24, 31], "pattern": 24, "simplic": [24, 26, 29, 30, 31], "just": [24, 29, 31], "maxium": 24, "simplex_order_k": 24, "ldown": 24, "valueerror": [24, 26, 30], "lup": 24, "gradient": 24, "tx_0": 24, "estim": 24, "multipli": 24, "diverg": 24, "deriv": 24, "could": [24, 29], "seen": 24, "incidence_0_1": 24, "plu": 24, "onto": 24, "accordingli": 24, "mm": 24, "henc": 24, "num_filters_j": 24, "approxim": [24, 31], "filter": [24, 26], "j_har": 24, "harmon": 24, "epsilon_har": 24, "compute_projection_matrix": 24, "matrix_pow": 24, "channels_in": 24, "y_hat_edg": 24, "fn": 24, "y_hat_edge_test": 24, "_pred_test": 24, "ge": 24, "7240": 24, "7114": 24, "7333": [24, 29], "6760": 24, "6721": 24, "6685": 24, "6677": 24, "6672": 24, "qquad": 25, "agg": 25, "sca_cmps_lay": 25, "scacmpslay": 25, "sc": [25, 26, 30, 31], "down_lap1_list": 25, "down_lap2_list": 25, "incidence1_t_list": 25, "incidence2_t_list": 25, "down_lap1": [25, 32], "down_lap2": 25, "incidence_1t": 25, "incidence_2t": 25, "channels_list": 25, "complex_dim": 25, "ampssca": 25, "tetahedron": 25, "complex_dimens": 25, "highest": [25, 31], "embed": 25, "lin0": 25, "lin1": 25, "lin2": 25, "aggr": [25, 27], "aggr_func": [25, 27], "update_func": [25, 26, 27, 29, 30, 31], "x_list": 25, "down_lap_list": 25, "incidencet_list": 25, "x_2f": 25, "flatten": [25, 27], "x_1f": 25, "x_0f": 25, "down_lap1_train": 25, "down_lap1_test": 25, "down_lap2_train": 25, "down_lap2_test": 25, "incidence1_t_train": 25, "incidence1_t_test": 25, "incidence2_t_train": 25, "incidence2_t_test": 25, "hzpmc22": 25, "wa": [25, 30], "did": 25, "incidence_t_list": 25, "correct_count": [25, 27], "round": [25, 27], "15074526998214": 25, "42108154296875": 25, "16418675570749": 25, "73768615722656": 25, "16661446671351": 25, "76749420166016": 25, "8968961050734": 25, "735595703125": 25, "84987897076644": 25, "7345199584961": 25, "18321903655306": 25, "809326171875": 25, "scnn": [26, 33], "account": 26, "At": [26, 30], "mathbf": [26, 30], "_t": [26, 30], "p_d": [26, 30], "p_u": [26, 30], "likewis": 26, "essenti": 26, "sccnn_layer": 26, "sccnnlayer": 26, "in_channels_al": 26, "_1": [26, 27, 30], "_2": [26, 27], "_0": 26, "yet": [26, 30], "max_rank": [26, 29, 30], "laplacian_0_list": [26, 30], "laplacian_down_1_list": [26, 30], "laplacian_up_1_list": [26, 30], "laplacian_2_list": [26, 30], "laplacian_0": [26, 30], "hodge_laplacian_matrix": [26, 30], "laplacian_down_1": [26, 30], "laplacian_up_1": [26, 30], "laplacian_2": [26, 30], "amend": 26, "readout": 26, "intermediate_channels_al": 26, "intermedi": [26, 30], "out_channels_al": 26, "conv_ord": 26, "sc_order": 26, "numer": [26, 30], "aggr_norm": [26, 30], "in_linear_0": 26, "in_linear_1": 26, "in_linear_2": 26, "out_channels_0": 26, "out_channels_1": 26, "out_channels_2": 26, "out_linear_0": 26, "out_linear_1": 26, "out_linear_2": 26, "x_all": 26, "laplacian_al": 26, "incidence_al": 26, "n_simplic": [26, 30], "l0": 26, "l1_d": 26, "l1_u": 26, "l2": 26, "pf": 26, "b2": [26, 27, 29, 30], "in_x_0": 26, "in_x_1": 26, "in_x_2": 26, "size_averag": 26, "out_featur": [26, 30], "bia": [26, 30], "laplacian_0_train": 26, "laplacian_0_test": 26, "laplacian_down_1_train": 26, "laplacian_down_1_test": 26, "laplacian_up_1_train": 26, "laplacian_up_1_test": 26, "laplacian_2_train": 26, "laplacian_2_test": 26, "288238": 26, "2517": 26, "7562": 26, "7251": 26, "7232": 26, "9496": 26, "2592": 26, "7179": 26, "8378": 26, "7978": 26, "laplacian_down_2": [26, 30], "laplacian_up_2": [26, 30], "coadjacency_matrix": [26, 29], "get_simplicial_featur": [26, 30], "which_feat": [26, 30], "elif": [26, 30], "binary_cross_entropi": 26, "0333": 26, "6766": 26, "3667": 26, "6162": 26, "6333": 26, "bunch": 27, "tild": 27, "rightarrow1": 27, "coo_matrix": 27, "diag": 27, "scconv_lay": 27, "scconvlay": 27, "return_count": 27, "0th": 27, "normalize_higher_order_adj": 27, "a_opt": 27, "arg": 27, "cochain": 27, "num_of_k_simplic": 27, "num_of_j_simplic": 27, "rowsum": 27, "ab": 27, "r_inv_sqrt": 27, "power": 27, "isinf": 27, "r_mat_inv_sqrt": 27, "a_opt_to": 27, "dot": 27, "neigborood": 27, "ssconv": 27, "incidence_1_norm": 27, "incidence_2_norm": 27, "adjacency_up_0_norm": 27, "adjacency_up_1_norm": 27, "adjacency_down_1_norm": 27, "adjacency_down_2_norm": 27, "get_neighborhood": 27, "incidence_1_norm_list": 27, "incidence_2_norm_list": 27, "adjacency_up_0_norm_list": 27, "adjacency_up_1_norm_list": 27, "adjacency_down_1_norm_list": 27, "adjacency_down_2_norm_list": 27, "up_laplacian_1_list": 27, "up_laplacian_2_list": 27, "down_laplacian_1_list": 27, "down_laplacian_2_list": 27, "up_laplacian_1": 27, "up_laplacian_2": 27, "down_laplacian_1": 27, "down_laplacian_2": 27, "edge_channel": [27, 32], "face_channel": 27, "linear_x0": 27, "linear_x1": 27, "linear_x2": 27, "node_mean": 27, "edge_mean": 27, "face_mean": 27, "todo": 27, "kha053": 27, "nvml": 27, "incid1": 27, "incid1_norm": 27, "incid2": 27, "incid2_norm": 27, "adj0_up_norm": 27, "adj1_up_norm": 27, "adj1_down_norm": 27, "adj2_down_norm": 27, "x_0t": 27, "x_1t": 27, "x_2t": 27, "incid1t": 27, "incid1_normt": 27, "incid2t": 27, "incid2_normt": 27, "adj0_up_normt": 27, "adj1_up_normt": 27, "adj1_down_normt": 27, "adj2_down_normt": 27, "yt": 27, "scn2_layer": 28, "scn2layer": 28, "chose": 28, "reshap": 28, "a_0": 28, "a_1": [28, 31], "a_2": [28, 31], "normalized_laplacian_matrix": 28, "scn2": 28, "x_0s_train": 28, "x_0s_test": 28, "x_1s_train": 28, "x_1s_test": 28, "x_2s_train": 28, "x_2s_test": 28, "a_0s_train": 28, "a_0s_test": 28, "a_1s_train": 28, "a_1s_test": 28, "a_2s_train": 28, "a_2s_test": 28, "6313": 28, "5828": 28, "7222": 28, "5361": 28, "4920": 28, "4495": 28, "4081": 28, "4065": 28, "3676": 28, "3283": 28, "2507": 28, "la": 29, "r_": 29, "mathrm": 29, "leq": [29, 31], "bigcup": 29, "scn_layer": 29, "scnlayer": 29, "feat_dim": 29, "arbitrari": 29, "maximum": [29, 31], "choos": [29, 31], "dictionari": 29, "tha": 29, "arbitrarili": 29, "formul": 29, "quit": 29, "close": 29, "h_r": 29, "2i": 29, "themselv": 29, "usual": 29, "suggest": [29, 33], "refrain": 29, "tetrahedron": 29, "sparse_to_torch": 29, "rank_": 29, "rank_0": 29, "h0": 29, "h1": 29, "h3": 29, "b3": 29, "program": 29, "recent": 29, "x_3": 29, "tetrahedron_feat": 29, "track": 29, "rank_1": 29, "rank_2": 29, "rank_3": 29, "dict": 29, "n_rank_r_cel": 29, "n_rank_r_minus_1_cel": 29, "via": [29, 30], "squeez": [29, 31], "typic": 29, "6779": 29, "7667": 29, "6076": 29, "5566": 29, "5347": 29, "5144": 29, "4904": 29, "4728": 29, "4449": 29, "8000": 29, "3994": 29, "8333": 29, "4043": 29, "3834": 29, "3222": 29, "3318": 29, "9000": 29, "2878": 29, "2527": 29, "2272": 29, "2147": 29, "9667": 29, "9333": 29, "0336": 29, "0182": 29, "0147": 29, "0132": 29, "0121": 29, "0114": 29, "0106": 29, "0093": 29, "0080": 29, "0070": 29, "0062": 29, "0057": 29, "0056": 29, "0053": 29, "0047": 29, "0040": 29, "0033": 29, "0029": 29, "0027": 29, "0026": 29, "0025": 29, "0023": 29, "0022": 29, "0021": 29, "0020": 29, "0019": 29, "0018": 29, "0017": 29, "0016": 29, "0015": 29, "0014": 29, "0013": 29, "0012": 29, "0011": 29, "0010": 29, "0009": 29, "0008": 29, "0007": 29, "0006": 29, "0005": 29, "0004": 29, "definit": 30, "itself": 30, "scnn_layer": 30, "scnnlayer": 30, "simplci": 30, "challeng": 30, "conv_order_down": 30, "conv_order_up": 30, "inter_channel": 30, "laplacian_down": 30, "laplacian_up": 30, "larger": 30, "x_train": 30, "x_test": 30, "laplacian_down_train": 30, "laplacian_down_test": 30, "laplacian_up_train": 30, "laplacian_up_test": 30, "simplex_order_select": 30, "8446": 30, "4423": 30, "6270": 30, "9483": 30, "9201": 30, "3076": 30, "6582": 30, "2524": 30, "maxim": 30, "chennel_edg": 30, "channel_fac": 30, "certain": 30, "classm": 30, "rm": 30, "mitchel": 30, "nichola": 30, "glaze": 30, "santiago": 30, "segarra": 30, "principl": [30, 31], "trajectori": 30, "confer": 30, "channels_x": 30, "7199": 30, "7196": 30, "7194": [30, 32], "7192": 30, "7190": 30, "rgs21": 31, "spend": 31, "synthet": 31, "ahead": 31, "itertool": 31, "product": 31, "tnx": 31, "networkx": 31, "nx": 31, "random_split": 31, "spatial": 31, "delaunai": 31, "distanc": 31, "scone_lay": 31, "sconelay": [31, 32], "seed": 31, "lt": 31, "_c": 31, "0x15d64d0b0": 31, "less": 31, "uniformli": 31, "point": 31, "triangul": 31, "cloud": 31, "disk": 31, "insid": 31, "remov": 31, "centroid": 31, "generate_complex": 31, "delet": 31, "uniform": 31, "sort": 31, "coordin": 31, "argsort": 31, "tri": 31, "disk_cent": 31, "disk_radiu": 31, "indices_includ": 31, "cdist": 31, "vertic": 31, "idx_dict": 31, "coord": 31, "instanc": 31, "euclidean": 31, "shortest": 31, "path": 31, "plot_complex": 31, "plane": 31, "idx": 31, "skeleton": 31, "poli": 31, "polygon": 31, "color": 31, "green": 31, "gca": 31, "add_patch": 31, "vstack": 31, "i_1": 31, "i_2": 31, "ldot": 31, "i_m": 31, "i_j": 31, "i_": 31, "neighbour": 31, "ground": 31, "truth": 31, "supervis": 31, "setup": 31, "subsect": 31, "randomli": 31, "pick": 31, "triplet": 31, "corner": 31, "around": 31, "middl": 31, "anti": 31, "diagon": 31, "n_max": 31, "determin": 31, "generate_trajectori": 31, "mid": 31, "region": 31, "start_nod": 31, "mid_nod": 31, "end_nod": 31, "all_triplet": 31, "increas": 31, "underli": 31, "distance_matrix": 31, "squareform": 31, "pdist": 31, "toarrai": 31, "from_numpy_arrai": 31, "path_1": 31, "shortest_path": 31, "path_2": 31, "plot_path": 31, "red": 31, "arrow": 31, "quiver": 31, "scale_unit": 31, "angl": [31, 32], "scale": 31, "yield": 31, "vectorized_trajectori": 31, "neigbors_mask": 31, "last_nod": 31, "turn": 31, "a_j": 31, "i_n": 31, "later": [31, 32], "trajectoriesdataset": 31, "lookup": 31, "speed": 31, "edge_lookup_t": 31, "__getitem__": 31, "vectorize_path": 31, "discard": 31, "neighbors_mask": 31, "__len__": 31, "c0": 31, "batch": 31, "loader": 31, "batch_siz": 31, "val_siz": 31, "train_siz": 31, "train_d": 31, "val_d": 31, "test_d": 31, "train_dl": 31, "val_dl": 31, "test_dl": 31, "c_1": 31, "chain": 31, "partial_1": 31, "c_0": 31, "That": 31, "score": 31, "hat": 31, "_m": 31, "hidden_dim": 31, "init": 31, "xavier_uniform_": 31, "hidden_dimens": 31, "reset_paramet": 31, "inf": 31, "log_softmax": 31, "neg": 31, "likelihood": 31, "penal": 31, "weight_decai": 31, "5e": 31, "loss_funct": 31, "nllloss": 31, "nll": 31, "training_histori": 31, "training_loss": 31, "traj": 31, "06": 31, "quick": 31, "confirm": 31, "everyth": 31, "reason": 31, "ax": 31, "ncol": 31, "figsiz": 31, "better": 31, "guess": 31, "3f": 31, "constructor": 31, "affect": 31, "capabl": 31, "revers": 31, "Or": 31, "real": 31, "world": 31, "ocean": 31, "drifter": 31, "scone_layer_bi": 32, "pyt": 32, "area": 32, "up_lap1": 32, "gather": 32, "pair": 32, "train_indic": 32, "test_indic": 32, "sconenn": 32, "iden": 32, "OF": 32, "7211": 32, "7185": 32, "5484": 32, "7205": 32, "7210": 32, "ajbr": 32, "appdata": 32, "temp": 32, "ipykernel_492": 32, "1152818844": 32, "recommend": 32, "sourcetensor": 32, "detach": 32, "requires_grad_": 32, "ccxn": 33, "unigcnii": 33, "homologi": 33, "dist2cycl": 33, "coadjac": 33, "cmp": 33, "sccnn": 33, "scconv": 33, "neighbourhood": 33, "scn": 33, "compl": 33, "content": 33, "experiment": 33, "prepar": 33}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"base": 0, "api": 1, "refer": [1, 6], "packag": 1, "modul": 1, "neural": [2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "network": [2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "hypergraph": [2, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "simplici": [2, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "complex": [2, 8, 25, 26, 27, 31, 32], "cell": [2, 8], "util": 3, "scatter": 3, "icml": 4, "2023": 4, "topolog": 4, "deep": 4, "learn": 4, "challeng": 4, "descript": 4, "public": 4, "outcom": 4, "particip": 4, "deadlin": 4, "how": 4, "submit": 4, "guidelin": 4, "submiss": 4, "requir": 4, "evalu": [4, 31], "question": 4, "contribut": 5, "make": 5, "chang": 5, "write": 5, "test": [5, 25, 27, 30, 31, 32], "run": 5, "document": 5, "intro": 5, "docstr": 5, "The": [5, 7, 8, 9, 24], "anatomi": 5, "exampl": 5, "topomodelx": 6, "tmx": 6, "get": 6, "start": 6, "train": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "cellular": 7, "attent": [7, 8, 24], "can": 7, "task": [7, 8, 9, 24], "set": [7, 8, 9], "up": [7, 8, 9], "pre": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "process": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "creat": [7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "convolut": [8, 26, 27, 28, 29, 30], "ccxn": 8, "cw": 9, "cwn": 9, "addit": [10, 11, 17], "theoret": [10, 11, 17], "clarif": [10, 11, 17], "defin": [11, 12, 14, 16, 17, 18, 22, 23, 26, 27, 28, 29, 30, 32], "import": [12, 14, 16, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 32], "data": [12, 16, 18, 19, 20, 21, 25, 27, 31], "neighborhood": [12, 14, 16, 18, 22, 23, 26, 28, 29, 30, 32], "structur": [12, 14, 16, 18, 22, 23, 27, 28, 29, 32], "lift": [12, 16, 18], "domain": [12, 16, 18], "messag": [13, 25], "pass": [13, 25], "hmpnn": 13, "hyperedg": [14, 15], "neuron": [14, 15], "hnhn": [14, 15], "dataset": [14, 22, 23, 26, 27, 28, 29, 30, 31, 32], "signal": [14, 22, 23, 26, 29, 30], "us": 19, "unigcnii": 19, "layer": 19, "load": 19, "homologi": 22, "local": 22, "dist2cycl": 22, "binari": [22, 23, 26, 29, 30], "label": [22, 23, 26, 29, 30, 32], "featur": 22, "high": 23, "skip": 23, "hsn": 23, "san": 24, "abstract": 24, "autoencod": 25, "sca": 25, "coadjac": 25, "scheme": 25, "cmp": 25, "prepar": [25, 27, 30, 32], "input": [25, 32], "each": 25, "split": [25, 30, 32], "model": [25, 26, 30, 31], "sccnn": 26, "we": [26, 30], "perform": [26, 30], "1": [26, 30], "classif": [26, 30], "shrec": 26, "strcture": [26, 30], "2": [26, 27, 28, 30], "node": [26, 30], "scconv": 27, "helper": 27, "function": 27, "neighbourhood": 27, "scn": [28, 29], "rank": 28, "scnn": 30, "compl": 30, "karat": 30, "weight": 30, "hodg": 30, "laplacian": 30, "net": 31, "scone": [31, 32], "tabl": 31, "content": 31, "gener": 31, "trajectori": 31, "pytorch": 31, "dataload": 31, "suggest": 31, "further": 31, "experiment": 31, "tutori": 33}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.viewcode": 1, "sphinx": 60}, "alltitles": {"Base": [[0, "base"]], "API Reference": [[1, "api-reference"]], "Packages & Modules": [[1, null]], "Neural Networks": [[2, "neural-networks"]], "Hypergraph Neural Networks": [[2, "hypergraph-neural-networks"]], "Simplicial Complex Neural Networks": [[2, "simplicial-complex-neural-networks"]], "Cell Complex Neural Networks": [[2, "cell-complex-neural-networks"]], "Utils": [[3, "utils"]], "Scatter": [[3, "scatter"]], "ICML 2023 Topological Deep Learning Challenge": [[4, "icml-2023-topological-deep-learning-challenge"]], "Description of the Challenge": [[4, "description-of-the-challenge"]], "\u2b50\ufe0f Publication Outcomes for Participants \u2b50\ufe0f": [[4, "publication-outcomes-for-participants"]], "Deadline": [[4, "deadline"]], "How to Submit": [[4, "how-to-submit"]], "Guidelines": [[4, "guidelines"]], "Submission Requirements": [[4, "submission-requirements"]], "Evaluation": [[4, "evaluation"]], "Questions": [[4, "questions"]], "Contributing": [[5, "contributing"]], "Making Changes": [[5, "making-changes"]], "Write Tests": [[5, "write-tests"]], "Run Tests": [[5, "run-tests"]], "Write Documentation": [[5, "write-documentation"]], "Intro to Docstrings": [[5, "intro-to-docstrings"]], "The Anatomy of a Docstring": [[5, "the-anatomy-of-a-docstring"]], "Docstring Examples": [[5, "docstring-examples"]], "\ud83c\udf10 TopoModelX (TMX) \ud83c\udf69": [[6, "topomodelx-tmx"]], "\ud83d\udd0d References": [[6, "references"]], "\ud83e\uddbe Getting Started": [[6, "getting-started"]], "Train a Cellular Attention Network (CAN)": [[7, "Train-a-Cellular-Attention-Network-(CAN)"]], "The Neural Network:": [[7, "The-Neural-Network:"], [8, "The-Neural-Network:"], [9, "The-Neural-Network:"]], "The Task:": [[7, "The-Task:"], [8, "The-Task:"], [9, "The-Task:"], [24, "The-Task:"]], "Set-up": [[7, "Set-up"], [8, "Set-up"], [9, "Set-up"]], "Pre-processing": [[7, "Pre-processing"], [8, "Pre-processing"], [9, "Pre-processing"], [10, "Pre-processing"], [11, "Pre-processing"], [12, "Pre-processing"], [13, "Pre-processing"], [14, "Pre-processing"], [15, "Pre-processing"], [16, "Pre-processing"], [17, "Pre-processing"], [18, "Pre-processing"], [20, "Pre-processing"], [21, "Pre-processing"], [22, "Pre-processing"], [23, "Pre-processing"], [24, "Pre-processing"], [25, "Pre-processing"], [26, "Pre-processing"], [27, "Pre-processing"], [28, "Pre-processing"], [29, "Pre-processing"], [30, "Pre-processing"], [32, "Pre-processing"]], "Create the Neural Network": [[7, "Create-the-Neural-Network"], [8, "Create-the-Neural-Network"], [9, "Create-the-Neural-Network"], [10, "Create-the-Neural-Network"], [12, "Create-the-Neural-Network"], [13, "Create-the-Neural-Network"], [14, "Create-the-Neural-Network"], [15, "Create-the-Neural-Network"], [18, "Create-the-Neural-Network"], [20, "Create-the-Neural-Network"], [21, "Create-the-Neural-Network"], [22, "Create-the-Neural-Network"], [23, "Create-the-Neural-Network"], [24, "Create-the-Neural-Network"], [27, "Create-the-Neural-Network"], [28, "Create-the-Neural-Network"], [29, "Create-the-Neural-Network"]], "Train the Neural Network": [[7, "Train-the-Neural-Network"], [8, "Train-the-Neural-Network"], [9, "Train-the-Neural-Network"], [10, "Train-the-Neural-Network"], [11, "Train-the-Neural-Network"], [12, "Train-the-Neural-Network"], [13, "Train-the-Neural-Network"], [14, "Train-the-Neural-Network"], [15, "Train-the-Neural-Network"], [16, "Train-the-Neural-Network"], [17, "Train-the-Neural-Network"], [18, "Train-the-Neural-Network"], [20, "Train-the-Neural-Network"], [21, "Train-the-Neural-Network"], [22, "Train-the-Neural-Network"], [23, "Train-the-Neural-Network"], [24, "Train-the-Neural-Network"], [26, "Train-the-Neural-Network"], [26, "id3"], [27, "Train-the-Neural-Network"], [28, "Train-the-Neural-Network"], [29, "Train-the-Neural-Network"], [30, "Train-the-Neural-Network"]], "Train the Neural Network with Attention": [[7, "Train-the-Neural-Network-with-Attention"], [8, "Train-the-Neural-Network-with-Attention"]], "Train a Convolutional Cell Complex Network (CCXN)": [[8, "Train-a-Convolutional-Cell-Complex-Network-(CCXN)"]], "Train a CW Network (CWN)": [[9, "Train-a-CW-Network-(CWN)"]], "Train a Hypergraph Neural Network": [[10, "Train-a-Hypergraph-Neural-Network"], [11, "Train-a-Hypergraph-Neural-Network"], [12, "Train-a-Hypergraph-Neural-Network"], [16, "Train-a-Hypergraph-Neural-Network"], [17, "Train-a-Hypergraph-Neural-Network"], [18, "Train-a-Hypergraph-Neural-Network"]], "Additional theoretical clarifications": [[10, "Additional-theoretical-clarifications"], [11, "Additional-theoretical-clarifications"], [17, "Additional-theoretical-clarifications"]], "Define the Neural Network": [[11, "Define-the-Neural-Network"], [16, "Define-the-Neural-Network"], [17, "Define-the-Neural-Network"]], "Import data": [[12, "Import-data"], [16, "Import-data"], [18, "Import-data"], [20, "Import-data"], [21, "Import-data"], [25, "Import-data"]], "Define neighborhood structures and lift into hypergraph domain.": [[12, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."], [16, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."], [18, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."]], "Train a Hypergraph Message Passing Neural Network (HMPNN)": [[13, "Train-a-Hypergraph-Message-Passing-Neural-Network-(HMPNN)"]], "Train a Hypergraph Networks with Hyperedge Neurons (HNHN)": [[14, "Train-a-Hypergraph-Networks-with-Hyperedge-Neurons-(HNHN)"]], "Import dataset": [[14, "Import-dataset"], [22, "Import-dataset"], [23, "Import-dataset"], [27, "Import-dataset"], [28, "Import-dataset"], [29, "Import-dataset"], [32, "Import-dataset"]], "Define neighborhood structures.": [[14, "Define-neighborhood-structures."], [22, "Define-neighborhood-structures."], [23, "Define-neighborhood-structures."], [28, "Define-neighborhood-structures."], [29, "Define-neighborhood-structures."]], "Import signal": [[14, "Import-signal"], [22, "Import-signal"], [23, "Import-signal"], [26, "Import-signal"], [29, "Import-signal"]], "Train a Hypergraph Network with Hyperedge Neurons (HNHN)": [[15, "Train-a-Hypergraph-Network-with-Hyperedge-Neurons-(HNHN)"]], "Train a hypergraph neural network using UniGCNII layers": [[19, "Train-a-hypergraph-neural-network-using-UniGCNII-layers"]], "Loading the data": [[19, "Loading-the-data"]], "Creating a neural network": [[19, "Creating-a-neural-network"]], "Training the neural network": [[19, "Training-the-neural-network"]], "Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)": [[22, "Train-a-Simplicial-Neural-Network-for-Homology-Localization-(Dist2Cycle)"]], "Define binary labels": [[22, "Define-binary-labels"], [23, "Define-binary-labels"], [26, "Define-binary-labels"], [29, "Define-binary-labels"]], "Create Features": [[22, "Create-Features"]], "Train a Simplicial High-Skip Network (HSN)": [[23, "Train-a-Simplicial-High-Skip-Network-(HSN)"]], "Train a Simplicial Attention Network (SAN)": [[24, "Train-a-Simplicial-Attention-Network-(SAN)"]], "Abstract": [[24, "Abstract"]], "The Neural Network": [[24, "The-Neural-Network"]], "Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)": [[25, "Train-a-Simplicial-Complex-Autoencoder-(SCA)-with-Coadjacency-Message-Passing-Scheme-(CMPS)"]], "Preparing the inputs to test each message passing scheme:": [[25, "Preparing-the-inputs-to-test-each-message-passing-scheme:"]], "Coadjacency Message Passing Scheme (CMPS):": [[25, "Coadjacency-Message-Passing-Scheme-(CMPS):"]], "Create the Neural Networks": [[25, "Create-the-Neural-Networks"]], "Train and Test Split": [[25, "Train-and-Test-Split"]], "Training and Testing Model": [[25, "Training-and-Testing-Model"]], "Train a SCCNN": [[26, "Train-a-SCCNN"]], "We train the model to perform:": [[26, "We-train-the-model-to-perform:"], [30, "We-train-the-model-to-perform:"]], "Simplicial Complex Convolutional Neural Networks [SCCNN]": [[26, "Simplicial-Complex-Convolutional-Neural-Networks-[SCCNN]"]], "1. Complex Classification": [[26, "1.-Complex-Classification"]], "Import shrec dataset": [[26, "Import-shrec-dataset"]], "Define Neighborhood Strctures": [[26, "Define-Neighborhood-Strctures"], [26, "id1"], [30, "Define-Neighborhood-Strctures"], [30, "id1"]], "Create the SCCNN": [[26, "Create-the-SCCNN"], [26, "id2"]], "2. Node Classification": [[26, "2.-Node-Classification"], [30, "2.-Node-Classification"]], "Train a Simplicial 2-complex convolutional neural network (SCConv)": [[27, "Train-a-Simplicial-2-complex-convolutional-neural-network-(SCConv)"]], "Helper functions": [[27, "Helper-functions"]], "Define Neighbourhood Structures": [[27, "Define-Neighbourhood-Structures"]], "prepare training and test data": [[27, "prepare-training-and-test-data"]], "Train a Simplicial Convolutional Network (SCN) of Rank 2": [[28, "Train-a-Simplicial-Convolutional-Network-(SCN)-of-Rank-2"]], "Train a Simplicial Convolutional Network (SCN)": [[29, "Train-a-Simplicial-Convolutional-Network-(SCN)"]], "Train a Simplicial Convolutional Neural Network (SCNN)": [[30, "Train-a-Simplicial-Convolutional-Neural-Network-(SCNN)"]], "Simplicial Convolutional Neural Networks [SCNN]": [[30, "Simplicial-Convolutional-Neural-Networks-[SCNN]"]], "1. Comples Classification": [[30, "1.-Comples-Classification"]], "Create the SCNN": [[30, "Create-the-SCNN"]], "Import Karate dataset": [[30, "Import-Karate-dataset"]], "Weighted Hodge Laplacians": [[30, "Weighted-Hodge-Laplacians"]], "Import signals": [[30, "Import-signals"]], "Define binary labels and Prepare the training-testing split": [[30, "Define-binary-labels-and-Prepare-the-training-testing-split"]], "Create the SCNN for node classification": [[30, "Create-the-SCNN-for-node-classification"]], "Train the SCNN": [[30, "Train-the-SCNN"]], "Train a Simplicial Complex Net (SCoNe)": [[31, "Train-a-Simplicial-Complex-Net-(SCoNe)"]], "Table of contents": [[31, "Table-of-contents"]], "Dataset generation": [[31, "Dataset-generation"]], "Generating trajectories": [[31, "Generating-trajectories"]], "Creating PyTorch dataloaders": [[31, "Creating-PyTorch-dataloaders"]], "Creating the Neural Network": [[31, "Creating-the-Neural-Network"]], "Training the Neural Network": [[31, "Training-the-Neural-Network"], [32, "Training-the-Neural-Network"]], "Evaluating the model on test data": [[31, "Evaluating-the-model-on-test-data"]], "Suggestions for further experimentation": [[31, "Suggestions-for-further-experimentation"]], "Train a Simplicial Complex Network (SCoNe)": [[32, "Train-a-Simplicial-Complex-Network-(SCoNe)"]], "Define Neighborhood Structures": [[32, "Define-Neighborhood-Structures"]], "Defining Labels and Preparing Input": [[32, "Defining-Labels-and-Preparing-Input"]], "Train/Test Split": [[32, "Train/Test-Split"]], "Creating Neural Network": [[32, "Creating-Neural-Network"]], "Tutorials": [[33, "tutorials"]]}, "indexentries": {}})