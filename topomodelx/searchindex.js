Search.setIndex({"docnames": ["api/base", "api/index", "api/nn", "api/utils", "challenge/index", "contributing/index", "index", "notebooks/cell/can_train", "notebooks/cell/ccxn_train", "notebooks/cell/cwn_train", "notebooks/hypergraph/allset_train", "notebooks/hypergraph/allset_transformer_train", "notebooks/hypergraph/dhgcn_train", "notebooks/hypergraph/hmpnn_train", "notebooks/hypergraph/hnhn_train", "notebooks/hypergraph/hnhn_train_bis", "notebooks/hypergraph/hypergat_train", "notebooks/hypergraph/hypersage_train", "notebooks/hypergraph/template_train", "notebooks/hypergraph/unigcn_train", "notebooks/hypergraph/unigcnii_train", "notebooks/hypergraph/unigin_train", "notebooks/hypergraph/unisage_train", "notebooks/simplicial/dist2cycle_train", "notebooks/simplicial/hsn_train", "notebooks/simplicial/san_train", "notebooks/simplicial/sca_cmps_train", "notebooks/simplicial/sccn_train", "notebooks/simplicial/sccnn_train", "notebooks/simplicial/scconv_train", "notebooks/simplicial/scn2_train", "notebooks/simplicial/scnn_train", "notebooks/simplicial/scone_train", "tutorials/index"], "filenames": ["api/base.rst", "api/index.rst", "api/nn.rst", "api/utils.rst", "challenge/index.rst", "contributing/index.rst", "index.rst", "notebooks/cell/can_train.ipynb", "notebooks/cell/ccxn_train.ipynb", "notebooks/cell/cwn_train.ipynb", "notebooks/hypergraph/allset_train.ipynb", "notebooks/hypergraph/allset_transformer_train.ipynb", "notebooks/hypergraph/dhgcn_train.ipynb", "notebooks/hypergraph/hmpnn_train.ipynb", "notebooks/hypergraph/hnhn_train.ipynb", "notebooks/hypergraph/hnhn_train_bis.ipynb", "notebooks/hypergraph/hypergat_train.ipynb", "notebooks/hypergraph/hypersage_train.ipynb", "notebooks/hypergraph/template_train.ipynb", "notebooks/hypergraph/unigcn_train.ipynb", "notebooks/hypergraph/unigcnii_train.ipynb", "notebooks/hypergraph/unigin_train.ipynb", "notebooks/hypergraph/unisage_train.ipynb", "notebooks/simplicial/dist2cycle_train.ipynb", "notebooks/simplicial/hsn_train.ipynb", "notebooks/simplicial/san_train.ipynb", "notebooks/simplicial/sca_cmps_train.ipynb", "notebooks/simplicial/sccn_train.ipynb", "notebooks/simplicial/sccnn_train.ipynb", "notebooks/simplicial/scconv_train.ipynb", "notebooks/simplicial/scn2_train.ipynb", "notebooks/simplicial/scnn_train.ipynb", "notebooks/simplicial/scone_train.ipynb", "tutorials/index.rst"], "titles": ["Base", "API Reference", "Neural Networks", "Utils", "ICML 2023 Topological Deep Learning Challenge", "Contributing", "\ud83c\udf10 TopoModelX (TMX) \ud83c\udf69", "Train a Cell Attention Network (CAN)", "Train a Convolutional Cell Complex Network (CCXN)", "Train a CW Network (CWN)", "Train a Hypergraph Neural Network", "Train a Hypergraph Neural Network", "Train a Hypergraph Neural Network", "Train a Hypergraph Message Passing Neural Network (HMPNN)", "Train a Hypergraph Networks with Hyperedge Neurons (HNHN)", "Train a Hypergraph Network with Hyperedge Neurons (HNHN)", "Train a Hypergraph Neural Network", "Train a Hypergraph Neural Network", "Train a Hypergraph Neural Network", "Pre-processing", "Train a hypergraph neural network using UniGCNII layers", "Pre-processing", "Pre-processing", "Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)", "Train a Simplicial High-Skip Network (HSN)", "Train a Simplicial Attention Network (SAN)", "Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)", "Train a Simplicial Complex Convolutional Network (SCCN)", "Train a SCCNN", "Train a Simplicial 2-complex convolutional neural network (SCConv)", "Train a Simplex Convolutional Network (SCN) of Rank 2", "Train a Simplicial Convolutional Neural Network (SCNN)", "Train a Simplicial Complex Net (SCoNe)", "Tutorials"], "terms": {"messag": [0, 1, 2, 4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27], "pass": [0, 1, 2, 4, 7, 8, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27, 31, 32], "modul": [0, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 28, 31], "class": [0, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32], "topomodelx": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "message_pass": 0, "messagepass": [0, 1], "aggr_func": [0, 7], "liter": 0, "sum": [0, 7, 8, 9, 14, 16, 25, 27, 29, 32], "mean": [0, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 32], "add": [0, 3, 5, 20], "att": [0, 2, 8, 16, 26], "bool": [0, 2, 5, 7, 8, 10, 11], "fals": [0, 2, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 21, 22, 26, 28, 29, 30, 31], "initi": [0, 2, 7, 8, 10, 11, 13, 14, 15, 17, 25, 28, 29, 31], "uniform": [0, 32], "xavier_uniform": [0, 17], "xavier_norm": 0, "initialization_gain": 0, "float": [0, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "1": [0, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32], "414": [0, 14, 19], "sourc": [0, 2, 3, 4], "thi": [0, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "defin": [0, 4, 5, 7, 8, 9, 10, 20, 25, 26, 32], "through": [0, 4, 8, 9, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 31, 32], "singl": [0, 4, 9], "neighborhood": [0, 2, 4, 7, 8, 9, 10, 11, 17, 25, 26, 32], "n": [0, 4, 5, 6, 7, 9, 16, 17, 25, 26, 32], "decompos": 0, "2": [0, 2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32], "step": [0, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "creat": [0, 4, 5, 11, 16, 17], "go": [0, 6, 7, 9, 25, 32], "from": [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "cell": [0, 1, 4, 9, 10, 11, 12, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "target": [0, 8, 28, 31], "aggreg": [0, 1, 4, 7, 16, 17, 25, 29, 31], "come": 0, "differ": [0, 5, 8, 14, 23, 24, 25, 27, 28, 31, 32], "onto": [0, 25], "each": [0, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 32], "should": [0, 4, 5, 32], "instanti": [0, 9], "directli": [0, 20], "rather": [0, 4, 5], "inherit": [0, 4], "subclass": 0, "effect": 0, "function": [0, 3, 4, 5, 7, 9, 10, 11, 17, 20, 23, 24, 25, 27, 28, 31, 32], "doe": [0, 4, 5, 28, 31, 32], "have": [0, 4, 5, 8, 10, 11, 12, 14, 16, 17, 18, 23, 24, 27, 28, 31, 32], "trainabl": [0, 16], "weight": [0, 5, 11, 16, 25, 27, 28, 32], "its": [0, 4, 5, 13, 15, 16], "paramet": [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "default": [0, 2, 5, 7, 10, 11, 15, 17, 20], "us": [0, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32], "whether": [0, 2, 7, 8, 10, 11], "attent": [0, 2, 4, 11, 16], "method": [0, 4, 5, 13, 15], "layer": [0, 1, 2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "gain": 0, "refer": [0, 2, 5, 7, 17, 25], "h23": 0, "hajij": [0, 2, 4, 6, 7, 8, 24, 25], "zamzmi": [0, 2, 6], "papamark": [0, 4, 6], "miolan": [0, 2, 4, 6], "guzm\u00e1n": [0, 2, 4, 6], "s\u00e1enz": [0, 2, 4, 6], "ramamurthi": [0, 2, 4, 6], "birdal": [0, 4, 6], "dei": [0, 4, 6], "mukherje": [0, 4, 6], "samaga": [0, 4, 6], "livesai": [0, 4, 6], "walter": [0, 4, 6], "rosen": [0, 4, 6], "schaub": [0, 4, 6], "topolog": [0, 1, 2, 6, 7, 8, 9, 14, 23, 24, 25, 26, 27, 29, 31, 32], "deep": [0, 2, 6, 7, 8, 9, 11, 14, 23, 24, 25, 26, 27, 29, 31, 32], "learn": [0, 2, 5, 6, 7, 8, 9, 14, 15, 16, 17, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "beyond": [0, 2, 6, 7, 25], "graph": [0, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32], "data": [0, 2, 5, 6, 7, 13, 15, 25, 27, 30], "2023": [0, 2, 6, 7, 8, 9, 14, 20, 23, 24, 25, 26, 27, 28, 29, 31, 32], "http": [0, 2, 7, 14, 15, 20, 22, 23, 24, 25, 27, 28, 30], "arxiv": [0, 2, 6], "org": [0, 2, 14, 23, 24, 25, 27, 28], "ab": [0, 2, 29], "2206": [0, 6, 23], "00606": [0, 6], "pshm23": [0, 2], "papillon": [0, 2, 4, 6, 7, 8, 9, 14, 23, 24, 25, 26, 27, 29, 31, 32], "sanborn": [0, 2, 4, 6], "architectur": [0, 2, 4, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 23, 24, 25, 26, 27, 29, 31, 32], "A": [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 23, 24, 25, 26, 27, 28, 29, 31, 32], "survei": [0, 2, 4, 6, 7, 8, 9, 14, 23, 24, 25, 26, 27, 29, 31, 32], "neural": [0, 1, 4, 6], "network": [0, 1, 4, 6], "2304": [0, 2, 6, 14], "10031": [0, 2, 6], "x_messag": 0, "receiv": [0, 4], "sever": [0, 1, 4], "output": [0, 2, 4, 5, 7, 10, 11, 12, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32], "featur": [0, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32], "per": [0, 4, 5], "correspond": [0, 7, 11, 13, 15, 20], "within": [0, 5, 7, 13, 15, 25], "tensor": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "shape": [0, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "n_messag": 0, "out_channel": [0, 2, 7, 9, 10, 11, 12, 16, 17, 18, 19, 21, 22, 25, 31], "associ": [0, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28], "One": [0, 4, 27, 31, 32], "i": [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "sent": [0, 20], "return": [0, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 27, 28, 29, 31, 32], "n_target_cel": 0, "assum": 0, "all": [0, 3, 4, 5, 7, 10, 11, 12, 16, 17, 18, 20, 23, 24, 25, 27, 28, 31, 32], "same": [0, 4, 5, 7, 8, 25, 26, 28, 31, 32], "rank": [0, 4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "": [0, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 18, 20, 23, 24, 26, 27, 28, 32], "x_sourc": 0, "x_target": 0, "none": [0, 2, 3, 5, 10, 31, 32], "comput": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 31, 32], "provid": [0, 4, 5, 26, 28, 31], "scheme": [0, 2, 4, 8, 25], "altern": [0, 4], "user": [0, 8, 23, 27, 28, 31], "can": [0, 2, 4, 5, 6, 16, 17, 20, 23, 24, 25, 27, 29, 31, 32], "overwrit": 0, "order": [0, 2, 4, 7, 24, 25, 27, 28, 30, 31, 32], "replac": 0, "own": 0, "mechan": [0, 2, 7, 8, 11, 16, 25], "detail": [0, 4, 5, 7, 11, 25], "definit": [0, 31], "higher": [0, 2, 4, 7, 24, 27, 30, 31], "torch": [0, 2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "n_source_cel": 0, "in_channel": [0, 2, 7, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31], "input": [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31], "r": [0, 2, 5, 7, 8, 9, 10, 11, 16, 25, 26, 27, 32], "one": [0, 4, 5, 8, 14, 20, 23, 24, 25, 26, 27, 28, 29, 32], "scalar": [0, 8, 9, 26, 32], "between": [0, 2, 7, 8, 25, 27], "forward": [0, 2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 31, 32], "implement": [0, 1, 2, 4, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 25, 26, 27, 31, 32], "given": [0, 2, 4, 7, 8, 9, 10, 11, 14, 16, 17, 20, 23, 24, 25, 27, 28, 29, 31, 32], "via": [0, 2, 31], "where": [0, 4, 5, 7, 8, 9, 11, 14, 16, 17, 23, 24, 25, 26, 27, 28, 29, 31, 32], "In": [0, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "practic": [0, 10, 11], "updat": [0, 7, 10, 11, 15, 25, 32], "If": [0, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 25, 26], "e": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 23, 24, 25, 28, 30, 31, 32], "send": [0, 2, 4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 23, 24, 25, 30], "themselv": [0, 27], "The": [0, 1, 2, 4, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32], "two": [0, 2, 7, 10, 11, 12, 14, 16, 17, 18, 23, 24, 25, 27, 28, 31, 32], "m_": [0, 2, 7, 8, 9, 10, 11, 14, 16, 17, 23, 24, 25, 26, 27, 29, 31, 32], "y": [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "rightarrow": [0, 2, 7, 8, 9, 10, 11, 14, 16, 17, 23, 24, 25, 26, 27, 29, 31, 32], "x": [0, 2, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "left": [0, 5, 9, 16, 17, 32], "right": [0, 5, 9, 16, 17, 32], "travel": 0, "denot": [0, 10, 11, 16, 17, 31, 32], "mathcal": [0, 2, 7, 8, 9, 10, 11, 14, 16, 17, 23, 24, 25, 26, 27, 29, 31, 32], "mathbf": [0, 28, 31], "h": [0, 2, 7, 11, 16, 17, 20, 24, 25, 27, 28, 29, 31], "_x": [0, 7, 23, 25, 29], "_y": [0, 2, 24, 27], "theta": [0, 2, 7, 8, 11, 14, 16, 17, 23, 24, 26, 27, 28, 29, 31, 32], "ar": [0, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 23, 24, 25, 26, 27, 28, 29, 31, 32], "call": [0, 5, 11, 32], "option": [0, 2, 4, 5, 7, 8, 10, 11], "appli": [0, 7, 10, 11, 13, 16, 25, 29, 32], "leftarrow": [0, 17], "across": 0, "belong": [0, 5, 14, 23, 24, 25, 27, 28], "m_x": [0, 2, 8, 9, 14, 16, 17, 23, 24, 26, 27, 29, 31, 32], "text": [0, 2, 5, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 25, 26, 27, 28], "agg": [0, 2, 26], "_": [0, 2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "result": [0, 5, 7, 8, 11, 14, 28, 31], "spars": [0, 1, 2, 5, 10, 11, 13, 14, 15, 16, 17, 20, 23, 25, 27, 28, 29], "matrix": [0, 2, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32], "construct": [0, 13, 15, 20, 32], "reset_paramet": [0, 2], "reset": [0, 2], "learnabl": [0, 2, 7, 11, 25, 31], "note": [0, 2, 4, 5, 10, 11, 12, 16, 17, 18, 23, 24, 28, 31, 32], "convolut": [0, 2, 4, 9, 25], "conv": [0, 1, 2], "aggr_norm": [0, 31], "update_func": [0, 7, 27, 31, 32], "relu": [0, 7, 16, 21, 32], "sigmoid": [0, 7, 10, 11, 16, 17, 18, 19, 21, 22, 27, 32], "with_linear_transform": 0, "true": [0, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "3": [0, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "build": [0, 4, 5, 32], "rout": 0, "includ": [0, 4, 5, 32], "an": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "specif": [0, 4, 5, 9, 14, 16, 20], "int": [0, 2, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 31, 32], "dimens": [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "normal": [0, 10, 11, 27, 30], "size": [0, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "linear": [0, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32], "transform": [0, 5, 15, 20, 25], "nb": 0, "ha": [0, 5, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31], "equal": [0, 5, 16, 32], "x_message_on_target": 0, "embed": 0, "4": [0, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "tanh": 0, "inter": [0, 17, 28], "merg": 0, "list": [0, 5, 10, 11, 12, 20, 32], "len": [0, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32], "n_messages_to_merg": 0, "n_skeleton_in": 0, "channel": [0, 2, 7, 20, 23, 24, 25, 27, 31], "arrai": [0, 5, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "like": [0, 5, 7, 8, 25, 27, 28, 31], "n_skeleton_out": 0, "skeleton": [0, 7, 32], "out": [0, 3, 4, 5, 6, 7, 12, 14, 15, 18, 25, 26, 27, 32], "give": [1, 7, 11, 25], "overview": 1, "which": [1, 4, 5, 10, 11, 13, 15, 16, 20, 23, 24, 25, 27, 28, 31, 32], "consist": [1, 4, 5, 20, 32], "base": [1, 4, 11, 28, 29, 31, 32], "core": 1, "mathemat": 1, "concept": 1, "nn": [1, 2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "organ": [1, 4, 27], "domain": [1, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "util": [1, 7, 10, 11, 19, 20, 21, 22, 25, 32], "hypergraph": [1, 4, 19, 21, 22], "simplici": [1, 4, 8, 9, 10, 11, 12, 14, 16, 17, 18, 30], "complex": [1, 4, 5, 7, 9, 10, 11, 12, 16, 17, 18, 19, 21, 22, 23, 24, 25, 30, 31], "scatter": [1, 15, 32], "templat": [2, 5, 16, 18], "template_lay": [2, 4, 18], "templatelay": [2, 10, 12, 18], "intermediate_channel": [2, 12, 18, 21, 31], "intermedi": [2, 31], "x_1": [2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "incidence_1": [2, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 31], "n_edg": [2, 8, 9, 14, 16, 17, 18, 19, 21, 22, 31], "edg": [2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "n_node": [2, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 31], "incid": [2, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 31], "map": [2, 14, 29, 32], "node": [2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32], "b_1": [2, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 25, 29, 31], "high": 2, "skip": [2, 7, 20, 32], "hsn": [2, 4], "hsn_layer": [2, 4], "hsnlayer": [2, 4, 24, 27], "propos": [2, 7, 8, 9, 14, 17, 23, 24, 25, 28, 29, 30, 31, 32], "hrgz22": 2, "classif": [2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30], "complic": 2, "gener": [2, 5, 7, 10, 11, 20, 24, 25], "connect": [2, 7, 16, 20, 24, 28, 32], "geometr": [2, 4], "represent": [2, 4, 7, 10, 11, 13, 14, 15, 16, 27, 30, 32], "workshop": [2, 4], "iclr": 2, "2022": [2, 4, 7, 13, 23, 24, 25, 27, 31], "openreview": 2, "net": [2, 4], "pdf": [2, 5], "id": [2, 5], "sc8glb": 2, "k6e9": 2, "x_0": [2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "adjacency_0": [2, 7, 8, 23, 24], "wa": [2, 26, 31], "Its": 2, "equat": [2, 5, 6, 7, 8, 9, 14, 23, 24, 25, 27, 29, 32], "tnn23": 2, "graphic": [2, 6], "illustr": [2, 30], "begin": [2, 5, 7, 25], "align": [2, 7, 25, 31], "quad": [2, 7, 8, 9, 10, 11, 14, 16, 17, 23, 24, 25, 26, 27, 29, 31, 32], "z": [2, 7, 8, 9, 10, 11, 16, 17, 24, 31, 32], "0": [2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "sigma": [2, 10, 14, 16, 17, 23, 24, 27, 28, 29, 31, 32], "a_": [2, 7, 8, 9, 16, 23, 24, 25], "uparrow": [2, 7, 8, 9, 23, 24, 25, 27, 28, 29, 31, 32], "xy": [2, 14, 23, 24, 27, 29, 31, 32], "cdot": [2, 7, 14, 16, 17, 23, 24, 25, 27, 29, 31, 32], "t": [2, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 20, 23, 24, 25, 26, 27, 28, 29, 31, 32], "zy": [2, 16, 17, 24], "h_y": [2, 7, 8, 9, 10, 11, 14, 17, 24, 25, 29, 31, 32], "xz": [2, 16, 17, 24], "sum_": [2, 14, 16, 17, 23, 24, 27, 28, 29, 31, 32], "l": [2, 7, 8, 9, 16, 17, 23, 24, 25, 26, 27, 28, 29, 31, 32], "c": [2, 6, 7, 8, 10, 11, 14, 15, 16, 17, 23, 24, 27, 29, 32], "h_x": [2, 7, 8, 9, 10, 11, 14, 16, 17, 23, 24, 25, 26, 27, 31, 32], "end": [2, 5, 7, 23, 24, 25, 27, 32], "awesom": [2, 6, 11, 17], "tnn": [2, 4, 6, 11, 17], "adjac": [2, 7, 8, 9, 13, 23, 24, 25, 27, 28, 32], "a_0": 2, "simplifi": [2, 8], "version": [2, 8, 9, 28, 31], "ccxn": 2, "et": [2, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 23, 24, 25, 26, 27, 28, 29, 31, 32], "al": [2, 4, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 23, 24, 25, 26, 27, 28, 29, 31, 32], "ccxn_layer": [2, 8], "ccxnlayer": [2, 8], "in_channels_0": [2, 7, 8, 9, 28, 30, 31], "in_channels_1": [2, 7, 8, 9, 28, 30, 31], "in_channels_2": [2, 7, 8, 9, 28, 30, 31], "hiz20": 2, "compos": 2, "face": [2, 4, 7, 8, 9, 10, 11, 12, 16, 17, 18, 23, 24, 25, 26, 27, 28, 29, 30, 31], "entir": [2, 7, 8, 9], "istvan": 2, "analysi": 2, "neurip": 2, "2020": [2, 4, 8, 13, 14, 16, 17, 29], "2010": 2, "00743": 2, "neighborhood_0_to_0": [2, 7, 8], "neighborhood_1_to_2": [2, 8], "x_2": [2, 8, 9, 10, 11, 12, 16, 17, 18, 23, 24, 25, 26, 27, 28, 29, 30, 31], "amp": [2, 8], "u": [2, 4, 8, 9, 10, 11, 16, 26, 32], "cohomologi": [2, 8], "coboundari": [2, 8, 9], "m": [2, 5, 8, 16, 23, 26, 29, 31, 32], "t_": [2, 8, 17], "h_": [2, 8, 16, 23, 26, 27], "n_0_cell": 2, "n_1_cell": 2, "a_0_up": 2, "n_2_cell": 2, "b_2": [2, 8, 25, 29], "onli": [2, 4, 5, 7, 12, 20, 25, 28, 30, 32], "requir": [2, 5, 7, 26], "num_class": [2, 7, 8, 9, 13, 15, 20, 28, 30], "predict": [2, 5, 7, 10, 11, 13, 14, 15, 31, 32], "adapt": 3, "torch_scatt": 3, "py": [3, 4, 5, 8, 15, 20, 23, 27, 28, 29, 31], "rusty1": 3, "pytorch_scatt": 3, "broadcast": [3, 8, 28, 31], "src": [3, 20], "other": [3, 5, 32], "dim": [3, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 31, 32], "str": [3, 5], "scatter_add": 3, "index": [3, 5, 27, 32], "dim_siz": 3, "valu": [3, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 23, 26, 28, 29, 30, 31, 32], "indic": [3, 15, 23, 24, 25, 27, 28, 32], "scatter_mean": 3, "scatter_sum": 3, "welcom": [4, 5], "host": 4, "second": [4, 10, 11, 26], "annual": 4, "topologi": [4, 12, 25], "geometri": 4, "tag": 4, "machin": [4, 30, 31], "review": [4, 5, 6], "contributor": [4, 5], "mathild": [4, 6], "mustafa": [4, 6], "nina": [4, 6], "florian": 4, "frantzen": 4, "ghada": [4, 6], "alzamzmi": 4, "theodor": [4, 6], "michael": [4, 6], "scholkemp": 4, "josef": 4, "hopp": 4, "karthikeyan": [4, 6], "natesan": [4, 6], "johan": 4, "math": [4, 5, 7, 11, 16, 17, 31, 32], "audun": 4, "myer": 4, "helen": 4, "jenn": 4, "tim": 4, "doster": 4, "tegan": 4, "emerson": 4, "henri": 4, "kving": 4, "bastian": [4, 30], "rieck": [4, 30], "sophia": [4, 6], "jan": 4, "meissner": 4, "paul": [4, 6, 30], "tolga": [4, 6], "vincent": 4, "grand": 4, "aldo": [4, 6], "tamal": [4, 6], "soham": [4, 6], "shreya": [4, 6], "neal": [4, 6], "robin": [4, 6], "edit": [4, 5], "now": [4, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 23, 24, 25, 30, 32], "over": [4, 7, 10, 11, 12, 13, 15, 17, 18, 19, 22, 23, 24, 25, 27, 29, 30, 32], "thank": 4, "you": [4, 5, 20], "stellar": 4, "contirbut": 4, "foster": 4, "reproduc": [4, 6], "open": [4, 20], "research": [4, 30], "winner": 4, "announc": 4, "here": [4, 5, 7, 12, 13, 15, 20, 23, 24, 27, 28, 32], "luca": 4, "scofano": 4, "claudio": 4, "battiloro": [4, 25], "guillermo": 4, "bernardez": 4, "simon": 4, "fiorellino": 4, "indro": 4, "spinelli": 4, "scardapan": 4, "lev": 4, "telyatninkov": 4, "olga": 4, "zaghen": 4, "allsettransform": [4, 11], "chien": [4, 10, 11], "sadrodin": 4, "barikbin": [4, 15], "hmpnn": 4, "heydari": [4, 13], "san": [4, 7], "giusti": [4, 7, 25], "odin": 4, "hoff": 4, "gardaa": 4, "scone": 4, "roddenberri": [4, 31, 32], "2021": [4, 9, 10, 11, 31, 32], "cellular": [4, 9], "dmitrii": 4, "gavrilev": 4, "gleb": 4, "bazhenov": 4, "suraj": 4, "singh": 4, "cw": 4, "cwn": 4, "bodnar": [4, 9], "combinatori": 4, "rub\u00e9n": 4, "ballest": 4, "manuel": 4, "lecha": 4, "sergio": 4, "escalera": 4, "hoan": 4, "aiden": 4, "brent": 4, "honor": 4, "mention": 4, "jen": 4, "agerberg": 4, "georg": 4, "b\u00f6kman": 4, "pavlo": 4, "melnyk": 4, "sccn": 4, "yang": [4, 27, 28, 30, 31], "autoencod": 4, "sca": 4, "alessandro": 4, "salatiello": 4, "hyperedg": [4, 10, 11, 12, 13, 16, 17, 18], "neuron": 4, "hnhn": 4, "dong": [4, 14, 15], "alexand": 4, "nikitin": 4, "unigcn": [4, 19], "huang": 4, "purpos": [4, 5, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 22, 23, 24, 25, 27, 28], "crowdsourc": 4, "ask": 4, "contribut": [4, 16, 28], "code": [4, 5, 32], "previous": 4, "exist": 4, "train": 4, "benchmark": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31], "dataset": [4, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26], "built": [4, 5], "python": [4, 5, 6], "packag": [4, 6, 8, 15, 20, 23, 27, 28, 29, 31], "take": [4, 7, 8, 9, 25, 32], "form": [4, 10, 11, 23, 24, 27, 28, 32], "pull": [4, 5], "request": [4, 5, 20, 32], "contain": [4, 7, 10, 11, 13, 15, 20, 28, 32], "necessari": [4, 7, 25], "literatur": [4, 6, 20], "leverag": [4, 25], "infrastructur": 4, "block": 4, "we": [4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32], "invit": 4, "file": [4, 5], "regularli": 4, "ad": [4, 5], "when": [4, 5, 7, 25, 32], "everi": [4, 20, 21], "respect": [4, 9, 10, 11, 16, 17, 25, 28, 31, 32], "white": 4, "paper": [4, 7, 13, 14, 15, 23, 24, 25, 28, 29, 30, 31, 32], "summar": 4, "find": [4, 7, 32], "publish": 4, "qualifi": 4, "opportun": 4, "co": [4, 20], "author": [4, 6, 15, 32], "top": [4, 7, 28], "8": [4, 7, 8, 9, 11, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32], "best": [4, 11], "addit": 4, "softwar": [4, 5], "journal": 4, "special": 4, "recognit": 4, "final": [4, 13, 14, 15, 20, 25, 31, 32], "date": 4, "time": [4, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 25, 27, 28, 31, 32], "must": [4, 10, 11, 12, 14, 16, 17, 18, 23, 24, 25, 27, 28, 31], "place": [4, 5, 10, 11], "befor": [4, 5, 20, 32], "juli": 4, "13": [4, 8, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32], "16": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32], "59": [4, 13, 14, 19, 23, 27], "pacif": 4, "standard": [4, 5, 20, 25], "modifi": [4, 5, 26], "until": 4, "everyon": [4, 5], "free": [4, 32], "It": [4, 13, 15, 20], "suffici": 4, "accept": 4, "automat": [4, 25], "subscrib": 4, "team": 4, "encourag": 4, "start": [4, 5, 20, 32], "earli": 4, "help": [4, 5], "debug": 4, "fail": 4, "test": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28], "address": 4, "potenti": 4, "issu": [4, 20], "case": [4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 23, 24, 25, 30, 32], "multipl": [4, 5, 10, 11, 32], "similar": [4, 27], "qualiti": 4, "earlier": [4, 27], "prioriti": 4, "consider": 4, "restrict": 4, "number": [4, 7, 8, 9, 10, 11, 13, 14, 15, 20, 23, 24, 25, 26, 27, 29, 30, 32], "member": 4, "more": [4, 5, 6, 23, 27, 28, 32], "than": [4, 31, 32], "model": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30], "There": [4, 5, 13, 14, 15, 23, 24, 25, 27, 31], "amount": [4, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 28], "princip": 4, "develop": [4, 5], "allow": [4, 27], "pre": [4, 32], "fig": [4, 32], "11": [4, 7, 8, 9, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32], "compli": 4, "github": [4, 11, 15, 17, 20], "action": 4, "workflow": 4, "successfulli": 4, "lint": 4, "format": [4, 5, 20, 28], "black": [4, 32], "isort": 4, "flake8": 4, "three": [4, 5, 20], "new": [4, 5, 8], "name": [4, 5, 7, 10, 11, 13, 19, 21, 22], "_layer": 4, "ex": 4, "store": [4, 14], "directori": [4, 5], "primit": 4, "equival": [4, 5], "depict": 4, "diagram": 4, "exampl": [4, 25, 28, 31, 32], "check": [4, 5, 6, 14, 23, 24], "_train": 4, "ipynb": 4, "hsn_train": 4, "tutori": [4, 6, 20], "follow": [4, 5, 6, 7, 10, 11, 12, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "process": [4, 5, 20], "import": [4, 5, 7, 8, 9, 10, 11, 13, 15, 17, 20, 25, 32], "well": [4, 5], "load": [4, 8, 9, 10, 11, 12, 15, 16, 17, 18, 22, 23, 24, 26, 27, 28, 29, 30, 31], "matric": [4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 23, 24, 25, 27, 28, 30, 31], "toponetx": [4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "either": [4, 5, 25, 32], "shrec16": [4, 8, 9, 10, 11, 12, 16, 17, 18, 26, 28, 31], "suitabl": [4, 14], "level": [4, 7, 10, 11, 12, 14, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 31], "see": [4, 5, 6, 15, 32], "karat": [4, 14, 23, 24, 25, 27, 28], "club": [4, 14, 23, 24, 25, 27, 28], "abov": [4, 5, 31, 32], "lift": [4, 7, 8, 9, 10, 11, 14, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31], "choic": [4, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 21, 22, 26], "along": [4, 7, 25], "task": [4, 10, 11, 13, 14, 15, 20, 23, 24, 27, 28, 31, 32], "simpl": [4, 31], "loop": [4, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 27, 29, 30, 32], "depend": 4, "perform": [4, 5, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 27, 29, 30, 32], "accuraci": [4, 14, 15, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32], "test_": [4, 5], "name_of_model": 4, "test_hsn_lay": 4, "testhsnlay": 4, "unit": [4, 5, 32], "pleas": [4, 5, 7, 8, 15, 20, 25, 28, 31], "pytest": [4, 5], "unittest": 4, "further": [4, 7, 25], "manipul": 4, "mai": 4, "modif": 4, "accompani": 4, "appropri": [4, 5], "locat": [4, 5, 20], "With": [4, 16], "being": [4, 25], "said": 4, "highli": 4, "make": [4, 7, 8, 9, 10, 11, 12, 13, 15, 18, 20, 26, 32], "most": [4, 5, 25, 27], "resort": 4, "absolut": 4, "condorcet": 4, "decid": [4, 25], "criteria": 4, "chosen": [4, 27], "correctli": 4, "term": [4, 25], "do": [4, 13, 15, 23, 24, 27, 32], "need": [4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 23, 24, 25, 30, 32], "match": 4, "origin": [4, 5, 7, 8, 9, 20, 25, 27, 28, 30, 31, 32], "readabl": [4, 5], "clean": 4, "api": [4, 5], "written": 4, "docstr": 4, "clearli": 4, "explain": 4, "robust": 4, "reward": 4, "nor": 4, "goal": 4, "accur": 4, "our": [4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32], "field": 4, "select": [4, 27, 31], "maintain": 4, "collabor": 4, "whose": [4, 5], "vote": 4, "onc": [4, 10, 11, 12, 16, 17, 18], "googl": [4, 5], "express": [4, 16], "prefer": [4, 5], "get": [4, 25, 28, 31, 32], "even": 4, "link": [4, 5], "record": [4, 5, 10, 11, 12, 16, 17, 18], "while": [4, 5, 25], "email": 4, "identifi": 4, "voter": 4, "ident": [4, 11, 23, 24, 28], "remain": [4, 32], "secret": 4, "share": [4, 7], "feel": [4, 32], "contact": 4, "repositori": [4, 5], "slack": 4, "ucsb": 4, "edu": 4, "guid": 5, "aim": [5, 7, 25], "eas": 5, "both": [5, 7, 25, 32], "novic": 5, "experienc": 5, "commun": 5, "effort": 5, "wai": [5, 25], "fork": 5, "upstream": 5, "submit": [5, 20], "pr": 5, "synchron": 5, "your": 5, "main": [5, 20], "branch": 5, "git": 5, "checkout": 5, "hold": 5, "b": [5, 9, 10, 11, 14, 16, 17, 26, 27, 28, 29], "sure": 5, "next": [5, 14, 16, 20, 32], "section": [5, 32], "re": [5, 23, 32], "done": [5, 8, 9, 10, 11, 12, 16, 17, 18, 22, 26, 28, 29, 30, 31, 32], "commit": 5, "modified_fil": 5, "my": [5, 26], "Then": [5, 8, 9], "push": 5, "toponextx": 5, "instruct": 5, "repeat": 5, "folder": 5, "valid": [5, 19, 20, 21, 22, 32], "filenam": 5, "For": [5, 6, 14, 17, 23, 24, 28, 31, 32], "test_add": 5, "def": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 27, 28, 29, 31, 32], "test_capital_cas": 5, "assert": [5, 32], "5": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "9": [5, 7, 8, 9, 11, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32], "statement": 5, "under": 5, "correct": [5, 7, 19, 21, 22, 32], "instal": 5, "tool": 5, "pip": 5, "dev": 5, "verifi": 5, "break": 5, "doc": 5, "descript": [5, 32], "usag": 5, "inform": [5, 10, 11, 13, 16, 17, 31], "markdown": 5, "languag": 5, "common": [5, 7], "restructuredtext": 5, "numpi": [5, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "style": 5, "up": [5, 25, 27, 32], "understand": 5, "role": 5, "syntax": 5, "also": [5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 30, 31], "autom": 5, "pars": 5, "inclus": 5, "look": [5, 32], "ani": [5, 7, 8, 17, 32], "object": 5, "print": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "__doc__": 5, "attribut": 5, "try": [5, 7, 8, 25, 32], "np": [5, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "good": [5, 30], "These": 5, "some": [5, 27, 32], "element": [5, 11], "ones": [5, 13, 15], "d": [5, 16, 23, 29], "summari": 5, "line": 5, "79": [5, 12, 13, 14, 19, 27], "char": 5, "immedi": 5, "after": [5, 7, 15, 21], "first": [5, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "capit": 5, "letter": 5, "period": 5, "describ": [5, 11], "verb": 5, "imper": 5, "mood": 5, "g": [5, 10, 11, 16, 25, 31, 32], "v": [5, 10, 11, 14, 16, 17, 20, 23, 24, 25, 27, 28, 31], "possibl": [5, 20], "uncertain": 5, "oppos": 5, "calcul": 5, "evalu": [5, 7, 13, 14, 15, 20, 21], "multi": [5, 11], "separ": 5, "blank": 5, "argument": [5, 10, 11, 25], "type": 5, "On": 5, "state": [5, 17, 20], "rest": 5, "space": [5, 28, 32], "side": 5, "default_valu": 5, "indent": 5, "esp": 5, "would": [5, 23, 24], "want": [5, 20, 32], "mani": [5, 7], "veri": [5, 20], "rais": [5, 28, 31], "etc": [5, 20], "latex": 5, "cite": [5, 20], "my_method": 5, "self": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 31, 32], "my_param_1": 5, "my_param_2": 5, "vector": [5, 11, 13, 15, 16, 32], "big": 5, "o": [5, 11, 14, 25], "short": 5, "my_result": 5, "relev": 5, "snippet": 5, "show": [5, 14, 23, 24, 32], "how": [5, 11, 23, 24, 25], "script": 5, "wikipedia": 5, "page": [5, 30], "And": 5, "fill": 5, "scikit": 5, "project": [5, 9, 25, 31], "fit_predict": 5, "sample_weight": 5, "cluster": [5, 26], "center": [5, 32], "sampl": [5, 7, 14, 32], "conveni": 5, "fit": 5, "sparse_matrix": 5, "n_featur": 5, "ignor": [5, 19, 22], "Not": 5, "present": [5, 7], "convent": [5, 7], "observ": 5, "assign": [5, 8, 9, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 32], "label": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 29, 30, 32], "labels_": 5, "mind": 5, "instead": [5, 20, 28], "boolean": 5, "vari": 5, "notat": [5, 7, 8, 9, 14, 23, 24, 25, 26, 27, 29, 31, 32], "axi": [5, 32], "string": [5, 17], "bracket": 5, "log": [5, 27, 32], "squar": [5, 32], "multinomi": 5, "1d": [5, 8, 9], "2d": [5, 8, 9], "subset": [5, 7, 13, 15], "ndarrai": [5, 32], "datafram": 5, "explicitli": 5, "relat": [5, 13], "colon": 5, "explan": 5, "_weight_boost": 5, "adaboost": 5, "great": 5, "ve": 5, "discuss": 5, "Of": 5, "cours": 5, "verbos": 5, "thei": [5, 7, 8, 9, 10, 11, 23, 24, 25, 27, 28, 31], "compon": [5, 25], "rst": 5, "keep": [5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 22, 23, 24, 25, 27, 28], "length": [5, 13, 15, 20], "80": [5, 12, 13, 14, 19, 26, 27, 31], "charact": 5, "except": [5, 7, 25], "tabl": 5, "tdl": 6, "blue": 6, "laid": 6, "extend": [6, 28], "avail": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 25, 26], "To": [6, 10, 14, 22, 23, 24, 31, 32], "about": 6, "blueprint": 6, "k": [6, 7, 9, 11, 14, 16, 23, 24, 25, 26, 27, 29, 31, 32], "misc": 6, "hajij2023topolog": 6, "titl": [6, 14], "year": 6, "eprint": 6, "archiveprefix": 6, "primaryclass": 6, "lg": 6, "papillon2023architectur": 6, "notebook": [7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 25, 28, 29, 30, 31, 32], "didact": [7, 25], "clear": [7, 25], "technic": [7, 25], "document": [7, 13, 15, 20, 25], "sinc": [7, 23, 24, 27, 28, 32], "introduct": 7, "achiev": [7, 11, 27, 32], "outstand": 7, "howev": [7, 20, 28, 31], "consid": [7, 25, 28, 31], "pairwis": [7, 10, 11, 12, 16, 17, 18, 32], "relationship": 7, "among": 7, "abl": [7, 25], "fulli": 7, "exploit": 7, "interact": 7, "real": [7, 32], "world": [7, 32], "introduc": [7, 13, 15, 16, 25], "oper": [7, 11, 16, 25, 27, 28, 32], "vertic": [7, 32], "repres": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 23, 24, 25, 30, 32], "captur": 7, "particular": 7, "lower": [7, 25, 26, 28, 31, 32], "upper": [7, 9, 25, 28, 31, 32], "encod": [7, 14, 23, 24, 25, 28, 32], "design": 7, "independ": [7, 11], "mask": [7, 13, 25, 32], "thu": [7, 25, 30], "strategi": [7, 17], "approach": 7, "hierarch": 7, "incorpor": 7, "algorithm": 7, "ii": 7, "optim": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "combin": [7, 10, 11], "neighbor": [7, 17, 31, 32], "iii": 7, "pool": [7, 8, 9, 12, 16, 17, 18, 19, 21, 22], "extract": [7, 10, 11, 16, 17, 22], "compact": 7, "meaning": 7, "remark": [7, 25], "custom": [7, 25], "symbol": [7, 25], "signal": [7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 21, 22, 25, 26], "could": [7, 25, 27], "involv": [7, 25], "n_1": [7, 25], "n_2": [7, 25], "downarrow": [7, 23, 25, 26, 27, 28, 29, 31, 32], "made": [7, 14, 23, 24, 25, 27, 28, 30, 31], "stage": 7, "nbsphinx": [7, 11, 16, 17, 31], "textrm": [7, 25], "alpha": [7, 17, 20, 25, 32], "h_z": [7, 9, 10, 11], "phi": [7, 25], "parameter": 7, "mathbb": [7, 10, 11, 16, 32], "2f_0": 7, "f_0": 7, "head": [7, 11], "concaten": [7, 11, 16, 32], "textbf": [7, 10, 11, 17, 25], "bigg": [7, 25, 28, 31], "bigotimes_": [7, 25], "_k": [7, 9, 25, 26], "bigoplus_": [7, 25], "alpha_k": [7, 25], "a_k": [7, 25, 32], "psi_k": [7, 25], "foral": [7, 16, 25], "n_k": [7, 25], "f": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "respons": [7, 20], "reciproc": 7, "part": [7, 23, 24, 25, 27, 28], "round": [7, 29], "gamma": [7, 15], "tau": 7, "tcdot": 7, "xin": 7, "c_r": 7, "coeffici": [7, 16], "score": [7, 32], "non": [7, 25], "_r": 7, "coars": 7, "mutag": [7, 19, 21, 22], "tudataset": [7, 19, 21, 22], "paperswithcod": 7, "com": [7, 15, 20, 22], "__": 7, "188": [7, 14, 19, 27], "chemic": 7, "compound": 7, "7": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "discret": 7, "mutagen": 7, "salmonella": 7, "typhimurium": 7, "gat": [7, 25], "gatv2": 7, "random": [7, 15, 32], "sklearn": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 26, 28, 30, 31], "model_select": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 21, 22, 26, 28, 30, 31], "train_test_split": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 21, 22, 26, 28, 30, 31], "cell_complex": [7, 8, 9], "cellcomplex": 7, "torch_geometr": [7, 13, 15, 19, 21, 22, 25], "convert": [7, 8, 9, 14, 19, 21, 22, 23, 24, 25, 28, 30], "to_networkx": [7, 19, 21, 22, 25], "can_lay": 7, "canlay": 7, "multiheadliftlay": 7, "poollay": 7, "gpu": [7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 26], "them": [7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 20, 25, 26, 27], "otherwis": [7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 26, 32], "run": [7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 27, 32], "cpu": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 25, 26, 29, 30], "devic": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 25, 26, 29, 30], "cuda": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 25, 26, 29, 30], "is_avail": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 25, 26, 29, 30], "els": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 25, 26, 28, 29, 30, 31], "retriev": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30], "binari": [7, 13, 14, 15, 19, 21, 22, 25], "root": [7, 19, 21, 22], "tmp": [7, 19, 20, 21, 22], "use_edge_attr": [7, 19, 21, 22], "use_node_attr": 7, "cc_list": [7, 8, 9], "x_0_list": 7, "x_1_list": [7, 19, 21, 22], "y_list": [7, 19, 21, 22], "append": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "edge_attr": 7, "i_cc": 7, "th": [7, 8, 9, 10, 11, 12, 16, 17, 18, 25, 26, 29, 30], "edge_index": [7, 10, 11, 13, 16, 17], "36": [7, 8, 13, 14, 15, 19, 21, 22, 23, 27], "0th": [7, 29], "17": [7, 13, 14, 15, 19, 21, 22, 23, 26, 27, 31], "38": [7, 13, 14, 15, 19, 21, 22, 23, 27], "structur": [7, 8, 9, 10, 11, 17, 25, 28, 31], "lower_neighborhood_list": 7, "upper_neighborhood_list": 7, "adjacency_0_list": [7, 8], "adjacency_matrix": [7, 8, 9, 23, 24, 27, 28, 29, 32], "from_numpi": [7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "todens": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "to_spars": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "lower_neighborhood_t": 7, "down_laplacian_matrix": [7, 23, 25, 26, 28, 29, 31], "upper_neighborhood_t": 7, "up_laplacian_matrix": [7, 25, 28, 29, 31], "zero": [7, 10, 11, 20, 23, 24, 25, 28, 31, 32], "stack": [7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 21, 22, 23, 24, 25, 27, 28, 31, 32], "6": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "__init__": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 29, 31, 32], "dropout": [7, 10, 11, 13, 15], "concat": 7, "skip_connect": 7, "att_activ": 7, "leakyrelu": [7, 16, 25], "n_layer": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "att_lift": 7, "arg": [7, 28, 29], "probabl": [7, 10, 11], "activ": [7, 11], "super": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 31], "lift_lay": 7, "signal_lift_dropout": 7, "rang": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "k_pool": 7, "signal_pool_activ": 7, "readout": 7, "modulelist": [7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 28, 31], "lin_0": [7, 8, 9], "128": [7, 14, 19, 27], "lin_1": [7, 8, 9], "lower_neighborhood": 7, "upper_neighborhood": 7, "hasattr": 7, "isinst": 7, "p": [7, 16, 17, 25], "max": [7, 10, 11, 16, 17, 18, 19, 21, 22, 27], "feed": [7, 10, 11, 12, 16, 17, 18, 19, 21, 22, 32], "foward": 7, "specifi": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31], "loss": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "without": [7, 8], "32": [7, 10, 13, 14, 15, 16, 19, 21, 22, 23, 27, 28, 32], "crit": [7, 8, 19, 21, 22], "crossentropyloss": [7, 8, 13, 14, 15, 20, 21], "opt": [7, 8, 10, 11, 12, 16, 17, 18, 26, 27, 28, 29, 31], "adam": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "lr": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "001": [7, 21, 30], "liftlay": 7, "lower_att": 7, "multiheadcellattent": 7, "negative_slop": 7, "lin": 7, "in_featur": [7, 13, 15, 20, 28, 31], "out_featur": [7, 28, 31], "64": [7, 10, 11, 13, 14, 19, 23, 27], "bia": [7, 28, 31], "upper_att": 7, "split": [7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 29, 32], "test_siz": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 21, 22, 26, 28, 30, 31, 32], "x_1_train": [7, 8, 9, 18, 19, 21, 22, 26, 28, 29], "x_1_test": [7, 8, 9, 18, 19, 21, 22, 26, 28], "shuffl": [7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 21, 22, 26, 28, 30, 31, 32], "x_0_train": [7, 8, 9, 10, 11, 12, 15, 16, 17, 26, 28, 29], "x_0_test": [7, 8, 9, 10, 11, 12, 15, 16, 17, 26, 28], "lower_neighborhood_train": 7, "lower_neighborhood_test": 7, "upper_neighborhood_train": 7, "upper_neighborhood_test": 7, "adjacency_0_train": [7, 8], "adjacency_0_test": [7, 8], "y_train": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "y_test": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "test_interv": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 23, 24, 25, 27, 28, 29, 30, 31], "num_epoch": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31], "epoch_i": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 23, 24, 25, 27, 28, 29, 30, 31], "epoch_loss": [7, 8, 9, 10, 11, 12, 16, 17, 18, 23, 24, 25, 27, 28, 29, 30, 31], "num_sampl": 7, "zip": [7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 21, 22, 28, 29, 30, 31], "dtype": [7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 28, 31], "long": [7, 13, 15, 27], "zero_grad": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "y_hat": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 23, 24, 25, 27, 28, 29, 30, 31], "argmax": [7, 13, 14, 15, 20, 21, 32], "item": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "backward": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "train_acc": [7, 13, 14, 20, 23, 24, 25, 27, 28, 31, 32], "epoch": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "4f": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 25, 27, 28, 30, 31], "flush": [7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 23, 24, 25, 27, 28, 29, 30, 31], "no_grad": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31], "test_acc": [7, 13, 14, 20, 23, 24, 25, 27, 28, 31], "6234": 7, "6794": 7, "5965": 7, "6047": 7, "6947": 7, "5953": 7, "5879": 7, "7099": 7, "5614": 7, "5801": 7, "6316": 7, "5755": [7, 14], "7405": 7, "7544": 7, "5624": [7, 23, 30], "5565": [7, 14], "7719": 7, "agg_": [8, 9, 10, 11, 26], "small": [8, 9, 10, 11, 12, 16, 17, 18, 26, 27, 28, 29, 30, 31], "3d": [8, 9, 10, 11, 12, 16, 17, 18, 26, 29, 30], "mesh": [8, 9, 10, 11, 12, 16, 17, 18, 26, 28, 29, 30, 31], "shrec": [8, 9, 10, 11, 12, 16, 17, 18, 26, 29, 30, 31], "shrec_16": [8, 9, 10, 11, 12, 16, 17, 18, 26, 28, 29, 30, 31], "kei": [8, 9, 10, 11, 12, 16, 17, 18, 26, 28, 29, 30, 31], "node_feat": [8, 9, 10, 11, 12, 14, 16, 17, 18, 23, 24, 25, 26, 27, 28, 29, 30, 31], "edge_feat": [8, 9, 10, 11, 12, 14, 16, 17, 18, 23, 24, 25, 26, 27, 28, 29, 30, 31], "face_feat": [8, 9, 10, 11, 12, 16, 17, 18, 23, 24, 25, 26, 27, 28, 29, 30, 31], "simplex": [8, 9, 10, 11, 12, 16, 17, 18, 23, 24, 25, 27, 28, 29, 31, 32], "i_complex": [8, 9, 10, 11, 12, 16, 17, 18, 26, 29, 30], "6th": [8, 9, 10, 11, 12, 16, 17, 18, 26, 30], "252": [8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 26, 29, 30], "750": [8, 9, 10, 11, 12, 14, 16, 17, 18, 26, 29, 30], "10": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "500": [8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 26, 29, 30], "messg": [8, 10, 11, 16, 17, 18, 23, 24, 30], "incidence_2_t_list": 8, "to_cell_complex": [8, 9], "incidence_2_t": [8, 26], "incidence_matrix": [8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "lin_2": [8, 9], "avg": 8, "n_face": [8, 9], "transpos": [8, 26, 29], "boundari": [8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 21, 22, 23, 24, 27, 32], "whole": [8, 9, 12, 16, 17, 18, 19, 21, 22], "averag": [8, 9, 12, 32], "0d": [8, 9], "nan": [8, 9, 14, 29], "two_dimensional_cells_mean": [8, 9], "nanmean": [8, 9], "isnan": [8, 9], "one_dimensional_cells_mean": [8, 9], "zero_dimensional_cells_mean": [8, 9], "loss_fn": [8, 10, 11, 12, 13, 15, 16, 17, 18, 20, 26, 28, 29, 30, 31], "mseloss": [8, 9, 10, 11, 12, 16, 17, 18, 26, 28, 29, 30, 31], "incidence_2_t_train": 8, "incidence_2_t_test": 8, "low": [8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 22, 23, 24, 25, 27, 28, 29, 30], "minim": [8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 22, 28], "rapid": [8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 22, 28], "test_loss": [8, 9, 10, 11, 12, 13, 16, 17, 18, 28, 29, 30, 31], "96": [8, 13, 14, 15, 19, 27], "4544": 8, "ninamiolan": [8, 27, 28, 31], "anaconda3": [8, 23, 27, 28, 29, 31], "env": [8, 23, 27, 28, 29, 31], "tmxtest": 8, "lib": [8, 15, 23, 27, 28, 29, 31], "python3": [8, 15, 27, 28, 29, 31], "site": [8, 15, 23, 27, 28, 29, 31], "536": [8, 14, 28, 31], "userwarn": [8, 20, 28, 29, 31], "lead": [8, 28, 31], "incorrect": [8, 28, 31], "due": [8, 27, 28, 31], "ensur": [8, 28, 31], "mse_loss": [8, 28, 31], "reduct": [8, 28, 31], "82": [8, 12, 13, 14, 19, 20, 27], "0496": [8, 14], "4422": [8, 14], "83": [8, 12, 13, 14, 15, 19, 27], "8916": 8, "9388": 8, "49": [8, 13, 14, 15, 19, 21, 22, 23, 27], "7630": 8, "12": [8, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32], "99": [8, 13, 14, 15, 19, 20, 27, 29, 32], "6948": 8, "84": [8, 9, 12, 13, 14, 19, 27, 31], "4177": 8, "39": [8, 13, 14, 15, 19, 20, 21, 22, 23, 27, 28, 29], "5379": [8, 23], "85": [8, 9, 12, 13, 14, 15, 19, 27], "5503": 8, "8946": 8, "6596": 8, "weisfeil": 9, "lehman": 9, "cwn_layer": 9, "cwnlayer": 9, "b_r": [9, 27], "interc": 9, "b_": [9, 26, 27], "incidence_2_list": [9, 28, 29, 31], "adjacency_1_list": 9, "incidence_1_t_list": 9, "incidence_2": [9, 28, 29, 31], "adjacency_1": [9, 29], "incidence_1_t": [9, 26], "hid_channel": 9, "hidden": [9, 10, 11, 13, 15, 16, 25, 32], "proj_0": 9, "proj_1": 9, "proj_2": 9, "neighborhood_1_to_1": 9, "neighborhood_2_to_1": 9, "neighborhood_0_to_1": 9, "elu": 9, "05": [9, 32], "criterion": [9, 14], "x_2_train": [9, 26, 28, 29], "x_2_test": [9, 26, 28], "adjacency_1_train": 9, "adjacency_1_test": 9, "incidence_2_train": [9, 28], "incidence_2_test": [9, 28], "incidence_1_t_train": 9, "incidence_1_t_test": 9, "106": [9, 14, 19, 27], "5665": 9, "4893": [9, 13], "54": [9, 13, 14, 19, 20, 23, 27], "3770": 9, "0177": 9, "6247": 9, "51": [9, 13, 14, 15, 19, 20, 23, 27], "4964": 9, "allset": [10, 11], "collect": [10, 11, 12, 13, 15, 16, 17, 18, 31], "vertex": [10, 11, 32], "let": [10, 11, 16, 17, 32], "addition": [10, 11, 27], "v_": [10, 11, 16], "multiset": [10, 11], "e_": [10, 11], "set": [10, 11, 12, 14, 17, 18, 19, 20, 21, 22, 25, 27, 32], "rule": [10, 11], "framework": [10, 11], "put": [10, 11, 27], "f_": [10, 11], "permut": [10, 11], "invari": [10, 11], "parametr": [10, 11], "learnt": [10, 11], "25": [10, 13, 14, 15, 19, 20, 21, 22, 23, 27, 32], "allset_lay": 10, "allsetlay": 10, "load_ext": [10, 11, 19, 22, 25], "autoreload": [10, 11, 19, 22, 25], "extens": [10, 22], "alreadi": [10, 22], "reload": [10, 22], "reload_ext": [10, 22], "26": [10, 13, 14, 15, 19, 21, 22, 23, 27], "what": [10, 11, 12, 16, 17, 18, 19, 21, 22, 27], "27": [10, 13, 14, 15, 19, 21, 22, 23, 27, 29], "28": [10, 13, 14, 15, 19, 21, 22, 23, 27], "n_": [10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 25, 27, 28, 31], "amtric": [10, 11, 12, 16, 17, 18], "unsign": [10, 11, 12, 16, 17, 18], "becom": [10, 11, 12, 16, 17, 18, 25], "simplciial": [10, 11, 12, 16, 17, 18], "wise": [10, 11, 12, 16, 17, 18], "29": [10, 13, 14, 15, 19, 21, 22, 23, 27], "hg_list": [10, 11, 12, 16, 17, 18, 19, 21, 22], "incidence_1_list": [10, 11, 12, 16, 17, 18, 19, 21, 22, 28, 29, 31], "sign": [10, 11, 12, 14, 16, 17, 18, 29, 32], "hg": [10, 11, 12, 16, 17, 18, 19, 21, 22], "to_hypergraph": [10, 11, 12, 14, 16, 17, 18, 19, 21, 22], "30": [10, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32], "1250": [10, 11, 14, 16, 17], "31": [10, 13, 14, 15, 19, 21, 22, 23, 27, 28], "channels_edg": [10, 12, 14, 16, 17, 18, 19, 22], "channels_nod": [10, 12, 14, 16, 17, 18, 19, 22, 23, 24, 25, 27, 28, 31], "allsetnn": 10, "in_dim": [10, 11], "hid_dim": [10, 11], "out_dim": [10, 11, 16, 21], "input_dropout": [10, 11], "mlp_num_lay": [10, 11], "mlp": [10, 11, 21], "mlp_norm": [10, 11], "hidden_channel": [10, 11, 25], "mlp_activ": 10, "mlp_dropout": [10, 11], "cidx": 10, "min": 10, "reversed_edge_index": 10, "pooled_x": [10, 11, 12, 16, 17, 18, 19, 22], "33": [10, 13, 14, 15, 19, 21, 22, 23, 27], "34": [10, 13, 14, 15, 19, 21, 22, 23, 24, 25, 27, 28, 29, 31], "incidence_1_train": [10, 11, 16, 17, 18, 19, 21, 22, 28], "incidence_1_test": [10, 11, 16, 17, 18, 19, 21, 22, 28], "35": [10, 13, 14, 15, 19, 20, 21, 22, 23, 27], "to_edge_index": [10, 11, 16, 17], "274": [10, 11, 14, 17, 18, 19], "8233": 10, "529": [10, 11, 14, 16, 17, 18], "0000": [10, 11, 14, 16, 17, 23, 24, 25, 27, 28, 31], "6125": [10, 11, 17], "repo": [11, 15, 17], "ln": 11, "rise": 11, "so": [11, 23, 24, 25, 27, 28, 31, 32], "dive": 11, "iter": 11, "Their": 11, "dimension": [11, 32], "omega": 11, "overset": [11, 25], "delta": 11, "mathbin": 11, "vert": [11, 17, 32], "mh": 11, "ba": 11, "2016": 11, "hf_": 11, "multihead": 11, "vaswani": 11, "2017": [11, 23], "perceptron": 11, "row": 11, "allset_transformer_lay": 11, "allsettransformerlay": 11, "q_n": 11, "9018": 11, "75": [12, 13, 14, 19, 20, 21, 22, 23, 27, 28], "dhgcn_layer": 12, "dhgcnlayer": 12, "76": [12, 13, 14, 19, 23, 27], "77": [12, 13, 14, 19, 23, 27, 30], "78": [12, 13, 14, 19, 23, 24, 25, 27, 28, 31], "100": [12, 13, 14, 15, 19, 20, 21, 22, 26, 27, 29, 30, 32], "dir": 12, "40": [12, 13, 14, 15, 19, 20, 21, 22, 23, 27], "81": [12, 13, 14, 19, 27], "dhgcn": 12, "dynam": 12, "global": [12, 16, 17, 18, 19, 21, 22], "node_channel": [12, 29], "86": [12, 13, 14, 15, 19, 27], "87": [12, 13, 14, 19, 27, 30], "88": [12, 13, 14, 19, 27], "8821578": 12, "6946": 12, "36521": 12, "6562": 12, "17477": 12, "7685": 12, "212": [12, 14, 19, 28], "8590": 12, "152": [12, 14, 19, 27], "9723": 12, "0999": 12, "177": [12, 14, 19, 27], "0583": [12, 14], "163": [12, 14, 19, 27], "9508": 12, "202": [12, 14, 19, 28], "9814": 12, "22": [12, 13, 14, 15, 19, 21, 22, 23, 27], "2991": 12, "livi": 13, "cora": [13, 20], "2708": 13, "academ": [13, 15], "5429": 13, "citat": [13, 20], "categori": [13, 15], "case_bas": 13, "genetic_algorithm": 13, "neural_network": 13, "probabilistic_method": 13, "reinforcement_learn": 13, "rule_learn": 13, "theori": 13, "1433": [13, 14], "stand": [13, 15], "uniqu": [13, 14, 15, 29], "word": [13, 15], "presenc": [13, 15], "planetoid": 13, "metric": [13, 14, 15], "accuracy_scor": [13, 15], "hmpnn_layer": 13, "hmpnnlayer": 13, "24": [13, 14, 15, 19, 21, 22, 23, 27], "download": [13, 15, 20, 22, 28], "val": [13, 19, 21, 22, 32], "below": [13, 21, 32], "sparse_coo_tensor": [13, 15], "hidden_featur": [13, 15], "tupl": [13, 32], "gradual": 13, "reduc": [13, 28], "last": [13, 27, 31, 32], "adjacency_dropout_r": 13, "rate": [13, 15], "regular_dropout_r": 13, "regular": 13, "to_hidden_linear": [13, 15], "sequenti": [13, 15, 21], "adjacency_dropout": 13, "updating_dropout": 13, "to_categories_linear": [13, 15], "n_hyperedg": [13, 15], "b1": [13, 14, 23, 24, 27, 28, 29, 31], "y_pred": [13, 15, 20, 23, 24, 25, 27, 28, 31], "logit": [13, 14, 15, 20, 31], "hyperparamet": [13, 15, 20], "manual_se": [13, 32], "41": [13, 14, 15, 19, 21, 22, 23, 27], "256": [13, 14, 19], "01": [13, 20, 23, 28, 31, 32], "train_y_tru": [13, 15], "train_mask": [13, 15], "val_y_tru": 13, "val_mask": 13, "initial_x_1": 13, "zeros_lik": 13, "y_pred_logit": [13, 15], "train_loss": [13, 32], "eval": [13, 15, 19, 20, 21, 22, 32], "val_loss": [13, 32], "val_acc": [13, 32], "acc": [13, 15], "2f": [13, 15], "1079": [13, 14], "14": [13, 14, 15, 16, 19, 20, 21, 22, 23, 26, 27, 28, 31, 32], "1436": [13, 14], "0234": 13, "15": [13, 14, 15, 18, 19, 20, 21, 22, 23, 26, 27, 28, 31, 32], "1016": [13, 14], "9800": 13, "0681": [13, 14], "9504": 13, "18": [13, 14, 15, 19, 20, 21, 22, 23, 26, 27, 31], "0389": [13, 14], "9194": 13, "21": [13, 14, 15, 19, 21, 22, 23, 26, 27, 30], "0137": 13, "9241": 13, "19": [13, 14, 15, 19, 21, 22, 23, 26, 27, 29, 32], "9917": 13, "8917": 13, "9729": 13, "8710": 13, "23": [13, 14, 15, 19, 21, 22, 23, 27], "9556": 13, "8574": 13, "9402": 13, "8646": 13, "9265": 13, "8540": 13, "9136": 13, "8430": 13, "9012": 13, "8336": 13, "8886": 13, "8405": 13, "8775": 13, "8264": 13, "8668": 13, "8065": 13, "8562": 13, "37": [13, 14, 15, 19, 20, 21, 22, 23, 27], "8158": 13, "8456": 13, "7957": 13, "44": [13, 14, 15, 19, 21, 22, 23, 27, 31], "8346": 13, "8028": 13, "8249": 13, "20": [13, 14, 15, 19, 20, 21, 22, 23, 26, 27, 32], "7882": 13, "8156": 13, "42": [13, 14, 15, 19, 21, 22, 23, 27, 28], "7912": 13, "8070": 13, "7610": 13, "46": [13, 14, 15, 19, 21, 22, 23, 27], "7987": 13, "7617": 13, "47": [13, 14, 15, 19, 21, 22, 23, 27, 31], "7905": 13, "7596": 13, "7830": 13, "7391": 13, "7740": 13, "7315": 13, "7655": 13, "7365": 13, "7565": 13, "43": [13, 14, 15, 19, 21, 22, 23, 27, 29], "7184": 13, "48": [13, 14, 15, 19, 21, 22, 23, 27], "7459": 13, "7085": 13, "7367": 13, "45": [13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31], "6815": [13, 14], "7279": 13, "6673": 13, "50": [13, 14, 15, 19, 20, 21, 22, 23, 27], "7178": 13, "6846": 13, "7077": 13, "6483": 13, "7000": [13, 27], "6436": 13, "6971": 13, "6353": 13, "6991": 13, "6336": 13, "6982": 13, "5938": 13, "60": [13, 14, 19, 23, 27, 32], "6980": 13, "5886": 13, "56": [13, 14, 19, 23, 27], "6979": 13, "5974": 13, "55": [13, 14, 19, 23, 27], "6881": [13, 14], "5600": 13, "52": [13, 14, 19, 20, 23, 27], "6694": 13, "5445": 13, "6513": 13, "5501": 13, "6308": 13, "5397": [13, 23], "6141": 13, "5096": 13, "6020": 13, "4992": 13, "5915": [13, 14], "5020": 13, "58": [13, 14, 19, 23, 27], "5829": 13, "4710": 13, "5747": 13, "4608": 13, "67": [13, 14, 15, 19, 23, 27, 28], "5703": 13, "4341": 13, "62": [13, 14, 19, 23, 27, 28], "5632": 13, "4428": 13, "66": [13, 14, 15, 19, 23, 27], "5630": 13, "4209": 13, "5502": 13, "4151": 13, "63": [13, 14, 19, 27], "5303": 13, "53": [13, 14, 19, 20, 23, 27], "4090": 13, "5051": 13, "4021": 13, "3847": 13, "65": [13, 14, 19, 23, 27], "4842": 13, "3907": 13, "61": [13, 14, 19, 23, 27], "4849": 13, "57": [13, 14, 15, 19, 23, 27], "3434": 13, "70": [13, 14, 19, 23, 27], "4866": 13, "3253": 13, "69": [13, 14, 19, 23, 27], "4864": 13, "3380": 13, "4896": 13, "2933": 13, "4921": 13, "3124": 13, "68": [13, 14, 19, 23, 27], "4948": 13, "3091": 13, "4931": 13, "2768": 13, "4881": 13, "2749": 13, "4827": [13, 14], "2740": 13, "4833": 13, "2773": 13, "4744": 13, "2430": 13, "4646": 13, "4648": 13, "1958": [13, 14], "4734": 13, "1895": [13, 14], "71": [13, 14, 19, 23, 27], "4748": 13, "2008": 13, "4760": 13, "72": [13, 14, 19, 23, 27], "1573": [13, 14], "74": [13, 14, 19, 23, 27, 28], "4385": 13, "73": [13, 14, 19, 23, 27, 28], "1751": [13, 14], "4242": 13, "1889": [13, 14], "4183": 13, "1762": [13, 14], "4250": 13, "1737": [13, 14], "4471": 13, "1242": [13, 14], "4559": 13, "0648": [13, 14], "4498": 13, "0717": [13, 14, 31], "4506": 13, "0568": [13, 14, 15], "4410": 13, "0650": [13, 14, 23], "4375": 13, "0475": [13, 14], "4441": 13, "0293": [13, 27], "4450": 13, "0494": [13, 14], "4622": 13, "0200": 13, "4609": 13, "0358": [13, 14], "4645": 13, "9877": 13, "0173": 13, "4788": 13, "89": [13, 14, 15, 19, 27], "9744": 13, "4970": 13, "90": [13, 14, 19, 27], "9497": 13, "4981": 13, "91": [13, 14, 15, 19, 27], "9345": 13, "4736": 13, "92": [13, 14, 19, 27], "9636": 13, "4339": 13, "93": [13, 14, 15, 19, 20, 27, 29], "9197": 13, "4162": 13, "94": [13, 14, 15, 19, 27], "8984": 13, "3813": 13, "95": [13, 14, 15, 19, 27], "8895": 13, "3547": 13, "9048": 13, "3499": 13, "97": [13, 14, 15, 19, 27, 29, 30], "8737": 13, "3502": [13, 15], "98": [13, 14, 15, 19, 27], "9479": 13, "3518": 13, "8906": 13, "3639": 13, "8589": 13, "3789": 13, "against": [13, 15], "test_y_tru": [13, 15], "test_mask": [13, 15], "2982": 13, "karateclub": [14, 23, 24, 25, 27, 28], "w": [14, 16, 25], "hnhn_layer": 14, "hnhnlayer": [14, 15], "matplotlib": [14, 15, 32], "pyplot": [14, 15, 32], "plt": [14, 15, 32], "www": [14, 22, 23, 24, 25, 27, 28], "jstor": [14, 23, 24, 25, 27, 28], "stabl": [14, 15, 23, 24, 25, 27, 28], "3629752": [14, 23, 24, 25, 27, 28], "singular": [14, 23, 24, 25, 27, 28], "social": [14, 23, 24, 25, 27, 28], "group": [14, 23, 24, 25, 27, 28], "dataset_sim": 14, "karate_club": [14, 23, 24, 25, 27, 28, 31], "complex_typ": [14, 23, 24, 25, 27, 28, 31], "dataset_hyp": 14, "santii": [14, 23, 24], "classifi": [14, 15, 20], "channels_": 14, "hot": [14, 23, 24, 25, 28], "get_simplex_attribut": [14, 23, 24, 25, 27, 28, 31], "n_class": [14, 26, 29], "y_1h": 14, "ey": [14, 20, 23, 27], "astyp": 14, "stratifi": 14, "ind_train": 14, "ind_test": 14, "arang": 14, "random_st": 14, "float32": [14, 18, 20], "int32": 14, "fraction": 14, "hnhnnetwork": 14, "multiclass": 14, "hypernod": 14, "softmax": [14, 20, 25, 31, 32], "1e": [14, 19, 22, 32], "2000": [14, 28], "get_accuraci": 14, "lambda": 14, "yhat": 14, "ytrue": 14, "full": 14, "y_hat_cl": 14, "nloss": 14, "ntrain_acc": 14, "7157": 14, "5000": [14, 27, 28], "7135": 14, "7113": 14, "7093": 14, "7074": 14, "7056": 14, "7039": [14, 24], "7024": 14, "7010": 14, "6997": 14, "6985": 14, "6975": 14, "6966": 14, "6958": 14, "6951": 14, "6945": 14, "6940": 14, "6936": 14, "6933": 14, "6931": 14, "6930": 14, "6929": 14, "6928": 14, "6932": 14, "6927": 14, "6926": 14, "6925": 14, "6924": 14, "6429": 14, "6923": 14, "6922": 14, "6921": 14, "6920": 14, "6919": 14, "8571": 14, "9643": 14, "6918": [14, 25], "7500": [14, 23, 27, 28], "6917": 14, "5714": 14, "5357": 14, "6916": 14, "6915": 14, "6914": 14, "6913": 14, "6912": 14, "6911": 14, "6910": 14, "6909": 14, "6908": 14, "6667": [14, 27], "101": [14, 19, 27], "6907": 14, "102": [14, 19, 27], "103": [14, 19, 27, 29], "6906": 14, "104": [14, 19, 27, 30], "105": [14, 19, 27, 29, 31], "6905": 14, "107": [14, 19, 27], "6904": 14, "108": [14, 19, 20, 27], "109": [14, 19, 20, 27], "6903": 14, "110": [14, 19, 20, 27], "6902": 14, "111": [14, 19, 20, 27], "112": [14, 19, 27], "6901": 14, "113": [14, 19, 27, 29], "114": [14, 19, 27], "6900": 14, "115": [14, 19, 27], "6899": 14, "116": [14, 19, 27], "117": [14, 19, 27], "6898": 14, "118": [14, 19, 27], "6897": 14, "119": [14, 19, 27], "120": [14, 19, 27], "6896": 14, "121": [14, 19, 20, 27], "6895": 14, "122": [14, 19, 27], "6894": 14, "123": [14, 19, 27], "124": [14, 19, 27], "6893": 14, "125": [14, 19, 27], "6892": 14, "126": [14, 19, 27], "6891": [14, 27], "127": [14, 19, 27, 31], "6890": 14, "129": [14, 19, 27], "6889": 14, "130": [14, 19, 27], "6888": 14, "131": [14, 19, 27], "6887": 14, "132": [14, 19, 27], "6886": 14, "133": [14, 19, 20, 27], "134": [14, 19, 27], "6885": 14, "135": [14, 19, 27], "6884": 14, "136": [14, 19, 27], "6883": 14, "137": [14, 19, 27], "6882": 14, "138": [14, 19, 27], "139": [14, 19, 27, 31], "6880": 14, "140": [14, 19, 20, 27], "6879": [14, 23], "141": [14, 19, 27], "6878": 14, "142": [14, 19, 27], "6877": 14, "143": [14, 19, 23, 27, 28], "6876": 14, "144": [14, 19, 27], "6875": [14, 19], "145": [14, 19, 27], "6874": 14, "146": [14, 19, 27], "6873": 14, "147": [14, 19, 27, 30], "6871": 14, "148": [14, 19, 27], "6870": 14, "149": [14, 19, 27], "6869": 14, "150": [14, 19, 27, 32], "6868": 14, "151": [14, 19, 27], "6867": 14, "6865": 14, "153": [14, 19, 27], "6864": 14, "154": [14, 19, 27], "6863": 14, "155": [14, 19, 27], "6861": 14, "156": [14, 19, 27], "6860": 14, "157": [14, 19, 27], "6859": 14, "158": [14, 19, 27], "6857": 14, "159": [14, 19, 27], "6856": 14, "160": [14, 19, 27], "6855": 14, "161": [14, 19, 27], "6853": 14, "162": [14, 19, 27], "6852": 14, "6850": 14, "164": [14, 19, 27], "6849": 14, "165": [14, 19, 27], "6847": 14, "166": [14, 19, 27], "6845": 14, "167": [14, 19, 27], "6844": 14, "168": [14, 19, 27], "6842": 14, "169": [14, 19, 27], "6840": 14, "170": [14, 19, 27], "6839": 14, "171": [14, 19, 27], "6837": 14, "172": [14, 19, 27], "6835": 14, "173": [14, 19, 27], "6833": 14, "174": [14, 19, 27], "6831": 14, "175": [14, 19, 27], "6829": 14, "176": [14, 19, 27, 31], "6827": 14, "6825": 14, "178": [14, 19, 27], "6823": 14, "179": [14, 19, 27], "6821": 14, "180": [14, 19, 27], "6819": 14, "181": [14, 19, 27], "6817": 14, "182": [14, 19, 27], "183": [14, 19, 27], "6813": 14, "184": [14, 19, 27], "6810": 14, "185": [14, 19, 20, 27], "6808": 14, "186": [14, 19, 27], "6806": 14, "187": [14, 19, 27], "6803": 14, "6801": 14, "189": [14, 19, 27], "6799": 14, "190": [14, 19, 27], "6796": 14, "191": [14, 19, 27], "6793": 14, "192": [14, 19, 27], "6791": 14, "193": [14, 19, 27], "6788": 14, "194": [14, 19, 27], "6785": 14, "195": [14, 19, 27], "6783": 14, "196": [14, 19, 27], "6780": 14, "197": [14, 19, 27], "6777": 14, "198": [14, 19, 27, 30], "6774": 14, "199": [14, 19, 20, 27], "6771": 14, "200": [14, 15, 19, 20, 27], "6768": 14, "201": [14, 19], "6765": 14, "6762": 14, "203": [14, 19], "6758": 14, "204": [14, 19], "6755": 14, "205": [14, 19], "6752": 14, "206": [14, 19], "6748": 14, "207": [14, 19], "6745": 14, "208": [14, 19], "6741": 14, "209": [14, 19], "6738": 14, "210": [14, 19], "6734": 14, "211": [14, 19], "6730": 14, "6726": 14, "213": [14, 19], "6723": 14, "214": [14, 19], "6719": 14, "215": [14, 19], "6715": 14, "216": [14, 19], "6710": 14, "217": [14, 19, 28], "6706": 14, "218": [14, 19], "6702": 14, "6786": 14, "219": [14, 19], "6698": 14, "220": [14, 19], "6693": 14, "221": [14, 19], "6689": 14, "222": [14, 19], "6684": 14, "223": [14, 19], "6679": 14, "224": [14, 19], "6675": 14, "225": [14, 19], "6670": 14, "226": [14, 19], "6665": 14, "227": [14, 19, 30], "6660": 14, "228": [14, 19], "6655": 14, "229": [14, 19], "6649": 14, "230": [14, 19], "6644": 14, "231": [14, 19], "6639": 14, "232": [14, 19, 30], "6633": 14, "233": [14, 19], "6628": 14, "234": [14, 19], "6622": 14, "235": [14, 19], "6616": 14, "236": [14, 19], "6610": 14, "237": [14, 19], "6604": 14, "238": [14, 19], "6598": 14, "239": [14, 19], "6592": 14, "240": [14, 19], "6585": 14, "7143": 14, "241": [14, 19], "6579": 14, "242": [14, 19], "6572": 14, "243": [14, 19], "6566": 14, "244": [14, 19], "6559": 14, "245": [14, 19], "6552": 14, "246": [14, 19], "6545": 14, "247": [14, 19], "6538": 14, "248": [14, 19], "6531": 14, "249": [14, 19], "6523": 14, "250": [14, 19], "6516": 14, "8214": 14, "251": [14, 19], "6508": 14, "6500": 14, "253": [14, 19], "6492": 14, "254": [14, 19], "6484": 14, "255": [14, 19], "6476": 14, "6468": 14, "257": [14, 19], "6459": 14, "258": [14, 19], "6451": 14, "259": [14, 19], "6442": 14, "260": [14, 19], "6433": 14, "261": [14, 19], "6424": 14, "262": [14, 19], "6415": 14, "263": [14, 19], "6406": 14, "264": [14, 19], "6397": 14, "265": [14, 19], "6387": 14, "266": [14, 19], "6378": 14, "267": [14, 19], "6368": 14, "268": [14, 19], "6358": 14, "269": [14, 19], "6348": 14, "270": [14, 19, 23], "6337": 14, "271": [14, 19], "6327": 14, "272": [14, 19], "6317": 14, "273": [14, 19], "6306": 14, "6295": 14, "275": [14, 17, 19], "6284": [14, 27], "276": [14, 19], "6273": 14, "277": [14, 19], "6262": 14, "278": [14, 16, 19], "6250": 14, "279": [14, 19], "6239": 14, "280": [14, 19], "6227": 14, "281": [14, 16, 19], "6215": 14, "282": [14, 16, 19, 30], "6203": 14, "283": [14, 19], "6191": 14, "284": [14, 19], "6178": 14, "285": [14, 19], "6166": 14, "286": [14, 19], "6153": 14, "287": [14, 19], "6140": 14, "288": [14, 19], "6127": 14, "289": [14, 19], "6114": 14, "290": [14, 19], "6101": 14, "291": [14, 19], "6088": 14, "292": [14, 19], "6074": 14, "293": [14, 19], "6060": 14, "294": [14, 19], "6046": [14, 15], "295": [14, 19], "6032": 14, "296": [14, 19], "6018": 14, "297": [14, 19], "6004": 14, "298": [14, 19], "5989": 14, "299": [14, 19], "5975": 14, "300": [14, 19], "5960": 14, "301": [14, 19], "5945": 14, "302": [14, 19, 20], "5930": 14, "303": [14, 19], "304": [14, 19, 30], "5900": 14, "305": [14, 19], "5884": 14, "306": [14, 19], "5868": 14, "307": [14, 19], "5853": 14, "308": [14, 19], "5837": 14, "309": [14, 19], "5821": 14, "310": [14, 19], "5805": [14, 23], "311": [14, 19], "5788": 14, "312": [14, 19], "5772": 14, "313": [14, 19], "314": [14, 19], "5739": 14, "315": [14, 19], "5722": 14, "316": [14, 19], "5705": 14, "317": [14, 19], "5688": 14, "318": [14, 19], "5671": 14, "319": [14, 19], "5653": 14, "320": [14, 19], "5636": 14, "321": [14, 19], "5618": 14, "322": [14, 19], "5601": 14, "323": [14, 19], "5583": 14, "324": [14, 19], "325": [14, 19], "5547": 14, "326": [14, 19], "5529": 14, "327": [14, 19], "5511": 14, "328": [14, 19], "5492": 14, "329": [14, 19], "5474": 14, "330": [14, 19], "5455": 14, "331": [14, 19], "5437": 14, "332": [14, 19], "5418": 14, "333": [14, 19], "5399": 14, "334": [14, 19], "5381": 14, "335": [14, 19], "5362": [14, 23], "336": [14, 19], "5343": 14, "337": [14, 19], "5323": 14, "338": [14, 19], "5304": 14, "339": [14, 19], "5285": 14, "340": [14, 19], "5266": 14, "8929": 14, "341": [14, 19], "5246": [14, 23], "342": [14, 19], "5227": 14, "343": [14, 19], "5207": 14, "344": [14, 19], "5188": [14, 23], "345": [14, 19], "5168": 14, "346": [14, 19], "5148": 14, "347": [14, 19], "5129": 14, "348": [14, 19], "5109": 14, "349": [14, 19], "5089": 14, "350": [14, 19], "5069": 14, "9286": 14, "351": [14, 19], "5049": 14, "352": [14, 19], "5029": 14, "353": [14, 19], "5009": 14, "354": [14, 19], "4989": 14, "355": [14, 19], "4969": 14, "356": [14, 19], "4949": 14, "357": [14, 19], "4928": 14, "358": [14, 19], "4908": 14, "359": [14, 19], "4888": 14, "360": [14, 19], "4868": 14, "361": [14, 19], "4847": 14, "362": [14, 19], "363": [14, 19], "4807": 14, "364": [14, 19], "4787": 14, "365": [14, 19], "4766": 14, "366": [14, 19], "4746": 14, "367": [14, 19], "4726": 14, "368": [14, 19], "4705": 14, "369": [14, 19], "4685": 14, "370": [14, 19], "4665": 14, "371": [14, 19], "4644": 14, "372": [14, 19], "4624": 14, "373": [14, 19], "4604": 14, "374": [14, 19], "4583": 14, "375": [14, 19], "4563": 14, "376": [14, 19], "4543": 14, "377": [14, 19], "4523": 14, "378": [14, 19], "4503": 14, "379": [14, 19], "4482": 14, "380": [14, 19], "4462": 14, "381": [14, 19], "4442": 14, "382": [14, 19], "383": [14, 19], "4402": 14, "384": [14, 19], "4382": 14, "385": [14, 19], "4362": 14, "386": [14, 19], "4342": 14, "387": [14, 19], "4322": 14, "388": [14, 19], "4302": 14, "389": [14, 19], "4282": 14, "390": [14, 19], "4262": 14, "391": [14, 19], "4243": 14, "392": [14, 19], "4223": 14, "393": [14, 19], "4203": 14, "394": [14, 19], "4184": 14, "395": [14, 19, 20], "4164": 14, "396": [14, 19], "4145": 14, "397": [14, 19], "4125": 14, "398": [14, 19], "4106": 14, "399": [14, 19], "4086": 14, "400": [14, 15, 19], "4067": 14, "401": [14, 19], "4048": 14, "402": [14, 19], "4029": 14, "403": [14, 19], "4010": 14, "404": [14, 19], "3991": 14, "405": [14, 19], "3972": 14, "406": [14, 19, 28], "3953": 14, "407": [14, 19], "3934": 14, "408": [14, 19], "3915": 14, "409": [14, 19], "3897": 14, "410": [14, 19], "3878": 14, "411": [14, 19], "3859": 14, "412": [14, 19], "3841": 14, "413": [14, 19], "3823": 14, "3804": 14, "415": [14, 19], "3786": 14, "416": [14, 19], "3768": 14, "417": [14, 19], "3750": [14, 16], "418": [14, 19], "3732": 14, "419": [14, 19], "3714": 14, "420": [14, 19], "3696": 14, "421": [14, 19], "3678": 14, "422": [14, 19], "3661": 14, "423": [14, 19], "3643": 14, "424": [14, 19], "3626": 14, "425": [14, 19], "3608": 14, "426": [14, 19], "3591": 14, "427": [14, 19], "3573": 14, "428": [14, 19], "3556": 14, "429": [14, 19], "3539": 14, "430": [14, 19], "3522": 14, "431": [14, 19], "3505": 14, "432": [14, 19], "3488": 14, "433": [14, 19], "3472": 14, "434": [14, 19], "3455": 14, "435": [14, 19], "3438": 14, "436": [14, 19], "3422": 14, "437": [14, 19], "3406": 14, "438": [14, 19], "3389": 14, "439": [14, 19], "3373": 14, "440": [14, 19], "3357": 14, "441": [14, 19], "3341": 14, "442": [14, 19], "3325": 14, "443": [14, 19, 20], "3309": 14, "444": [14, 19], "3293": 14, "445": [14, 19], "3278": 14, "446": [14, 19], "3262": 14, "447": [14, 19], "3247": 14, "448": [14, 19], "3231": 14, "449": [14, 19], "3216": 14, "450": [14, 19], "3201": 14, "451": [14, 19], "3185": 14, "452": [14, 19], "3170": 14, "453": [14, 19], "3155": 14, "454": [14, 19], "3140": 14, "455": [14, 19], "3126": 14, "456": [14, 19], "3111": 14, "457": [14, 19], "3096": 14, "458": [14, 19], "3082": 14, "459": [14, 19], "3067": 14, "460": [14, 19], "3053": 14, "461": [14, 19], "3039": 14, "462": [14, 19], "3025": 14, "463": [14, 19], "3011": 14, "464": [14, 19], "2997": 14, "465": [14, 19], "2983": 14, "466": [14, 19], "2969": 14, "467": [14, 19], "2955": 14, "468": [14, 19], "2941": 14, "469": [14, 19], "2928": 14, "470": [14, 19], "2914": [14, 15], "471": [14, 19], "2901": 14, "472": [14, 19], "2888": 14, "473": [14, 19], "2874": 14, "474": [14, 19], "2861": 14, "475": [14, 19], "2848": 14, "476": [14, 19], "2835": 14, "477": [14, 19], "2822": 14, "478": [14, 19], "2810": 14, "479": [14, 19], "2797": 14, "480": [14, 19], "2784": 14, "481": [14, 19], "2772": 14, "482": [14, 19], "2759": 14, "483": [14, 19], "2747": 14, "484": [14, 19], "2735": 14, "485": [14, 19], "2722": 14, "486": [14, 19], "2710": 14, "487": [14, 19], "2698": 14, "488": [14, 19], "2686": 14, "489": [14, 19], "2674": 14, "490": [14, 19], "2662": 14, "491": [14, 19], "2651": 14, "492": [14, 19], "2639": 14, "493": [14, 19], "2627": 14, "494": [14, 19], "2616": 14, "495": [14, 19], "2604": 14, "496": [14, 19], "2593": 14, "497": [14, 19], "2582": 14, "498": [14, 19], "2571": 14, "499": [14, 19], "2559": 14, "2548": 14, "501": 14, "2537": 14, "502": 14, "2526": 14, "503": 14, "2516": 14, "504": 14, "2505": 14, "505": 14, "2494": 14, "506": 14, "2484": 14, "507": 14, "2473": 14, "508": 14, "2463": 14, "509": 14, "2452": [14, 15], "510": 14, "2442": 14, "511": 14, "2432": 14, "512": 14, "2421": 14, "513": 14, "2411": 14, "514": [14, 30], "2401": 14, "515": 14, "2391": 14, "516": 14, "2381": 14, "517": 14, "2371": 14, "518": 14, "2362": 14, "519": 14, "2352": 14, "520": 14, "2342": 14, "521": 14, "2333": [14, 28], "522": 14, "2323": 14, "523": 14, "2314": 14, "524": 14, "525": 14, "2295": 14, "526": 14, "2286": 14, "527": 14, "2276": 14, "528": 14, "2267": 14, "2258": 14, "530": 14, "2249": 14, "531": 14, "2240": 14, "532": 14, "2231": [14, 15], "533": 14, "2223": 14, "534": 14, "2214": 14, "535": 14, "2205": 14, "2196": 14, "537": 14, "2188": 14, "538": 14, "2179": 14, "539": 14, "2171": 14, "540": 14, "2162": 14, "541": 14, "2154": 14, "542": 14, "2146": 14, "543": 14, "2137": 14, "544": 14, "2129": 14, "545": 14, "2121": 14, "546": [14, 29], "2113": 14, "547": 14, "2105": 14, "548": 14, "2097": 14, "549": 14, "2089": 14, "550": 14, "2081": 14, "551": 14, "2073": 14, "552": 14, "2066": 14, "553": 14, "2058": 14, "554": 14, "2050": 14, "555": 14, "2043": 14, "556": 14, "2035": 14, "557": 14, "2028": 14, "558": 14, "559": 14, "2013": 14, "560": 14, "2005": 14, "561": 14, "1998": 14, "562": 14, "1991": 14, "563": 14, "1983": 14, "564": 14, "1976": 14, "565": 14, "1969": 14, "566": 14, "1962": [14, 23], "567": 14, "1955": 14, "568": 14, "1948": 14, "569": 14, "1941": 14, "570": 14, "1934": 14, "571": 14, "1927": 14, "572": 14, "1921": 14, "573": 14, "1914": 14, "574": 14, "1907": 14, "575": 14, "1900": 14, "576": 14, "1894": 14, "577": 14, "1887": 14, "578": 14, "1881": 14, "579": 14, "1874": 14, "580": 14, "1868": 14, "581": 14, "1861": 14, "582": 14, "1855": 14, "583": 14, "1849": 14, "584": 14, "1842": 14, "585": 14, "1836": [14, 23], "586": 14, "1830": 14, "587": 14, "1824": 14, "588": 14, "1818": 14, "589": 14, "1811": 14, "590": 14, "1805": 14, "591": 14, "1799": 14, "592": 14, "1793": 14, "593": 14, "1788": 14, "594": 14, "1782": 14, "595": 14, "1776": 14, "596": 14, "1770": 14, "597": 14, "1764": 14, "598": 14, "1758": 14, "599": 14, "1753": 14, "600": 14, "1747": 14, "601": 14, "1741": 14, "602": 14, "1736": 14, "603": 14, "1730": [14, 23], "604": 14, "1725": [14, 23], "605": 14, "1719": 14, "606": 14, "1714": 14, "607": 14, "1708": 14, "608": 14, "1703": 14, "609": 14, "1697": 14, "610": 14, "1692": 14, "611": 14, "1687": 14, "612": 14, "1682": 14, "613": [14, 32], "1676": 14, "614": 14, "1671": 14, "615": 14, "1666": 14, "616": 14, "1661": 14, "617": 14, "1656": 14, "618": 14, "1651": 14, "619": 14, "1646": 14, "620": 14, "1640": 14, "621": 14, "1636": 14, "622": 14, "1631": 14, "623": 14, "1626": 14, "624": 14, "1621": 14, "625": [14, 19], "1616": 14, "626": 14, "1611": 14, "627": 14, "1606": 14, "628": 14, "1601": 14, "629": 14, "1597": 14, "630": 14, "1592": 14, "631": 14, "1587": 14, "632": 14, "1583": 14, "633": 14, "1578": 14, "634": 14, "635": 14, "1569": 14, "636": 14, "1564": 14, "637": 14, "1560": [14, 23], "638": 14, "1555": 14, "639": 14, "1551": 14, "640": 14, "1546": 14, "641": 14, "1542": 14, "642": 14, "1537": 14, "643": 14, "1533": 14, "644": 14, "1529": 14, "645": 14, "1524": 14, "646": 14, "1520": 14, "647": 14, "1516": [14, 27], "648": 14, "1511": [14, 23], "649": 14, "1507": 14, "650": 14, "1503": 14, "651": 14, "1499": 14, "652": 14, "1495": [14, 23], "653": 14, "1491": 14, "654": 14, "1487": [14, 23], "655": 14, "1482": 14, "656": 14, "1478": 14, "657": 14, "1474": [14, 23], "658": 14, "1470": 14, "659": 14, "1466": 14, "660": 14, "1462": 14, "661": 14, "1458": 14, "662": 14, "1454": 14, "663": 14, "1451": 14, "664": 14, "1447": 14, "665": 14, "1443": 14, "666": 14, "1439": 14, "667": 14, "1435": 14, "668": 14, "1431": 14, "669": 14, "1428": 14, "670": 14, "1424": 14, "671": 14, "1420": 14, "672": 14, "1416": 14, "673": 14, "1413": 14, "674": 14, "1409": 14, "675": 14, "1405": 14, "676": 14, "1402": 14, "677": 14, "1398": 14, "678": 14, "1395": 14, "679": 14, "1391": 14, "680": 14, "1387": 14, "681": 14, "1384": 14, "682": 14, "1380": [14, 23], "683": 14, "1377": 14, "684": 14, "1373": 14, "685": 14, "1370": 14, "686": 14, "1367": 14, "687": 14, "1363": 14, "688": 14, "1360": 14, "689": 14, "1356": [14, 23], "690": 14, "1353": 14, "691": 14, "1350": 14, "692": 14, "1346": 14, "693": 14, "1343": [14, 23], "694": 14, "1340": 14, "695": 14, "1336": 14, "696": 14, "1333": [14, 28], "697": 14, "1330": 14, "698": 14, "1327": 14, "699": 14, "1323": 14, "700": 14, "1320": 14, "701": 14, "1317": 14, "702": 14, "1314": 14, "703": 14, "1311": 14, "704": 14, "1308": 14, "705": 14, "1304": 14, "706": 14, "1301": 14, "707": 14, "1298": 14, "708": 14, "1295": 14, "709": 14, "1292": 14, "710": 14, "1289": 14, "711": 14, "1286": 14, "712": 14, "1283": [14, 27], "713": 14, "1280": 14, "714": 14, "1277": 14, "715": 14, "1274": 14, "716": 14, "1271": 14, "717": 14, "1268": 14, "718": 14, "1265": 14, "719": 14, "1263": 14, "720": 14, "1260": 14, "721": 14, "1257": [14, 27], "722": 14, "1254": 14, "723": 14, "1251": 14, "724": 14, "1248": 14, "725": 14, "1245": 14, "726": 14, "1243": 14, "727": 14, "1240": 14, "728": 14, "1237": 14, "729": 14, "1234": 14, "730": 14, "1232": 14, "731": 14, "1229": 14, "732": 14, "1226": 14, "733": 14, "1223": 14, "734": 14, "1221": 14, "735": 14, "1218": 14, "736": 14, "1215": 14, "737": 14, "1213": 14, "738": 14, "1210": 14, "739": 14, "1207": 14, "740": 14, "1205": 14, "741": 14, "1202": 14, "742": 14, "1200": [14, 32], "743": 14, "1197": 14, "744": 14, "1194": 14, "745": 14, "1192": 14, "746": 14, "1189": 14, "747": 14, "1187": 14, "748": 14, "1184": 14, "749": 14, "1182": 14, "1179": [14, 23], "751": 14, "1177": 14, "752": 14, "1174": 14, "753": 14, "1172": 14, "754": 14, "1169": 14, "755": 14, "1167": 14, "756": 14, "1165": 14, "757": 14, "1162": 14, "758": 14, "1160": 14, "759": 14, "1157": 14, "760": 14, "1155": 14, "761": 14, "1153": 14, "762": 14, "1150": 14, "763": 14, "1148": 14, "764": 14, "1146": 14, "765": 14, "1143": 14, "766": 14, "1141": 14, "767": 14, "1139": [14, 15], "768": 14, "1136": [14, 27], "769": 14, "1134": 14, "770": 14, "1132": 14, "771": 14, "1130": 14, "772": 14, "1127": 14, "773": 14, "1125": 14, "774": 14, "1123": 14, "775": 14, "1121": 14, "776": 14, "1118": 14, "777": 14, "1116": 14, "778": 14, "1114": 14, "779": 14, "1112": 14, "780": 14, "1110": 14, "781": 14, "1107": [14, 15], "782": 14, "1105": 14, "783": 14, "1103": 14, "784": 14, "1101": [14, 27], "785": 14, "1099": 14, "786": 14, "1097": 14, "787": 14, "1095": 14, "788": 14, "1093": 14, "789": 14, "1090": 14, "790": 14, "1088": 14, "791": 14, "1086": 14, "792": 14, "1084": 14, "793": 14, "1082": 14, "794": 14, "1080": [14, 23], "795": [14, 15], "1078": 14, "796": 14, "1076": 14, "797": 14, "1074": 14, "798": 14, "1072": 14, "799": 14, "1070": 14, "800": 14, "1068": 14, "801": 14, "1066": 14, "802": 14, "1064": 14, "803": 14, "1062": 14, "804": 14, "1060": 14, "805": [14, 15], "1058": 14, "806": 14, "1056": 14, "807": 14, "1054": 14, "808": 14, "1052": 14, "809": 14, "1050": 14, "810": 14, "1049": 14, "811": 14, "1047": 14, "812": 14, "1045": 14, "813": 14, "1043": 14, "814": 14, "1041": 14, "815": 14, "1039": 14, "816": 14, "1037": 14, "817": 14, "1035": 14, "818": 14, "1033": 14, "819": 14, "1032": 14, "820": 14, "1030": 14, "821": 14, "1028": 14, "822": 14, "1026": 14, "823": 14, "1024": 14, "824": 14, "1023": [14, 23], "825": 14, "1021": 14, "826": 14, "1019": [14, 23], "827": 14, "1017": 14, "828": 14, "1015": 14, "829": 14, "1014": 14, "830": 14, "1012": [14, 23], "831": 14, "1010": 14, "832": 14, "1008": 14, "833": 14, "1007": 14, "834": 14, "1005": 14, "835": 14, "1003": 14, "836": 14, "1001": 14, "837": 14, "1000": [14, 32], "838": 14, "0998": [14, 23], "839": 14, "0996": [14, 23], "840": 14, "0995": 14, "841": 14, "0993": 14, "842": 14, "0991": 14, "843": 14, "0990": 14, "844": 14, "0988": 14, "845": 14, "0986": 14, "846": 14, "0985": 14, "847": 14, "0983": 14, "848": 14, "0981": 14, "849": 14, "0980": 14, "850": 14, "0978": 14, "851": 14, "0976": 14, "852": 14, "0975": 14, "853": 14, "0973": 14, "854": 14, "0972": 14, "855": 14, "0970": 14, "856": 14, "0968": [14, 23], "857": 14, "0967": 14, "858": 14, "0965": 14, "859": 14, "0964": 14, "860": 14, "0962": 14, "861": 14, "0961": 14, "862": 14, "0959": [14, 23], "863": 14, "0957": 14, "864": 14, "0956": 14, "865": 14, "0954": [14, 23], "866": 14, "0953": 14, "867": 14, "0951": 14, "868": 14, "0950": 14, "869": 14, "0948": [14, 23], "870": 14, "0947": 14, "871": 14, "0945": 14, "872": 14, "0944": 14, "873": 14, "0942": 14, "874": 14, "0941": 14, "875": 14, "0939": 14, "876": 14, "0938": 14, "877": 14, "0936": 14, "878": 14, "0935": 14, "879": 14, "0933": 14, "880": 14, "0932": 14, "881": 14, "0930": [14, 23], "882": 14, "0929": 14, "883": 14, "0928": 14, "884": 14, "0926": 14, "885": 14, "0925": 14, "886": 14, "0923": [14, 23], "887": 14, "0922": 14, "888": 14, "0920": [14, 23], "889": 14, "0919": 14, "890": 14, "0918": 14, "891": 14, "0916": 14, "892": 14, "0915": 14, "893": 14, "0913": 14, "894": 14, "0912": 14, "895": 14, "0911": 14, "896": 14, "0909": 14, "897": 14, "0908": 14, "898": 14, "0907": 14, "899": 14, "0905": 14, "900": 14, "0904": 14, "901": 14, "0902": 14, "902": 14, "0901": 14, "903": 14, "0900": 14, "904": 14, "0898": 14, "905": 14, "0897": [14, 23], "906": 14, "0896": 14, "907": 14, "0894": 14, "908": 14, "0893": 14, "909": 14, "0892": [14, 23], "910": 14, "0891": [14, 23], "911": 14, "0889": 14, "912": 14, "0888": 14, "913": 14, "0887": 14, "914": 14, "0885": 14, "915": 14, "0884": 14, "916": 14, "0883": 14, "917": 14, "0881": 14, "918": 14, "0880": 14, "919": 14, "0879": 14, "920": 14, "0878": 14, "921": 14, "0876": 14, "922": 14, "0875": 14, "923": 14, "0874": 14, "924": 14, "0873": [14, 27], "925": 14, "0871": [14, 30], "926": 14, "0870": 14, "927": 14, "0869": 14, "928": 14, "0868": 14, "929": 14, "0866": 14, "930": 14, "0865": 14, "931": 14, "0864": [14, 23], "932": 14, "0863": 14, "933": 14, "0862": 14, "934": 14, "0860": 14, "935": 14, "0859": 14, "936": 14, "0858": 14, "937": 14, "0857": 14, "938": 14, "0856": 14, "939": 14, "0854": 14, "940": 14, "0853": 14, "941": 14, "0852": 14, "942": 14, "0851": [14, 27], "943": 14, "0850": 14, "944": 14, "0848": 14, "945": 14, "0847": 14, "946": 14, "0846": 14, "947": 14, "0845": 14, "948": 14, "0844": 14, "949": 14, "0843": 14, "950": 14, "0842": 14, "951": 14, "0840": 14, "952": 14, "0839": 14, "953": 14, "0838": 14, "954": 14, "0837": 14, "955": 14, "0836": 14, "956": 14, "0835": 14, "957": 14, "0834": 14, "958": 14, "0833": 14, "959": 14, "0831": 14, "960": 14, "0830": 14, "961": 14, "0829": 14, "962": 14, "0828": 14, "963": 14, "0827": 14, "964": 14, "0826": 14, "965": 14, "0825": 14, "966": 14, "0824": 14, "967": 14, "0823": 14, "968": 14, "0822": 14, "969": 14, "0820": 14, "970": 14, "0819": [14, 23], "971": 14, "0818": 14, "972": 14, "0817": 14, "973": 14, "0816": 14, "974": 14, "0815": 14, "975": 14, "0814": 14, "976": 14, "0813": 14, "977": [14, 28], "0812": 14, "978": 14, "0811": 14, "979": 14, "0810": 14, "980": 14, "0809": 14, "981": 14, "0808": 14, "982": 14, "0807": 14, "983": 14, "0806": 14, "984": 14, "0805": 14, "985": 14, "0804": [14, 23], "986": 14, "0803": [14, 23], "987": 14, "0802": 14, "988": 14, "0800": 14, "989": 14, "0799": 14, "990": 14, "0798": 14, "991": 14, "0797": 14, "992": 14, "0796": 14, "993": 14, "0795": 14, "994": 14, "0794": 14, "995": 14, "0793": 14, "996": 14, "0792": 14, "997": 14, "0791": 14, "998": 14, "0790": 14, "999": 14, "0789": [14, 23], "0788": 14, "0787": 14, "1002": 14, "0786": [14, 15], "1004": 14, "0785": 14, "0784": 14, "1006": [14, 23], "0783": 14, "0782": 14, "0781": 14, "1009": [14, 23], "0780": 14, "0779": 14, "1011": 14, "0778": 14, "0777": 14, "1013": 14, "0776": 14, "0775": 14, "0774": 14, "0773": 14, "0772": 14, "1018": 14, "0771": 14, "0770": 14, "1020": 14, "0769": 14, "0768": 14, "1022": 14, "0767": 14, "0766": 14, "1025": 14, "0765": 14, "0764": 14, "1027": 14, "0763": 14, "0762": [14, 23], "1029": 14, "0761": 14, "0760": 14, "1031": 14, "0759": [14, 23], "0758": 14, "1034": 14, "0757": 14, "0756": 14, "1036": 14, "0755": 14, "0754": [14, 23], "1038": 14, "0753": 14, "0752": 14, "1040": 14, "0751": 14, "0750": 14, "1042": 14, "0749": [14, 23], "1044": 14, "0748": 14, "0747": 14, "1046": [14, 23], "0746": [14, 23], "0745": 14, "1048": 14, "0744": 14, "0743": 14, "1051": 14, "0742": 14, "0741": 14, "1053": 14, "0740": 14, "0739": 14, "1055": 14, "0738": 14, "1057": 14, "0737": 14, "0736": 14, "1059": 14, "0735": 14, "0734": 14, "1061": 14, "0733": 14, "1063": 14, "0732": 14, "0731": [14, 23], "1065": 14, "0730": 14, "0729": 14, "1067": 14, "0728": 14, "1069": 14, "0727": 14, "0726": 14, "1071": 14, "0725": [14, 23], "0724": [14, 23], "1073": 14, "0723": 14, "1075": 14, "0722": 14, "0721": [14, 23], "1077": 14, "0720": [14, 23], "0719": 14, "0718": 14, "1081": 14, "0716": 14, "1083": 14, "0715": 14, "1085": 14, "0714": 14, "0713": 14, "1087": 14, "0712": 14, "1089": 14, "0711": 14, "0710": 14, "1091": 14, "0709": 14, "1092": 14, "0708": 14, "1094": [14, 31], "0707": 14, "0706": 14, "1096": 14, "0705": 14, "1098": 14, "0704": 14, "0703": 14, "1100": 14, "0702": 14, "1102": 14, "0701": [14, 23], "0700": 14, "1104": 14, "0699": [14, 23], "1106": [14, 23], "0698": 14, "0697": 14, "1108": 14, "1109": 14, "0696": 14, "0695": 14, "1111": 14, "0694": 14, "1113": 14, "0693": [14, 23], "0692": 14, "1115": 14, "0691": 14, "1117": 14, "0690": 14, "0689": 14, "1119": 14, "1120": 14, "0688": 14, "0687": [14, 23], "1122": 14, "0686": 14, "1124": 14, "0685": [14, 23], "0684": 14, "1126": 14, "0683": 14, "1128": 14, "0682": 14, "1129": 14, "1131": 14, "0680": 14, "0679": 14, "1133": 14, "0678": 14, "1135": 14, "0677": 14, "1137": 14, "0676": 14, "1138": 14, "0675": 14, "0674": [14, 27], "1140": 14, "0673": 14, "1142": 14, "0672": 14, "1144": 14, "0671": 14, "1145": 14, "0670": 14, "1147": 14, "0669": 14, "0668": 14, "1149": 14, "0667": 14, "1151": 14, "0666": 14, "1152": 14, "0665": 14, "1154": 14, "0664": 14, "1156": 14, "0663": [14, 23], "0662": 14, "1158": 14, "1159": 14, "0661": 14, "0660": 14, "1161": 14, "0659": 14, "1163": 14, "0658": 14, "1164": 14, "0657": 14, "1166": 14, "0656": 14, "1168": 14, "0655": 14, "1170": 14, "0654": 14, "1171": 14, "0653": 14, "1173": 14, "0652": 14, "0651": 14, "1175": 14, "1176": 14, "1178": 14, "0649": 14, "1180": 14, "1181": 14, "0647": 14, "0646": 14, "1183": 14, "0645": 14, "1185": 14, "1186": 14, "0644": 14, "0643": 14, "1188": 14, "0642": 14, "1190": 14, "0641": 14, "1191": 14, "0640": 14, "1193": 14, "0639": 14, "1195": 14, "0638": 14, "1196": 14, "0637": 14, "1198": 14, "1199": 14, "0636": 14, "0635": 14, "1201": 14, "0634": 14, "1203": 14, "1204": 14, "0633": 14, "0632": 14, "1206": 14, "0631": 14, "1208": 14, "1209": 14, "0630": 14, "0629": 14, "1211": 14, "1212": 14, "0628": 14, "1214": 14, "0627": 14, "1216": 14, "0626": 14, "1217": 14, "0625": 14, "1219": 14, "0624": 14, "1220": 14, "0623": 14, "1222": 14, "0622": 14, "1224": 14, "0621": 14, "1225": 14, "0620": 14, "1227": 14, "1228": 14, "0619": 14, "1230": 14, "0618": 14, "1231": 14, "0617": 14, "1233": 14, "0616": 14, "1235": 14, "0615": 14, "1236": 14, "0614": 14, "1238": 14, "0613": 14, "1239": 14, "0612": 14, "1241": 14, "0611": 14, "1244": 14, "0610": 14, "1246": 14, "0609": 14, "1247": 14, "0608": 14, "1249": 14, "0607": [14, 23], "0606": 14, "1252": 14, "1253": 14, "0605": 14, "1255": [14, 23], "0604": 14, "1256": 14, "0603": 14, "1258": 14, "1259": 14, "0602": 14, "1261": 14, "0601": 14, "1262": 14, "0600": 14, "1264": 14, "0599": 14, "1266": 14, "0598": 14, "1267": 14, "0597": 14, "1269": 14, "1270": 14, "0596": 14, "1272": 14, "0595": 14, "1273": 14, "0594": 14, "1275": 14, "1276": 14, "0593": 14, "1278": 14, "0592": 14, "1279": 14, "0591": 14, "1281": 14, "1282": 14, "0590": 14, "1284": 14, "0589": 14, "1285": 14, "0588": 14, "1287": 14, "0587": 14, "1288": [14, 23], "0586": 14, "1290": 14, "1291": 14, "0585": 14, "1293": [14, 23], "0584": 14, "1294": [14, 23], "1296": 14, "1297": 14, "0582": 14, "1299": 14, "0581": 14, "1300": 14, "0580": [14, 23], "1302": 14, "1303": 14, "0579": 14, "1305": 14, "1306": 14, "0578": 14, "1307": 14, "0577": 14, "1309": 14, "1310": 14, "0576": [14, 23], "1312": 14, "0575": 14, "1313": 14, "0574": 14, "1315": 14, "1316": [14, 23], "0573": 14, "1318": 14, "0572": 14, "1319": 14, "0571": 14, "1321": 14, "1322": 14, "0570": 14, "1324": 14, "0569": 14, "1325": 14, "1326": 14, "1328": 14, "0567": 14, "1329": 14, "1331": 14, "0566": 14, "1332": [14, 23], "0565": 14, "1334": 14, "1335": 14, "0564": 14, "1337": 14, "0563": 14, "1338": 14, "1339": 14, "0562": [14, 27], "1341": 14, "0561": [14, 15], "1342": 14, "1344": 14, "0560": [14, 15], "1345": 14, "0559": [14, 15], "1347": 14, "1348": [14, 27], "0558": 14, "1349": 14, "0557": 14, "1351": 14, "1352": 14, "0556": 14, "1354": 14, "1355": 14, "0555": 14, "1357": 14, "0554": 14, "1358": 14, "1359": 14, "0553": [14, 23], "1361": 14, "0552": 14, "1362": 14, "0551": 14, "1364": 14, "1365": 14, "1366": 14, "0550": 14, "1368": 14, "0549": 14, "1369": 14, "0548": 14, "1371": 14, "1372": 14, "0547": 14, "1374": 14, "1375": 14, "0546": [14, 23], "1376": 14, "0545": 14, "1378": 14, "1379": 14, "0544": 14, "1381": 14, "1382": 14, "0543": 14, "1383": 14, "0542": 14, "1385": 14, "1386": 14, "0541": 14, "1388": 14, "1389": 14, "0540": 14, "1390": 14, "0539": 14, "1392": 14, "1393": 14, "1394": 14, "0538": 14, "1396": 14, "0537": [14, 23], "1397": 14, "0536": 14, "1399": 14, "1400": 14, "1401": 14, "0535": 14, "1403": 14, "0534": 14, "1404": 14, "0533": 14, "1406": 14, "1407": 14, "1408": 14, "0532": 14, "1410": 14, "0531": 14, "1411": 14, "1412": 14, "0530": 14, "1414": 14, "1415": 14, "0529": [14, 27], "1417": 14, "1418": 14, "0528": 14, "1419": 14, "0527": 14, "1421": 14, "1422": 14, "1423": 14, "0526": 14, "1425": 14, "0525": 14, "1426": [14, 23], "1427": 14, "0524": 14, "1429": [14, 23], "1430": 14, "0523": 14, "1432": 14, "0522": 14, "1434": 14, "0521": 14, "1437": 14, "1438": 14, "0520": 14, "1440": 14, "0519": 14, "1441": 14, "1442": 14, "0518": 14, "1444": 14, "1445": 14, "0517": 14, "1446": 14, "1448": 14, "0516": 14, "1449": 14, "1450": 14, "0515": 14, "1452": 14, "1453": 14, "0514": 14, "1455": 14, "0513": 14, "1456": 14, "1457": [14, 23], "0512": [14, 27], "1459": 14, "1460": 14, "1461": 14, "0511": 14, "1463": 14, "0510": 14, "1464": 14, "1465": 14, "0509": 14, "1467": 14, "1468": 14, "1469": 14, "0508": 14, "1471": 14, "0507": 14, "1472": 14, "1473": [14, 23], "0506": 14, "1475": [14, 23], "1476": 14, "0505": 14, "1477": 14, "1479": 14, "0504": 14, "1480": 14, "1481": 14, "0503": 14, "1483": 14, "1484": [14, 23], "1485": 14, "0502": 14, "1486": 14, "0501": 14, "1488": 14, "1489": 14, "1490": 14, "0500": 14, "1492": 14, "1493": 14, "0499": 14, "1494": 14, "0498": 14, "1496": 14, "1497": 14, "1498": [14, 15], "0497": 14, "1500": 14, "1501": 14, "1502": 14, "1504": 14, "0495": 14, "1505": 14, "1506": 14, "1508": 14, "1509": 14, "0493": 14, "1510": 14, "1512": 14, "0492": 14, "1513": 14, "1514": 14, "1515": 14, "0491": 14, "1517": 14, "1518": [14, 23], "0490": 14, "1519": [14, 23], "0489": 14, "1521": 14, "1522": 14, "1523": 14, "0488": 14, "1525": 14, "1526": 14, "0487": 14, "1527": 14, "1528": 14, "0486": 14, "1530": 14, "1531": 14, "1532": 14, "0485": 14, "1534": 14, "1535": 14, "0484": 14, "1536": 14, "1538": 14, "0483": 14, "1539": 14, "1540": 14, "1541": 14, "0482": 14, "1543": 14, "1544": 14, "0481": 14, "1545": [14, 23], "0480": 14, "1547": 14, "1548": 14, "1549": 14, "0479": 14, "1550": 14, "1552": 14, "0478": 14, "1553": 14, "1554": 14, "0477": 14, "1556": 14, "1557": 14, "1558": 14, "0476": 14, "1559": 14, "1561": 14, "1562": 14, "1563": 14, "0474": 14, "1565": 14, "1566": 14, "1567": 14, "0473": 14, "1568": 14, "1570": 14, "0472": 14, "1571": 14, "1572": 14, "0471": 14, "1574": 14, "1575": [14, 23], "1576": 14, "0470": 14, "1577": 14, "1579": 14, "0469": [14, 27], "1580": 14, "1581": 14, "1582": 14, "0468": 14, "1584": 14, "1585": 14, "1586": 14, "0467": 14, "1588": 14, "1589": 14, "0466": 14, "1590": 14, "1591": [14, 28], "0465": 14, "1593": 14, "1594": 14, "1595": 14, "0464": 14, "1596": 14, "1598": 14, "0463": 14, "1599": 14, "1600": 14, "0462": 14, "1602": 14, "1603": 14, "1604": 14, "0461": 14, "1605": 14, "1607": 14, "0460": 14, "1608": 14, "1609": 14, "1610": 14, "0459": 14, "1612": 14, "1613": 14, "1614": 14, "0458": 14, "1615": 14, "1617": 14, "0457": 14, "1618": 14, "1619": 14, "1620": 14, "0456": 14, "1622": 14, "1623": 14, "0455": 14, "1624": 14, "1625": 14, "0454": 14, "1627": 14, "1628": [14, 23], "1629": 14, "1630": 14, "0453": 14, "1632": 14, "1633": 14, "0452": 14, "1634": 14, "1635": 14, "0451": 14, "1637": 14, "1638": 14, "1639": 14, "0450": 14, "1641": 14, "1642": 14, "1643": 14, "0449": 14, "1644": 14, "1645": 14, "0448": 14, "1647": 14, "1648": 14, "1649": 14, "0447": [14, 15], "1650": 14, "1652": 14, "0446": 14, "1653": 14, "1654": [14, 23], "1655": 14, "0445": 14, "1657": 14, "1658": 14, "1659": 14, "0444": 14, "1660": 14, "1662": 14, "1663": 14, "0443": 14, "1664": 14, "1665": 14, "0442": 14, "1667": 14, "1668": 14, "1669": 14, "0441": 14, "1670": 14, "1672": 14, "1673": 14, "0440": 14, "1674": 14, "1675": 14, "0439": 14, "1677": 14, "1678": 14, "1679": 14, "0438": 14, "1680": 14, "1681": 14, "1683": 14, "0437": 14, "1684": 14, "1685": 14, "1686": 14, "0436": 14, "1688": 14, "1689": 14, "1690": 14, "0435": 14, "1691": 14, "1693": 14, "0434": 14, "1694": 14, "1695": 14, "1696": 14, "0433": 14, "1698": 14, "1699": 14, "1700": 14, "0432": 14, "1701": 14, "1702": 14, "1704": 14, "0431": 14, "1705": 14, "1706": 14, "1707": 14, "0430": 14, "1709": 14, "1710": 14, "1711": 14, "0429": 14, "1712": 14, "1713": 14, "0428": 14, "1715": 14, "1716": 14, "1717": 14, "1718": 14, "0427": 14, "1720": 14, "1721": 14, "0426": 14, "1722": 14, "1723": 14, "1724": [14, 23], "0425": 14, "1726": 14, "1727": 14, "1728": 14, "0424": 14, "1729": 14, "1731": 14, "1732": 14, "0423": 14, "1733": 14, "1734": [14, 23], "1735": 14, "0422": 14, "1738": [14, 23], "1739": 14, "0421": 14, "1740": 14, "1742": 14, "1743": 14, "0420": 14, "1744": 14, "1745": 14, "1746": 14, "0419": 14, "1748": 14, "1749": 14, "1750": 14, "0418": 14, "1752": 14, "1754": 14, "0417": 14, "1755": 14, "1756": 14, "1757": 14, "0416": 14, "1759": 14, "1760": 14, "1761": 14, "0415": 14, "1763": [14, 23], "1765": 14, "0414": 14, "1766": 14, "1767": 14, "1768": 14, "1769": 14, "0413": 14, "1771": 14, "1772": 14, "0412": 14, "1773": 14, "1774": 14, "1775": 14, "0411": 14, "1777": 14, "1778": 14, "1779": 14, "1780": [14, 23], "0410": 14, "1781": 14, "1783": 14, "1784": 14, "0409": [14, 31], "1785": 14, "1786": 14, "1787": 14, "0408": 14, "1789": 14, "1790": 14, "1791": 14, "0407": 14, "1792": 14, "1794": 14, "1795": 14, "0406": [14, 15], "1796": 14, "1797": 14, "1798": 14, "0405": 14, "1800": 14, "1801": 14, "1802": 14, "1803": 14, "0404": 14, "1804": [14, 23], "1806": 14, "1807": 14, "0403": 14, "1808": 14, "1809": 14, "1810": 14, "0402": 14, "1812": [14, 23], "1813": 14, "1814": 14, "0401": 14, "1815": 14, "1816": 14, "1817": 14, "0400": 14, "1819": 14, "1820": 14, "1821": [14, 23], "1822": 14, "0399": 14, "1823": 14, "1825": 14, "1826": 14, "0398": 14, "1827": 14, "1828": 14, "1829": 14, "0397": 14, "1831": [14, 23], "1832": 14, "1833": 14, "1834": 14, "0396": [14, 15], "1835": 14, "1837": 14, "1838": 14, "0395": 14, "1839": 14, "1840": 14, "1841": 14, "0394": 14, "1843": 14, "1844": 14, "1845": 14, "1846": 14, "0393": 14, "1847": [14, 28], "1848": 14, "1850": 14, "0392": 14, "1851": [14, 23], "1852": 14, "1853": 14, "1854": 14, "0391": [14, 30], "1856": 14, "1857": 14, "1858": 14, "0390": 14, "1859": 14, "1860": 14, "1862": 14, "1863": 14, "1864": 14, "1865": 14, "1866": 14, "0388": 14, "1867": 14, "1869": 14, "1870": 14, "0387": 14, "1871": 14, "1872": 14, "1873": 14, "0386": 14, "1875": 14, "1876": 14, "1877": 14, "1878": 14, "0385": 14, "1879": 14, "1880": 14, "1882": 14, "0384": 14, "1883": 14, "1884": 14, "1885": 14, "1886": 14, "0383": 14, "1888": 14, "1890": 14, "1891": 14, "0382": 14, "1892": 14, "1893": 14, "0381": 14, "1896": 14, "1897": 14, "1898": 14, "1899": 14, "0380": 14, "1901": 14, "1902": 14, "1903": 14, "0379": 14, "1904": 14, "1905": 14, "1906": 14, "0378": 14, "1908": 14, "1909": 14, "1910": 14, "1911": 14, "1912": 14, "0377": 14, "1913": [14, 27], "1915": 14, "1916": 14, "0376": 14, "1917": 14, "1918": 14, "1919": 14, "1920": 14, "0375": 14, "1922": 14, "1923": 14, "1924": 14, "0374": 14, "1925": 14, "1926": 14, "1928": 14, "1929": 14, "0373": 14, "1930": 14, "1931": 14, "1932": 14, "1933": 14, "0372": 14, "1935": 14, "1936": 14, "1937": 14, "0371": 14, "1938": 14, "1939": 14, "1940": 14, "1942": 14, "0370": 14, "1943": 14, "1944": 14, "1945": 14, "1946": 14, "0369": 14, "1947": 14, "1949": 14, "1950": 14, "0368": 14, "1951": 14, "1952": 14, "1953": 14, "1954": 14, "0367": 14, "1956": 14, "1957": 14, "1959": 14, "0366": 14, "1960": 14, "1961": 14, "1963": 14, "0365": 14, "1964": 14, "1965": 14, "1966": 14, "1967": 14, "1968": 14, "0364": 14, "1970": 14, "1971": 14, "1972": 14, "0363": [14, 27], "1973": 14, "1974": 14, "1975": [14, 28], "1977": 14, "0362": 14, "1978": 14, "1979": 14, "1980": 14, "1981": 14, "0361": 14, "1982": 14, "1984": 14, "1985": 14, "0360": 14, "1986": 14, "1987": 14, "1988": 14, "1989": 14, "1990": 14, "0359": 14, "1992": 14, "1993": 14, "1994": 14, "1995": 14, "1996": 14, "1997": 14, "1999": 14, "0357": 14, "plot": [14, 32], "figur": 14, "dpi": 14, "test_epoch": 14, "isfinit": 14, "linestyl": 14, "marker": 14, "legend": [14, 32], "xlabel": 14, "cites": 15, "3703": 15, "manifold": 15, "tsne": 15, "hnhn_layer_bi": 15, "randomnodesplit": 15, "home": [15, 29], "sadra": 15, "local": 15, "tqdm": [15, 32], "auto": 15, "tqdmwarn": 15, "iprogress": 15, "found": [15, 20], "jupyt": 15, "ipywidget": 15, "readthedoc": 15, "io": 15, "en": 15, "user_instal": 15, "html": [15, 30], "autonotebook": 15, "notebook_tqdm": 15, "offici": 15, "accord": [15, 30], "wget": [15, 20], "twistedcub": 15, "raw": [15, 20], "master": [15, 20], "citeseer6cls3703": 15, "pt": [15, 32], "paper_x": 15, "longtensor": [15, 20], "paper_author": 15, "train_test_splitt": 15, "num_test": 15, "num_val": 15, "dropout_r": 15, "normalization_param_alpha": 15, "normalization_param_beta": 15, "enumer": [15, 20, 32], "schedul": 15, "initial_lr": 15, "04": [15, 23, 32], "lr_schedul": 15, "steplr": 15, "7889": 15, "6347": 15, "6458": 15, "9118": 15, "5491": 15, "7203": 15, "5956": 15, "4068": 15, "4721": 15, "7964": 15, "3431": 15, "5075": 15, "0124": 15, "9682": 15, "2804": 15, "2483": 15, "2004": 15, "2019": [15, 27], "0248": 15, "0219": 15, "0217": 15, "0328": 15, "0180": 15, "0220": 15, "0232": 15, "0241": 15, "0130": 15, "0239": 15, "0240": 15, "0284": 15, "0295": 15, "0163": 15, "0195": 15, "0323": 15, "8441": 15, "worth": 15, "visual": [15, 32], "n_compon": 15, "fit_transform": 15, "ax1": 15, "ax2": 15, "subplot": [15, 32], "suptitl": 15, "set_titl": [15, 32], "_t_sne": 15, "futurewarn": 15, "chang": [15, 23, 27, 28, 32], "pca": 15, "warn": [15, 19, 22, 28, 29], "hypergat": 16, "ding": 16, "t_1": 16, "odot": [16, 23], "m_z": [16, 17], "rightarrow0": [16, 29], "As": 16, "j": [16, 17, 23, 27, 28, 29, 32], "highlight": 16, "those": [16, 25], "formal": [16, 25], "alpha_": 16, "jk": 16, "nonlinear": [16, 31], "frac": [16, 17], "operatornam": 16, "exp": 16, "u_": 16, "limits_": 16, "context": 16, "again": [16, 25, 26], "vi": [16, 17], "beta_": 16, "ij": 16, "anoth": 16, "measur": 16, "hypergat_lay": 16, "hypergatlay": 16, "7875": 16, "9625": 16, "hypersag": 17, "arya": 17, "w_y": 17, "w_z": 17, "lvert": 17, "rvert": 17, "interpret": 17, "propag": 17, "problem": [17, 20], "divid": 17, "intra": 17, "obtain": [17, 20, 25, 28, 31, 32], "hypersage_lay": 17, "hypersagelay": 17, "hypersagemodel": 17, "kwarg": 17, "features_nod": 17, "2431": 17, "templatenn": 18, "6126": 18, "0002": 18, "0001": 18, "simplicial_complex": [19, 21, 22, 32], "simplicialcomplex": [19, 21, 22, 32], "unigcn_lay": 19, "unigcnlay": 19, "filterwarn": [19, 22], "to_sparse_csr": [19, 20, 22], "bceloss": [19, 22], "x_1_val": [19, 21, 22], "incidence_1_v": [19, 21, 22], "y_val": [19, 21, 22], "pred": [19, 21, 22, 32], "0971908569336": 19, "94380187988281": 19, "2369270324707": 19, "26074981689453": 19, "98492431640625": 19, "20859909057617": 19, "80668640136719": 19, "686824798583984": 19, "83675765991211": 19, "03213882446289": 19, "238582611083984": 19, "33390426635742": 19, "644731521606445": 19, "585487365722656": 19, "487186431884766": 19, "787471771240234": 19, "63153076171875": 19, "06392478942871": 19, "550783157348633": 19, "08787727355957": 19, "46900749206543": 19, "992172241210938": 19, "090089797973633": 19, "6256160736084": 19, "858888626098633": 19, "25303077697754": 19, "14973258972168": 19, "443086624145508": 19, "693538665771484": 19, "53269386291504": 19, "046640396118164": 19, "61376190185547": 19, "491796493530273": 19, "60036277770996": 19, "690528869628906": 19, "603723526000977": 19, "351343154907227": 19, "073862075805664": 19, "908754348754883": 19, "88480567932129": 19, "900497436523438": 19, "822755813598633": 19, "63096809387207": 19, "415300369262695": 19, "28574562072754": 19, "239614486694336": 19, "227548599243164": 19, "16373634338379": 19, "053255081176758": 19, "935653686523438": 19, "852752685546875": 19, "81441307067871": 19, "792282104492188": 19, "750215530395508": 19, "678442001342773": 19, "601423263549805": 19, "548017501831055": 19, "518722534179688": 19, "489871978759766": 19, "43247413635254": 19, "345685958862305": 19, "245248794555664": 19, "150096893310547": 19, "066505432128906": 19, "986852645874023": 19, "90121841430664": 19, "803401947021484": 19, "703289031982422": 19, "632183074951172": 19, "587385177612305": 19, "54228401184082": 19, "49706268310547": 19, "451065063476562": 19, "407331466674805": 19, "371335983276367": 19, "337526321411133": 19, "306472778320312": 19, "273452758789062": 19, "237478256225586": 19, "20127296447754": 19, "167097091674805": 19, "132389068603516": 19, "098857879638672": 19, "060476303100586": 19, "02267837524414": 19, "9860782623291": 19, "950490951538086": 19, "914758682250977": 19, "878108978271484": 19, "842838287353516": 19, "811080932617188": 19, "780370712280273": 19, "74917221069336": 19, "71664810180664": 19, "699419021606445": 19, "676870346069336": 19, "647939682006836": 19, "61389923095703": 19, "5761775970459": 19, "549442291259766": 19, "5289249420166": 19, "49772071838379": 19, "474157333374023": 19, "45038414001465": 19, "424612045288086": 19, "40214729309082": 19, "378002166748047": 19, "351882934570312": 19, "324098587036133": 19, "298376083374023": 19, "274303436279297": 19, "24971580505371": 19, "228342056274414": 19, "197002410888672": 19, "17634391784668": 19, "151491165161133": 19, "128210067749023": 19, "113391876220703": 19, "088733673095703": 19, "06772232055664": 19, "04320526123047": 19, "0169734954834": 19, "99879264831543": 19, "976442337036133": 19, "94951820373535": 19, "926555633544922": 19, "90591812133789": 19, "884706497192383": 19, "859689712524414": 19, "834184646606445": 19, "812297821044922": 19, "79071807861328": 19, "770198822021484": 19, "74526596069336": 19, "72126579284668": 19, "695659637451172": 19, "671920776367188": 19, "650121688842773": 19, "63254737854004": 19, "603469848632812": 19, "58234405517578": 19, "55916976928711": 19, "540271759033203": 19, "513303756713867": 19, "49028968811035": 19, "466527938842773": 19, "449338912963867": 19, "419330596923828": 19, "39695167541504": 19, "375646591186523": 19, "3538875579834": 19, "334510803222656": 19, "312015533447266": 19, "285579681396484": 19, "269054412841797": 19, "242639541625977": 19, "22045135498047": 19, "203929901123047": 19, "183347702026367": 19, "160404205322266": 19, "133930206298828": 19, "104745864868164": 19, "098697662353516": 19, "078676223754883": 19, "040504455566406": 19, "02244758605957": 19, "011486053466797": 19, "993385314941406": 19, "96799087524414": 19, "939449310302734": 19, "912992477416992": 19, "884111404418945": 19, "86220359802246": 19, "8441219329834": 19, "813901901245117": 19, "801708221435547": 19, "786155700683594": 19, "761951446533203": 19, "740060806274414": 19, "71567726135254": 19, "68885040283203": 19, "670719146728516": 19, "652807235717773": 19, "618999481201172": 19, "5964298248291": 19, "57932472229004": 19, "557270050048828": 19, "530651092529297": 19, "504606246948242": 19, "476253509521484": 19, "45449447631836": 19, "434545516967773": 19, "411243438720703": 19, "382360458374023": 19, "362293243408203": 19, "335590362548828": 19, "30755043029785": 19, "284061431884766": 19, "25484275817871": 19, "22318458557129": 19, "19426155090332": 19, "173973083496094": 19, "14513397216797": 19, "10979652404785": 19, "082422256469727": 19, "0560359954834": 19, "033998489379883": 19, "013517379760742": 19, "987682342529297": 19, "960020065307617": 19, "938085556030273": 19, "911584854125977": 19, "887819290161133": 19, "859230041503906": 19, "83808708190918": 19, "825475692749023": 19, "791316986083984": 19, "769617080688477": 19, "746116638183594": 19, "724519729614258": 19, "69559097290039": 19, "676664352416992": 19, "659330368041992": 19, "623565673828125": 19, "596616744995117": 19, "573455810546875": 19, "547086715698242": 19, "527324676513672": 19, "50086784362793": 19, "473081588745117": 19, "447193145751953": 19, "41757583618164": 19, "402799606323242": 19, "38097381591797": 19, "355859756469727": 19, "32827377319336": 19, "316627502441406": 19, "297752380371094": 19, "263805389404297": 19, "23656463623047": 19, "23184585571289": 19, "2138671875": 19, "183242797851562": 19, "142995834350586": 19, "137985229492188": 19, "11527442932129": 19, "083709716796875": 19, "5625": [19, 21, 22], "04819107055664": 19, "046104431152344": 19, "027341842651367": 19, "99266242980957": 19, "961795806884766": 19, "930912017822266": 19, "911731719970703": 19, "880786895751953": 19, "845874786376953": 19, "83226203918457": 19, "812429428100586": 19, "780649185180664": 19, "75445556640625": 19, "74269676208496": 19, "706310272216797": 19, "682571411132812": 19, "67528533935547": 19, "641508102416992": 19, "615623474121094": 19, "612245559692383": 19, "574350357055664": 19, "543176651000977": 19, "523324966430664": 19, "500341415405273": 19, "460468292236328": 19, "45850944519043": 19, "433353424072266": 19, "38702392578125": 19, "373823165893555": 19, "356149673461914": 19, "33302116394043": 19, "2984619140625": 19, "27631950378418": 19, "242095947265625": 19, "220375061035156": 19, "19377326965332": 19, "166545867919922": 19, "145954132080078": 19, "118263244628906": 19, "103313446044922": 19, "090181350708008": 19, "05240821838379": 19, "038013458251953": 19, "01729965209961": 19, "008516311645508": 19, "97707748413086": 19, "94068717956543": 19, "90737533569336": 19, "87880516052246": 19, "850223541259766": 19, "817041397094727": 19, "79216194152832": 19, "768423080444336": 19, "73453712463379": 19, "714162826538086": 19, "683536529541016": 19, "661930084228516": 19, "627168655395508": 19, "591276168823242": 19, "575401306152344": 19, "538806915283203": 19, "532752990722656": 19, "491992950439453": 19, "470623016357422": 19, "447834014892578": 19, "417621612548828": 19, "395700454711914": 19, "371519088745117": 19, "34141731262207": 19, "317161560058594": 19, "290822982788086": 19, "27621078491211": 19, "252424240112305": 19, "223106384277344": 19, "191679000854492": 19, "167285919189453": 19, "146617889404297": 19, "1218204498291": 19, "092159271240234": 19, "068817138671875": 19, "043107986450195": 19, "020431518554688": 19, "99953842163086": 19, "965152740478516": 19, "948270797729492": 19, "9256591796875": 19, "89617347717285": 19, "867271423339844": 19, "838720321655273": 19, "820175170898438": 19, "80241584777832": 19, "77659797668457": 19, "735746383666992": 19, "71509552001953": 19, "694164276123047": 19, "66806411743164": 19, "638553619384766": 19, "61126136779785": 19, "588682174682617": 19, "57335090637207": 19, "55010223388672": 19, "518211364746094": 19, "497529983520508": 19, "474842071533203": 19, "450790405273438": 19, "426084518432617": 19, "395307540893555": 19, "374881744384766": 19, "35700798034668": 19, "3305721282959": 19, "315614700317383": 19, "27733039855957": 19, "254539489746094": 19, "226396560668945": 19, "21523666381836": 19, "177637100219727": 19, "150047302246094": 19, "121498107910156": 19, "07767677307129": 19, "025562286376953": 19, "97791290283203": 19, "93244743347168": 19, "88832664489746": 19, "836246490478516": 19, "796043395996094": 19, "74243927001953": 19, "702007293701172": 19, "6556339263916": 19, "615976333618164": 19, "584707260131836": 19, "56226348876953": 19, "522308349609375": 19, "483394622802734": 19, "425535202026367": 19, "371274948120117": 19, "33834457397461": 19, "30695152282715": 19, "257896423339844": 19, "215682983398438": 19, "17093849182129": 19, "115076065063477": 19, "079204559326172": 19, "051490783691406": 19, "033987045288086": 19, "01789093017578": 19, "02878189086914": 19, "052005767822266": 19, "115055084228516": 19, "044801712036133": 19, "891642570495605": 19, "728387832641602": 19, "788483619689941": 19, "005611419677734": 19, "045494079589844": 19, "028085708618164": 19, "70627212524414": 19, "557747840881348": 19, "639880180358887": 19, "732135772705078": 19, "785037994384766": 19, "548952102661133": 19, "409181594848633": 19, "439441680908203": 19, "51244068145752": 19, "506211280822754": 19, "33906364440918": 19, "261138916015625": 19, "3150053024292": 19, "368926048278809": 19, "32858943939209": 19, "185369491577148": 19, "1485595703125": 19, "187846183776855": 19, "209299087524414": 19, "182910919189453": 19, "098752975463867": 19, "044387817382812": 19, "052579879760742": 19, "05774211883545": 19, "031035423278809": 19, "977952003479004": 19, "939553260803223": 19, "92505931854248": 19, "922098159790039": 19, "910082817077637": 19, "877153396606445": 19, "838932991027832": 19, "809442520141602": 19, "788487434387207": 19, "78007698059082": 19, "799392700195312": 19, "814967155456543": 19, "780838966369629": 19, "738446235656738": 19, "707448959350586": 19, "675198554992676": 19, "641422271728516": 19, "6210355758667": 19, "609297752380371": 19, "609857559204102": 19, "6266508102417": 19, "633983612060547": 19, "6951904296875": 19, "658025741577148": 19, "600869178771973": 19, "535354614257812": 19, "497736930847168": 19, "458619117736816": 19, "456388473510742": 19, "473320007324219": 19, "49333667755127": 19, "535053253173828": 19, "544401168823242": 19, "582549095153809": 19, "526555061340332": 19, "50399112701416": 19, "38758373260498": 19, "308337211608887": 19, "299043655395508": 19, "327571868896484": 19, "388229370117188": 19, "417525291442871": 19, "455561637878418": 19, "416516304016113": 19, "392356872558594": 19, "28682804107666": 19, "192612648010254": 19, "12002182006836": 19, "091236114501953": 19, "14907455444336": 19, "283432006835938": 19, "588083267211914": 19, "7717866897583": 19, "171638488769531": 19, "575143814086914": 19, "168379783630371": 19, "044833183288574": 19, "277763366699219": 19, "634512901306152": 19, "24776554107666": 19, "931353569030762": 19, "041153907775879": 19, "249833106994629": 19, "302783966064453": 19, "985976219177246": 19, "880131721496582": 19, "02563762664795": 19, "059005737304688": 19, "942398071289062": 19, "796463012695312": 19, "87881088256836": 19, "039618492126465": 19, "918492317199707": 19, "420305252075195": 19, "406696319580078": 19, "394020080566406": 19, "37169075012207": 19, "35594940185547": 19, "34318733215332": 19, "33356475830078": 19, "31667137145996": 19, "302318572998047": 19, "28500747680664": 19, "26559066772461": 19, "25322914123535": 19, "238706588745117": 19, "220836639404297": 19, "208791732788086": 19, "1856746673584": 19, "171249389648438": 19, "15633201599121": 19, "145591735839844": 19, "12535285949707": 19, "112903594970703": 19, "096086502075195": 19, "082990646362305": 19, "068315505981445": 19, "050025939941406": 19, "046539306640625": 19, "030738830566406": 19, "007352828979492": 19, "004419326782227": 19, "990276336669922": 19, "96859359741211": 19, "95843505859375": 19, "941267013549805": 19, "93852424621582": 19, "93297004699707": 19, "905284881591797": 19, "90688705444336": 19, "88941764831543": 19, "867488861083984": 19, "852458953857422": 19, "82878303527832": 19, "848604202270508": 19, "816743850708008": 19, "798707962036133": 19, "782867431640625": 19, "770641326904297": 19, "765010833740234": 19, "74397087097168": 19, "730905532836914": 19, "71582794189453": 19, "692882537841797": 19, "678205490112305": 19, "659757614135742": 19, "66231918334961": 19, "63972282409668": 19, "637910842895508": 19, "620912551879883": 19, "613643646240234": 19, "592449188232422": 19, "578832626342773": 19, "5690860748291": 19, "5478572845459": 19, "536046981811523": 19, "518606185913086": 19, "507850646972656": 19, "49575424194336": 19, "47629737854004": 19, "466197967529297": 19, "446958541870117": 19, "431520462036133": 19, "42148780822754": 19, "418920516967773": 19, "382413864135742": 19, "38419532775879": 19, "382558822631836": 19, "373292922973633": 19, "359771728515625": 19, "339229583740234": 19, "32771873474121": 19, "31146240234375": 19, "291799545288086": 19, "266311645507812": 19, "25176429748535": 19, "275617599487305": 19, "243261337280273": 19, "198863983154297": 19, "190418243408203": 19, "180404663085938": 19, "159381866455078": 19, "132848739624023": 19, "08831024169922": 19, "07340431213379": 19, "040719985961914": 19, "018062591552734": 19, "98824119567871": 19, "994766235351562": 19, "97658348083496": 19, "954269409179688": 19, "931133270263672": 19, "923803329467773": 19, "900142669677734": 19, "883092880249023": 19, "874980926513672": 19, "859506607055664": 19, "83385467529297": 19, "821224212646484": 19, "808631896972656": 19, "790834426879883": 19, "770950317382812": 19, "753965377807617": 19, "74176597595215": 19, "726638793945312": 19, "71209144592285": 19, "717884063720703": 19, "69021987915039": 19, "684720993041992": 19, "65319061279297": 19, "64687728881836": 19, "641027450561523": 19, "62809181213379": 19, "599239349365234": 19, "57975196838379": 19, "56479835510254": 19, "56086540222168": 19, "538368225097656": 19, "528959274291992": 19, "50667953491211": 19, "503355026245117": 19, "473203659057617": 19, "480627059936523": 19, "455434799194336": 19, "448516845703125": 19, "433578491210938": 19, "42472267150879": 19, "41015625": 19, "397563934326172": 19, "366233825683594": 19, "36186981201172": 19, "347782135009766": 19, "334121704101562": 19, "319826126098633": 19, "311002731323242": 19, "29153060913086": 19, "269283294677734": 19, "26325225830078": 19, "24094581604004": 19, "23046112060547": 19, "2217960357666": 19, "21772575378418": 19, "204160690307617": 19, "186527252197266": 19, "18400764465332": 19, "16082763671875": 19, "150056838989258": 19, "157442092895508": 19, "121925354003906": 19, "12659454345703": 19, "10972023010254": 19, "108051300048828": 19, "09576988220215": 19, "07231903076172": 19, "065282821655273": 19, "032222747802734": 19, "040668487548828": 19, "02615737915039": 19, "99028778076172": 19, "992895126342773": 19, "986125946044922": 19, "971839904785156": 19, "947101593017578": 19, "93064308166504": 19, "940488815307617": 19, "926761627197266": 19, "89728355407715": 19, "92677116394043": 19, "90224266052246": 19, "888980865478516": 19, "871950149536133": 19, "850805282592773": 19, "85380744934082": 19, "83152961730957": 19, "820480346679688": 19, "813871383666992": 19, "811283111572266": 19, "79723358154297": 19, "773174285888672": 19, "76585578918457": 19, "763370513916016": 19, "74306297302246": 19, "733776092529297": 19, "727794647216797": 19, "726064682006836": 19, "721574783325195": 19, "69578742980957": 19, "671518325805664": 19, "67192268371582": 19, "675018310546875": 19, "652587890625": 19, "63589859008789": 19, "632600784301758": 19, "618101119995117": 19, "61069679260254": 19, "603355407714844": 19, "587169647216797": 19, "568763732910156": 19, "55999183654785": 19, "554792404174805": 19, "530359268188477": 19, "52699851989746": 19, "524051666259766": 19, "511272430419922": 19, "492382049560547": 19, "48703384399414": 19, "472692489624023": 19, "478933334350586": 19, "467594146728516": 19, "44580841064453": 19, "4395809173584": 19, "439208984375": 19, "427417755126953": 19, "416553497314453": 19, "407917022705078": 19, "396162033081055": 19, "377273559570312": 19, "370101928710938": 19, "381824493408203": 19, "365995407104492": 19, "33931541442871": 19, "341108322143555": 19, "34080696105957": 19, "326269149780273": 19, "295074462890625": 19, "290189743041992": 19, "294099807739258": 19, "279863357543945": 19, "259613037109375": 19, "255352020263672": 19, "243770599365234": 19, "24730682373047": 19, "235071182250977": 19, "221952438354492": 19, "20149803161621": 19, "19734001159668": 19, "199737548828125": 19, "179275512695312": 19, "176069259643555": 19, "170211791992188": 19, "16652488708496": 19, "136791229248047": 19, "125789642333984": 19, "123292922973633": 19, "109601974487305": 19, "100919723510742": 19, "0986270904541": 19, "09308624267578": 19, "078474044799805": 19, "067218780517578": 19, "05537223815918": 19, "03988265991211": 19, "03138542175293": 19, "026723861694336": 19, "008121490478516": 19, "018474578857422": 19, "014162063598633": 19, "001453399658203": 19, "981800079345703": 19, "987455368041992": 19, "983600616455078": 19, "cicitationcora": 20, "hgnn": 20, "utlil": 20, "neccessari": 20, "pickl": 20, "scipi": [20, 23, 27, 28, 29, 32], "sp": 20, "unigcnii_lay": 20, "unigcniilay": 20, "computation": 20, "expens": [20, 23, 27, 28], "malllabiisc": 20, "hypergcn": 20, "cocit": 20, "07": [20, 23, 32], "ca": 20, "certif": 20, "ssl": 20, "cert": 20, "crt": 20, "resolv": 20, "await": 20, "githubusercont": 20, "ok": 20, "404937": 20, "395k": 20, "applic": 20, "octet": 20, "stream": 20, "save": 20, "gt": [20, 32], "45k": 20, "kb": 20, "mb": 20, "101905": 20, "100k": 20, "52k": 20, "02": [20, 23, 32], "5436": 20, "3k": 20, "31k": 20, "51582": 20, "50k": 20, "37k": 20, "rb": 20, "handl": 20, "ipykernel_14655": 20, "121206761": 20, "deprecationwarn": 20, "csr_matrix": [20, 23, 27, 28], "namespac": 20, "csr": 20, "deprec": [20, 28], "pytorch": 20, "floattensor": 20, "num": 20, "hyper": [20, 32], "expect": [20, 27, 29], "gcnii": 20, "h2": [20, 27], "hstack": 20, "2226475299": 20, "support": [20, 25, 28, 31], "beta": [20, 32], "miss": 20, "trigger": 20, "intern": [20, 31], "aten": 20, "sparsecsrtensorimpl": 20, "cpp": 20, "predefin": 20, "train_idx": 20, "test_idx": 20, "unigcniimodel": 20, "num_lay": [20, 28, 31], "num_featur": 20, "num_nod": 20, "num_edg": 20, "copi": 20, "x_0_skip": 20, "clone": 20, "ommit": 20, "cross": 20, "entropi": 20, "current": [20, 25, 28, 31], "readi": [20, 32], "mode": 20, "7071428298950195": 20, "39291277527809143": 20, "4376946985721588": 20, "9357143044471741": 20, "6137071847915649": 20, "8714285492897034": 20, "45210281014442444": 20, "9071428775787354": 20, "5502336621284485": 20, "9785714149475098": 20, "5463395714759827": 20, "5747663378715515": 20, "9857142567634583": 20, "5673676133155823": 20, "9428571462631226": 20, "552570104598999": 20, "9571428298950195": 20, "5607476830482483": 20, "unigin_lay": 21, "uniginlay": 21, "unigin_nn": 21, "unigin": 21, "in_channels_nod": 21, "inp_emb": 21, "out_decod": 21, "pooled_x_0": 21, "node_dim": 21, "seper": 21, "unsqueez": [21, 32], "3916015625": 21, "91788864135742": 21, "573387145996094": 21, "32501220703125": 21, "29070281982422": 21, "48554229736328": 21, "905006408691406": 21, "502838134765625": 21, "23980712890625": 21, "084415435791016": 21, "003536224365234": 21, "96804428100586": 21, "95846939086914": 21, "9611930847168": 21, "96879196166992": 21, "977806091308594": 21, "98638916015625": 21, "99394989013672": 21, "00029754638672": 21, "00556945800781": 21, "00981521606445": 21, "01326370239258": 21, "01602554321289": 21, "018226623535156": 21, "01999282836914": 21, "0213737487793": 21, "02241897583008": 21, "02317810058594": 21, "023704528808594": 21, "02401351928711": 21, "02414321899414": 21, "024078369140625": 21, "023826599121094": 21, "02338790893555": 21, "02278137207031": 21, "021995544433594": 21, "02100372314453": 21, "019805908203125": 21, "018394470214844": 21, "01671600341797": 21, "0147590637207": 21, "01249313354492": 21, "00986862182617": 21, "0068359375": 21, "003334045410156": 21, "999298095703125": 21, "99464416503906": 21, "98926544189453": 21, "98302459716797": 21, "975791931152344": 21, "unisage_lay": 22, "unisagelay": 22, "chrsmrr": 22, "graphkerneldataset": 22, "unisagenn": 22, "unisag": 22, "38711929321289": 22, "50642013549805": 22, "88081741333008": 22, "313419342041016": 22, "208885192871094": 22, "00963592529297": 22, "59610366821289": 22, "292537689208984": 22, "19595718383789": 22, "106815338134766": 22, "913330078125": 22, "710723876953125": 22, "6346549987793": 22, "63870620727539": 22, "57096481323242": 22, "44948196411133": 22, "391658782958984": 22, "39373779296875": 22, "34821319580078": 22, "241302490234375": 22, "159812927246094": 22, "131492614746094": 22, "08507537841797": 22, "99526023864746": 22, "924638748168945": 22, "894010543823242": 22, "868173599243164": 22, "829978942871094": 22, "808109283447266": 22, "807811737060547": 22, "785655975341797": 22, "746475219726562": 22, "724843978881836": 22, "700727462768555": 22, "660417556762695": 22, "624387741088867": 22, "606855392456055": 22, "585779190063477": 22, "568805694580078": 22, "556062698364258": 22, "53620147705078": 22, "51841163635254": 22, "507102966308594": 22, "491756439208984": 22, "478620529174805": 22, "475711822509766": 22, "467418670654297": 22, "449710845947266": 22, "429576873779297": 22, "42317771911621": 22, "alexandro": 23, "kero": 23, "linalg": 23, "npla": 23, "a0": [23, 24], "becaus": [23, 24, 26, 28, 31], "serv": [23, 24], "simpli": [23, 24, 32], "demonstr": [23, 24], "similarli": [23, 24, 27], "emerg": [23, 24, 25, 27, 28], "four": [23, 24, 25, 27, 28], "y_true": [23, 24, 25, 28, 31], "ld": 23, "l_tilde_pinv": 23, "pinv": 23, "invers": 23, "linv": 23, "x_1e": 23, "0971": 23, "0937": 23, "2140": 23, "2069": 23, "2927": 23, "3018": 23, "2309": 23, "0992": 23, "0943": 23, "0927": 23, "2678": 23, "3090": 23, "0960": 23, "2077": 23, "2056": 23, "2813": 23, "nnz": 23, "layout": 23, "sparse_coo": 23, "56771909e": 23, "49643084e": 23, "13434650e": 23, "60154799e": 23, "03": [23, 32], "73820292e": 23, "65885226e": 23, "04038181e": 23, "08": [23, 32], "51925802e": 23, "09": [23, 30, 32], "73643677e": 23, "95577741e": 23, "09312067e": 23, "39698386e": 23, "11006736e": 23, "25540316e": 23, "87149896e": 23, "65674657e": 23, "43987098e": 23, "79396772e": 23, "00662204e": 23, "45058060e": 23, "36910174e": 23, "82942520e": 23, "24798042e": 23, "85055751e": 23, "78386103e": 23, "24821486e": 23, "81510593e": 23, "07917011e": 23, "30485535e": 23, "19925834e": 23, "56662779e": 23, "25658545e": 23, "29514395e": 23, "73054542e": 23, "57650283e": 23, "87089108e": 23, "31973699e": 23, "45874534e": 23, "78385898e": 23, "24821523e": 23, "38282800e": 23, "29527006e": 23, "24821542e": 23, "45585343e": 23, "20149602e": 23, "39614227e": 23, "52603984e": 23, "02427802e": 23, "38569428e": 23, "20058507e": 23, "89658767e": 23, "67997003e": 23, "90682733e": 23, "88636552e": 23, "61071175e": 23, "75768661e": 23, "22418800e": 23, "07488209e": 23, "26928225e": 23, "52925774e": 23, "50903371e": 23, "71863856e": 23, "40345353e": 23, "36909867e": 23, "82943824e": 23, "90223058e": 23, "08467136e": 23, "43380561e": 23, "27135092e": 23, "31898531e": 23, "01219751e": 23, "78963115e": 23, "97890193e": 23, "49229891e": 23, "67953214e": 23, "75078206e": 23, "75904313e": 23, "03583546e": 23, "12457962e": 23, "10897127e": 23, "18870673e": 23, "28672193e": 23, "61245163e": 23, "48166016e": 23, "75217551e": 23, "67996958e": 23, "90682673e": 23, "44834775e": 23, "90006804e": 23, "59747154e": 23, "69860917e": 23, "59747209e": 23, "69862127e": 23, "59747284e": 23, "69861429e": 23, "59747191e": 23, "59747247e": 23, "69860823e": 23, "59747135e": 23, "11979373e": 23, "90869734e": 23, "59747228e": 23, "69860637e": 23, "59747303e": 23, "69861010e": 23, "59747116e": 23, "17587730e": 23, "43268425e": 23, "43105909e": 23, "32787512e": 23, "03376685e": 23, "44168448e": 23, "62169540e": 23, "41996737e": 23, "73246880e": 23, "97727704e": 23, "03496753e": 23, "71378374e": 23, "92902595e": 23, "15740368e": 23, "94057676e": 23, "48602486e": 23, "40909785e": 23, "14646482e": 23, "38315065e": 23, "76777497e": 23, "38311899e": 23, "76780128e": 23, "37373477e": 23, "49392605e": 23, "30545244e": 23, "10224779e": 23, "69429579e": 23, "59057510e": 23, "11831834e": 23, "86165255e": 23, "07662510e": 23, "53556532e": 23, "82225195e": 23, "76254632e": 23, "62731223e": 23, "63466549e": 23, "16528196e": 23, "62805045e": 23, "36022410e": 23, "48832843e": 23, "19494419e": 23, "13972221e": 23, "zia003": 23, "topox2": 23, "_index": [23, 27, 28], "sparseefficiencywarn": [23, 27, 28], "sparsiti": [23, 27, 28], "lil_matrix": [23, 27, 28], "effici": [23, 27, 28, 30], "_set_arrayxarrai": [23, 27, 28], "produc": [23, 24, 25, 27, 31], "compar": [23, 24, 25, 27, 31], "binary_cross_entropy_with_logit": [23, 24, 25, 27, 31], "y_hat_test": [23, 24, 25, 27, 28, 31], "y_pred_test": [23, 24, 25, 27, 28, 31], "test_accuraci": [23, 24, 25, 27, 28, 31], "eq": [23, 24, 25, 28, 31], "7231": 23, "6000": 23, "6989": 23, "5667": [23, 24, 27], "2500": [23, 28], "6737": 23, "6564": 23, "6434": 23, "6362": 23, "6290": 23, "4333": [23, 31], "6199": 23, "6117": 23, "6057": 23, "6011": 23, "5964": 23, "5911": 23, "5855": 23, "5764": 23, "4000": 23, "5730": 23, "5696": 23, "5660": 23, "5593": 23, "5567": 23, "5544": 23, "5520": 23, "5496": 23, "5472": 23, "5451": 23, "5432": 23, "5414": 23, "5346": 23, "5333": 23, "5320": 23, "5308": 23, "5295": 23, "5284": 23, "5273": 23, "5264": 23, "5255": 23, "5238": 23, "5230": 23, "5223": 23, "5216": 23, "5210": 23, "5204": 23, "5198": 23, "5193": 23, "5183": 23, "5178": 23, "5174": 23, "5170": 23, "5166": 23, "5163": 23, "5159": 23, "5156": 23, "7216": 24, "7169": 24, "7151": 24, "7109": 24, "work": 25, "novel": 25, "hing": 25, "proper": 25, "triangl": [25, 28, 32], "total": 25, "orient": 25, "fashion": 25, "2p": 25, "q_r": 25, "kernel": 25, "hodg": [25, 27, 28], "laplacian": [25, 26, 27, 28, 30], "l_r": 25, "widetild": 25, "hy": 25, "neq": [25, 32], "affin": 25, "entri": 25, "therefor": 25, "hop": [25, 31], "suppos": 25, "_j": 25, "underset": 25, "w_": 25, "q_": 25, "l_": [25, 26, 31, 32], "tb_1": 25, "b_2b_2": 25, "notic": 25, "pattern": 25, "simplic": [25, 27, 28, 31, 32], "just": [25, 27, 32], "down": 25, "maxium": 25, "simplex_order_k": 25, "laplacian_down": [25, 31], "valueerror": [25, 28, 31], "laplacian_up": [25, 31], "gradient": 25, "tx_0": 25, "estim": 25, "multipli": 25, "diverg": 25, "deriv": 25, "seen": 25, "incidence_0_1": 25, "plu": 25, "accordingli": 25, "mm": 25, "henc": 25, "y_hat_edg": 25, "fn": 25, "y_hat_edge_test": 25, "_pred_test": 25, "ge": 25, "7322": 25, "3667": 25, "7208": 25, "7333": [25, 27], "7070": 25, "6814": 25, "6753": 25, "6717": 25, "6695": 25, "6682": 25, "6674": 25, "qquad": 26, "sca_cmp": 26, "scacmp": 26, "sc": [26, 28, 31, 32], "laplacian_down_1_list": [26, 28, 31], "laplacian_down_2_list": 26, "incidence1_t_list": 26, "incidence2_t_list": 26, "laplacian_down_1": [26, 28, 31], "laplacian_down_2": [26, 28, 31], "scacmpslay": 26, "channels_list": 26, "complex_dim": 26, "laplacian_down_1_train": [26, 28], "laplacian_down_1_test": [26, 28], "laplacian_down_2_train": 26, "laplacian_down_2_test": 26, "incidence1_t_train": 26, "incidence1_t_test": 26, "incidence2_t_train": 26, "incidence2_t_test": 26, "hzpmc22": 26, "did": 26, "la": 27, "r_": 27, "mathrm": 27, "leq": [27, 32], "bigcup": 27, "feat_dim": 27, "arbitrari": 27, "maximum": [27, 32], "max_rank": [27, 28, 31], "choos": [27, 32], "dictionari": 27, "sccnlayer": 27, "tha": 27, "arbitrarili": 27, "formul": 27, "quit": 27, "close": 27, "h_r": 27, "2i": 27, "usual": 27, "suggest": 27, "refrain": 27, "tetrahedron": 27, "sparse_to_torch": 27, "rank_": 27, "rank_0": 27, "coadjacency_matrix": [27, 28], "h0": 27, "h1": 27, "b2": [27, 28, 29, 31], "h3": 27, "b3": 27, "tmx": [27, 28, 31], "x_3": 27, "tetrahedron_feat": 27, "track": 27, "rank_1": 27, "rank_2": 27, "rank_3": 27, "typic": 27, "6721": 27, "6333": 27, "6173": 27, "6110": 27, "5831": 27, "5695": 27, "5638": 27, "5493": 27, "5384": 27, "7667": 27, "5141": 27, "5201": 27, "5038": 27, "5016": 27, "4906": 27, "4763": 27, "4545": 27, "4483": 27, "4153": 27, "8000": 27, "4062": 27, "3790": 27, "8333": 27, "3916": 27, "3529": 27, "8667": 27, "2900": 27, "2359": 27, "9333": 27, "2002": 27, "9667": 27, "2970": 27, "9000": 27, "2032": 27, "2329": 27, "0272": 27, "0264": 27, "0245": 27, "0207": 27, "0165": 27, "0132": 27, "0114": 27, "0113": 27, "0117": 27, "0101": 27, "0081": 27, "0071": 27, "0065": 27, "0061": 27, "0057": 27, "0054": 27, "0050": 27, "0046": 27, "0043": 27, "0040": 27, "0038": 27, "0036": 27, "0034": 27, "0033": 27, "0032": 27, "0031": 27, "0030": 27, "0029": 27, "0028": 27, "0027": 27, "0026": 27, "0025": 27, "0024": 27, "0023": 27, "0022": 27, "0021": 27, "0020": 27, "0019": 27, "0018": 27, "0017": 27, "0016": 27, "0015": 27, "0014": 27, "0013": 27, "0012": 27, "0011": 27, "0010": 27, "0009": 27, "0008": 27, "scnn": 28, "account": 28, "At": [28, 31], "_t": [28, 31], "filter": 28, "p_d": [28, 31], "p_u": [28, 31], "likewis": 28, "essenti": 28, "sccnncomplex": 28, "in_channels_al": 28, "_1": [28, 29, 31], "_2": 28, "_0": 28, "yet": [28, 31], "laplacian_0_list": [28, 31], "laplacian_up_1_list": [28, 31], "laplacian_2_list": [28, 31], "laplacian_0": [28, 30, 31], "hodge_laplacian_matrix": [28, 31], "laplacian_up_1": [28, 31], "laplacian_2": [28, 30, 31], "conv_ord": 28, "intermediate_channels_al": 28, "out_channels_al": 28, "sc_order": 28, "size_averag": 28, "in_linear_0": 28, "in_linear_1": 28, "in_linear_2": 28, "sccnnlayer": 28, "out_linear_0": 28, "out_linear_1": 28, "out_linear_2": 28, "_reduct": 28, "ret": 28, "laplacian_0_train": 28, "laplacian_0_test": 28, "laplacian_up_1_train": 28, "laplacian_up_1_test": 28, "laplacian_2_train": 28, "laplacian_2_test": 28, "x_all": 28, "laplacian_al": 28, "incidence_al": 28, "117979": 28, "8366": 28, "8377": 28, "5059": 28, "4212": 28, "5435": 28, "9460": 28, "7320": 28, "8642": 28, "laplacian_up_2": [28, 31], "get_simplicial_featur": [28, 31], "which_feat": [28, 31], "elif": [28, 31], "binary_cross_entropi": 28, "6678": 28, "3241": 28, "2667": 28, "3333": 28, "bunch": 29, "tild": 29, "rightarrow1": 29, "coo_matrix": 29, "diag": 29, "return_count": 29, "normalize_higher_order_adj": 29, "a_opt": 29, "cochain": 29, "num_of_k_simplic": 29, "num_of_j_simplic": 29, "rowsum": 29, "r_inv_sqrt": 29, "power": 29, "flatten": 29, "isinf": 29, "r_mat_inv_sqrt": 29, "a_opt_to": 29, "dot": 29, "neigborood": 29, "ssconv": 29, "incidence_1_norm": 29, "incidence_2_norm": 29, "adjacency_up_0_norm": 29, "adjacency_up_1_norm": 29, "adjacency_down_1_norm": 29, "adjacency_down_2_norm": 29, "get_neighborhood": 29, "incidence_1_norm_list": 29, "incidence_2_norm_list": 29, "adjacency_up_0_norm_list": 29, "adjacency_up_1_norm_list": 29, "adjacency_down_1_norm_list": 29, "adjacency_down_2_norm_list": 29, "up_laplacian_1_list": 29, "up_laplacian_2_list": 29, "down_laplacian_1_list": 29, "down_laplacian_2_list": 29, "up_laplacian_1": 29, "up_laplacian_2": 29, "down_laplacian_1": 29, "down_laplacian_2": 29, "todo": 29, "edge_channel": 29, "face_channel": 29, "kha053": 29, "nvml": 29, "incid1": 29, "incid1_norm": 29, "incid2": 29, "incid2_norm": 29, "adj0_up_norm": 29, "adj1_up_norm": 29, "adj1_down_norm": 29, "adj2_down_norm": 29, "correct_count": 29, "x_0t": 29, "x_1t": 29, "x_2t": 29, "incid1t": 29, "incid1_normt": 29, "incid2t": 29, "incid2_normt": 29, "adj0_up_normt": 29, "adj1_up_normt": 29, "adj1_down_normt": 29, "adj2_down_normt": 29, "yt": 29, "yang22c": 30, "ysb22": 30, "ruochen": 30, "freder": 30, "sala": 30, "bogdan": 30, "razvan": 30, "pascanu": 30, "editor": 30, "proceed": 30, "confer": [30, 31], "volum": 30, "pmlr": 30, "dec": 30, "2022a": 30, "mlr": 30, "press": 30, "v198": 30, "yang22a": 30, "scn2": 30, "chose": 30, "reshap": 30, "laplacian_1": 30, "normalized_laplacian_matrix": 30, "x_0s_train": 30, "x_0s_test": 30, "x_1s_train": 30, "x_1s_test": 30, "x_2s_train": 30, "x_2s_test": 30, "laplacian_0s_train": 30, "laplacian_0s_test": 30, "laplacian_1s_train": 30, "laplacian_1s_test": 30, "laplacian_2s_train": 30, "laplacian_2s_test": 30, "6056": 30, "2707": 30, "9831": 30, "8605": 30, "0164": 30, "0106": 30, "9957": 30, "0872": 30, "5802": 30, "itself": 31, "conv_order_down": 31, "conv_order_up": 31, "larger": 31, "x_train": 31, "x_test": 31, "laplacian_down_train": 31, "laplacian_down_test": 31, "laplacian_up_train": 31, "laplacian_up_test": 31, "simplex_order_select": 31, "0324": 31, "8604": 31, "5140": 31, "2026": 31, "5221": 31, "9650": 31, "8648": 31, "5553": 31, "maxim": 31, "chennel_edg": 31, "channel_fac": 31, "certain": 31, "scnnlayer": 31, "classm": 31, "rm": 31, "scnn_layer": 31, "simplci": 31, "challeng": 31, "mitchel": 31, "nichola": 31, "glaze": 31, "santiago": 31, "segarra": 31, "principl": [31, 32], "trajectori": 31, "numer": 31, "inter_channel": 31, "n_simplic": 31, "channels_x": 31, "7314": 31, "7310": 31, "7306": 31, "7302": 31, "7297": 31, "rgs21": 32, "spend": 32, "synthet": 32, "ahead": 32, "itertool": 32, "product": 32, "tnx": 32, "networkx": 32, "nx": 32, "random_split": 32, "spatial": 32, "delaunai": 32, "distanc": 32, "seed": 32, "lt": 32, "_c": 32, "0x1664f0f50": 32, "less": 32, "uniformli": 32, "point": 32, "triangul": 32, "cloud": 32, "disk": 32, "insid": 32, "remov": 32, "centroid": 32, "generate_complex": 32, "delet": 32, "sort": 32, "coordin": 32, "argsort": 32, "tri": 32, "disk_cent": 32, "disk_radiu": 32, "indices_includ": 32, "cdist": 32, "idx_dict": 32, "coord": 32, "instanc": 32, "euclidean": 32, "shortest": 32, "path": 32, "plot_complex": 32, "plane": 32, "idx": 32, "poli": 32, "polygon": 32, "color": 32, "green": 32, "gca": 32, "add_patch": 32, "vstack": 32, "i_1": 32, "i_2": 32, "ldot": 32, "i_m": 32, "i_j": 32, "i_": 32, "neighbour": 32, "ground": 32, "truth": 32, "supervis": 32, "setup": 32, "subsect": 32, "randomli": 32, "pick": 32, "triplet": 32, "corner": 32, "around": 32, "middl": 32, "anti": 32, "diagon": 32, "n_max": 32, "determin": 32, "generate_trajectori": 32, "mid": 32, "region": 32, "start_nod": 32, "mid_nod": 32, "end_nod": 32, "all_triplet": 32, "increas": 32, "underli": 32, "distance_matrix": 32, "squareform": 32, "pdist": 32, "toarrai": 32, "from_numpy_arrai": 32, "path_1": 32, "shortest_path": 32, "path_2": 32, "plot_path": 32, "red": 32, "arrow": 32, "quiver": 32, "scale_unit": 32, "angl": 32, "scale": 32, "yield": 32, "vectorized_trajectori": 32, "neigbors_mask": 32, "last_nod": 32, "turn": 32, "a_1": 32, "a_2": 32, "a_j": 32, "i_n": 32, "later": 32, "trajectoriesdataset": 32, "lookup": 32, "speed": 32, "edge_lookup_t": 32, "__getitem__": 32, "vectorize_path": 32, "discard": 32, "neighbors_mask": 32, "__len__": 32, "c0": 32, "batch": 32, "loader": 32, "batch_siz": 32, "val_siz": 32, "train_siz": 32, "train_d": 32, "val_d": 32, "test_d": 32, "train_dl": 32, "val_dl": 32, "test_dl": 32, "sconelay": 32, "c_1": 32, "chain": 32, "partial_1": 32, "c_0": 32, "That": 32, "highest": 32, "hat": 32, "_m": 32, "neg": 32, "likelihood": 32, "penal": 32, "weight_decai": 32, "5e": 32, "hidden_dim": 32, "loss_funct": 32, "nllloss": 32, "nll": 32, "training_histori": 32, "training_loss": 32, "traj": 32, "squeez": 32, "06": 32, "quick": 32, "confirm": 32, "everyth": 32, "reason": 32, "ax": 32, "ncol": 32, "figsiz": 32, "approxim": 32, "better": 32, "guess": 32, "3f": 32, "constructor": 32, "affect": 32, "capabl": 32, "revers": 32, "Or": 32, "ocean": 32, "drifter": 32}, "objects": {"topomodelx.base": [[0, 0, 0, "-", "aggregation"], [0, 0, 0, "-", "conv"], [0, 0, 0, "-", "message_passing"]], "topomodelx.base.aggregation": [[0, 1, 1, "", "Aggregation"]], "topomodelx.base.aggregation.Aggregation": [[0, 2, 1, "", "forward"], [0, 2, 1, "", "update"]], "topomodelx.base.conv": [[0, 1, 1, "", "Conv"]], "topomodelx.base.conv.Conv": [[0, 2, 1, "", "forward"], [0, 2, 1, "", "update"]], "topomodelx.base.message_passing": [[0, 1, 1, "", "MessagePassing"]], "topomodelx.base.message_passing.MessagePassing": [[0, 2, 1, "", "aggregate"], [0, 2, 1, "", "attention"], [0, 2, 1, "", "forward"], [0, 2, 1, "", "message"], [0, 2, 1, "", "reset_parameters"]], "topomodelx.nn.cell": [[2, 0, 0, "-", "ccxn_layer"]], "topomodelx.nn.cell.ccxn_layer": [[2, 1, 1, "", "CCXNLayer"]], "topomodelx.nn.cell.ccxn_layer.CCXNLayer": [[2, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph": [[2, 0, 0, "-", "template_layer"]], "topomodelx.nn.hypergraph.template_layer": [[2, 1, 1, "", "TemplateLayer"]], "topomodelx.nn.hypergraph.template_layer.TemplateLayer": [[2, 2, 1, "", "forward"], [2, 2, 1, "", "reset_parameters"]], "topomodelx.nn.simplicial": [[2, 0, 0, "-", "hsn_layer"]], "topomodelx.nn.simplicial.hsn_layer": [[2, 1, 1, "", "HSNLayer"]], "topomodelx.nn.simplicial.hsn_layer.HSNLayer": [[2, 2, 1, "", "forward"], [2, 2, 1, "", "reset_parameters"]], "topomodelx.utils": [[3, 0, 0, "-", "scatter"]], "topomodelx.utils.scatter": [[3, 3, 1, "", "broadcast"], [3, 3, 1, "", "scatter"], [3, 3, 1, "", "scatter_add"], [3, 3, 1, "", "scatter_mean"], [3, 3, 1, "", "scatter_sum"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"]}, "titleterms": {"base": 0, "api": 1, "refer": [1, 6, 30], "packag": 1, "modul": 1, "neural": [2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "network": [2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "hypergraph": [2, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20], "simplici": [2, 23, 24, 25, 26, 27, 28, 29, 31, 32], "complex": [2, 8, 26, 27, 28, 29, 32], "cell": [2, 7, 8], "util": 3, "scatter": 3, "icml": 4, "2023": 4, "topolog": 4, "deep": 4, "learn": 4, "challeng": 4, "descript": 4, "public": 4, "outcom": 4, "particip": 4, "deadlin": 4, "how": 4, "submit": 4, "guidelin": 4, "submiss": 4, "requir": 4, "evalu": [4, 32], "question": 4, "contribut": 5, "make": 5, "chang": 5, "write": 5, "test": [5, 26, 29, 31, 32], "run": 5, "document": 5, "intro": 5, "docstr": 5, "The": [5, 7, 8, 9, 25], "anatomi": 5, "exampl": 5, "topomodelx": 6, "tmx": 6, "get": 6, "start": 6, "train": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "attent": [7, 8, 25], "can": 7, "abstract": [7, 25], "task": [7, 8, 9, 25], "set": [7, 8, 9], "up": [7, 8, 9], "pre": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "process": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "creat": [7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "convolut": [8, 27, 28, 29, 30, 31], "ccxn": 8, "cw": 9, "cwn": 9, "addit": [10, 11, 17], "theoret": [10, 11, 17], "clarif": [10, 11, 17], "defin": [11, 12, 14, 16, 17, 18, 23, 24, 27, 28, 29, 30, 31], "import": [12, 14, 16, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31], "data": [12, 16, 18, 19, 20, 21, 22, 26, 29, 32], "neighborhood": [12, 14, 16, 18, 23, 24, 27, 28, 30, 31], "structur": [12, 14, 16, 18, 23, 24, 27, 29, 30], "lift": [12, 16, 18], "domain": [12, 16, 18], "messag": [13, 26], "pass": [13, 26], "hmpnn": 13, "hyperedg": [14, 15], "neuron": [14, 15], "hnhn": [14, 15], "dataset": [14, 23, 24, 27, 28, 29, 30, 31, 32], "signal": [14, 23, 24, 27, 28, 31], "us": 20, "unigcnii": 20, "layer": 20, "load": 20, "homologi": 23, "local": 23, "dist2cycl": 23, "binari": [23, 24, 27, 28, 31], "label": [23, 24, 27, 28, 31], "featur": 23, "high": 24, "skip": 24, "hsn": 24, "san": 25, "autoencod": 26, "sca": 26, "coadjac": 26, "scheme": 26, "cmp": 26, "prepar": [26, 29, 31], "input": 26, "each": 26, "split": [26, 31], "model": [26, 28, 31, 32], "sccn": 27, "sccnn": 28, "we": [28, 31], "perform": [28, 31], "1": [28, 31], "classif": [28, 31], "shrec": 28, "strcture": [28, 31], "2": [28, 29, 30, 31], "node": [28, 31], "scconv": 29, "helper": 29, "function": 29, "neighbourhood": 29, "simplex": 30, "scn": 30, "rank": 30, "scnn": 31, "compl": 31, "karat": 31, "weight": 31, "hodg": 31, "laplacian": 31, "net": 32, "scone": 32, "tabl": 32, "content": 32, "gener": 32, "trajectori": 32, "pytorch": 32, "dataload": 32, "suggest": 32, "further": 32, "experiment": 32, "tutori": 33}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.viewcode": 1, "sphinx": 60}, "alltitles": {"Base": [[0, "module-topomodelx.base.message_passing"]], "API Reference": [[1, "api-reference"]], "Packages & Modules": [[1, null]], "Neural Networks": [[2, "neural-networks"]], "Hypergraph Neural Networks": [[2, "module-topomodelx.nn.hypergraph.template_layer"]], "Simplicial Complex Neural Networks": [[2, "module-topomodelx.nn.simplicial.hsn_layer"]], "Cell Complex Neural Networks": [[2, "module-topomodelx.nn.cell.ccxn_layer"]], "Utils": [[3, "utils"]], "Scatter": [[3, "module-topomodelx.utils.scatter"]], "ICML 2023 Topological Deep Learning Challenge": [[4, "icml-2023-topological-deep-learning-challenge"]], "Description of the Challenge": [[4, "description-of-the-challenge"]], "\u2b50\ufe0f Publication Outcomes for Participants \u2b50\ufe0f": [[4, "publication-outcomes-for-participants"]], "Deadline": [[4, "deadline"]], "How to Submit": [[4, "how-to-submit"]], "Guidelines": [[4, "guidelines"]], "Submission Requirements": [[4, "submission-requirements"]], "Evaluation": [[4, "evaluation"]], "Questions": [[4, "questions"]], "Contributing": [[5, "contributing"]], "Making Changes": [[5, "making-changes"]], "Write Tests": [[5, "write-tests"]], "Run Tests": [[5, "run-tests"]], "Write Documentation": [[5, "write-documentation"]], "Intro to Docstrings": [[5, "intro-to-docstrings"]], "The Anatomy of a Docstring": [[5, "the-anatomy-of-a-docstring"]], "Docstring Examples": [[5, "docstring-examples"]], "\ud83c\udf10 TopoModelX (TMX) \ud83c\udf69": [[6, "topomodelx-tmx"]], "\ud83d\udd0d References": [[6, "references"]], "\ud83e\uddbe Getting Started": [[6, "getting-started"]], "Train a Cell Attention Network (CAN)": [[7, "Train-a-Cell-Attention-Network-(CAN)"]], "Abstract:": [[7, "Abstract:"]], "The Neural Network:": [[7, "The-Neural-Network:"], [8, "The-Neural-Network:"], [9, "The-Neural-Network:"]], "The Task:": [[7, "The-Task:"], [8, "The-Task:"], [9, "The-Task:"], [25, "The-Task:"]], "Set-up": [[7, "Set-up"], [8, "Set-up"], [9, "Set-up"]], "Pre-processing": [[7, "Pre-processing"], [8, "Pre-processing"], [9, "Pre-processing"], [10, "Pre-processing"], [11, "Pre-processing"], [12, "Pre-processing"], [13, "Pre-processing"], [14, "Pre-processing"], [15, "Pre-processing"], [16, "Pre-processing"], [17, "Pre-processing"], [18, "Pre-processing"], [19, "Pre-processing"], [21, "Pre-processing"], [22, "Pre-processing"], [23, "Pre-processing"], [24, "Pre-processing"], [25, "Pre-processing"], [26, "Pre-processing"], [27, "Pre-processing"], [28, "Pre-processing"], [29, "Pre-processing"], [30, "Pre-processing"], [31, "Pre-processing"]], "Create the Neural Network": [[7, "Create-the-Neural-Network"], [8, "Create-the-Neural-Network"], [9, "Create-the-Neural-Network"], [10, "Create-the-Neural-Network"], [12, "Create-the-Neural-Network"], [13, "Create-the-Neural-Network"], [14, "Create-the-Neural-Network"], [15, "Create-the-Neural-Network"], [18, "Create-the-Neural-Network"], [19, "Create-the-Neural-Network"], [21, "Create-the-Neural-Network"], [22, "Create-the-Neural-Network"], [23, "Create-the-Neural-Network"], [24, "Create-the-Neural-Network"], [25, "Create-the-Neural-Network"], [27, "Create-the-Neural-Network"]], "Train the Neural Network": [[7, "Train-the-Neural-Network"], [8, "Train-the-Neural-Network"], [9, "Train-the-Neural-Network"], [10, "Train-the-Neural-Network"], [11, "Train-the-Neural-Network"], [12, "Train-the-Neural-Network"], [13, "Train-the-Neural-Network"], [14, "Train-the-Neural-Network"], [15, "Train-the-Neural-Network"], [16, "Train-the-Neural-Network"], [17, "Train-the-Neural-Network"], [18, "Train-the-Neural-Network"], [19, "Train-the-Neural-Network"], [21, "Train-the-Neural-Network"], [22, "Train-the-Neural-Network"], [23, "Train-the-Neural-Network"], [24, "Train-the-Neural-Network"], [25, "Train-the-Neural-Network"], [27, "Train-the-Neural-Network"], [30, "Train-the-Neural-Network"], [31, "Train-the-Neural-Network"]], "Train a Convolutional Cell Complex Network (CCXN)": [[8, "Train-a-Convolutional-Cell-Complex-Network-(CCXN)"]], "Train the Neural Network with Attention": [[8, "Train-the-Neural-Network-with-Attention"]], "Train a CW Network (CWN)": [[9, "Train-a-CW-Network-(CWN)"]], "Train a Hypergraph Neural Network": [[10, "Train-a-Hypergraph-Neural-Network"], [11, "Train-a-Hypergraph-Neural-Network"], [12, "Train-a-Hypergraph-Neural-Network"], [16, "Train-a-Hypergraph-Neural-Network"], [17, "Train-a-Hypergraph-Neural-Network"], [18, "Train-a-Hypergraph-Neural-Network"]], "Additional theoretical clarifications": [[10, "Additional-theoretical-clarifications"], [11, "Additional-theoretical-clarifications"], [17, "Additional-theoretical-clarifications"]], "Define the Neural Network": [[11, "Define-the-Neural-Network"], [16, "Define-the-Neural-Network"], [17, "Define-the-Neural-Network"]], "Import data": [[12, "Import-data"], [16, "Import-data"], [18, "Import-data"], [19, "Import-data"], [21, "Import-data"], [22, "Import-data"], [26, "Import-data"]], "Define neighborhood structures and lift into hypergraph domain.": [[12, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."], [16, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."], [18, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."]], "Train a Hypergraph Message Passing Neural Network (HMPNN)": [[13, "Train-a-Hypergraph-Message-Passing-Neural-Network-(HMPNN)"]], "Train a Hypergraph Networks with Hyperedge Neurons (HNHN)": [[14, "Train-a-Hypergraph-Networks-with-Hyperedge-Neurons-(HNHN)"]], "Import dataset": [[14, "Import-dataset"], [23, "Import-dataset"], [24, "Import-dataset"], [27, "Import-dataset"], [29, "Import-dataset"], [30, "Import-dataset"]], "Define neighborhood structures.": [[14, "Define-neighborhood-structures."], [23, "Define-neighborhood-structures."], [24, "Define-neighborhood-structures."], [27, "Define-neighborhood-structures."], [30, "Define-neighborhood-structures."]], "Import signal": [[14, "Import-signal"], [23, "Import-signal"], [24, "Import-signal"], [27, "Import-signal"], [28, "Import-signal"]], "Train a Hypergraph Network with Hyperedge Neurons (HNHN)": [[15, "Train-a-Hypergraph-Network-with-Hyperedge-Neurons-(HNHN)"]], "Train a hypergraph neural network using UniGCNII layers": [[20, "Train-a-hypergraph-neural-network-using-UniGCNII-layers"]], "Loading the data": [[20, "Loading-the-data"]], "Creating a neural network": [[20, "Creating-a-neural-network"]], "Training the neural network": [[20, "Training-the-neural-network"]], "Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)": [[23, "Train-a-Simplicial-Neural-Network-for-Homology-Localization-(Dist2Cycle)"]], "Define binary labels": [[23, "Define-binary-labels"], [24, "Define-binary-labels"], [27, "Define-binary-labels"], [28, "Define-binary-labels"]], "Create Features": [[23, "Create-Features"]], "Train a Simplicial High-Skip Network (HSN)": [[24, "Train-a-Simplicial-High-Skip-Network-(HSN)"]], "Train a Simplicial Attention Network (SAN)": [[25, "Train-a-Simplicial-Attention-Network-(SAN)"]], "Abstract": [[25, "Abstract"]], "The Neural Network": [[25, "The-Neural-Network"]], "Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)": [[26, "Train-a-Simplicial-Complex-Autoencoder-(SCA)-with-Coadjacency-Message-Passing-Scheme-(CMPS)"]], "Preparing the inputs to test each message passing scheme:": [[26, "Preparing-the-inputs-to-test-each-message-passing-scheme:"]], "Coadjacency Message Passing Scheme (CMPS):": [[26, "Coadjacency-Message-Passing-Scheme-(CMPS):"]], "Create the Neural Networks": [[26, "Create-the-Neural-Networks"]], "Train and Test Split": [[26, "Train-and-Test-Split"]], "Training and Testing Model": [[26, "Training-and-Testing-Model"]], "Train a Simplicial Complex Convolutional Network (SCCN)": [[27, "Train-a-Simplicial-Complex-Convolutional-Network-(SCCN)"]], "Train a SCCNN": [[28, "Train-a-SCCNN"]], "We train the model to perform:": [[28, "We-train-the-model-to-perform:"], [31, "We-train-the-model-to-perform:"]], "Simplicial Complex Convolutional Neural Networks [SCCNN]": [[28, "Simplicial-Complex-Convolutional-Neural-Networks-[SCCNN]"]], "1. Complex Classification": [[28, "1.-Complex-Classification"]], "Import shrec dataset": [[28, "Import-shrec-dataset"]], "Define Neighborhood Strctures": [[28, "Define-Neighborhood-Strctures"], [28, "id1"], [31, "Define-Neighborhood-Strctures"], [31, "id1"]], "Create and Train the Neural Network": [[28, "Create-and-Train-the-Neural-Network"], [28, "id2"], [29, "Create-and-Train-the-Neural-Network"]], "2. Node Classification": [[28, "2.-Node-Classification"], [31, "2.-Node-Classification"]], "Train a Simplicial 2-complex convolutional neural network (SCConv)": [[29, "Train-a-Simplicial-2-complex-convolutional-neural-network-(SCConv)"]], "Helper functions": [[29, "Helper-functions"]], "Define Neighbourhood Structures": [[29, "Define-Neighbourhood-Structures"]], "prepare training and test data": [[29, "prepare-training-and-test-data"]], "Train a Simplex Convolutional Network (SCN) of Rank 2": [[30, "Train-a-Simplex-Convolutional-Network-(SCN)-of-Rank-2"]], "References": [[30, "References"]], "Train a Simplicial Convolutional Neural Network (SCNN)": [[31, "Train-a-Simplicial-Convolutional-Neural-Network-(SCNN)"]], "Simplicial Convolutional Neural Networks [SCNN]": [[31, "Simplicial-Convolutional-Neural-Networks-[SCNN]"]], "1. Comples Classification": [[31, "1.-Comples-Classification"]], "Import Karate dataset": [[31, "Import-Karate-dataset"]], "Weighted Hodge Laplacians": [[31, "Weighted-Hodge-Laplacians"]], "Import signals": [[31, "Import-signals"]], "Define binary labels and Prepare the training-testing split": [[31, "Define-binary-labels-and-Prepare-the-training-testing-split"]], "Create the SCNN for node classification": [[31, "Create-the-SCNN-for-node-classification"]], "Train the SCNN": [[31, "Train-the-SCNN"]], "Train a Simplicial Complex Net (SCoNe)": [[32, "Train-a-Simplicial-Complex-Net-(SCoNe)"]], "Table of contents": [[32, "Table-of-contents"]], "Dataset generation": [[32, "Dataset-generation"]], "Generating trajectories": [[32, "Generating-trajectories"]], "Creating PyTorch dataloaders": [[32, "Creating-PyTorch-dataloaders"]], "Creating the Neural Network": [[32, "Creating-the-Neural-Network"]], "Training the Neural Network": [[32, "Training-the-Neural-Network"]], "Evaluating the model on test data": [[32, "Evaluating-the-model-on-test-data"]], "Suggestions for further experimentation": [[32, "Suggestions-for-further-experimentation"]], "Tutorials": [[33, "tutorials"]]}, "indexentries": {"aggregation (class in topomodelx.base.aggregation)": [[0, "topomodelx.base.aggregation.Aggregation"]], "conv (class in topomodelx.base.conv)": [[0, "topomodelx.base.conv.Conv"]], "messagepassing (class in topomodelx.base.message_passing)": [[0, "topomodelx.base.message_passing.MessagePassing"]], "aggregate() (topomodelx.base.message_passing.messagepassing method)": [[0, "topomodelx.base.message_passing.MessagePassing.aggregate"]], "attention() (topomodelx.base.message_passing.messagepassing method)": [[0, "topomodelx.base.message_passing.MessagePassing.attention"]], "forward() (topomodelx.base.aggregation.aggregation method)": [[0, "topomodelx.base.aggregation.Aggregation.forward"]], "forward() (topomodelx.base.conv.conv method)": [[0, "topomodelx.base.conv.Conv.forward"]], "forward() (topomodelx.base.message_passing.messagepassing method)": [[0, "topomodelx.base.message_passing.MessagePassing.forward"]], "message() (topomodelx.base.message_passing.messagepassing method)": [[0, "topomodelx.base.message_passing.MessagePassing.message"]], "module": [[0, "module-topomodelx.base.aggregation"], [0, "module-topomodelx.base.conv"], [0, "module-topomodelx.base.message_passing"], [2, "module-topomodelx.nn.cell.ccxn_layer"], [2, "module-topomodelx.nn.hypergraph.template_layer"], [2, "module-topomodelx.nn.simplicial.hsn_layer"], [3, "module-topomodelx.utils.scatter"]], "reset_parameters() (topomodelx.base.message_passing.messagepassing method)": [[0, "topomodelx.base.message_passing.MessagePassing.reset_parameters"]], "topomodelx.base.aggregation": [[0, "module-topomodelx.base.aggregation"]], "topomodelx.base.conv": [[0, "module-topomodelx.base.conv"]], "topomodelx.base.message_passing": [[0, "module-topomodelx.base.message_passing"]], "update() (topomodelx.base.aggregation.aggregation method)": [[0, "topomodelx.base.aggregation.Aggregation.update"]], "update() (topomodelx.base.conv.conv method)": [[0, "topomodelx.base.conv.Conv.update"]], "ccxnlayer (class in topomodelx.nn.cell.ccxn_layer)": [[2, "topomodelx.nn.cell.ccxn_layer.CCXNLayer"]], "hsnlayer (class in topomodelx.nn.simplicial.hsn_layer)": [[2, "topomodelx.nn.simplicial.hsn_layer.HSNLayer"]], "templatelayer (class in topomodelx.nn.hypergraph.template_layer)": [[2, "topomodelx.nn.hypergraph.template_layer.TemplateLayer"]], "forward() (topomodelx.nn.cell.ccxn_layer.ccxnlayer method)": [[2, "topomodelx.nn.cell.ccxn_layer.CCXNLayer.forward"]], "forward() (topomodelx.nn.hypergraph.template_layer.templatelayer method)": [[2, "topomodelx.nn.hypergraph.template_layer.TemplateLayer.forward"]], "forward() (topomodelx.nn.simplicial.hsn_layer.hsnlayer method)": [[2, "topomodelx.nn.simplicial.hsn_layer.HSNLayer.forward"]], "reset_parameters() (topomodelx.nn.hypergraph.template_layer.templatelayer method)": [[2, "topomodelx.nn.hypergraph.template_layer.TemplateLayer.reset_parameters"]], "reset_parameters() (topomodelx.nn.simplicial.hsn_layer.hsnlayer method)": [[2, "topomodelx.nn.simplicial.hsn_layer.HSNLayer.reset_parameters"]], "topomodelx.nn.cell.ccxn_layer": [[2, "module-topomodelx.nn.cell.ccxn_layer"]], "topomodelx.nn.hypergraph.template_layer": [[2, "module-topomodelx.nn.hypergraph.template_layer"]], "topomodelx.nn.simplicial.hsn_layer": [[2, "module-topomodelx.nn.simplicial.hsn_layer"]], "broadcast() (in module topomodelx.utils.scatter)": [[3, "topomodelx.utils.scatter.broadcast"]], "scatter() (in module topomodelx.utils.scatter)": [[3, "topomodelx.utils.scatter.scatter"]], "scatter_add() (in module topomodelx.utils.scatter)": [[3, "topomodelx.utils.scatter.scatter_add"]], "scatter_mean() (in module topomodelx.utils.scatter)": [[3, "topomodelx.utils.scatter.scatter_mean"]], "scatter_sum() (in module topomodelx.utils.scatter)": [[3, "topomodelx.utils.scatter.scatter_sum"]], "topomodelx.utils.scatter": [[3, "module-topomodelx.utils.scatter"]]}})