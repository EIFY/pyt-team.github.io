Search.setIndex({"docnames": ["api/base/aggregation", "api/base/conv", "api/base/index", "api/base/message_passing", "api/index", "api/nn/cell/can", "api/nn/cell/can_layer", "api/nn/cell/ccxn", "api/nn/cell/ccxn_layer", "api/nn/cell/cwn", "api/nn/cell/cwn_layer", "api/nn/cell/index", "api/nn/hypergraph/allset", "api/nn/hypergraph/allset_layer", "api/nn/hypergraph/allset_transformer", "api/nn/hypergraph/allset_transformer_layer", "api/nn/hypergraph/dhgcn", "api/nn/hypergraph/dhgcn_layer", "api/nn/hypergraph/hmpnn", "api/nn/hypergraph/hmpnn_layer", "api/nn/hypergraph/hnhn", "api/nn/hypergraph/hnhn_layer", "api/nn/hypergraph/hnhn_layer_bis", "api/nn/hypergraph/hypergat", "api/nn/hypergraph/hypergat_layer", "api/nn/hypergraph/hypersage", "api/nn/hypergraph/hypersage_layer", "api/nn/hypergraph/index", "api/nn/hypergraph/unigcn", "api/nn/hypergraph/unigcn_layer", "api/nn/hypergraph/unigcnii", "api/nn/hypergraph/unigcnii_layer", "api/nn/hypergraph/unigin", "api/nn/hypergraph/unigin_layer", "api/nn/hypergraph/unisage", "api/nn/hypergraph/unisage_layer", "api/nn/index", "api/nn/simplicial/dist2cycle", "api/nn/simplicial/dist2cycle_layer", "api/nn/simplicial/hsn", "api/nn/simplicial/hsn_layer", "api/nn/simplicial/index", "api/nn/simplicial/san", "api/nn/simplicial/san_layer", "api/nn/simplicial/sca_cmps", "api/nn/simplicial/sca_cmps_layer", "api/nn/simplicial/sccn", "api/nn/simplicial/sccn_layer", "api/nn/simplicial/sccnn", "api/nn/simplicial/sccnn_layer", "api/nn/simplicial/scconv", "api/nn/simplicial/scconv_layer", "api/nn/simplicial/scn2", "api/nn/simplicial/scn2_layer", "api/nn/simplicial/scnn", "api/nn/simplicial/scnn_layer", "api/nn/simplicial/scone", "api/nn/simplicial/scone_layer", "api/utils/index", "challenge/index", "contributing/index", "index", "notebooks/cell/can_train", "notebooks/cell/ccxn_train", "notebooks/cell/cwn_train", "notebooks/combinatorial/hmc_train", "notebooks/hypergraph/allset_train", "notebooks/hypergraph/allset_transformer_train", "notebooks/hypergraph/dhgcn_train", "notebooks/hypergraph/hmpnn_train", "notebooks/hypergraph/hnhn_train", "notebooks/hypergraph/hypergat_train", "notebooks/hypergraph/hypersage_train", "notebooks/hypergraph/unigcn_train", "notebooks/hypergraph/unigcnii_train", "notebooks/hypergraph/unigin_train", "notebooks/hypergraph/unisage_train", "notebooks/simplicial/dist2cycle_train", "notebooks/simplicial/hsn_train", "notebooks/simplicial/san_train", "notebooks/simplicial/sca_cmps_train", "notebooks/simplicial/sccn_train", "notebooks/simplicial/sccnn_train", "notebooks/simplicial/scconv_train", "notebooks/simplicial/scn2_train", "notebooks/simplicial/scnn_train", "notebooks/simplicial/scone_train", "tutorials/index"], "filenames": ["api/base/aggregation.rst", "api/base/conv.rst", "api/base/index.rst", "api/base/message_passing.rst", "api/index.rst", "api/nn/cell/can.rst", "api/nn/cell/can_layer.rst", "api/nn/cell/ccxn.rst", "api/nn/cell/ccxn_layer.rst", "api/nn/cell/cwn.rst", "api/nn/cell/cwn_layer.rst", "api/nn/cell/index.rst", "api/nn/hypergraph/allset.rst", "api/nn/hypergraph/allset_layer.rst", "api/nn/hypergraph/allset_transformer.rst", "api/nn/hypergraph/allset_transformer_layer.rst", "api/nn/hypergraph/dhgcn.rst", "api/nn/hypergraph/dhgcn_layer.rst", "api/nn/hypergraph/hmpnn.rst", "api/nn/hypergraph/hmpnn_layer.rst", "api/nn/hypergraph/hnhn.rst", "api/nn/hypergraph/hnhn_layer.rst", "api/nn/hypergraph/hnhn_layer_bis.rst", "api/nn/hypergraph/hypergat.rst", "api/nn/hypergraph/hypergat_layer.rst", "api/nn/hypergraph/hypersage.rst", "api/nn/hypergraph/hypersage_layer.rst", "api/nn/hypergraph/index.rst", "api/nn/hypergraph/unigcn.rst", "api/nn/hypergraph/unigcn_layer.rst", "api/nn/hypergraph/unigcnii.rst", "api/nn/hypergraph/unigcnii_layer.rst", "api/nn/hypergraph/unigin.rst", "api/nn/hypergraph/unigin_layer.rst", "api/nn/hypergraph/unisage.rst", "api/nn/hypergraph/unisage_layer.rst", "api/nn/index.rst", "api/nn/simplicial/dist2cycle.rst", "api/nn/simplicial/dist2cycle_layer.rst", "api/nn/simplicial/hsn.rst", "api/nn/simplicial/hsn_layer.rst", "api/nn/simplicial/index.rst", "api/nn/simplicial/san.rst", "api/nn/simplicial/san_layer.rst", "api/nn/simplicial/sca_cmps.rst", "api/nn/simplicial/sca_cmps_layer.rst", "api/nn/simplicial/sccn.rst", "api/nn/simplicial/sccn_layer.rst", "api/nn/simplicial/sccnn.rst", "api/nn/simplicial/sccnn_layer.rst", "api/nn/simplicial/scconv.rst", "api/nn/simplicial/scconv_layer.rst", "api/nn/simplicial/scn2.rst", "api/nn/simplicial/scn2_layer.rst", "api/nn/simplicial/scnn.rst", "api/nn/simplicial/scnn_layer.rst", "api/nn/simplicial/scone.rst", "api/nn/simplicial/scone_layer.rst", "api/utils/index.rst", "challenge/index.rst", "contributing/index.rst", "index.rst", "notebooks/cell/can_train.ipynb", "notebooks/cell/ccxn_train.ipynb", "notebooks/cell/cwn_train.ipynb", "notebooks/combinatorial/hmc_train.ipynb", "notebooks/hypergraph/allset_train.ipynb", "notebooks/hypergraph/allset_transformer_train.ipynb", "notebooks/hypergraph/dhgcn_train.ipynb", "notebooks/hypergraph/hmpnn_train.ipynb", "notebooks/hypergraph/hnhn_train.ipynb", "notebooks/hypergraph/hypergat_train.ipynb", "notebooks/hypergraph/hypersage_train.ipynb", "notebooks/hypergraph/unigcn_train.ipynb", "notebooks/hypergraph/unigcnii_train.ipynb", "notebooks/hypergraph/unigin_train.ipynb", "notebooks/hypergraph/unisage_train.ipynb", "notebooks/simplicial/dist2cycle_train.ipynb", "notebooks/simplicial/hsn_train.ipynb", "notebooks/simplicial/san_train.ipynb", "notebooks/simplicial/sca_cmps_train.ipynb", "notebooks/simplicial/sccn_train.ipynb", "notebooks/simplicial/sccnn_train.ipynb", "notebooks/simplicial/scconv_train.ipynb", "notebooks/simplicial/scn2_train.ipynb", "notebooks/simplicial/scnn_train.ipynb", "notebooks/simplicial/scone_train.ipynb", "tutorials/index.rst"], "titles": ["Aggregation", "Conv", "Base", "Message Passing", "API Reference", "CAN", "Can_Layer", "CCXN", "CCXN_Layer", "CWN", "Cwn_Layer", "Cell", "AllSet", "AllSet_Layer", "AllSet_Transformer", "AllSet_Transformer_Layer", "DHGCN", "DHGCN_Layer", "HMPNN", "HMPNN_Layer", "HNHN", "HNHN_Layer", "HNHN_Layer_Bis", "Hypergat", "Hypergat_Layer", "Hypersage", "Hypersage_Layer", "Hypergraph", "Unigcn", "Unigcn_Layer", "Unigcnii", "Unigcnii_Layer", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "Neural Networks", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "Simplicial", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "Utils", "ICML 2023 Topological Deep Learning Challenge", "Contributing", "\ud83c\udf10 TopoModelX (TMX) \ud83c\udf69", "Train a Cell Attention Network (CAN)", "Train a Convolutional Cell Complex Network (CCXN)", "Train a CW Network (CWN)", "Train a Combinatorial Complex Attention Neural Network for Mesh Classification.", "Train an All-Set TNN", "Train an All-Set-Transformer TNN", "Train a DHGCN TNN", "Train a Hypergraph Message Passing Neural Network (HMPNN)", "Train a Hypergraph Networks with Hyperedge Neurons (HNHN)", "Train a Hypergraph Neural Network", "Train a Hypersage TNN", "Train a UNIGCN TNN", "Train a hypergraph neural network using UniGCNII layers", "Train a UNIGIN TNN", "Train a Uni-sage TNN", "Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)", "Train a Simplicial High-Skip Network (HSN)", "Train a Simplicial Attention Network (SAN)", "Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)", "Train a Simplicial Complex Convolutional Network (SCCN)", "Train a SCCNN", "Train a Simplicial 2-complex convolutional neural network (SCConv)", "Train a Simplex Convolutional Network (SCN) of Rank 2", "Train a Simplicial Convolutional Neural Network (SCNN)", "Train a Simplicial Complex Net (SCoNe)", "Tutorials"], "terms": {"modul": [0, 3, 5, 6, 10, 12, 13, 14, 15, 19, 36, 59, 60, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "class": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "topomodelx": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "base": [0, 1, 3, 4, 10, 11, 15, 26, 27, 41, 45, 59, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 82, 85, 86], "aggr_func": [0, 3, 6, 19, 47], "liter": [0, 1, 3, 6, 15, 19, 21, 24, 26, 35, 43, 47, 57], "mean": [0, 3, 6, 19, 26, 35, 47, 49, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "sum": [0, 3, 6, 15, 19, 29, 31, 33, 35, 47, 49, 62, 65, 66, 67, 70, 71, 72, 74, 76, 79, 81, 82, 83, 84, 86], "update_func": [0, 1, 6, 15, 24, 26, 46, 47, 48, 49, 50, 54, 55, 57, 81, 82, 86], "relu": [0, 1, 6, 13, 15, 24, 26, 47, 57, 65, 71, 86], "sigmoid": [0, 1, 6, 19, 26, 46, 47, 57, 62, 79, 81, 82, 86], "tanh": [0, 6, 47, 57], "none": [0, 1, 3, 6, 8, 10, 12, 13, 15, 19, 21, 24, 29, 31, 35, 38, 40, 42, 43, 45, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 60, 65, 82, 85, 86], "sourc": [0, 1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "messag": [0, 1, 2, 4, 6, 8, 10, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53, 59, 62, 63, 64, 65, 66, 67, 68, 71, 72, 79, 81], "pass": [0, 1, 2, 4, 5, 6, 8, 10, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 56, 57, 59, 62, 63, 65, 66, 67, 68, 71, 72, 79, 81, 82, 85, 86], "layer": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "paramet": [0, 1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "default": [0, 1, 3, 5, 6, 8, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 35, 42, 43, 44, 45, 47, 49, 54, 60], "method": [0, 1, 3, 6, 15, 21, 24, 26, 43, 49, 55, 59, 60, 65, 69], "inter": [0, 26, 72, 82], "neighborhood": [0, 1, 2, 3, 5, 6, 8, 10, 15, 29, 43, 49, 59, 62, 63, 64, 65, 66, 67, 72, 79, 86], "updat": [0, 1, 2, 3, 6, 10, 15, 24, 26, 29, 31, 33, 35, 41, 43, 48, 49, 55, 57, 62, 65, 66, 67, 79, 86], "appli": [0, 1, 3, 5, 6, 10, 12, 15, 18, 19, 24, 26, 47, 57, 67, 71, 77, 79, 85, 86], "merg": 0, "forward": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "x": [0, 1, 3, 6, 8, 10, 13, 15, 19, 21, 24, 25, 26, 29, 31, 33, 35, 38, 40, 42, 43, 44, 45, 47, 49, 51, 53, 54, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "list": [0, 12, 13, 14, 15, 44, 45, 56, 60, 65, 66, 67, 68, 70, 72, 74, 76, 86], "A": [0, 3, 8, 10, 12, 13, 14, 15, 18, 21, 26, 38, 51, 59, 60, 61, 62, 63, 64, 65, 70, 77, 78, 79, 80, 81, 82, 83, 85, 86], "each": [0, 1, 3, 6, 24, 26, 40, 44, 45, 47, 48, 49, 55, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86], "ha": [0, 1, 6, 60, 63, 64, 68, 71, 77, 78, 79, 81, 82, 84, 85], "shape": [0, 1, 3, 5, 6, 7, 8, 9, 10, 13, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "n_skeleton_in": 0, "channel": [0, 5, 6, 8, 13, 15, 37, 38, 39, 40, 43, 46, 47, 48, 50, 51, 52, 53, 54, 55, 65, 77, 78, 79, 80, 81, 83], "len": [0, 65, 66, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "n_messages_to_merg": 0, "return": [0, 1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "torch": [0, 1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "tensor": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "input": [0, 1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85], "step": [0, 1, 3, 6, 8, 10, 21, 24, 26, 29, 33, 35, 49, 55, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "4": [0, 1, 10, 14, 15, 24, 26, 49, 55, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "featur": [0, 1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86], "same": [0, 1, 3, 6, 15, 24, 26, 43, 47, 48, 49, 53, 59, 60, 62, 63, 65, 68, 71, 79, 82, 85, 86], "convolut": [1, 6, 8, 9, 10, 21, 42, 43, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 59, 79], "in_channel": [1, 3, 6, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 42, 43, 49, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "out_channel": [1, 3, 5, 6, 10, 15, 26, 42, 43, 49, 54, 55, 57, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "aggr_norm": [1, 15, 29, 48, 49, 54, 55], "bool": [1, 3, 5, 6, 7, 8, 12, 13, 15, 21, 29, 33, 35, 44, 45, 48, 49, 54, 55, 60], "fals": [1, 3, 6, 7, 8, 12, 13, 15, 29, 33, 35, 44, 45, 48, 49, 54, 55, 62, 63, 64, 68, 71, 73, 75, 82, 84, 85], "att": [1, 3, 7, 8, 24, 43, 44, 45, 49, 63, 65, 71, 80], "initi": [1, 3, 6, 8, 10, 15, 21, 24, 26, 29, 33, 35, 40, 43, 45, 47, 49, 55, 57, 62, 63, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 82], "xavier_uniform": [1, 3, 6, 15, 21, 24, 26, 43, 55], "xavier_norm": [1, 3, 6, 15, 21, 24, 26, 43, 49], "initialization_gain": [1, 3, 15, 24], "float": [1, 3, 5, 6, 12, 13, 14, 15, 19, 21, 24, 30, 31, 32, 33, 34, 42, 49, 55, 57, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "1": [1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 86], "414": [1, 3, 15, 21, 24, 49, 55], "with_linear_transform": 1, "true": [1, 5, 6, 21, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "2": [1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 18, 20, 21, 23, 25, 26, 28, 29, 30, 32, 33, 34, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 86], "3": [1, 5, 6, 8, 10, 21, 26, 29, 33, 35, 40, 45, 47, 51, 53, 55, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "build": [1, 2, 56, 59, 60, 86], "rout": 1, "given": [1, 3, 8, 10, 19, 21, 29, 33, 35, 40, 45, 47, 57, 59, 62, 63, 64, 65, 66, 67, 70, 71, 72, 77, 78, 79, 81, 82, 83, 85, 86], "one": [1, 3, 15, 21, 24, 47, 53, 54, 57, 59, 60, 63, 65, 66, 67, 70, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86], "matrix": [1, 3, 5, 6, 7, 8, 9, 10, 13, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 42, 43, 44, 49, 50, 51, 53, 55, 57, 60, 63, 64, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86], "includ": [1, 59, 60, 65, 86], "an": [1, 4, 6, 8, 10, 49, 55, 59, 60, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "option": [1, 3, 5, 6, 8, 10, 13, 15, 26, 31, 59, 60, 66, 67, 70, 72, 74, 76], "specif": [1, 9, 59, 60, 64, 66, 67, 70, 71, 72], "function": [1, 3, 5, 6, 12, 13, 14, 15, 19, 26, 31, 35, 45, 46, 47, 48, 49, 50, 51, 55, 57, 58, 59, 60, 62, 64, 65, 66, 67, 72, 74, 77, 78, 79, 80, 81, 82, 83, 85, 86], "int": [1, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 86], "dimens": [1, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "output": [1, 3, 5, 6, 8, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 42, 43, 45, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "whether": [1, 3, 5, 6, 7, 8, 12, 13, 15, 21, 29, 33, 35, 44, 45, 48, 49, 54], "normal": [1, 6, 12, 13, 15, 21, 29, 31, 47, 48, 49, 50, 51, 53, 55, 65, 67, 81, 84], "aggreg": [1, 2, 3, 4, 6, 10, 15, 19, 26, 29, 35, 45, 46, 47, 48, 49, 50, 54, 55, 59, 62, 65, 71, 72, 79, 85], "size": [1, 12, 14, 15, 29, 49, 62, 63, 64, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 81, 82, 84, 85, 86], "us": [1, 3, 5, 6, 7, 8, 10, 19, 21, 29, 31, 33, 35, 42, 43, 44, 45, 46, 47, 49, 50, 51, 56, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "attent": [1, 2, 3, 5, 6, 7, 8, 14, 15, 24, 42, 43, 44, 45, 59, 67, 71], "gain": [1, 3, 15, 21, 24, 49, 55, 57], "learnabl": [1, 3, 6, 13, 15, 21, 29, 35, 38, 40, 43, 47, 49, 53, 55, 57, 62, 65, 67, 79, 85], "linear": [1, 6, 7, 9, 19, 23, 25, 28, 29, 31, 32, 34, 35, 44, 54, 59, 62, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "transform": [1, 6, 14, 15, 29, 31, 35, 60, 65, 79], "nb": 1, "equal": [1, 60, 66, 67, 70, 71, 72, 74, 76, 86], "x_sourc": [1, 3, 6, 15, 24, 43], "x_target": [1, 3, 6, 24], "thi": [1, 2, 3, 6, 8, 10, 19, 21, 26, 29, 33, 35, 40, 43, 45, 47, 48, 49, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "implement": [1, 3, 4, 6, 8, 9, 10, 15, 18, 20, 21, 23, 24, 25, 26, 28, 29, 31, 32, 33, 34, 35, 37, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 65, 66, 67, 70, 72, 79, 81, 86], "from": [1, 3, 5, 6, 8, 10, 15, 18, 19, 21, 26, 29, 33, 35, 43, 45, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "cell": [1, 3, 5, 6, 7, 8, 9, 10, 15, 24, 26, 36, 40, 43, 46, 47, 49, 50, 53, 54, 55, 59, 64, 65, 66, 67, 68, 70, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "via": [1, 3, 38, 40, 43, 46, 47, 66, 70, 72, 74, 76], "defin": [1, 2, 3, 43, 56, 59, 60, 62, 63, 64, 65, 66, 67, 69, 72, 73, 75, 79, 86], "where": [1, 3, 43, 45, 49, 55, 59, 60, 62, 63, 64, 65, 67, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 85, 86], "can": [1, 3, 6, 8, 11, 21, 43, 47, 48, 55, 57, 59, 60, 61, 65, 66, 70, 71, 72, 74, 76, 77, 78, 79, 81, 83, 85, 86], "target": [1, 3, 6, 15, 24, 26, 43, 49, 55, 63, 68, 71, 82, 85], "In": [1, 3, 19, 43, 48, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "practic": [1, 3, 43, 66, 67], "If": [1, 3, 6, 10, 19, 24, 26, 31, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 79, 80, 82, 84], "provid": [1, 3, 6, 31, 49, 55, 59, 60, 82, 85], "i": [1, 2, 3, 5, 6, 8, 10, 11, 19, 21, 26, 27, 29, 30, 31, 33, 35, 38, 40, 41, 42, 45, 47, 53, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "assum": [1, 3, 15, 24, 26, 43], "e": [1, 3, 6, 12, 14, 19, 49, 54, 55, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 82, 84, 85, 86], "send": [1, 3, 8, 10, 21, 59, 62, 63, 64, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 84], "themselv": [1, 3, 81], "n_source_cel": [1, 3, 15, 24, 43], "all": [1, 3, 6, 15, 24, 26, 30, 31, 43, 48, 58, 59, 60, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "have": [1, 3, 15, 19, 24, 26, 43, 49, 55, 59, 60, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86], "rank": [1, 3, 7, 9, 15, 20, 23, 24, 25, 26, 28, 32, 34, 39, 42, 43, 46, 47, 50, 51, 53, 59, 62, 63, 64, 65, 68, 71, 77, 78, 79, 80, 81, 82, 85], "r": [1, 3, 6, 8, 10, 15, 24, 43, 45, 46, 47, 53, 60, 62, 63, 64, 65, 66, 67, 71, 79, 80, 81, 86], "spars": [1, 3, 4, 6, 8, 10, 13, 15, 18, 19, 20, 21, 24, 29, 33, 35, 38, 40, 43, 46, 47, 49, 53, 55, 57, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "n_target_cel": [1, 3, 15, 24, 26, 43, 49, 55], "": [1, 3, 15, 18, 19, 26, 43, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 77, 78, 80, 81, 82, 83, 86], "x_message_on_target": [1, 15, 24, 26], "embed": [1, 24, 26, 49, 55, 65], "The": [2, 3, 4, 6, 8, 10, 11, 19, 21, 26, 27, 29, 31, 33, 35, 36, 40, 41, 42, 43, 45, 47, 49, 53, 55, 57, 59, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86], "compos": [2, 8, 10, 11, 21, 27, 29, 33, 35, 41, 65], "primarili": [2, 11, 27, 36, 41], "three": [2, 29, 33, 35, 36, 41, 59, 60, 74], "conv": [2, 4, 21], "structur": [2, 62, 63, 64, 66, 67, 72, 79, 82, 85], "messagepass": [2, 3, 49, 55], "reset_paramet": [2, 3, 6, 13, 15, 21, 24, 27, 29, 31, 35, 38, 40, 41, 43, 45, 47, 49, 51, 53, 55, 57], "message_pass": 3, "add": [3, 6, 13, 15, 19, 58, 60, 66, 67, 70, 72, 74, 76, 85], "uniform": [3, 6, 26, 86], "through": [3, 7, 9, 10, 18, 23, 25, 28, 30, 32, 34, 44, 56, 59, 85, 86], "singl": [3, 26, 59, 64], "n": [3, 6, 10, 43, 45, 56, 59, 60, 61, 62, 64, 65, 71, 72, 79, 80, 86], "decompos": 3, "creat": [3, 10, 56, 59, 60, 69, 71], "go": [3, 9, 10, 61, 62, 64, 65, 79, 86], "come": 3, "differ": [3, 47, 53, 60, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "onto": [3, 79], "should": [3, 6, 59, 60, 62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 86], "instanti": [3, 64], "directli": [3, 66, 70, 72, 74, 76], "rather": [3, 59, 60, 66, 67, 70, 72, 74, 76], "inherit": [3, 59], "subclass": [3, 49, 55], "effect": [3, 19, 65], "doe": [3, 59, 60, 82, 85, 86], "trainabl": [3, 33, 49, 55, 71], "weight": [3, 6, 15, 24, 43, 45, 49, 55, 60, 65, 67, 71, 79, 81, 82, 86], "its": [3, 19, 29, 31, 33, 35, 59, 60, 65, 69, 71], "refer": [3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 60, 62, 72, 79], "hajij": [3, 7, 8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 62, 63, 65, 78, 79], "zamzmi": [3, 7, 8, 40, 45, 61], "papamark": [3, 45, 59, 61], "miolan": [3, 8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61], "guzm\u00e1n": [3, 40, 59, 61], "s\u00e1enz": [3, 40, 59, 61], "ramamurthi": [3, 40, 59, 61], "birdal": [3, 59, 61], "dei": [3, 59, 61], "mukherje": [3, 59, 61], "samaga": [3, 59, 61], "livesai": [3, 59, 61], "walter": [3, 59, 61], "rosen": [3, 59, 61], "schaub": [3, 59, 61], "topolog": [3, 4, 7, 8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 61, 62, 63, 64, 65, 70, 77, 78, 79, 80, 81, 83, 85, 86], "deep": [3, 8, 10, 21, 26, 29, 33, 35, 40, 45, 47, 51, 53, 55, 57, 61, 62, 63, 64, 65, 67, 70, 77, 78, 79, 80, 81, 83, 85, 86], "learn": [3, 8, 10, 20, 21, 25, 26, 29, 31, 33, 35, 40, 45, 47, 51, 53, 55, 57, 60, 61, 62, 63, 64, 65, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "beyond": [3, 7, 8, 20, 21, 51, 61, 62, 65, 79], "graph": [3, 5, 6, 13, 15, 20, 21, 28, 29, 30, 31, 32, 33, 34, 35, 48, 49, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "data": [3, 7, 8, 47, 53, 60, 61, 62, 66, 67, 72, 79, 81, 84], "2023": [3, 8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 61, 62, 63, 64, 65, 70, 77, 78, 79, 80, 81, 82, 83, 85, 86], "http": [3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 40, 43, 45, 47, 51, 53, 55, 57, 62, 65, 66, 77, 78, 79, 80, 81, 82, 83, 84], "arxiv": [3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 21, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 40, 43, 45, 47, 51, 53, 55, 57, 61], "org": [3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 40, 43, 45, 47, 51, 53, 55, 57, 77, 78, 79, 80, 81, 82, 83], "ab": [3, 8, 9, 10, 12, 13, 14, 15, 18, 19, 21, 25, 26, 29, 33, 35, 40, 43, 45, 47, 51, 53, 55, 57, 83], "2206": [3, 61, 77], "00606": [3, 61], "papillon": [3, 8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 62, 63, 64, 65, 70, 77, 78, 79, 80, 81, 83, 85, 86], "sanborn": [3, 8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61], "architectur": [3, 8, 10, 15, 21, 26, 29, 33, 35, 40, 43, 45, 47, 51, 53, 55, 57, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 83, 85, 86], "survei": [3, 8, 10, 21, 26, 29, 33, 35, 40, 45, 47, 51, 53, 55, 57, 59, 61, 62, 63, 64, 65, 70, 77, 78, 79, 80, 81, 83, 85, 86], "neural": [3, 4, 7, 8, 10, 12, 13, 14, 15, 18, 19, 21, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 43, 45, 47, 49, 51, 53, 54, 55, 56, 57, 59, 61], "network": [3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 61], "2304": [3, 8, 10, 21, 26, 29, 33, 35, 40, 45, 47, 51, 53, 55, 57, 61], "10031": [3, 8, 10, 21, 26, 29, 33, 35, 40, 45, 47, 51, 53, 55, 57, 61], "x_messag": [3, 26], "receiv": [3, 10, 19, 26, 59], "sever": [3, 4, 26, 59], "per": [3, 15, 24, 26, 59, 60, 65], "correspond": [3, 10, 26, 47, 53, 55, 62, 65, 67, 69, 74], "within": [3, 60, 62, 65, 69, 79], "_": [3, 6, 8, 10, 15, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 63, 64, 65, 66, 67, 68, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "n_messag": [3, 24, 26], "associ": [3, 26, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83], "One": [3, 26, 59, 81, 85, 86], "sent": [3, 26], "comput": [3, 4, 6, 7, 9, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 31, 32, 34, 37, 39, 42, 44, 46, 48, 49, 50, 52, 54, 55, 58, 59, 60, 62, 65, 71, 79, 86], "scheme": [3, 6, 8, 45, 59, 63, 65, 79], "altern": [3, 59, 66, 70, 72, 74, 76], "user": [3, 77, 81, 82, 85], "overwrit": 3, "order": [3, 40, 42, 43, 47, 48, 49, 53, 54, 55, 57, 59, 62, 65, 78, 79, 81, 82, 84, 85, 86], "replac": 3, "own": 3, "mechan": [3, 5, 6, 8, 15, 24, 62, 63, 65, 67, 71, 79], "follow": [3, 6, 10, 56, 59, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "scalar": [3, 15, 21, 24, 63, 64, 86], "between": [3, 6, 8, 10, 13, 15, 19, 24, 26, 47, 53, 62, 65, 79, 81], "two": [3, 8, 10, 19, 21, 31, 49, 62, 65, 66, 67, 68, 71, 72, 77, 78, 79, 80, 81, 82, 83, 85, 86], "m_": [3, 6, 8, 10, 13, 15, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 62, 63, 64, 66, 67, 70, 71, 72, 77, 78, 79, 80, 81, 83, 85, 86], "y": [3, 6, 8, 10, 13, 15, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "rightarrow": [3, 6, 8, 10, 13, 15, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 62, 63, 64, 65, 66, 67, 70, 71, 72, 77, 78, 79, 80, 81, 83, 85, 86], "left": [3, 10, 26, 45, 56, 60, 64, 65, 71, 72, 86], "right": [3, 10, 26, 56, 60, 64, 65, 71, 72, 86], "travel": 3, "denot": [3, 66, 67, 71, 72, 85, 86], "mathcal": [3, 6, 8, 10, 13, 15, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 62, 63, 64, 66, 67, 70, 71, 72, 77, 78, 79, 80, 81, 83, 85, 86], "mathbf": [3, 82, 85], "h": [3, 24, 31, 40, 47, 51, 62, 67, 71, 72, 78, 79, 81, 82, 83, 85], "_x": [3, 38, 51, 53, 62, 77, 79, 83], "_y": [3, 31, 40, 47, 78, 81], "theta": [3, 6, 8, 21, 24, 26, 29, 33, 38, 40, 43, 45, 47, 49, 51, 53, 57, 62, 63, 65, 67, 70, 71, 72, 77, 78, 80, 81, 82, 83, 85, 86], "ar": [3, 6, 8, 10, 12, 13, 14, 15, 19, 21, 29, 33, 35, 40, 43, 45, 47, 49, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "call": [3, 19, 49, 55, 60, 67, 86], "leftarrow": [3, 72], "across": 3, "belong": [3, 60, 65, 77, 78, 79, 80, 81, 82, 83], "m_x": [3, 6, 8, 10, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 63, 64, 65, 70, 71, 72, 77, 78, 80, 81, 83, 85, 86], "text": [3, 8, 10, 15, 45, 49, 60, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83], "agg": [3, 8, 10, 19, 45, 80], "result": [3, 60, 62, 63, 67, 68, 71, 82, 85], "detail": [3, 10, 59, 60, 62, 67, 79], "found": [3, 65], "construct": [3, 6, 66, 67, 69, 70, 72, 74, 76, 86], "reset": [3, 6, 13, 15, 21, 24, 29, 31, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57], "note": [3, 6, 8, 10, 21, 40, 43, 45, 48, 49, 51, 53, 54, 55, 57, 59, 60, 62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 82, 86], "give": [4, 62, 65, 67, 79], "overview": 4, "which": [4, 6, 19, 26, 43, 48, 59, 60, 65, 66, 67, 69, 71, 74, 77, 78, 79, 80, 81, 82, 83, 85, 86], "consist": [4, 31, 36, 58, 59, 60, 66, 67, 70, 72, 74, 76, 86], "core": 4, "mathemat": 4, "concept": 4, "nn": [4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "organ": [4, 59, 81], "domain": [4, 59, 61, 62, 63, 64, 66, 67, 69, 72, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "util": [4, 6, 30, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "broadcast": [4, 58, 63, 68, 71, 82, 85], "scatter": [4, 58, 86], "scatter_add": [4, 58], "scatter_mean": [4, 58], "scatter_sum": [4, 58], "in_channels_0": [5, 6, 7, 8, 9, 10, 49, 52, 53, 62, 63, 64, 82, 84, 85], "in_channels_1": [5, 6, 7, 8, 9, 10, 49, 52, 53, 62, 63, 64, 82, 84, 85], "num_class": [5, 7, 8, 9, 18, 62, 63, 64, 65], "dropout": [5, 6, 12, 13, 14, 15, 18, 19, 30, 32, 34, 62], "0": [5, 6, 7, 8, 9, 12, 13, 14, 15, 18, 19, 21, 24, 26, 29, 30, 31, 32, 33, 34, 35, 39, 40, 42, 43, 45, 49, 50, 51, 53, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "5": [5, 18, 19, 21, 30, 42, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "head": [5, 6, 14, 15, 62, 67], "concat": [5, 6, 49, 55], "skip_connect": [5, 6], "att_activ": [5, 6, 62], "leakyrelu": [5, 6, 62, 65, 71, 79], "negative_slop": [5, 6, 62, 65], "n_layer": [5, 7, 9, 12, 14, 18, 20, 23, 25, 28, 30, 32, 34, 37, 39, 42, 44, 46, 48, 50, 52, 54, 56, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "att_lift": [5, 62], "classif": [5, 8, 10, 20, 21, 23, 25, 28, 30, 32, 34, 37, 39, 40, 42, 43, 45, 46, 48, 50, 52, 53, 54, 56, 59, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84], "number": [5, 6, 7, 9, 12, 13, 14, 15, 18, 19, 20, 30, 42, 43, 46, 48, 50, 54, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86], "node": [5, 6, 7, 8, 9, 10, 12, 13, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 86], "level": [5, 24, 30, 45, 59, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85], "edg": [5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 23, 24, 25, 28, 29, 31, 32, 33, 34, 35, 38, 40, 42, 44, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "probabl": [5, 6, 12, 13, 14, 15, 65, 82], "concaten": [5, 6, 19, 62, 67, 71, 86], "skip": [5, 6, 31, 37, 39, 40, 86], "connect": [5, 6, 31, 40, 56, 65, 71, 78, 82, 86], "activ": [5, 6, 12, 13, 15, 46, 47, 49, 50, 65, 67], "lift": [5, 6, 59, 62, 63, 64, 65, 66, 67, 72, 73, 75, 77, 78, 79, 80, 81, 82, 83, 85], "signal": [5, 6, 62, 63, 64, 65, 68, 71, 73, 75, 79], "giusti": [5, 6, 43, 59, 62, 79], "battiloro": [5, 6, 43, 59, 79], "testa": [5, 6], "di": [5, 6, 43], "lorenzo": [5, 6, 43], "sardellitti": [5, 6, 43], "barbarossa": [5, 6, 43], "2022": [5, 6, 12, 13, 14, 15, 18, 19, 40, 43, 45, 47, 53, 59, 62, 69, 77, 78, 79, 81, 85], "paper": [5, 6, 15, 19, 20, 21, 59, 62, 65, 69, 70, 77, 78, 79, 82, 83, 84, 85, 86], "pdf": [5, 6, 7, 8, 20, 21, 23, 24, 28, 29, 30, 31, 32, 33, 34, 35, 40, 45, 55, 60], "2209": [5, 6], "08179": [5, 6], "repositori": [5, 6, 59, 60], "lrnzgiusti": [5, 6], "x_0": [5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 49, 50, 51, 52, 53, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "x_1": [5, 6, 7, 8, 9, 10, 12, 13, 15, 18, 19, 20, 21, 23, 24, 28, 29, 30, 31, 32, 33, 34, 35, 49, 50, 51, 52, 53, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "neighborhood_0_to_0": [5, 6, 7, 8], "lower_neighborhood": [5, 6, 62], "upper_neighborhood": [5, 6, 62], "n_node": [5, 7, 9, 13, 15, 18, 19, 20, 21, 23, 25, 28, 29, 32, 33, 34, 35, 37, 38, 39, 40, 42, 48, 49, 50, 51, 52, 53, 54, 57], "n_edg": [5, 7, 9, 19, 20, 21, 23, 25, 28, 29, 32, 33, 34, 35, 38, 39, 40, 42, 48, 49, 50, 51, 52, 53, 54, 55, 57], "lower": [5, 6, 46, 47, 49, 54, 55, 56, 62, 79, 80, 82, 85, 86], "neighbourhood": [5, 6, 66, 67, 70, 72, 74, 76], "upper": [5, 6, 9, 10, 19, 42, 46, 47, 48, 49, 50, 51, 54, 55, 56, 62, 64, 79, 82, 85, 86], "predict": [5, 8, 14, 57, 60, 62, 65, 86], "complex": [5, 6, 7, 8, 9, 10, 25, 38, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59, 60, 62, 64, 68, 71, 77, 78, 79, 84], "canlay": [6, 11, 62], "01": [6, 63, 64, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 85, 86], "add_self_loop": [6, 11], "version": [6, 8, 9, 21, 63, 64, 65, 82, 85], "v1": 6, "v2": 6, "share_weight": 6, "model": [6, 30, 37, 39, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84], "consid": [6, 48, 49, 54, 55, 62, 77, 78, 79, 81, 82, 83], "though": 6, "addition": [6, 66, 67, 70, 72, 74, 76, 81], "ad": [6, 19, 59, 60, 65], "coeffici": [6, 62, 71], "otherwis": [6, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 80, 86], "averag": [6, 9, 54, 82, 84, 86], "callabl": [6, 13, 15, 19, 26], "self": [6, 30, 31, 60, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "loop": [6, 30, 31, 59, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86], "origin": [6, 31, 59, 60, 62, 63, 64, 79, 81, 82, 84, 85, 86], "while": [6, 59, 60, 79], "attet": 6, "gatv2": [6, 62], "valid": [6, 60, 65, 73, 74, 75, 86], "onli": [6, 8, 19, 53, 59, 60, 62, 65, 79, 82, 84, 86], "share": [6, 19, 59, 62, 65], "prefer": [6, 59, 60], "necessari": [6, 58, 59, 62, 65, 79], "preprocess": 6, "n_k_cell": 6, "map": [6, 8, 10, 13, 15, 19, 20, 21, 29, 33, 35, 38, 40, 46, 47, 57, 65, 83, 86], "a_k_low": 6, "a_k_up": 6, "n_1": [6, 43, 62, 79], "n_2": [6, 43, 62, 79], "a_": [6, 10, 40, 43, 62, 63, 64, 65, 71, 77, 78, 79], "uparrow": [6, 8, 10, 38, 40, 43, 47, 51, 53, 55, 57, 62, 63, 64, 65, 77, 78, 79, 81, 82, 83, 85, 86], "downarrow": [6, 38, 43, 45, 47, 51, 53, 55, 57, 62, 65, 77, 79, 80, 81, 82, 83, 85, 86], "begin": [6, 8, 10, 13, 15, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 60, 62, 79], "align": [6, 8, 10, 13, 15, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 62, 79, 85], "quad": [6, 8, 10, 13, 15, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 62, 63, 64, 65, 66, 67, 70, 71, 72, 77, 78, 79, 80, 81, 83, 85, 86], "k": [6, 10, 19, 43, 45, 49, 61, 62, 64, 67, 71, 77, 78, 79, 80, 81, 83, 85, 86], "alpha_k": [6, 43, 62, 79], "h_x": [6, 8, 10, 13, 15, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 53, 55, 57, 62, 63, 64, 65, 66, 67, 70, 71, 72, 77, 78, 79, 80, 81, 85, 86], "t": [6, 8, 10, 13, 15, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 85, 86], "h_y": [6, 8, 10, 13, 15, 19, 21, 26, 29, 33, 35, 40, 43, 49, 51, 55, 57, 62, 63, 64, 65, 66, 67, 70, 72, 78, 79, 83, 85, 86], "a_k": [6, 43, 62, 79, 86], "cdot": [6, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 47, 49, 51, 53, 55, 57, 62, 65, 70, 71, 72, 77, 78, 79, 81, 83, 85, 86], "psi_k": [6, 43, 62, 79], "foral": [6, 43, 62, 71, 79], "n_k": [6, 43, 62, 79], "bigoplus_": [6, 43, 62, 79], "_k": [6, 10, 43, 45, 62, 64, 79, 80], "m": [6, 8, 38, 43, 45, 51, 53, 55, 57, 60, 63, 65, 71, 77, 80, 83, 85, 86], "bigotimes_": [6, 43, 62, 79], "phi": [6, 43, 62, 65, 79], "end": [6, 8, 10, 13, 15, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 60, 62, 77, 78, 79, 81, 83, 86], "liftlay": [6, 11, 62], "signal_lift_activ": 6, "signal_lift_dropout": 6, "adapt": [6, 58], "offici": 6, "rate": [6, 18, 19, 30, 32, 34, 65], "num_nod": [6, 30, 31, 66, 67, 70, 72, 74, 76], "num_edg": [6, 30, 31], "reiniti": 6, "xavier": 6, "multiheadcellattent": [6, 11, 62], "propos": [6, 8, 10, 15, 21, 24, 26, 29, 33, 35, 40, 43, 45, 47, 51, 53, 57, 62, 63, 64, 70, 72, 77, 78, 79, 82, 83, 84, 85, 86], "gat": [6, 62, 79], "adjac": [6, 7, 8, 9, 10, 18, 19, 37, 38, 39, 40, 46, 47, 49, 50, 51, 55, 62, 63, 64, 65, 69, 77, 78, 79, 81, 82, 86], "non": [6, 62, 65, 79, 86], "zero": [6, 62, 66, 67, 70, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "valu": [6, 42, 58, 63, 64, 65, 68, 69, 71, 77, 82, 84, 85, 86], "empti": [6, 66, 67, 70, 72, 74, 76], "veli\u010dkovi\u0107": 6, "cucurul": 6, "casanova": 6, "romero": 6, "li\u00f2": 6, "bengio": [6, 20, 21], "2017": [6, 67, 77], "1710": 6, "10903": 6, "multiheadcellattention_v2": [6, 11], "brodi": 6, "alon": 6, "yahav": 6, "how": [6, 60, 67, 77, 78, 79], "2105": [6, 28, 29, 30, 31, 32, 33, 34, 35], "14491": 6, "up": [6, 7, 10, 29, 31, 33, 35, 39, 43, 46, 54, 55, 60, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 79, 81, 86], "down": [6, 42, 43, 44, 45, 48, 50, 51, 54, 55, 79], "multiheadliftlay": [6, 11, 62], "collect": [6, 66, 67, 68, 69, 71, 72, 85], "abc": 6, "built": [6, 59, 60], "type": [6, 13, 15, 60, 65, 66, 67, 70, 72], "object": [6, 19, 60], "signal_lift_readout": 6, "str": [6, 13, 15, 24, 26, 46, 48, 49, 50, 55, 58, 60, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "cat": 6, "multi": [6, 13, 15, 60, 67], "readout": [6, 48, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "index": [6, 58, 60, 65, 66, 81, 86], "z": [6, 8, 10, 13, 15, 19, 24, 26, 29, 31, 33, 35, 40, 43, 49, 55, 57, 62, 63, 64, 66, 67, 71, 72, 78, 85, 86], "alpha": [6, 21, 30, 31, 55, 62, 72, 79, 86], "h_z": [6, 10, 13, 15, 19, 43, 62, 64, 66, 67], "poollay": [6, 11, 62], "k_pool": 6, "signal_pool_activ": [6, 62], "pool": [6, 7, 9, 23, 25, 28, 32, 34, 44, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "ratio": [6, 65], "fraction": 6, "keep": [6, 60, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 76, 77, 78, 79, 80, 81, 82, 83], "after": [6, 29, 35, 60, 62], "oper": [6, 13, 15, 49, 55, 57, 62, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 79, 81, 82, 86], "tupl": [6, 18, 48, 49, 51, 56, 65, 66, 67, 70, 72, 74, 76, 86], "num_pooled_nod": 6, "gamma": [6, 62], "tau": [6, 62], "c_r": [6, 62], "sparse_coo_tensor": [6, 69], "file": [6, 59, 60, 65], "softmax": [6, 11, 57, 65, 77, 78, 79, 80, 81, 82, 83, 85, 86], "src": [6, 58], "num_cel": 6, "indic": [6, 58, 77, 78, 79, 80, 81, 82, 83, 86], "batch": [6, 86], "There": [6, 59, 60, 69, 77, 78, 79, 80, 81, 82, 83, 85], "subtract": 6, "maximum": [6, 46, 47, 81, 86], "element": [6, 60, 65, 67], "avoid": [6, 49, 55], "overflow": 6, "underflow": 6, "in_channels_2": [7, 8, 9, 10, 49, 52, 53, 62, 63, 64, 82, 84, 85], "face": [7, 8, 9, 10, 44, 48, 49, 50, 51, 52, 53, 54, 59, 62, 63, 64, 65, 68, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85], "istvan": [7, 8], "analysi": [7, 8], "workshop": [7, 8, 20, 21, 40, 51, 59], "neurip": [7, 8, 9, 10, 51], "2020": [7, 8, 20, 21, 23, 24, 25, 26, 51, 59, 63, 70, 71, 72, 83], "2010": [7, 8, 25, 26], "00743": [7, 8], "neighborhood_1_to_2": [7, 8], "avg": [7, 44], "n_face": [7, 9, 48, 49, 50, 51, 52, 53], "transpos": [7, 44, 45, 80, 83], "boundari": [7, 9, 10, 20, 23, 25, 28, 32, 34, 39, 57, 64, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 81, 86], "label": [7, 9, 25, 44, 47, 50, 53, 60, 62, 63, 64, 65, 68, 69, 71, 73, 75, 79, 84, 86], "assign": [7, 9, 25, 44, 50, 60, 77, 78, 79, 80, 81, 82, 83, 86], "whole": [7, 9, 25, 44, 50, 54], "simplifi": [8, 21, 63], "ccxn": [8, 11], "et": [8, 9, 10, 19, 29, 33, 35, 53, 59, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 85, 86], "al": [8, 9, 10, 29, 33, 35, 53, 59, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 85, 86], "ccxnlayer": [8, 11, 63], "entir": [8, 10, 62, 63, 64, 65], "equat": [8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 60, 61, 62, 63, 64, 70, 77, 78, 79, 81, 83, 86], "awesom": [8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 61, 67, 72], "tnn": [8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61], "x_2": [8, 9, 10, 49, 50, 51, 52, 53, 63, 64, 65, 68, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85], "wa": [8, 10, 21, 40, 45, 47, 57, 65], "Its": [8, 10, 21, 29, 33, 35, 40, 45, 47, 57], "graphic": [8, 10, 21, 29, 33, 35, 40, 45, 47, 57, 61], "illustr": [8, 10, 21, 29, 33, 35, 40, 45, 47, 57, 84], "amp": [8, 63], "l": [8, 10, 18, 19, 38, 40, 43, 45, 47, 51, 53, 55, 57, 62, 63, 64, 65, 71, 72, 77, 78, 79, 80, 81, 82, 83, 85, 86], "u": [8, 10, 19, 43, 45, 55, 59, 63, 64, 66, 67, 71, 80, 86], "cohomologi": [8, 63], "coboundari": [8, 9, 63, 64], "t_": [8, 26, 63, 65, 72], "c": [8, 13, 15, 19, 21, 24, 26, 29, 31, 33, 35, 40, 47, 49, 51, 61, 62, 63, 65, 66, 67, 70, 71, 72, 78, 81, 83, 86], "h_": [8, 24, 38, 45, 47, 53, 63, 71, 77, 80, 81], "n_0_cell": 8, "n_1_cell": 8, "a_0_up": 8, "n_2_cell": 8, "b_2": [8, 49, 50, 51, 57, 63, 79, 83], "requir": [8, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 80, 86], "hid_channel": [9, 64], "cw": [9, 10, 59], "hidden": [9, 12, 13, 14, 15, 18, 20, 21, 23, 25, 28, 29, 30, 31, 32, 34, 37, 39, 42, 46, 48, 52, 54, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 86], "bodnar": [9, 10, 59, 64], "weisfeil": [9, 10, 64], "lehman": [9, 10, 64], "cellular": [9, 10, 59, 64], "2021": [9, 10, 28, 29, 30, 31, 32, 33, 34, 35, 55, 57, 59, 64, 66, 67, 86], "2106": [9, 10, 12, 13, 14, 15], "12575": [9, 10], "neighborhood_1_to_1": [9, 10], "neighborhood_2_to_1": [9, 10], "neighborhood_0_to_1": [9, 10], "project": [9, 42, 43, 60, 77, 79, 82, 85], "cwn": [10, 11, 59], "cwnlayer": [10, 11, 64], "conv_1_to_1": 10, "conv_0_to_1": 10, "aggregate_fn": 10, "update_fn": 10, "represent": [10, 18, 19, 20, 21, 25, 26, 37, 39, 40, 42, 46, 47, 53, 54, 56, 59, 62, 65, 66, 67, 69, 71, 81, 84, 86], "case": [10, 59, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 86], "convolv": 10, "neighbor": [10, 19, 62, 66, 67, 70, 72, 74, 76, 85, 86], "co": [10, 59], "check": [10, 59, 60, 61, 77, 78], "docstr": [10, 59], "_cwndefaultfirstconv": 10, "more": [10, 19, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 81, 86], "_cwndefaultsecondconv": 10, "obtain": [10, 54, 66, 67, 70, 72, 74, 76, 79, 82, 85, 86], "_cwndefaultaggreg": 10, "_cwndefaultupd": 10, "final": [10, 19, 37, 39, 42, 46, 48, 52, 54, 57, 59, 65, 77, 79, 85, 86], "first": [10, 29, 31, 35, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "exploit": [10, 62], "second": [10, 29, 31, 35, 59, 65, 66, 67, 80], "b": [10, 13, 15, 19, 21, 24, 26, 29, 31, 33, 35, 45, 47, 49, 50, 51, 60, 64, 65, 66, 67, 70, 71, 72, 80, 81, 82, 83], "Then": [10, 60, 63, 64], "agg_": [10, 13, 15, 19, 45, 63, 64, 66, 67, 80], "n_": [10, 43, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85], "_cell": 10, "in_channels_": 10, "b_": [10, 47, 64, 65, 80, 81], "t_r": 10, "six": 11, "can_lay": 11, "ccxn_layer": 11, "cwn_layer": 11, "hypergraph": [12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 59, 66, 67, 72, 73, 75], "hidden_channel": [12, 13, 14, 15, 18, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 34, 35, 42, 54, 56, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 85, 86], "layer_dropout": 12, "mlp_num_lay": [12, 13, 14, 15, 66, 67, 70, 72, 73, 74, 75], "mlp_activ": [12, 13, 15], "mlp_dropout": [12, 13, 14, 15], "mlp_norm": [12, 13, 15], "combin": [12, 14, 31, 62], "multipl": [12, 14, 59, 60, 86], "form": [12, 14, 56, 59, 77, 78, 81, 82, 86], "mlp": [12, 13, 14, 15, 27, 67], "chien": [12, 13, 14, 15, 59, 66, 67], "pan": [12, 13, 14, 15], "peng": [12, 13, 14, 15], "milenkov": [12, 13, 14, 15], "you": [12, 13, 14, 15, 51, 59, 60, 66, 70, 72, 74, 76], "multiset": [12, 13, 14, 15, 66, 67], "framework": [12, 13, 14, 15, 28, 29, 30, 31, 32, 33, 34, 35, 66, 67], "iclr": [12, 13, 14, 15, 40], "13264": [12, 13, 14, 15], "incidence_1": [12, 13, 14, 15, 18, 19, 20, 21, 23, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 50, 51, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 82, 83, 85, 86], "hyperedg": [12, 13, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 59, 66, 67, 68, 71, 72, 74, 76], "allset": [13, 14, 15, 27, 66, 67, 71, 72], "allsetblock": [13, 27], "block": [13, 15, 59], "bipartit": [13, 15], "incid": [13, 15, 18, 19, 20, 21, 24, 25, 26, 29, 30, 31, 33, 35, 38, 40, 44, 45, 46, 47, 48, 49, 50, 51, 57, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 85], "allsetlay": [13, 27], "vertex": [13, 15, 66, 67, 86], "sigma": [13, 21, 24, 26, 38, 40, 43, 47, 51, 53, 55, 57, 66, 70, 71, 72, 77, 78, 81, 82, 83, 85, 86], "n_hyperedg": [13, 15, 18], "b_1": [13, 15, 19, 20, 21, 24, 26, 29, 31, 33, 35, 38, 40, 49, 50, 51, 57, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 83], "norm_lay": [13, 15], "activation_lay": [13, 15], "inplac": [13, 15], "bia": [13, 15, 21, 62, 82, 85], "perceptron": [13, 15, 67], "do": [13, 15, 59, 66, 69, 70, 72, 74, 76, 77, 78, 81, 86], "place": [13, 15, 59, 60, 66, 67], "allsettransform": [14, 15, 27, 59, 67], "allsettransformerblock": [15, 27], "number_queri": 15, "queri": 15, "over": [15, 59, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86], "allsettransformerlay": [15, 27], "ln": [15, 67], "multiheadattent": [15, 27], "qk": 15, "v": [15, 60, 65, 66, 67, 71, 72, 77, 78, 79, 80, 81, 82, 83, 85], "mh": [15, 67], "eq": [15, 77, 78, 79, 80, 81, 82, 83, 85], "7": [15, 18, 19, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "factor": 15, "adjacency_dropout_r": 18, "regular_dropout_r": 18, "gradual": 18, "reduc": [18, 19, 82], "in_featur": [18, 62, 82, 85], "last": [18, 54, 57, 65, 81, 86], "item": [18, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "hmpnnlayer": [18, 19, 27], "regular": [18, 19], "heydari": [18, 19, 59, 69], "livi": [18, 19, 69], "icann": [18, 19], "2203": [18, 19, 43], "16995": [18, 19], "b1": [18, 48, 49, 65, 77, 78, 81, 82, 85], "hmpnn": [19, 27, 59], "introduc": [19, 62, 65, 69, 71, 79], "node_to_hyperedge_messaging_func": 19, "hyperedge_to_node_messaging_func": 19, "adjacency_dropout": 19, "updating_dropout": 19, "updating_func": 19, "compris": 19, "make": [19, 33, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 80, 86], "new": [19, 59, 60, 63], "reprsent": 19, "them": [19, 49, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 79, 80, 81, 82, 84], "also": [19, 55, 60, 62, 63, 64, 65, 68, 71, 73, 75, 77, 78, 79, 80, 83, 84], "reciev": 19, "beforehand": 19, "wai": [19, 60, 79], "could": [19, 62, 65, 79, 81], "explicit": 19, "rightarrow1": [19, 31, 49, 51, 83], "rightarrow0": [19, 24, 29, 31, 33, 35, 49, 51, 71, 83], "m_z": [19, 24, 26, 29, 31, 33, 35, 49, 71, 72], "plu": [19, 79], "accord": [19, 45, 84], "It": [19, 30, 31, 59, 66, 69, 70, 72, 74, 76], "get": [19, 57, 59, 66, 67, 70, 72, 74, 76, 77, 79, 82, 85, 86], "back": 19, "retriev": [19, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84], "apply_regular_dropout": 19, "unmask": 19, "vector": [19, 56, 60, 65, 67, 69, 71, 86], "scale": [19, 86], "d": [19, 43, 55, 60, 71, 77, 83], "mask": [19, 62, 69, 79, 86], "total": [19, 79], "node_in_channel": 19, "hyperedge_in_channel": 19, "neuron": [20, 21, 59], "multiclass": 20, "dong": [20, 21, 59, 70], "sawin": [20, 21], "icml": [20, 21, 57], "grlplu": [20, 21], "github": [20, 21, 59, 66, 67, 72], "io": [20, 21], "40": [20, 21, 64, 68, 69, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85], "channels_nod": [20, 21, 77, 78, 79, 80, 81, 82, 83, 85], "hypernod": [20, 21], "templat": [21, 23, 60], "hnhnlayer": [21, 27], "use_bia": 21, "use_normalized_incid": 21, "beta": [21, 30, 31, 86], "bias_gain": 21, "bias_init": 21, "hnhn": [21, 27, 59], "matric": [21, 44, 45, 46, 47, 48, 51, 59, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 81, 82, 84, 85], "usign": 21, "cardin": 21, "hyperparamet": [21, 31, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "control": 21, "strenght": 21, "support": [21, 79, 82, 85], "train": [21, 26, 44, 59], "term": [21, 59, 79], "flag": 21, "import": [21, 31, 59, 60, 62, 63, 64, 66, 67, 69, 72, 79, 86], "compute_normalization_matric": 21, "w": [21, 29, 31, 70, 71, 79], "xy": [21, 38, 40, 43, 47, 51, 53, 55, 57, 65, 70, 77, 78, 81, 83, 85, 86], "sum_": [21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 47, 49, 51, 53, 55, 57, 65, 70, 71, 72, 77, 78, 81, 82, 83, 85, 86], "channels_edg": [21, 23, 28, 34], "init_bias": 21, "normalize_incidence_matric": 21, "amount": [23, 25, 28, 32, 34, 37, 39, 44, 52, 59, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 82], "ding": [23, 24, 71], "wang": [23, 24], "li": [23, 24], "huan": [23, 24], "liu": [23, 24], "emnlp": [23, 24], "aclanthologi": [23, 24], "main": [23, 24, 60, 74], "399": [23, 24], "global": [23, 25, 28, 32, 34], "max": [23, 25, 28, 32, 34, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 81], "hypergat": [24, 27, 71], "hypergatlay": [24, 27], "set": [24, 26, 68, 70, 71, 72, 73, 74, 75, 76, 79, 81, 86], "see": [24, 26, 49, 51, 53, 59, 60, 61, 65, 86], "t_1": [24, 31, 71], "odot": [24, 38, 43, 49, 71, 77], "zy": [24, 26, 31, 40, 71, 72, 78], "xz": [24, 26, 40, 71, 72, 78], "kwarg": [25, 26, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "arya": [25, 26, 72], "gupta": [25, 26], "rudinac": [25, 26], "wor": [25, 26], "gener": [25, 26, 40, 56, 60, 62, 66, 67, 74, 78, 79, 82], "induct": [25, 26], "04558": [25, 26], "features_nod": 25, "hypersag": [26, 27], "generalizedmean": [26, 27], "power": [26, 83], "keyword": 26, "argument": [26, 60, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79], "hypersagelay": [26, 27], "aggr_func_intra": 26, "aggr_func_int": 26, "devic": [26, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 83, 84], "cpu": [26, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 83, 84], "p": [26, 43, 55, 71, 72, 79], "name": [26, 59, 60, 62, 66, 67, 69, 70, 72, 73, 74, 75, 76], "mode": [26, 74], "intra": [26, 45, 72], "either": [26, 59, 60, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 86], "w_y": [26, 72], "frac": [26, 31, 49, 71, 72], "vert": [26, 67, 72, 86], "w_z": [26, 72], "lvert": [26, 72], "rvert": [26, 72], "n_target_nod": 26, "allset_lay": 27, "allset_transformer_lay": 27, "allset_transform": [27, 67], "dhgcn_layer": 27, "dhgcn": 27, "hmpnn_layer": 27, "hnhn_layer_bi": 27, "hnhn_layer": 27, "hypergat_lay": 27, "hypersage_lay": 27, "unigcn_lay": 27, "unigcnlay": [27, 29], "unigcn": [27, 29, 59], "unigcnii_lay": 27, "unigcniilay": [27, 31], "unigcnii": [27, 31, 32], "uniginlay": [27, 33], "unigin": [27, 32, 33], "unisagelay": [27, 35], "unisag": [27, 34, 35, 76], "huang": [28, 29, 30, 31, 32, 33, 34, 35, 59], "yang": [28, 29, 30, 31, 32, 33, 34, 35, 47, 53, 55, 59, 81, 82, 84, 85], "unignn": [28, 29, 30, 31, 32, 33, 34, 35], "unifi": [28, 29, 30, 31, 32, 33, 34, 35], "ijcai": [28, 29, 30, 31, 32, 33, 34, 35], "00956": [28, 29, 30, 31, 32, 33, 34, 35], "use_bn": [29, 35], "bathnorm": [29, 35], "everi": [29, 31, 33, 35, 59, 66, 70, 72, 74, 76], "hyper": [29, 31, 33, 35, 86], "constitu": [29, 31, 33, 35], "third": [29, 31, 35], "input_drop": [30, 32, 34, 74, 75, 76], "layer_drop": [30, 32, 34, 75, 76], "expect": [30, 31, 81, 83], "contain": [30, 31, 56, 59, 62, 65, 66, 67, 69, 70, 72, 82, 86], "determin": [31, 86], "theta_2": 31, "theta_1": 31, "x_skip": 31, "degre": 31, "sqrt": 31, "d_x": 31, "d_z": 31, "in_channels_nod": 32, "unigin_lay": 33, "ep": 33, "train_ep": 33, "constant": 33, "gin": 33, "boolm": 33, "unisage_lay": 35, "e_aggr": 35, "v_aggr": 35, "boolean": [35, 60], "operatornam": [35, 43, 71], "sage": 35, "submodul": 36, "simplici": [36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 63, 64, 65, 68, 71, 84], "dist2cycl": [37, 38, 41], "binari": [37, 39, 42, 46, 50, 52, 62, 69, 70, 73, 75, 79], "high": [37, 39, 40, 65], "x_1e": [37, 77], "linv": [37, 38, 77], "dist2cycle_lay": 38, "dist2cyclelay": [38, 41], "x_e": 38, "adjacency_0": [38, 39, 40, 62, 63, 65, 77, 78, 83], "a_0": [38, 40], "hsn": [39, 40, 41, 59], "hsn_layer": [40, 59], "hsnlayer": [40, 41, 59], "complic": [40, 43], "higher": [40, 47, 53, 59, 62, 65, 78, 81, 84, 85], "geometr": [40, 59], "openreview": [40, 51], "net": [40, 51, 57, 59], "id": [40, 51, 60], "sc8glb": 40, "k6e9": 40, "sanconv": [41, 43], "sanlay": [41, 43], "san": [41, 42, 43, 59, 62, 77, 81, 83], "compute_projection_matrix": [41, 42], "scacmpslay": [41, 45, 80], "intra_aggr": [41, 45], "weight_func": [41, 45], "scacmp": [41, 44, 80], "sccnlayer": [41, 47, 53, 81], "sccn": [41, 46, 47, 53, 59], "sccnnlayer": [41, 49, 82], "aggr_norm_func": [41, 49, 55], "chebyshev_conv": [41, 49, 55], "sccnn": [41, 48, 49], "scconvlay": [41, 51], "scconv": [41, 50, 51], "scn2layer": [41, 47, 53], "scn2": [41, 52, 84], "scnnlayer": [41, 55, 85], "scnn": [41, 54, 55, 82], "sconelay": [41, 57, 86], "scone": [41, 56, 57, 59], "trajectoriesdataset": [41, 56, 86], "vectorize_path": [41, 56, 86], "generate_complex": [41, 56, 86], "generate_trajectori": [41, 56, 86], "n_filter": [42, 43], "order_harmon": 42, "epsilon_harmon": 42, "approxim": [42, 43, 86], "filter": [42, 43, 49, 82], "harmon": 42, "1e": [42, 86], "epsilon": 42, "laplacian": [42, 43, 44, 45, 48, 49, 53, 54, 55, 79, 80, 81, 82, 84], "calcul": [42, 60, 66, 67, 70, 72, 74, 76], "compon": [42, 60, 79], "hodg": [42, 49, 53, 55, 79, 81, 82], "laplacian_up": [42, 43, 54, 55, 79, 85], "laplacian_down": [42, 43, 54, 55, 79, 85], "channels_in": 42, "san_lay": 43, "07485": 43, "l_": [43, 55, 57, 79, 80, 85, 86], "wh_1": 43, "simplex": [43, 44, 52, 53, 63, 64, 68, 71, 77, 78, 79, 80, 81, 82, 83, 85, 86], "projection_mat": 43, "2p": [43, 79], "q_r": [43, 79], "n_cell": 43, "sca": [44, 45, 59], "cmp": [44, 45], "sca_cmp": [44, 80], "in_channels_al": [44, 48, 80, 82], "complex_dim": [44, 45, 80], "tetahedron": 44, "respect": [44, 59, 64, 65, 66, 67, 71, 72, 79, 82, 85, 86], "highest": [44, 45, 86], "being": [44, 59, 79], "laplacian_down_list": [44, 80], "incidence_t_list": [44, 80], "etc": [44, 55, 60], "start": [44, 59, 60, 86], "simplic": [45, 48, 55, 79, 81, 82, 85, 86], "autoencod": [45, 59], "sca_cmps_lay": 45, "channels_list": 45, "coadjac": [45, 65], "chain": [45, 57, 86], "maroula": 45, "cai": 45, "2103": 45, "04046": 45, "x_list": 45, "down_lap_list": 45, "incidencet_list": 45, "qquad": [45, 49, 80], "hold": [45, 60], "skeleton": [45, 62, 86], "untouch": 45, "max_rank": [46, 47, 81, 82, 85], "dict": [46, 47, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "length": [46, 47, 60, 69], "n_rank_r_cel": [46, 47], "n_rank_r_minus_1_cel": [46, 47], "b_r": [46, 47, 64, 81], "h_r": [46, 47, 53, 81], "rank_0": [46, 81], "rank_1": [46, 81], "rank_2": [46, 81], "triangl": [46, 49, 55, 56, 57, 65, 79, 82, 86], "rank_3": [46, 81], "tetrahedra": 46, "sccn_layer": [47, 53], "ani": [47, 48, 60, 62, 63, 66, 67, 70, 72, 74, 76, 86], "leftmost": 47, "diagram": [47, 53, 59, 65], "yang22c": [47, 53, 84], "figur": [47, 53, 65], "11": [47, 53, 59, 62, 63, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "scn2_layer": [47, 53], "scn": [47, 53], "abov": [47, 53, 59, 60, 85, 86], "below": [47, 53, 62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 86], "sala": [47, 53, 84], "bogdan": [47, 53, 84], "effici": [47, 53, 77, 81, 84], "proceed": [47, 53, 57, 84], "mlr": [47, 53, 57, 84], "press": [47, 53, 57, 84], "v198": [47, 53, 84], "yang22a": [47, 53, 84], "html": [47, 53, 57, 84], "describ": [47, 56, 60, 67], "unnorm": 47, "bigcup": [47, 81], "hidden_channels_al": [48, 82], "conv_ord": [48, 49, 55, 82], "sc_order": [48, 49, 82], "task": [48, 54, 59, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 86], "we": [48, 49, 54, 55, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 86], "cours": [48, 60], "amend": 48, "x_all": [48, 49, 82], "laplacian_al": [48, 49, 82], "incidence_al": [48, 49, 82], "entri": [48, 79], "n_simplic": [48, 49, 54, 55], "l0": 48, "l1_d": 48, "l1_u": 48, "l2": 48, "b2": [48, 49, 65, 81, 82, 85], "state": [48, 52, 60, 72], "sccnn_layer": 49, "To": [49, 54, 61, 65, 66, 67, 70, 72, 74, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86], "too": 49, "mani": [49, 60, 62], "sc": [49, 56, 82, 85, 86], "exampl": [49, 55, 59, 79, 82, 85, 86], "here": [49, 51, 55, 59, 60, 62, 69, 77, 78, 80, 81, 82, 83, 86], "pseudocod": [49, 55], "l_0": 49, "lap_down": [49, 55], "l_1_down": 49, "lap_up": [49, 55], "l_1_up": 49, "lap": 49, "l_2": 49, "g": [49, 54, 55, 60, 66, 67, 71, 79, 86], "y_0": 49, "y_1": 49, "y_2": 49, "look": [49, 55, 60, 86], "like": [49, 55, 57, 60, 62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 81, 82, 85, 86], "einsum": [49, 55], "weight_0": 49, "weight_1": 49, "weight_2": 49, "total_order_0": 49, "total_order_1": 49, "total_order_2": 49, "chebyshev": [49, 55], "conv_oper": [49, 55], "perform": [49, 54, 55, 59, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 83, 84, 86], "num_channel": [49, 55], "repres": [49, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 84, 86], "n_triangl": [49, 57], "laplacian_0": [49, 52, 53, 82, 84, 85], "laplacian_down_1": [49, 80, 82, 85], "laplacian_up_1": [49, 82, 85], "laplacian_2": [49, 52, 53, 82, 84, 85], "part": [49, 55, 62, 77, 78, 79, 80, 81, 82, 83], "node_channel": [50, 51, 83], "edge_channel": [50, 51], "face_channel": [50, 51], "n_class": 50, "incidence_1_norm": [50, 51, 83], "incidence_2": [50, 51, 56, 57, 64, 65, 82, 83, 85, 86], "incidence_2_norm": [50, 51, 83], "adjacency_up_0_norm": [50, 51, 83], "adjacency_up_1_norm": [50, 51, 83], "adjacency_down_1_norm": [50, 51, 83], "adjacency_down_2_norm": [50, 51, 83], "_1": [50, 51, 82, 83, 85], "_2": [50, 51, 82], "scconv_lay": 51, "bunch": [51, 83], "fung": 51, "singh": [51, 59], "tda": 51, "forum": 51, "tlbnskrt6j": 51, "tild": [51, 83], "x0_out": 51, "x1_out": 51, "x2_out": 51, "For": [51, 54, 57, 60, 61, 65, 72, 77, 78, 82, 85, 86], "mai": [51, 59], "helper": 51, "pyt": 51, "team": [51, 59], "laplacian_1": [52, 53, 84], "log": [53, 60, 81, 86], "rightmost": 53, "pshm23": 53, "2i": [53, 81], "node_featur": 53, "edge_featur": 53, "face_featur": 53, "l_upper": 53, "l_lower": 53, "conv_order_down": [54, 55, 85], "conv_order_up": [54, 55, 85], "At": [54, 82, 85], "simplci": 54, "challeng": 54, "aggr": 54, "dimension": [54, 65, 67, 86], "scnn_layer": 55, "isufi": 55, "leu": 55, "2110": 55, "02585": 55, "total_ord": 55, "n_simplex": 55, "simplicialcomplex": [56, 73, 75, 86], "trajectori": [56, 57], "dataset": [56, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79], "path": [56, 86], "100": [56, 68, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "ndarrai": [56, 60, 86], "uniformli": [56, 86], "sampl": [56, 60, 62, 65, 86], "random": [56, 62, 63, 64, 66, 67, 69, 70, 72, 73, 74, 75, 76, 86], "point": [56, 86], "unit": [56, 59, 60, 86], "squar": [56, 60, 65, 86], "delaunai": [56, 86], "triangul": [56, 86], "delet": [56, 86], "some": [56, 60, 66, 67, 70, 72, 74, 76, 81, 86], "pre": [56, 59, 86], "disk": [56, 86], "coord": [56, 86], "n_max": [56, 86], "1000": [56, 86], "corner": [56, 86], "middl": [56, 86], "scone_lay": 57, "when": [57, 59, 60, 62, 79, 86], "stack": [57, 62, 63, 64, 66, 70, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "befor": [57, 59, 60, 86], "neighbour": [57, 86], "next": [57, 60, 71, 74, 86], "roddenberri": [57, 59, 86], "mitchel": 57, "glaze": 57, "principl": [57, 86], "v139": 57, "roddenberry21a": 57, "variou": 58, "librari": 58, "torch_scatt": 58, "py": [58, 59, 60, 63, 66, 67, 68, 70, 71, 72, 74, 76, 77, 81, 82, 85], "rusty1": 58, "pytorch_scatt": 58, "other": [58, 60, 86], "dim": [58, 60, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "out": [58, 59, 60, 61, 62, 68, 79, 80, 83, 86], "dim_siz": 58, "welcom": [59, 60], "host": 59, "annual": 59, "topologi": [59, 79], "geometri": 59, "tag": 59, "machin": [59, 84], "review": [59, 60, 61, 83], "contributor": [59, 60], "mathild": [59, 61], "mustafa": [59, 61], "nina": [59, 61], "florian": 59, "frantzen": 59, "ghada": [59, 61], "alzamzmi": 59, "theodor": [59, 61], "michael": [59, 61], "scholkemp": 59, "josef": 59, "hopp": 59, "karthikeyan": [59, 61], "natesan": [59, 61], "johan": 59, "math": [59, 60, 62, 67, 71, 72, 85, 86], "audun": 59, "myer": 59, "helen": 59, "jenn": 59, "tim": 59, "doster": 59, "tegan": 59, "emerson": 59, "henri": 59, "kving": 59, "bastian": [59, 84], "rieck": [59, 84], "sophia": [59, 61], "jan": 59, "meissner": 59, "paul": [59, 61, 84], "tolga": [59, 61], "vincent": 59, "grand": 59, "aldo": [59, 61], "tamal": [59, 61], "soham": [59, 61], "shreya": [59, 61], "neal": [59, 61], "robin": [59, 61], "edit": [59, 60], "now": [59, 62, 63, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 84, 86], "thank": 59, "stellar": 59, "contirbut": 59, "foster": 59, "reproduc": [59, 61], "open": 59, "research": [59, 84], "winner": 59, "announc": 59, "luca": 59, "scofano": 59, "claudio": 59, "guillermo": 59, "bernardez": 59, "simon": 59, "fiorellino": 59, "indro": 59, "spinelli": 59, "scardapan": 59, "lev": 59, "telyatninkov": 59, "olga": 59, "zaghen": 59, "sadrodin": 59, "barikbin": 59, "odin": 59, "hoff": 59, "gardaa": 59, "dmitrii": 59, "gavrilev": 59, "gleb": 59, "bazhenov": 59, "suraj": 59, "combinatori": 59, "rub\u00e9n": 59, "ballest": 59, "manuel": 59, "lecha": 59, "sergio": 59, "escalera": 59, "hoan": [59, 65], "aiden": 59, "brent": 59, "honor": 59, "mention": 59, "jen": 59, "agerberg": 59, "georg": 59, "b\u00f6kman": 59, "pavlo": 59, "melnyk": 59, "alessandro": 59, "salatiello": 59, "alexand": 59, "nikitin": 59, "purpos": [59, 60, 63, 64, 65, 66, 67, 69, 70, 71, 72, 76, 77, 78, 79, 80, 81, 82, 83], "crowdsourc": 59, "ask": 59, "contribut": [59, 71, 82], "code": [59, 60, 86], "previous": 59, "exist": 59, "benchmark": [59, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 82, 84, 85], "python": [59, 60, 61], "packag": [59, 61, 63, 66, 68, 70, 71, 72, 74, 76, 77, 81, 82, 85], "take": [59, 62, 79, 82, 84, 86], "pull": [59, 60], "request": [59, 60, 86], "literatur": [59, 61], "leverag": [59, 79], "infrastructur": 59, "invit": 59, "regularli": 59, "white": 59, "summar": 59, "find": [59, 62, 86], "publish": 59, "qualifi": 59, "opportun": 59, "author": [59, 61, 66, 67, 70, 72, 86], "top": [59, 62, 82], "8": [59, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "best": [59, 67], "addit": [59, 65, 68, 69, 70, 71, 73, 74, 75, 76], "softwar": [59, 60], "journal": 59, "special": 59, "recognit": 59, "date": 59, "time": [59, 62, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "must": [59, 68, 71, 77, 78, 79, 80, 81, 82, 83, 85], "juli": 59, "13": [59, 67, 68, 73, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "16": [59, 62, 63, 64, 65, 67, 68, 69, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "59": [59, 77, 78, 79, 80, 81, 82, 83, 84, 85], "pacif": 59, "standard": [59, 60, 79], "modifi": [59, 60, 80], "until": 59, "everyon": [59, 60], "free": [59, 86], "suffici": 59, "accept": 59, "automat": [59, 79], "subscrib": 59, "encourag": 59, "earli": 59, "help": [59, 60], "debug": [59, 62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 86], "fail": 59, "test": [59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83], "address": [59, 65], "potenti": 59, "issu": 59, "similar": [59, 81], "qualiti": 59, "earlier": [59, 81], "prioriti": 59, "consider": 59, "restrict": 59, "member": 59, "than": [59, 66, 67, 70, 72, 74, 76, 85, 86], "princip": 59, "develop": [59, 60], "allow": [59, 81], "fig": [59, 86], "compli": 59, "action": 59, "workflow": 59, "successfulli": 59, "lint": 59, "format": [59, 60, 66, 70, 72, 74, 76, 82], "black": [59, 86], "isort": 59, "flake8": 59, "_layer": 59, "ex": 59, "store": 59, "directori": [59, 60], "primit": 59, "equival": [59, 60, 65], "depict": 59, "_train": 59, "ipynb": 59, "hsn_train": 59, "tutori": [59, 61, 74], "process": [59, 60], "well": [59, 60], "load": [59, 63, 64, 65, 68, 71, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85], "toponetx": [59, 62, 63, 64, 65, 68, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "shrec16": [59, 63, 64, 65, 66, 67, 68, 71, 72, 82, 85], "suitabl": 59, "template_lay": 59, "karat": [59, 77, 78, 79, 80, 81, 82, 83], "club": [59, 77, 78, 79, 80, 81, 82, 83], "choic": [59, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76], "along": [59, 62, 79], "simpl": [59, 85], "depend": 59, "accuraci": [59, 65, 66, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "test_": [59, 60], "name_of_model": 59, "test_hsn_lay": 59, "testhsnlay": 59, "pleas": [59, 60, 62, 63, 68, 71, 79, 82, 85], "pytest": [59, 60], "unittest": 59, "further": [59, 62, 79], "manipul": 59, "modif": 59, "accompani": 59, "appropri": [59, 60], "locat": [59, 60], "With": [59, 71], "said": 59, "highli": 59, "most": [59, 60, 79, 81], "resort": 59, "absolut": [59, 66, 70, 72, 74, 76], "condorcet": 59, "decid": [59, 79], "criteria": 59, "chosen": [59, 81], "correctli": 59, "need": [59, 62, 63, 64, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 83, 84, 86], "match": 59, "readabl": [59, 60], "clean": 59, "api": [59, 60], "written": 59, "clearli": 59, "explain": 59, "robust": 59, "reward": 59, "nor": 59, "goal": 59, "accur": 59, "our": [59, 60, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "field": 59, "select": [59, 81, 85], "maintain": 59, "collabor": 59, "whose": [59, 60], "vote": 59, "onc": [59, 68, 71], "googl": [59, 60], "express": [59, 71], "even": 59, "link": [59, 60], "record": [59, 60, 68, 71], "email": 59, "identifi": 59, "voter": 59, "ident": [59, 65, 67, 77, 78], "remain": [59, 86], "secret": 59, "feel": [59, 86], "contact": 59, "slack": 59, "ucsb": 59, "edu": [59, 65], "guid": 60, "aim": [60, 62, 79], "eas": 60, "both": [60, 62, 65, 79, 86], "novic": 60, "experienc": 60, "commun": 60, "effort": 60, "fork": 60, "upstream": 60, "submit": 60, "pr": 60, "synchron": 60, "your": [60, 66, 67, 70, 72], "branch": 60, "git": 60, "checkout": 60, "sure": 60, "section": [60, 65, 86], "re": [60, 77, 86], "done": [60, 63, 64, 65, 66, 68, 71, 82, 84, 85, 86], "commit": 60, "modified_fil": 60, "my": 60, "push": 60, "toponextx": 60, "instruct": 60, "repeat": 60, "folder": 60, "filenam": 60, "test_add": 60, "def": [60, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "test_capital_cas": 60, "assert": [60, 66, 67, 70, 72, 74, 76, 86], "9": [60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "statement": 60, "under": 60, "correct": [60, 62, 65, 73, 75, 86], "instal": 60, "tool": 60, "pip": 60, "dev": 60, "verifi": 60, "break": 60, "doc": 60, "descript": [60, 65, 86], "usag": 60, "inform": [60, 65, 66, 67, 69, 71, 72, 85], "markdown": 60, "languag": 60, "common": [60, 62, 65], "restructuredtext": 60, "numpi": [60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "style": 60, "understand": 60, "role": 60, "syntax": 60, "autom": 60, "pars": 60, "inclus": 60, "print": [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "__doc__": 60, "attribut": [60, 66, 70, 72, 74, 76], "try": [60, 62, 63, 79, 86], "np": [60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "arrai": [60, 63, 64, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "good": [60, 84], "These": 60, "ones": [60, 69], "summari": 60, "line": 60, "79": [60, 63, 77, 78, 79, 80, 81, 82, 83, 84, 85], "char": 60, "immedi": 60, "capit": 60, "letter": 60, "period": 60, "verb": 60, "imper": 60, "mood": 60, "possibl": 60, "uncertain": 60, "oppos": 60, "evalu": [60, 62, 74], "separ": 60, "blank": 60, "On": 60, "rest": 60, "space": [60, 65, 82, 86], "side": 60, "default_valu": 60, "indent": 60, "esp": 60, "would": [60, 77, 78], "want": [60, 74, 86], "veri": 60, "rais": [60, 82, 85], "latex": 60, "cite": 60, "my_method": 60, "my_param_1": 60, "my_param_2": 60, "big": 60, "o": [60, 67, 79], "short": 60, "my_result": 60, "relev": 60, "snippet": 60, "show": [60, 77, 78, 86], "script": 60, "wikipedia": 60, "page": [60, 84], "And": 60, "fill": 60, "scikit": 60, "fit_predict": 60, "sample_weight": 60, "cluster": 60, "center": [60, 86], "conveni": 60, "fit": 60, "sparse_matrix": 60, "n_featur": 60, "ignor": 60, "Not": [60, 83], "present": [60, 62, 65], "convent": [60, 62], "observ": 60, "labels_": 60, "mind": 60, "instead": [60, 66, 70, 72, 74, 76, 82], "vari": 60, "notat": [60, 62, 63, 64, 65, 70, 77, 78, 79, 80, 81, 83, 85, 86], "axi": [60, 86], "string": 60, "bracket": 60, "multinomi": 60, "1d": [60, 82, 84], "2d": [60, 82, 84], "subset": [60, 62, 69], "datafram": 60, "explicitli": 60, "relat": [60, 69], "colon": 60, "explan": 60, "_weight_boost": 60, "adaboost": 60, "great": 60, "ve": 60, "discuss": 60, "Of": 60, "verbos": 60, "thei": [60, 62, 63, 66, 67, 68, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85], "rst": 60, "80": [60, 77, 78, 79, 80, 81, 82, 83, 84, 85], "charact": 60, "except": [60, 62, 79], "tabl": 60, "tdl": 61, "blue": 61, "laid": 61, "extend": [61, 82], "avail": [61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 79, 80], "about": [61, 65], "blueprint": 61, "misc": 61, "hajij2023topolog": 61, "titl": 61, "year": 61, "eprint": 61, "archiveprefix": 61, "primaryclass": 61, "lg": 61, "papillon2023architectur": 61, "notebook": [62, 65, 66, 67, 68, 69, 70, 71, 72, 77, 78, 79, 82, 83, 84, 85, 86], "didact": [62, 79], "clear": [62, 79], "technic": [62, 79], "document": [62, 69, 77, 79, 81, 82, 85], "sinc": [62, 77, 78, 81, 86], "introduct": 62, "achiev": [62, 65, 67, 86], "outstand": [62, 65], "howev": [62, 82, 85], "pairwis": [62, 68, 71, 86], "relationship": 62, "among": 62, "abl": [62, 79], "fulli": [62, 65], "interact": 62, "real": [62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 86], "world": [62, 86], "vertic": [62, 65, 86], "captur": 62, "particular": 62, "encod": [62, 77, 78, 79, 80, 82, 83, 86], "design": 62, "independ": [62, 67], "thu": [62, 79, 84], "strategi": [62, 72], "approach": 62, "hierarch": [62, 65], "incorpor": 62, "algorithm": 62, "ii": 62, "optim": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "iii": 62, "extract": [62, 66, 67, 70, 71, 72, 76], "compact": 62, "meaning": 62, "remark": [62, 79], "custom": [62, 79], "symbol": [62, 79], "involv": [62, 79], "made": [62, 77, 79, 82, 84, 85], "stage": 62, "nbsphinx": [62, 67, 71, 72, 85], "textrm": [62, 79], "parameter": 62, "mathbb": [62, 65, 66, 67, 71, 86], "2f_0": 62, "f_0": 62, "textbf": [62, 66, 67, 72, 79], "bigg": [62, 79, 82, 85], "f": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "respons": 62, "reciproc": 62, "round": 62, "tcdot": 62, "xin": 62, "score": [62, 86], "_r": 62, "coars": 62, "mutag": [62, 73, 75], "tudataset": [62, 73, 75], "paperswithcod": 62, "com": [62, 66], "__": [62, 65], "188": [62, 79, 80, 83], "chemic": 62, "compound": 62, "discret": 62, "mutagen": 62, "salmonella": 62, "typhimurium": 62, "sklearn": [62, 63, 64, 68, 69, 71, 73, 75, 82, 84, 85], "model_select": [62, 63, 64, 68, 71, 73, 75, 82, 84, 85], "train_test_split": [62, 63, 64, 68, 71, 73, 75, 82, 84, 85], "cell_complex": [62, 63, 64], "cellcomplex": 62, "torch_geometr": [62, 66, 67, 69, 70, 72, 73, 74, 75, 76], "convert": [62, 65, 73, 75, 77, 78, 79, 80, 82, 83, 84], "to_networkx": [62, 73, 75], "from_spars": [62, 63, 64, 68, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85], "manual_se": [62, 63, 64, 66, 67, 69, 70, 72, 73, 74, 75, 76, 86], "seed": [62, 63, 64, 66, 67, 69, 70, 72, 73, 74, 75, 76, 86], "gpu": [62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 80], "run": [62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 81, 86], "cuda": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 83, 84], "is_avail": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 83, 84], "els": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 82, 83, 84, 85], "root": [62, 66, 67, 69, 70, 72, 73, 74, 75, 76], "tmp": [62, 66, 67, 69, 70, 72, 73, 74, 75, 76], "use_edge_attr": [62, 73, 75], "use_node_attr": 62, "cc_list": [62, 63, 64], "x_0_list": 62, "x_1_list": [62, 73, 75], "y_list": [62, 73, 75], "append": [62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "edge_attr": 62, "i_cc": 62, "th": [62, 63, 64, 65, 68, 71, 72, 79, 84], "edge_index": [62, 66, 67, 69, 70, 71, 72, 74, 76], "36": [62, 69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "0th": 62, "17": [62, 67, 77, 78, 79, 80, 81, 82, 83, 84, 85], "38": [62, 69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "6": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "lower_neighborhood_list": 62, "upper_neighborhood_list": 62, "adjacency_0_list": [62, 63], "adjacency_matrix": [62, 63, 64, 65, 77, 78, 81, 86], "from_numpi": [62, 65, 77, 78, 79, 80, 81, 82, 83, 85], "todens": [62, 65, 77], "to_spars": [62, 65, 77, 79, 81], "lower_neighborhood_t": 62, "down_laplacian_matrix": [62, 77, 79, 80, 82, 83, 85], "upper_neighborhood_t": 62, "up_laplacian_matrix": [62, 79, 82, 83, 85], "valueerror": [62, 79, 82, 85], "32": [62, 65, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "specifi": [62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 82, 84, 85], "loss": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "without": [62, 63, 66, 67, 70, 72, 74, 76, 85], "crit": [62, 63, 65, 73, 75], "crossentropyloss": [62, 63, 65, 66, 67, 69, 70, 72, 73, 74, 75, 76], "opt": [62, 63, 65, 66, 67, 68, 70, 71, 72, 76, 83], "adam": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "lr": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "001": [62, 65], "lift_lay": 62, "modulelist": [62, 82, 85], "lower_att": 62, "lin": 62, "out_featur": [62, 82, 85], "64": [62, 63, 73, 77, 78, 79, 80, 81, 82, 83, 84, 85], "upper_att": 62, "lin_0": [62, 84], "128": [62, 66, 67, 69, 70, 72, 74, 76, 79, 80, 83], "lin_1": [62, 84], "split": [62, 63, 64, 68, 73, 75, 86], "test_siz": [62, 63, 64, 68, 71, 73, 75, 82, 84, 85, 86], "x_1_train": [62, 63, 64, 73, 75, 82], "x_1_test": [62, 63, 64, 73, 75, 82], "shuffl": [62, 63, 64, 65, 68, 71, 73, 75, 82, 84, 85, 86], "x_0_train": [62, 63, 64, 68, 71, 82], "x_0_test": [62, 63, 64, 68, 71, 82], "lower_neighborhood_train": 62, "lower_neighborhood_test": 62, "upper_neighborhood_train": 62, "upper_neighborhood_test": 62, "adjacency_0_train": [62, 63], "adjacency_0_test": [62, 63], "y_train": [62, 63, 64, 68, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85], "y_test": [62, 63, 64, 68, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85], "epoch": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "been": [62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 86], "kept": [62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 86], "low": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "facilit": [62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 86], "10": [62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "test_interv": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "num_epoch": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "epoch_i": [62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "rang": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "epoch_loss": [62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "num_sampl": 62, "zip": [62, 63, 64, 68, 71, 73, 75, 82, 84, 85], "dtype": [62, 66, 67, 68, 69, 70, 71, 72, 74, 76, 82, 85], "long": [62, 65, 66, 67, 69, 70, 72, 74, 76], "zero_grad": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "y_hat": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "argmax": [62, 65, 66, 67, 69, 70, 72, 73, 74, 75, 76, 86], "backward": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "train_acc": [62, 65, 69, 74, 77, 78, 79, 80, 81, 82, 83, 85, 86], "4f": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "flush": [62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "no_grad": [62, 63, 64, 65, 68, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85], "test_acc": [62, 65, 66, 67, 69, 70, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85], "6348": 62, "6718": [62, 77], "5965": 62, "6101": [62, 80], "6947": 62, "6008": 62, "5888": 62, "7099": [62, 78, 83], "6316": [62, 81], "5850": [62, 80], "7252": 62, "7368": 62, "5841": 62, "7328": 62, "6491": [62, 79], "5772": 62, "5375": 62, "7405": 62, "7193": 62, "small": [63, 64, 68, 71, 81, 82, 84, 85], "3d": [63, 64, 65, 66, 67, 68, 71, 72, 84], "mesh": [63, 64, 66, 67, 68, 71, 72, 82, 84, 85], "shrec": [63, 64, 65, 68, 71, 84, 85], "shrec_16": [63, 64, 65, 68, 71, 82, 84, 85], "kei": [63, 64, 68, 71, 82, 84, 85], "node_feat": [63, 64, 65, 68, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85], "edge_feat": [63, 64, 65, 68, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85], "face_feat": [63, 64, 65, 68, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85], "i_complex": [63, 64, 68, 71, 84], "6th": [63, 64, 68, 71, 84], "252": [63, 64, 68, 71, 84], "750": [63, 64, 68, 71, 84], "500": [63, 64, 65, 68, 71, 84], "messg": [63, 66, 67, 70, 71, 72, 74, 76, 77, 78, 84], "incidence_2_t_list": 63, "to_cell_complex": [63, 64], "incidence_2_t": [63, 80], "incidence_matrix": [63, 64, 65, 68, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 85, 86], "loss_fn": [63, 66, 67, 68, 69, 70, 71, 72, 74, 76, 82, 84, 85], "mseloss": [63, 64, 68, 71, 82, 84, 85], "incidence_2_t_train": 63, "incidence_2_t_test": 63, "minim": [63, 64, 65, 66, 67, 69, 70, 71, 72, 76, 82], "rapid": [63, 64, 65, 66, 67, 69, 70, 71, 72, 76, 82], "train_mean_loss": [63, 64], "test_loss": [63, 64, 66, 67, 68, 69, 70, 71, 72, 74, 76, 82, 84, 85], "usr": [63, 66, 68, 70, 71, 72, 74, 76], "local": [63, 66, 68, 70, 71, 72, 74, 76], "lib": [63, 66, 68, 70, 71, 72, 74, 76, 77, 81, 82, 85], "python3": [63, 66, 68, 70, 71, 72, 74, 76, 77, 81, 82, 85], "site": [63, 66, 68, 70, 71, 72, 74, 76, 77, 81, 82, 85], "536": [63, 68, 71, 82, 85], "userwarn": [63, 66, 67, 68, 70, 71, 72, 74, 76, 82, 85], "lead": [63, 68, 71, 82, 85], "incorrect": [63, 68, 71, 82, 85], "due": [63, 68, 71, 81, 82, 85], "ensur": [63, 66, 67, 68, 70, 71, 72, 74, 76, 82, 85], "mse_loss": [63, 68, 71, 82, 85], "reduct": [63, 68, 71, 82, 85], "82": [63, 69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "9399": 63, "72": [63, 77, 78, 79, 80, 81, 82, 83, 84, 85], "3905": 63, "9278": 63, "76": [63, 69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "1475": [63, 77], "7409": 63, "75": [63, 64, 77, 78, 79, 80, 81, 82, 83, 84, 85], "5150": [63, 69], "74": [63, 64, 77, 78, 79, 80, 81, 82, 83, 84, 85], "2580": 63, "6475": [63, 79], "1732": 63, "78": [63, 64, 77, 78, 79, 80, 81, 82, 83, 84, 85], "3276": 63, "12": [63, 67, 68, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "96": [63, 69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "2627": 63, "67": [63, 77, 78, 79, 80, 81, 82, 83, 84, 85], "7411": 63, "83": [63, 64, 77, 78, 79, 80, 81, 82, 83, 84, 85], "8081": 63, "60": [63, 65, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "9365": 63, "7461": 63, "3800": 63, "0083": 63, "3870": 63, "73": [63, 64, 77, 78, 79, 80, 81, 82, 83, 84, 85], "6383": 63, "6792": 63, "interc": 64, "incidence_2_list": [64, 82, 85], "adjacency_1_list": 64, "incidence_1_t_list": 64, "adjacency_1": [64, 65], "incidence_1_t": [64, 80], "criterion": 64, "x_2_train": [64, 82], "x_2_test": [64, 82], "adjacency_1_train": 64, "adjacency_1_test": 64, "incidence_2_train": [64, 82], "incidence_2_test": [64, 82], "incidence_1_t_train": 64, "incidence_1_t_test": 64, "8053": 64, "7517": 64, "81": [64, 69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "9552": 64, "50": [64, 69, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85], "2781": 64, "3991": 64, "49": [64, 69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "9034": 64, "8107": 64, "45": [64, 69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "7201": 64, "3833": 64, "5558": [64, 85], "35": [65, 77, 78, 79, 80, 81, 82, 83, 84, 85], "sequenc": 65, "definit": [65, 85], "31": [65, 69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "33": [65, 77, 78, 79, 80, 81, 82, 83, 84, 85], "phi_u": 65, "phi_a": 65, "i_x": 65, "intermedi": 65, "i_i": 65, "previou": 65, "actual": 65, "column": 65, "row": [65, 66, 67, 70, 72, 74, 76], "2016": [65, 67], "shapenet": 65, "stanford": 65, "480": 65, "30": [65, 66, 70, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "distinct": 65, "latter": 65, "entiti": 65, "direct": 65, "posit": 65, "p_v": 65, "coordin": [65, 86], "n_v": 65, "dihedr": 65, "angl": [65, 86], "span": 65, "theta_": 65, "area": 65, "n_f": 65, "theta_f": 65, "certain": [65, 66, 67, 70, 72, 74, 76, 85], "dataload": 65, "hmc": 65, "shrecdataset": 65, "npz": 65, "__init__": [65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "cc": 65, "to_combinatorial_complex": 65, "a0": [65, 77, 78], "a1": 65, "coa2": 65, "_get_neighborhood_matrix": 65, "floattensor": 65, "to_rank": 65, "setdiag": 65, "uniqu": [65, 66, 67, 69, 70, 72, 74, 76], "channels_dim": 65, "__len__": [65, 86], "__getitem__": [65, 86], "idx": [65, 86], "shrec_train": 65, "shrec_test": 65, "full": 65, "training_dataset": 65, "training_dataload": 65, "batch_siz": [65, 86], "testing_dataset": 65, "testing_dataload": 65, "classifi": 65, "emploi": 65, "outlin": 65, "articl": 65, "integr": 65, "nodal": 65, "euclidean": [65, 86], "trainer": 65, "cross": [65, 66, 67, 70, 72, 74, 76], "entropi": [65, 66, 67, 70, 72, 74, 76], "hoanmeshclassifi": 65, "learning_r": 65, "_to_devic": 65, "move": 65, "el": 65, "25": [65, 66, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "interv": 65, "training_accuraci": 65, "_train_epoch": 65, "test_accuraci": [65, 77, 78, 79, 80, 81, 82, 83, 85], "training_sampl": 65, "total_loss": 65, "coadjacency_2": 65, "_compute_loss_and_upd": 65, "backpropag": 65, "ground": [65, 86], "truth": [65, 86], "eval": [65, 66, 67, 69, 70, 72, 73, 74, 75, 76, 86], "test_sampl": 65, "moreov": 65, "neg": [65, 86], "slope": 65, "leaki": 65, "alreadi": [65, 79, 80, 82, 83, 84], "almost": 65, "perfect": 65, "although": 65, "intermediate_channel": 65, "final_channel": 65, "channels_per_lay": 65, "defub": 65, "6020": [65, 69], "0333": 65, "0917": 65, "2161": 65, "0750": 65, "1333": 65, "9366": 65, "1437": 65, "1583": 65, "6148": 65, "2167": 65, "2500": [65, 77, 78, 79], "3257": 65, "2875": 65, "2750": 65, "let": [65, 66, 67, 71, 72, 86], "longer": 65, "v_": [66, 67, 71], "e_": [66, 67], "rule": [66, 67], "put": [66, 67, 81], "f_": [66, 67], "permut": [66, 67], "invari": [66, 67], "parametr": [66, 67], "learnt": [66, 67], "solv": [66, 67, 70, 72], "problem": [66, 67, 70, 72], "geom_dataset": [66, 67, 69, 70, 72, 74, 76], "to_undirect": [66, 67, 70, 72, 74, 76], "cora": [66, 67, 69, 70, 72, 74, 76], "datas": [66, 67, 70, 72, 74, 76], "planetoid": [66, 67, 69, 70, 72, 74, 76], "train_mask": [66, 67, 69, 70, 72, 74, 76], "val_mask": [66, 67, 69, 70, 72, 74, 76], "test_mask": [66, 67, 69, 70, 72, 74, 76], "download": [66, 69], "kimiyoung": 66, "raw": 66, "master": 66, "ind": 66, "tx": 66, "allx": 66, "ty": 66, "alli": 66, "in_memory_dataset": [66, 70, 72, 74, 76], "285": 66, "recommend": [66, 67, 70, 72, 74, 76], "access": [66, 70, 72, 74, 76], "intern": [66, 70, 72, 74, 76], "storag": [66, 70, 72, 74, 76], "39": [66, 69, 70, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "inmemorydataset": [66, 70, 72, 74, 76], "what": [66, 68, 70, 71, 72, 73, 74, 75, 76, 81], "_data": [66, 70, 72, 74, 76], "suppress": [66, 70, 72, 74, 76], "warn": [66, 70, 72, 74, 76, 82], "individu": [66, 70, 72, 74, 76], "attr_nam": [66, 70, 72, 74, 76], "msg": [66, 70, 72, 74, 76], "citat": [66, 67, 69, 70, 72, 74, 76], "hop": [66, 67, 70, 72, 74, 76, 79, 85], "undirect": [66, 67, 70, 72, 74, 76], "often": [66, 67, 70, 72, 74, 76], "one_hop_neighborhood": [66, 67, 70, 72, 74, 76], "current": [66, 67, 70, 72, 74, 76, 79, 82, 85], "detect": [66, 67, 70, 72, 74, 76], "elimin": [66, 67, 70, 72, 74, 76], "duplic": [66, 67, 70, 72, 74, 76], "unique_hyperedg": [66, 67, 70, 72, 74, 76], "sort": [66, 67, 70, 72, 74, 76, 86], "comparison": [66, 67, 70, 72, 74, 76], "staticti": [66, 67, 70, 72, 74, 76], "statist": [66, 67, 70, 72, 74, 76], "hyperedge_s": [66, 67, 70, 72, 74, 76], "he": [66, 67, 70, 72, 74, 76], "min_siz": [66, 67, 70, 72, 74, 76], "min": [66, 67, 70, 72, 74, 76], "max_siz": [66, 67, 70, 72, 74, 76], "mean_siz": [66, 67, 70, 72, 74, 76], "median_s": [66, 67, 70, 72, 74, 76], "median": [66, 67, 70, 72, 74, 76], "std_size": [66, 67, 70, 72, 74, 76], "std": [66, 67, 70, 72, 74, 76], "num_single_node_hyperedg": [66, 67, 70, 72, 74, 76], "2581": [66, 70, 72, 74, 76], "168": [66, 70, 72, 74, 76, 79, 80, 83], "003099573808601": [66, 70, 72, 74, 76], "327622607829558": [66, 70, 72, 74, 76], "412": [66, 70, 72, 74, 76], "max_edg": [66, 67, 70, 72, 74, 76], "col": [66, 67, 70, 72, 74, 76], "neighibourhood": [66, 67, 70, 72, 74, 76], "enumer": [66, 67, 70, 72, 74, 76, 86], "to_sparse_coo": [66, 67, 70, 72, 74, 76], "downstream": [66, 67, 68, 70, 71, 72, 73, 74, 75, 76], "might": [66, 67, 68, 70, 71, 72, 73, 74, 75, 76], "procedur": [66, 67, 68, 70, 71, 72, 73, 74, 75, 76], "reqir": [66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "optit": [66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "task_level": [66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "super": [66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "base_model": [66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "out_pool": [66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "categori": [66, 67, 69, 70, 72, 74, 76], "acc_fn": [66, 67, 70, 72, 74, 76], "ipykernel_1791": 66, "1422611997": [66, 70, 72, 74, 76], "copi": [66, 67, 70, 72, 74, 76], "sourcetensor": [66, 67, 70, 72, 74, 76], "clone": [66, 67, 70, 72, 74, 76], "detach": [66, 67, 70, 72, 74, 76], "requires_grad_": [66, 67, 70, 72, 74, 76], "train_loss": [66, 67, 69, 70, 71, 72, 74, 76, 86], "acc": [66, 67, 69, 70, 72, 76], "val_loss": [66, 67, 69, 70, 72, 76, 86], "val_acc": [66, 67, 69, 70, 72, 76, 86], "8307": 66, "4929": 66, "7379": 66, "3560": 66, "6873": [66, 78], "4080": 66, "4922": 66, "6857": 66, "5380": 66, "5160": 66, "3973": 66, "15": [66, 67, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "1529": 66, "9786": [66, 72, 76], "0844": 66, "6820": 66, "9983": 66, "7010": 66, "20": [66, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "0032": 66, "9214": 66, "8625": 66, "5820": 66, "7555": 66, "5950": [66, 80], "8708": 66, "0000": [66, 67, 70, 72, 76, 78, 80, 81, 83], "0274": 66, "7040": 66, "8696": 66, "6960": 66, "7377": 66, "0471": 66, "6940": 66, "8233": 66, "repo": [67, 72], "rise": 67, "so": [67, 77, 78, 79, 80, 81, 82, 83, 85, 86], "dive": 67, "iter": 67, "Their": 67, "omega": 67, "overset": [67, 79], "delta": 67, "mathbin": 67, "ba": 67, "hf_": 67, "multihead": 67, "vaswani": 67, "wise": [67, 68, 71], "14": [67, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "18": [67, 73, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "19": [67, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "21": [67, 69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "ipykernel_909051": 67, "276484184": 67, "22": [67, 77, 78, 79, 80, 81, 82, 83, 84, 85], "9825": 67, "9895": 67, "7380": 67, "8713": 67, "7740": 67, "feed": [68, 71, 73, 75, 86], "dir": 68, "amtric": [68, 71], "unsign": [68, 71], "becom": [68, 71, 79], "simplciial": [68, 71], "hg_list": [68, 71, 73, 75], "incidence_1_list": [68, 71, 73, 75, 82, 85], "sign": [68, 71, 86], "hg": [68, 71, 73, 75], "to_hypergraph": [68, 71, 73, 75], "11062303": 68, "5101": [68, 82], "135039": 68, "8750": 68, "12746": 68, "0434": 68, "7911": 68, "8130": 68, "1477": 68, "9950": 68, "228": 68, "0758": 68, "702": 68, "3154": 68, "2958": 68, "872": 68, "6976": 68, "1025": 68, "2914": 68, "2708": 69, "academ": 69, "5429": [69, 83], "case_bas": 69, "genetic_algorithm": 69, "neural_network": 69, "probabilistic_method": 69, "reinforcement_learn": 69, "rule_learn": 69, "theori": 69, "1433": 69, "stand": 69, "word": 69, "presenc": 69, "metric": 69, "accuracy_scor": 69, "val": [69, 73, 75, 86], "initial_x_1": 69, "zeros_lik": 69, "y_pred": [69, 77, 78, 79, 80, 81, 82, 83, 85], "2f": 69, "2665": 69, "9848": 69, "23": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "2270": 69, "8439": 69, "99": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "7569": 69, "3970": 69, "5119": [69, 82], "00": 69, "6846": 69, "4160": 69, "42": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "2717": 69, "5872": [69, 80], "43": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "4500": 69, "26": [69, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85], "1571": 69, "6143": 69, "41": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "4230": 69, "0816": 69, "5894": [69, 80], "4490": 69, "0478": 69, "46": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "4630": 69, "0298": [69, 84], "6153": 69, "47": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "4670": 69, "0214": 69, "6499": [69, 79], "4720": 69, "51": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "0160": 69, "6764": 69, "48": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "4830": 69, "56": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "0149": 69, "6986": 69, "4900": 69, "61": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "0123": 69, "6888": [69, 78], "4920": 69, "66": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "0097": 69, "6670": [69, 79], "4970": [69, 71], "71": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "0078": 69, "6547": [69, 80], "5030": 69, "0072": 69, "6484": [69, 79], "0066": 69, "6378": 69, "5100": 69, "86": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "0064": 69, "6507": [69, 79, 80], "5110": 69, "91": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "0060": 69, "6745": [69, 81, 83], "0051": 69, "6682": [69, 79], "52": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "101": [69, 79, 80, 83], "0047": 69, "6412": 69, "5190": 69, "karateclub": [70, 77, 78, 79, 80, 81, 82, 83], "284": [70, 72, 74, 76], "ipykernel_96287": 70, "1216": 70, "9929": [70, 72, 76], "8693": 70, "7340": 70, "8030": 70, "7570": [70, 76], "5751": [70, 80], "6032": [70, 80], "7140": 70, "3768": 70, "7370": 70, "3835": 70, "6746": [70, 79], "7120": [70, 83], "2858": 70, "7320": 70, "2876": 70, "5548": [70, 83, 85], "7160": 70, "0300": 70, "7310": 70, "2301": 70, "1969": 70, "5745": [70, 80], "1917": 70, "6384": 70, "9496": 70, "As": 71, "j": [71, 72, 77, 81, 83, 86], "highlight": 71, "those": [71, 79], "formal": [71, 79], "alpha_": 71, "jk": 71, "nonlinear": [71, 85], "exp": 71, "u_": 71, "limits_": 71, "context": 71, "again": [71, 79, 80], "vi": [71, 72], "beta_": 71, "ij": 71, "anoth": 71, "measur": 71, "1250": 71, "out_dim": 71, "incidence_1_train": [71, 73, 75, 82], "incidence_1_test": [71, 73, 75, 82], "to_edge_index": 71, "test_epoch_loss": 71, "7195": 71, "0287": 71, "19283": 71, "1447": 71, "1705": 71, "4479": 71, "4695": 71, "8421": 71, "2624": 71, "2060": 71, "3844": 71, "4079": 71, "6754": 71, "1770": 71, "3517": 71, "interpret": 72, "propag": 72, "divid": 72, "ipykernel_33450": 72, "9424": 72, "5929": [72, 80], "9401": 72, "2460": 72, "9405": 72, "2620": 72, "9305": 72, "9357": 72, "9221": 72, "5680": [72, 80], "9220": 72, "5580": 72, "9105": 72, "9714": 72, "8899": 72, "6560": 72, "8904": 72, "6490": [72, 79], "8811": 72, "8450": 72, "7260": 72, "8466": 72, "6990": 72, "8412": 72, "7831": 72, "7360": 72, "7857": 72, "7210": 72, "7905": 72, "7067": 72, "7420": 72, "7103": 72, "7220": 72, "simplicial_complex": [73, 75, 86], "x_1_val": [73, 75], "incidence_1_v": [73, 75], "y_val": [73, 75], "unsqueez": [73, 75, 86], "pred": [73, 75, 86], "389": 73, "1796569824219": 73, "5625": [73, 75], "91588592529297": 73, "873802185058594": 73, "4375": [73, 75], "046907424926758": 73, "625": [73, 75], "672311782836914": 73, "24": [73, 77, 78, 79, 80, 81, 82, 83, 84, 85], "973644256591797": 73, "025209426879883": 73, "cicitationcora": 74, "hgnn": 74, "utlil": 74, "neccessari": 74, "readi": [74, 86], "ipykernel_7355": 74, "3311": 74, "1429": [74, 77], "4650": 74, "1430": 74, "7255": 74, "6000": [74, 78, 83], "7909": 74, "4460": 74, "4779": 74, "6714": 74, "6235": 74, "5080": 74, "2046": 74, "7786": 74, "5192": 74, "5790": 74, "8618": 74, "8500": 74, "4219": 74, "6350": 74, "6326": 74, "8643": 74, "4752": 74, "6700": [74, 79], "modelo": 75, "1261": 75, "591552734375": 75, "00477600097656": 75, "37": [75, 77, 78, 79, 80, 81, 82, 83, 84, 85], "117366790771484": 75, "90342903137207": 75, "3125": 75, "588314056396484": 75, "57889747619629": 75, "412574768066406": 75, "ipykernel_20995": 76, "0359": 76, "9799": 76, "7840": 76, "0519": [76, 84], "7970": 76, "5867": [76, 80], "4344": 76, "7620": 76, "6381": 76, "4123": 76, "7868": 76, "7440": 76, "8944": 76, "7610": 76, "3157": 76, "1006": [76, 77], "7520": 76, "3052": 76, "7560": 76, "2532": 76, "4428": 76, "7480": 76, "7105": [76, 78, 83], "7460": 76, "2113": 76, "5174": 76, "7498": 76, "alexandro": 77, "kero": 77, "linalg": 77, "npla": 77, "load_ext": [77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "autoreload": [77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "www": [77, 78, 79, 80, 81, 82, 83], "jstor": [77, 78, 79, 80, 81, 82, 83], "stabl": [77, 78, 79, 80, 81, 82, 83], "3629752": [77, 78, 79, 80, 81, 82, 83], "singular": [77, 78, 79, 80, 81, 82, 83], "34": [77, 78, 79, 80, 81, 82, 83, 84, 85], "social": [77, 78, 79, 80, 81, 82, 83], "group": [77, 78, 79, 80, 81, 82, 83], "karate_club": [77, 78, 79, 80, 81, 82, 83, 85], "complex_typ": [77, 78, 79, 80, 81, 82, 83, 85], "santii": [77, 78], "becaus": [77, 78, 82, 85], "hot": [77, 78, 79, 80, 82, 83], "get_simplex_attribut": [77, 78, 79, 80, 81, 82, 83, 85], "serv": [77, 78], "simpli": [77, 78, 86], "demonstr": [77, 78], "similarli": [77, 78, 81], "emerg": [77, 78, 79, 80, 81, 82, 83], "four": [77, 78, 79, 80, 81, 82, 83], "y_true": [77, 78, 79, 80, 81, 82, 83, 85], "ld": 77, "l_tilde_pinv": 77, "pinv": 77, "ey": [77, 81], "invers": 77, "incidence_0_1": [77, 79, 83], "28": [77, 78, 79, 80, 81, 82, 83, 84, 85], "53": [77, 78, 79, 80, 81, 82, 83, 84, 85], "54": [77, 78, 79, 80, 81, 82, 83, 84, 85], "55": [77, 78, 79, 80, 81, 82, 83, 84, 85], "58": [77, 78, 79, 80, 81, 82, 83, 84, 85], "62": [77, 78, 79, 80, 81, 82, 83, 84, 85], "65": [77, 78, 79, 80, 81, 82, 83, 84, 85], "68": [77, 78, 79, 80, 81, 82, 83, 84, 85], "69": [77, 78, 79, 80, 81, 82, 83, 84, 85], "70": [77, 78, 79, 80, 81, 82, 83, 84, 85], "77": [77, 78, 79, 80, 81, 82, 83, 84, 85], "0650": 77, "0663": 77, "0701": 77, "0685": 77, "0731": 77, "0699": 77, "0971": 77, "0959": 77, "0920": 77, "0937": 77, "0891": 77, "0923": 77, "0687": 77, "0721": 77, "0754": 77, "0725": 77, "0968": 77, "0930": [77, 82], "0897": 77, "0864": 77, "0892": 77, "0789": 77, "0749": 77, "1380": 77, "1356": 77, "1255": 77, "1179": 77, "1294": 77, "1009": 77, "1080": 77, "2140": 77, "2069": 77, "1106": 77, "1724": 77, "1821": 77, "1851": 77, "1831": 77, "1763": 77, "1628": 77, "2927": 77, "1560": 77, "1519": 77, "1495": 77, "3018": 77, "2309": 77, "0996": 77, "0992": 77, "1012": 77, "0943": [77, 84], "0948": 77, "0927": 77, "1046": 77, "1023": 77, "1343": 77, "1293": 77, "1316": 77, "1780": 77, "1725": 77, "1484": 77, "1473": 77, "0998": 77, "0954": 77, "1288": 77, "1332": 77, "1730": 77, "1487": 77, "1457": 77, "2678": 77, "1426": 77, "1734": [77, 85], "1738": 77, "1654": 77, "0724": 77, "0804": 77, "0576": 77, "3090": 77, "0693": 77, "0607": 77, "1474": 77, "1836": 77, "1511": 77, "1518": 77, "1812": 77, "1804": 77, "0960": 77, "0746": 77, "0803": 77, "0759": 77, "0553": 77, "2077": 77, "2056": 77, "2813": 77, "1545": 77, "1019": 77, "0819": 77, "0546": 77, "1962": 77, "0720": 77, "0580": 77, "1575": 77, "0762": 77, "0537": 77, "nnz": 77, "270": 77, "layout": 77, "sparse_coo": 77, "40770523e": 77, "02": [77, 86], "11494370e": 77, "97384816e": 77, "02294368e": 77, "64641943e": 77, "86156419e": 77, "83606968e": 77, "08": [77, 86], "49915427e": 77, "00650188e": 77, "83463633e": 77, "75156136e": 77, "83463678e": 77, "05313901e": 77, "90156896e": 77, "20998740e": 77, "07190537e": 77, "09101162e": 77, "62092721e": 77, "98118326e": 77, "23208503e": 77, "03": [77, 86], "53657054e": 77, "43603450e": 77, "50192329e": 77, "20385336e": 77, "53667741e": 77, "72664091e": 77, "49207789e": 77, "20385485e": 77, "95071507e": 77, "25182593e": 77, "38155320e": 77, "95849722e": 77, "05412391e": 77, "36992298e": 77, "46084312e": 77, "20638106e": 77, "84373805e": 77, "39397243e": 77, "20385038e": 77, "50549929e": 77, "48587048e": 77, "44989747e": 77, "20385019e": 77, "50550078e": 77, "26969576e": 77, "39617124e": 77, "32742967e": 77, "32841964e": 77, "92070971e": 77, "09105867e": 77, "12601468e": 77, "28915999e": 77, "50366500e": 77, "93094122e": 77, "62186569e": 77, "49070593e": 77, "30901868e": 77, "55232428e": 77, "51894227e": 77, "22967193e": 77, "15316376e": 77, "22131526e": 77, "93280513e": 77, "29361625e": 77, "23212508e": 77, "29043306e": 77, "78961600e": 77, "72971559e": 77, "76038641e": 77, "18312794e": 77, "32374076e": 77, "55317712e": 77, "97262095e": 77, "09": [77, 84, 86], "42880568e": 77, "96564454e": 77, "18312198e": 77, "07279651e": 77, "27834606e": 77, "21484074e": 77, "27835426e": 77, "98071399e": 77, "66642778e": 77, "40563001e": 77, "23841551e": 77, "83955252e": 77, "74787247e": 77, "50366411e": 77, "16282904e": 77, "75315768e": 77, "67087543e": 77, "21695530e": 77, "16733683e": 77, "21695669e": 77, "97473371e": 77, "16734018e": 77, "21695707e": 77, "97473222e": 77, "16733590e": 77, "21251035e": 77, "11335017e": 77, "21695511e": 77, "16733608e": 77, "21695651e": 77, "16733944e": 77, "21695725e": 77, "97473520e": 77, "66296689e": 77, "70098506e": 77, "54005478e": 77, "45874349e": 77, "84309315e": 77, "33008221e": 77, "11998310e": 77, "11719538e": 77, "55389528e": 77, "02689916e": 77, "43989541e": 77, "58042466e": 77, "93099503e": 77, "70438008e": 77, "17499000e": 77, "70586307e": 77, "41898049e": 77, "46390563e": 77, "55402555e": 77, "45243965e": 77, "55398457e": 77, "46499884e": 77, "40789945e": 77, "23143601e": 77, "49792436e": 77, "31365804e": 77, "69150501e": 77, "28155053e": 77, "23110419e": 77, "44727693e": 77, "71080101e": 77, "37488726e": 77, "57507989e": 77, "30902189e": 77, "14116156e": 77, "18122974e": 77, "24033478e": 77, "10169996e": 77, "80642232e": 77, "59393880e": 77, "43391562e": 77, "89420712e": 77, "gbg141": [77, 81, 82, 85], "topoprojectx": [77, 81, 82, 85], "venv_modelx": [77, 81, 82, 85], "scipi": [77, 81, 83, 86], "_index": [77, 81], "143": [77, 79, 80, 81, 83], "sparseefficiencywarn": [77, 81], "chang": [77, 81, 86], "sparsiti": [77, 81], "csr_matrix": [77, 81], "expens": [77, 81], "lil_matrix": [77, 81], "_set_arrayxarrai": [77, 81], "produc": [77, 78, 79, 81, 83, 85], "compar": [77, 78, 79, 81, 83, 85], "y_hat_edg": [77, 79, 85], "fn": [77, 79, 85], "mm": [77, 79, 85], "binary_cross_entropy_with_logit": [77, 78, 79, 80, 81, 83, 85], "y_hat_edge_test": [77, 79, 85], "y_hat_test": [77, 78, 79, 80, 81, 82, 83, 85], "y_pred_test": [77, 78, 79, 80, 81, 82, 83, 85], "_pred_test": [77, 81], "ge": [77, 81], "7234": 77, "6333": [77, 83], "6930": 77, "6667": [77, 83, 84], "6769": 77, "7000": [77, 79, 80, 81, 83], "6701": 77, "6694": [77, 79], "6691": 77, "6689": [77, 79], "6688": 77, "27": [77, 78, 79, 80, 81, 82, 83, 84, 85], "29": [77, 78, 79, 80, 81, 82, 83, 84, 85], "44": [77, 78, 79, 80, 81, 82, 83, 84, 85], "57": [77, 78, 79, 80, 81, 82, 83, 84, 85], "63": [77, 78, 79, 80, 81, 82, 83, 84, 85], "84": [77, 78, 79, 80, 81, 82, 83, 84, 85], "85": [77, 78, 79, 80, 81, 82, 83, 84, 85], "87": [77, 78, 79, 80, 81, 82, 83, 84, 85], "88": [77, 78, 79, 80, 81, 82, 83, 84, 85], "89": [77, 78, 79, 80, 81, 82, 83, 84, 85], "90": [77, 78, 79, 80, 81, 82, 83, 84, 85], "92": [77, 78, 79, 80, 81, 82, 83, 84, 85], "93": [77, 78, 79, 80, 81, 82, 83, 84, 85], "94": [77, 78, 79, 80, 81, 82, 83, 84, 85], "95": [77, 78, 79, 80, 81, 82, 83, 84, 85], "97": [77, 78, 79, 80, 81, 82, 83, 84, 85], "98": [77, 78, 79, 80, 81, 82, 83, 84, 85], "7200": 78, "5667": [78, 80, 81, 83], "7183": 78, "7167": 78, "7153": 78, "7142": 78, "7133": [78, 83], "7125": [78, 83], "7118": 78, "7111": 78, "7093": [78, 83], "7087": 78, "7081": 78, "7076": [78, 80], "7070": [78, 83], "7066": 78, "7061": 78, "7058": 78, "7054": 78, "7050": 78, "7046": 78, "7042": [78, 83], "7037": [78, 80], "7033": 78, "7029": 78, "7025": 78, "7021": 78, "7017": [78, 83], "5333": [78, 83], "7013": [78, 81], "5000": [78, 80, 81, 82, 83, 85], "7009": 78, "7005": 78, "7001": 78, "6997": 78, "6993": 78, "6989": 78, "6985": 78, "6981": 78, "6977": 78, "6973": 78, "6969": 78, "6966": 78, "6962": 78, "6958": [78, 79], "6955": [78, 80], "6951": 78, "6948": 78, "6945": 78, "6942": 78, "6938": 78, "6935": [78, 83], "6932": 78, "6929": 78, "6927": 78, "6924": 78, "6921": 78, "6919": 78, "6916": [78, 83], "6914": 78, "6911": 78, "6909": 78, "6907": 78, "6905": 78, "6903": 78, "6901": 78, "6899": 78, "6897": 78, "6895": 78, "6893": 78, "6892": 78, "6890": [78, 79], "6887": 78, "6885": 78, "6884": 78, "6883": 78, "6881": 78, "6880": 78, "6879": 78, "6878": 78, "6876": 78, "6875": 78, "6874": 78, "6872": [78, 83], "6871": 78, "6870": [78, 80], "6869": 78, "6868": 78, "6867": [78, 81], "6866": 78, "6865": 78, "6864": 78, "6863": 78, "6862": [78, 79, 84, 85], "6861": 78, "6860": [78, 84], "work": [79, 83], "novel": 79, "hing": 79, "proper": 79, "orient": 79, "fashion": 79, "kernel": 79, "l_r": 79, "widetild": 79, "hy": 79, "neq": [79, 86], "affin": 79, "therefor": 79, "suppos": 79, "_j": 79, "underset": 79, "w_": 79, "q_": 79, "extens": [79, 80, 82, 83, 84], "reload": [79, 80, 82, 83, 84], "reload_ext": [79, 80, 82, 83, 84], "tb_1": 79, "b_2b_2": 79, "notic": 79, "pattern": 79, "just": [79, 81, 86], "maxium": 79, "simplex_order_k": 79, "gradient": 79, "tx_0": 79, "estim": 79, "multipli": 79, "diverg": 79, "deriv": 79, "seen": 79, "accordingli": 79, "henc": 79, "200": [79, 80, 83], "7225": 79, "7185": 79, "7139": 79, "7091": 79, "7333": [79, 83, 85], "7044": [79, 80], "6999": 79, "6922": 79, "6837": 79, "6816": 79, "6798": [79, 80], "6782": 79, "6768": [79, 80], "6756": 79, "6737": 79, "6730": 79, "6723": 79, "6717": 79, "6712": [79, 80], "6708": 79, "6704": 79, "6697": 79, "6692": 79, "6687": [79, 83], "6685": 79, "6683": 79, "6680": 79, "6678": 79, "6677": [79, 82], "6676": 79, "6674": 79, "6673": [79, 85], "6672": 79, "6669": 79, "6668": 79, "6666": 79, "6665": 79, "6664": [79, 80], "6663": 79, "6661": 79, "6660": 79, "6659": 79, "6657": [79, 83], "6656": 79, "6654": 79, "6653": 79, "6652": 79, "6650": 79, "6648": 79, "6647": 79, "6645": [79, 81], "6644": 79, "6642": 79, "6640": 79, "6638": 79, "6637": [79, 80], "6635": 79, "6633": 79, "6631": 79, "6629": 79, "6627": 79, "6624": 79, "6622": 79, "6620": 79, "6618": 79, "6615": 79, "6613": 79, "6610": 79, "6608": [79, 80], "6605": 79, "6603": 79, "6600": 79, "6597": 79, "6594": 79, "6592": [79, 81], "6589": 79, "6586": 79, "6583": 79, "7667": [79, 81, 82, 83, 85], "6580": 79, "6577": [79, 80], "6574": 79, "6571": 79, "6568": 79, "6565": 79, "6562": [79, 80], "6559": 79, "6556": 79, "6553": 79, "8000": [79, 81, 82, 85], "6550": 79, "6548": 79, "6545": 79, "6543": 79, "6541": 79, "102": [79, 80, 83], "6539": 79, "8333": [79, 81, 85], "103": [79, 80, 83], "6537": 79, "104": [79, 80, 83], "6535": 79, "105": [79, 80, 83], "6534": 79, "106": [79, 80, 83, 84], "6532": 79, "107": [79, 80, 83], "6531": 79, "108": [79, 80, 83], "6529": 79, "109": [79, 80, 83], "6528": 79, "110": [79, 80, 83, 85], "6526": 79, "111": [79, 80, 83], "6525": 79, "112": [79, 80, 83], "6524": 79, "113": [79, 80, 83], "6522": 79, "114": [79, 80, 83], "6521": 79, "115": [79, 80, 83], "6520": [79, 80], "116": [79, 80, 83, 85], "6518": 79, "117": [79, 80, 83, 85], "6517": 79, "118": [79, 80, 83], "6516": 79, "119": [79, 80, 83], "6515": 79, "120": [79, 80, 83], "6513": 79, "121": [79, 80, 83], "6512": 79, "122": [79, 80, 83], "6511": 79, "123": [79, 80, 83], "6510": 79, "124": [79, 80, 83], "6509": 79, "125": [79, 80, 83], "6508": 79, "126": [79, 80, 83], "127": [79, 80, 83], "6506": 79, "6505": 79, "129": [79, 80, 83], "6504": 79, "130": [79, 80, 83], "131": [79, 80, 83], "6503": 79, "132": [79, 80, 83], "6502": 79, "133": [79, 80, 83], "6501": [79, 83], "134": [79, 80, 83], "6500": 79, "135": [79, 80, 83], "136": [79, 80, 83], "137": [79, 80, 83], "6498": 79, "138": [79, 80, 83], "139": [79, 80, 83], "6497": 79, "140": [79, 80, 83], "6496": 79, "141": [79, 80, 83], "6495": 79, "142": [79, 80, 83], "6494": [79, 80], "144": [79, 80, 83], "145": [79, 80, 83], "6493": 79, "146": [79, 80, 83], "6492": 79, "147": [79, 80, 82, 83], "148": [79, 80, 83], "149": [79, 80, 83, 85], "150": [79, 80, 83, 86], "151": [79, 80, 83], "152": [79, 80, 83], "6489": 79, "153": [79, 80, 83], "154": [79, 80, 83], "6488": 79, "155": [79, 80, 83], "156": [79, 80, 83], "6487": 79, "157": [79, 80, 83], "158": [79, 80, 83, 85], "6486": [79, 81], "159": [79, 80, 83], "160": [79, 80, 83], "6485": 79, "161": [79, 80, 83], "162": [79, 80, 83], "163": [79, 80, 83], "164": [79, 80, 83], "6483": 79, "165": [79, 80, 83], "166": [79, 80, 83], "167": [79, 80, 83], "6482": 79, "169": [79, 80, 83], "6481": [79, 80], "170": [79, 80, 83], "171": [79, 80, 83], "172": [79, 80, 83, 85], "6480": 79, "173": [79, 80, 83], "174": [79, 80, 83], "175": [79, 80, 83], "6479": 79, "176": [79, 80, 83], "177": [79, 80, 83], "178": [79, 80, 83, 85], "6478": 79, "179": [79, 80, 83], "180": [79, 80, 83], "6477": 79, "181": [79, 80, 83], "182": [79, 80, 83], "183": [79, 80, 83], "184": [79, 80, 83], "6476": 79, "185": [79, 80, 83], "186": [79, 80, 83], "187": [79, 80, 83], "189": [79, 80, 83], "190": [79, 80, 83], "6474": 79, "191": [79, 80, 83], "192": [79, 80, 83], "193": [79, 80, 83], "194": [79, 80, 83], "6473": 79, "195": [79, 80, 83], "196": [79, 80, 83], "197": [79, 80, 83], "6472": 79, "198": [79, 80, 83, 84], "199": [79, 80, 83], "laplacian_down_2": [80, 82, 85], "lin0": 80, "7272": 80, "4333": [80, 81, 84], "7215": 80, "7166": 80, "7126": 80, "7097": 80, "7062": [80, 83], "7052": [80, 83], "7028": 80, "7018": 80, "7006": 80, "6991": 80, "6974": 80, "6934": 80, "6913": 80, "6891": 80, "6852": 80, "6836": 80, "6822": 80, "6810": 80, "9333": [80, 81, 83], "9667": [80, 81, 83], "6784": 80, "6750": 80, "6731": 80, "6695": 80, "6679": 80, "9000": [80, 85], "6651": 80, "6623": 80, "6593": 80, "7500": [80, 81, 85], "6533": [80, 83], "6468": 80, "6455": 80, "6441": 80, "6429": 80, "6417": 80, "6405": 80, "6393": 80, "6382": 80, "6370": 80, "6358": 80, "6347": 80, "6336": 80, "6325": 80, "6314": 80, "6304": 80, "6294": 80, "6283": 80, "6273": 80, "6263": 80, "6253": [80, 83], "6244": 80, "6234": 80, "6225": 80, "6216": 80, "6207": 80, "6198": 80, "6189": 80, "6180": 80, "6172": 80, "6164": 80, "6155": 80, "6147": 80, "6139": 80, "6131": 80, "6124": 80, "6116": 80, "6108": 80, "6094": 80, "6086": 80, "6079": 80, "6072": 80, "6065": 80, "6058": 80, "6052": 80, "6045": 80, "6038": [80, 83], "6026": 80, "6019": 80, "6013": 80, "6007": [80, 81], "6001": 80, "5995": 80, "5989": 80, "5983": 80, "5977": 80, "5972": 80, "5966": 80, "5961": 80, "5955": 80, "5944": 80, "5939": 80, "5934": [80, 82], "5924": 80, "5919": 80, "5914": 80, "5909": 80, "5904": 80, "5899": 80, "5890": 80, "5885": 80, "5881": 80, "5876": 80, "5863": 80, "5859": 80, "5854": 80, "5846": 80, "5842": 80, "5838": 80, "5834": 80, "5830": 80, "5826": 80, "5822": 80, "5818": 80, "5814": 80, "5810": 80, "5806": 80, "5803": 80, "5799": 80, "5795": 80, "5792": 80, "5788": 80, "5785": [80, 83], "5781": 80, "5778": 80, "5774": 80, "5771": 80, "5768": 80, "5764": 80, "5761": 80, "5758": 80, "5755": 80, "5748": 80, "5742": [80, 83], "5739": 80, "5736": 80, "5733": 80, "5730": 80, "5727": 80, "5724": 80, "5721": [80, 85], "5718": 80, "5715": [80, 83], "5712": 80, "5709": 80, "5707": 80, "5704": 80, "5701": 80, "5698": 80, "5696": 80, "5693": [80, 85], "5690": 80, "5688": 80, "5685": 80, "5683": 80, "5678": 80, "5675": 80, "5673": 80, "5670": 80, "5668": [80, 83], "5665": 80, "5663": 80, "5660": 80, "5658": 80, "5656": 80, "5653": 80, "5651": 80, "5649": 80, "5647": [80, 83], "5644": 80, "5642": 80, "5640": 80, "5638": 80, "5635": 80, "la": 81, "r_": 81, "mathrm": 81, "leq": [81, 86], "feat_dim": 81, "arbitrari": 81, "choos": [81, 86], "dictionari": 81, "tha": 81, "arbitrarili": 81, "formul": 81, "quit": 81, "close": 81, "usual": 81, "suggest": 81, "refrain": 81, "tetrahedron": 81, "sparse_to_torch": 81, "rank_": 81, "coadjacency_matrix": 81, "h0": 81, "h1": 81, "h2": 81, "h3": 81, "b3": 81, "x_3": 81, "tetrahedron_feat": 81, "track": 81, "7267": 81, "7176": 81, "7089": 81, "6953": 81, "6906": 81, "6829": 81, "6789": 81, "6696": 81, "6538": 81, "4667": [81, 82, 84], "6437": [81, 83], "6392": 81, "6351": 81, "6286": 81, "6260": 81, "6238": 81, "6220": 81, "6203": [81, 85], "6188": 81, "6173": 81, "6158": 81, "6142": 81, "6125": 81, "6106": 81, "6084": 81, "6061": 81, "6035": 81, "5975": 81, "5942": 81, "5905": 81, "8667": [81, 85], "5860": 81, "5706": [81, 84], "5554": [81, 85], "5529": [81, 83], "5500": 81, "5448": [81, 83], "5443": 81, "5422": 81, "5390": [81, 83], "5368": 81, "5358": [81, 83], "5351": [81, 83], "5342": [81, 83], "5329": [81, 83], "5316": 81, "5305": 81, "5298": 81, "5292": 81, "5287": 81, "5283": 81, "5278": 81, "5274": 81, "5269": 81, "5264": 81, "5260": 81, "5256": 81, "5252": 81, "5249": 81, "5246": 81, "5244": 81, "5242": [81, 84], "5240": 81, "5238": 81, "5236": 81, "5235": 81, "5234": 81, "5232": 81, "5231": 81, "5230": 81, "5229": 81, "5228": 81, "5227": 81, "5226": 81, "5225": 81, "5224": 81, "5223": [81, 82], "5222": 81, "5221": 81, "5220": 81, "5219": 81, "5218": 81, "5217": 81, "5216": 81, "account": 82, "_t": [82, 85], "p_d": [82, 85], "p_u": [82, 85], "likewis": 82, "essenti": 82, "_0": 82, "yet": [82, 85], "laplacian_0_list": [82, 85], "laplacian_down_1_list": [82, 85], "laplacian_up_1_list": [82, 85], "laplacian_2_list": [82, 85], "hodge_laplacian_matrix": [82, 85], "out_channels_0": 82, "out_channels_1": 82, "out_channels_2": 82, "out_linear_0": 82, "out_linear_1": 82, "out_linear_2": 82, "0d": [82, 84], "nan": [82, 84], "two_dimensional_cells_mean": [82, 84], "nanmean": [82, 84, 85], "isnan": [82, 84, 85], "one_dimensional_cells_mean": [82, 84, 85], "zero_dimensional_cells_mean": [82, 84], "intermediate_channels_al": 82, "num_lay": [82, 85], "num": [82, 85], "size_averag": 82, "in_linear_0": 82, "in_linear_1": 82, "in_linear_2": 82, "_reduct": 82, "arg": [82, 83], "deprec": 82, "ret": 82, "laplacian_0_train": 82, "laplacian_0_test": 82, "laplacian_down_1_train": 82, "laplacian_down_1_test": 82, "laplacian_up_1_train": 82, "laplacian_up_1_test": 82, "laplacian_2_train": 82, "laplacian_2_test": 82, "399008": 82, "926": 82, "6080": 82, "477": 82, "8325": 82, "204": 82, "4115": 82, "299": 82, "4982": 82, "243": 82, "1712": 82, "202": 82, "5915": 82, "302": 82, "4839": 82, "9002": 82, "311": 82, "9497": 82, "laplacian_up_2": [82, 85], "get_simplicial_featur": [82, 85], "which_feat": [82, 85], "elif": [82, 85], "logit": [82, 86], "binary_cross_entropi": 82, "6788": 82, "6248": 82, "5903": 82, "5666": 82, "5496": 82, "5381": [82, 83], "5306": 82, "5257": 82, "5198": 82, "5182": 82, "5170": 82, "5162": 82, "5156": 82, "5151": 82, "5147": 82, "5144": 82, "5142": 82, "5140": 82, "5139": 82, "5138": 82, "5137": 82, "5136": 82, "5135": 82, "5134": 82, "5133": 82, "5132": 82, "5131": 82, "5130": 82, "5129": 82, "5128": 82, "5127": 82, "5126": 82, "5125": 82, "5124": 82, "5123": 82, "5122": 82, "5121": 82, "5120": 82, "5118": 82, "5116": 82, "5115": 82, "5113": 82, "5111": 82, "5109": 82, "5107": 82, "5105": 82, "5103": 82, "5099": 82, "5098": 82, "5096": 82, "5094": 82, "5092": 82, "5089": 82, "5085": 82, "5082": 82, "5078": 82, "5075": 82, "5071": 82, "5068": 82, "5064": 82, "5060": 82, "5056": 82, "5051": 82, "5046": 82, "5041": 82, "5037": 82, "5032": [82, 84], "5027": 82, "5022": 82, "5016": 82, "5011": 82, "5005": 82, "4994": 82, "4989": 82, "coo_matrix": 83, "diag": 83, "neigborood": 83, "ssconv": 83, "normalize_higher_order_adj": 83, "a_opt": 83, "cochain": 83, "num_of_k_simplic": 83, "num_of_j_simplic": 83, "rowsum": 83, "r_inv_sqrt": 83, "flatten": 83, "isinf": 83, "r_mat_inv_sqrt": 83, "a_opt_to": 83, "dot": 83, "incidence_1_0": 83, "coincidence_matrix": 83, "incidence_1_2": 83, "incidence_2_1": 83, "adjacency_1_up": 83, "adjacency_1_down": 83, "adjacency_2": 83, "linear_x0": 83, "linear_x1": 83, "linear_x2": 83, "7134": 83, "7132": 83, "7131": 83, "7128": 83, "7117": 83, "7113": 83, "7109": 83, "7086": 83, "7079": 83, "7030": 83, "7003": 83, "6988": 83, "6971": 83, "6954": 83, "6894": 83, "6849": 83, "6824": 83, "6799": 83, "6772": 83, "6716": 83, "6626": 83, "6596": 83, "6564": 83, "6469": 83, "6406": 83, "6374": 83, "6343": 83, "6313": 83, "6282": 83, "6223": 83, "6195": 83, "6167": 83, "6140": 83, "6113": 83, "6087": 83, "6062": 83, "6014": 83, "5991": 83, "5969": 83, "5948": 83, "5927": 83, "5907": 83, "5887": 83, "5869": 83, "5851": 83, "5833": 83, "5817": 83, "5801": 83, "5770": 83, "5756": 83, "5728": 83, "5703": 83, "5691": 83, "5679": [83, 85], "5657": 83, "5637": 83, "5627": 83, "5618": 83, "5609": 83, "5601": 83, "5592": [83, 85], "5584": [83, 85], "5577": 83, "5569": 83, "5562": [83, 85], "5555": [83, 85], "5542": [83, 85], "5535": 83, "5523": 83, "5518": 83, "5512": 83, "5507": 83, "5502": 83, "5497": 83, "5492": 83, "5487": 83, "5483": 83, "5478": 83, "5474": 83, "5470": 83, "5466": 83, "5462": 83, "5458": 83, "5455": 83, "5451": 83, "5444": 83, "5441": 83, "5438": 83, "5435": 83, "5432": [83, 84], "5426": 83, "5423": 83, "5421": 83, "5418": 83, "5416": 83, "5413": 83, "5411": 83, "5408": 83, "5406": 83, "5404": 83, "5402": 83, "5400": 83, "5398": 83, "5395": 83, "5393": 83, "5392": 83, "5388": 83, "5386": 83, "5384": 83, "5383": 83, "5379": 83, "5378": 83, "5376": 83, "5374": 83, "5373": 83, "5371": 83, "5370": 83, "5369": 83, "5367": 83, "5366": 83, "5364": 83, "5363": 83, "5362": 83, "5361": 83, "5359": 83, "5357": 83, "5356": 83, "5355": 83, "5354": 83, "5352": 83, "5350": 83, "5349": 83, "5348": 83, "5347": 83, "5346": 83, "5345": 83, "5344": [83, 84], "5343": 83, "5341": 83, "5340": 83, "5339": 83, "5338": 83, "5337": 83, "5336": 83, "5335": 83, "5334": 83, "5332": 83, "5331": 83, "5330": 83, "5328": 83, "5327": 83, "5326": 83, "5325": 83, "5324": 83, "5323": 83, "ysb22": 84, "ruochen": 84, "freder": 84, "razvan": 84, "pascanu": 84, "editor": 84, "confer": 84, "volum": 84, "pmlr": 84, "dec": 84, "2022a": 84, "chose": 84, "reshap": 84, "normalized_laplacian_matrix": 84, "lin_2": 84, "x_0s_train": 84, "x_0s_test": 84, "x_1s_train": 84, "x_1s_test": 84, "x_2s_train": 84, "x_2s_test": 84, "laplacian_0s_train": 84, "laplacian_0s_test": 84, "laplacian_1s_train": 84, "laplacian_1s_test": 84, "laplacian_2s_train": 84, "laplacian_2s_test": 84, "9616": 84, "0319": 84, "9816": 84, "9647": 84, "0454": 84, "2352": 84, "0969": 84, "4979": 84, "4806": 84, "7194": 84, "1580": 84, "5705": 84, "1465": 84, "0466": 84, "0446": 84, "5840": 84, "3278": 84, "2363": 84, "6831": 84, "5437": 84, "6770": 84, "6057": 84, "3240": 84, "4743": 84, "0289": 84, "6414": 84, "2671": 84, "8572": 84, "7918": 84, "1627": 84, "9490": 84, "8358": 84, "0702": 84, "5069": 84, "7774": 84, "2788": 84, "7978": 84, "3558": 84, "9096": 84, "2390": 84, "4291": 84, "3779": 84, "3256": 84, "9241": 84, "3715": 84, "1551": 84, "7596": 84, "3155": 84, "5445": 84, "3427": 84, "1711": 84, "1126": 84, "3567": 84, "5716": 84, "7865": 84, "4044": 84, "9258": 84, "7257": 84, "8615": 84, "6709": 84, "1890": 84, "6630": 84, "8225": 84, "8715": 84, "1793": 84, "7412": 84, "2721": 84, "6078": 84, "2701": 84, "6752": 84, "3450": 84, "4395": 84, "2776": 84, "0761": 84, "7860": 84, "9918": 84, "4742": 84, "2551": 84, "2153": 84, "0425": 84, "2843": 84, "9831": 84, "4091": 84, "9356": 84, "3874": 84, "4505": 84, "2496": 84, "6815": 84, "8954": 84, "0596": 84, "2672": 84, "1773": 84, "1011": 84, "0988": 84, "5479": 84, "7246": 84, "itself": 85, "larger": 85, "x_train": 85, "x_test": 85, "laplacian_down_train": 85, "laplacian_down_test": 85, "laplacian_up_train": 85, "laplacian_up_test": 85, "simplex_order_select": 85, "888": 85, "6446": 85, "8124": 85, "0982": 85, "9690": 85, "3029": 85, "9724": 85, "4266": 85, "1082": 85, "9618": 85, "3142": 85, "8797": 85, "maxim": 85, "chennel_edg": 85, "channel_fac": 85, "classm": 85, "channels_x": 85, "rm": 85, "7327": 85, "3000": 85, "7171": 85, "6984": 85, "6773": 85, "6590": 85, "6431": 85, "6288": 85, "6184": 85, "6100": 85, "6023": 85, "5951": 85, "5880": 85, "5796": 85, "5686": 85, "5669": 85, "5655": 85, "5639": 85, "5622": 85, "5605": 85, "5590": 85, "5603": 85, "5607": 85, "5594": 85, "5582": 85, "5579": 85, "5581": 85, "5576": 85, "5570": 85, "5565": 85, "5563": 85, "5564": 85, "5553": 85, "5552": 85, "5551": 85, "5549": 85, "5547": 85, "5546": 85, "5545": 85, "5544": 85, "5543": 85, "5541": 85, "5540": 85, "5539": 85, "5538": 85, "rgs21": 86, "spend": 86, "synthet": 86, "ahead": 86, "itertool": 86, "product": 86, "matplotlib": 86, "pyplot": 86, "plt": 86, "networkx": 86, "nx": 86, "spatial": 86, "distanc": 86, "random_split": 86, "lt": 86, "_c": 86, "0x13507d2d0": 86, "gt": 86, "less": 86, "cloud": 86, "insid": 86, "remov": 86, "centroid": 86, "argsort": 86, "tri": 86, "disk_cent": 86, "disk_radiu": 86, "indices_includ": 86, "cdist": 86, "idx_dict": 86, "instanc": 86, "shortest": 86, "visual": 86, "plot_complex": 86, "plot": 86, "plane": 86, "pt": 86, "poli": 86, "polygon": 86, "color": 86, "green": 86, "gca": 86, "add_patch": 86, "vstack": 86, "i_1": 86, "i_2": 86, "ldot": 86, "i_m": 86, "i_j": 86, "i_": 86, "supervis": 86, "setup": 86, "subsect": 86, "randomli": 86, "pick": 86, "triplet": 86, "around": 86, "anti": 86, "diagon": 86, "mid": 86, "region": 86, "start_nod": 86, "mid_nod": 86, "end_nod": 86, "all_triplet": 86, "increas": 86, "underli": 86, "distance_matrix": 86, "squareform": 86, "pdist": 86, "toarrai": 86, "from_numpy_arrai": 86, "path_1": 86, "shortest_path": 86, "path_2": 86, "1200": 86, "plot_path": 86, "red": 86, "arrow": 86, "quiver": 86, "scale_unit": 86, "yield": 86, "vectorized_trajectori": 86, "neigbors_mask": 86, "last_nod": 86, "turn": 86, "a_1": 86, "a_2": 86, "a_j": 86, "i_n": 86, "later": 86, "lookup": 86, "speed": 86, "edge_lookup_t": 86, "discard": 86, "neighbors_mask": 86, "c0": 86, "loader": 86, "val_siz": 86, "train_siz": 86, "train_d": 86, "val_d": 86, "test_d": 86, "train_dl": 86, "val_dl": 86, "test_dl": 86, "c_1": 86, "partial_1": 86, "c_0": 86, "That": 86, "hat": 86, "_m": 86, "init": 86, "xavier_uniform_": 86, "inf": 86, "log_softmax": 86, "likelihood": 86, "penal": 86, "weight_decai": 86, "5e": 86, "loss_funct": 86, "nllloss": 86, "nll": 86, "training_histori": 86, "training_loss": 86, "traj": 86, "squeez": 86, "04": 86, "05": 86, "06": 86, "07": 86, "quick": 86, "confirm": 86, "everyth": 86, "reason": 86, "ax": 86, "subplot": 86, "ncol": 86, "figsiz": 86, "set_titl": 86, "legend": 86, "better": 86, "guess": 86, "3f": 86, "600": 86, "constructor": 86, "affect": 86, "capabl": 86, "revers": 86, "Or": 86, "ocean": 86, "drifter": 86}, "objects": {"topomodelx.base": [[0, 0, 0, "-", "aggregation"], [1, 0, 0, "-", "conv"], [3, 0, 0, "-", "message_passing"]], "topomodelx.base.aggregation": [[0, 1, 1, "", "Aggregation"]], "topomodelx.base.aggregation.Aggregation": [[0, 2, 1, "", "forward"], [0, 2, 1, "", "update"]], "topomodelx.base.conv": [[1, 1, 1, "", "Conv"]], "topomodelx.base.conv.Conv": [[1, 2, 1, "", "forward"], [1, 2, 1, "", "update"]], "topomodelx.base.message_passing": [[3, 1, 1, "", "MessagePassing"]], "topomodelx.base.message_passing.MessagePassing": [[3, 2, 1, "", "aggregate"], [3, 2, 1, "", "attention"], [3, 2, 1, "", "forward"], [3, 2, 1, "", "message"], [3, 2, 1, "", "reset_parameters"]], "topomodelx.nn.cell": [[5, 0, 0, "-", "can"], [6, 0, 0, "-", "can_layer"], [7, 0, 0, "-", "ccxn"], [8, 0, 0, "-", "ccxn_layer"], [9, 0, 0, "-", "cwn"], [10, 0, 0, "-", "cwn_layer"]], "topomodelx.nn.cell.can": [[5, 1, 1, "", "CAN"]], "topomodelx.nn.cell.can.CAN": [[5, 2, 1, "", "forward"]], "topomodelx.nn.cell.can_layer": [[6, 1, 1, "", "CANLayer"], [6, 1, 1, "", "LiftLayer"], [6, 1, 1, "", "MultiHeadCellAttention"], [6, 1, 1, "", "MultiHeadCellAttention_v2"], [6, 1, 1, "", "MultiHeadLiftLayer"], [6, 1, 1, "", "PoolLayer"], [6, 3, 1, "", "add_self_loops"], [6, 3, 1, "", "softmax"]], "topomodelx.nn.cell.can_layer.CANLayer": [[6, 2, 1, "", "forward"], [6, 2, 1, "", "reset_parameters"]], "topomodelx.nn.cell.can_layer.LiftLayer": [[6, 2, 1, "", "forward"], [6, 2, 1, "", "message"], [6, 2, 1, "", "reset_parameters"]], "topomodelx.nn.cell.can_layer.MultiHeadCellAttention": [[6, 2, 1, "", "attention"], [6, 2, 1, "", "forward"], [6, 2, 1, "", "message"], [6, 2, 1, "", "reset_parameters"]], "topomodelx.nn.cell.can_layer.MultiHeadCellAttention_v2": [[6, 2, 1, "", "attention"], [6, 2, 1, "", "forward"], [6, 2, 1, "", "message"], [6, 2, 1, "", "reset_parameters"]], "topomodelx.nn.cell.can_layer.MultiHeadLiftLayer": [[6, 2, 1, "", "forward"], [6, 2, 1, "", "reset_parameters"]], "topomodelx.nn.cell.can_layer.PoolLayer": [[6, 2, 1, "", "forward"], [6, 2, 1, "", "reset_parameters"]], "topomodelx.nn.cell.ccxn": [[7, 1, 1, "", "CCXN"]], "topomodelx.nn.cell.ccxn.CCXN": [[7, 2, 1, "", "forward"]], "topomodelx.nn.cell.ccxn_layer": [[8, 1, 1, "", "CCXNLayer"]], "topomodelx.nn.cell.ccxn_layer.CCXNLayer": [[8, 2, 1, "", "forward"]], "topomodelx.nn.cell.cwn": [[9, 1, 1, "", "CWN"]], "topomodelx.nn.cell.cwn.CWN": [[9, 2, 1, "", "forward"]], "topomodelx.nn.cell.cwn_layer": [[10, 1, 1, "", "CWNLayer"]], "topomodelx.nn.cell.cwn_layer.CWNLayer": [[10, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph": [[12, 0, 0, "-", "allset"], [13, 0, 0, "-", "allset_layer"], [14, 0, 0, "-", "allset_transformer"], [15, 0, 0, "-", "allset_transformer_layer"], [18, 0, 0, "-", "hmpnn"], [19, 0, 0, "-", "hmpnn_layer"], [20, 0, 0, "-", "hnhn"], [21, 0, 0, "-", "hnhn_layer"], [23, 0, 0, "-", "hypergat"], [24, 0, 0, "-", "hypergat_layer"], [25, 0, 0, "-", "hypersage"], [26, 0, 0, "-", "hypersage_layer"], [28, 0, 0, "-", "unigcn"], [29, 0, 0, "-", "unigcn_layer"], [30, 0, 0, "-", "unigcnii"], [31, 0, 0, "-", "unigcnii_layer"], [32, 0, 0, "-", "unigin"], [33, 0, 0, "-", "unigin_layer"], [34, 0, 0, "-", "unisage"], [35, 0, 0, "-", "unisage_layer"]], "topomodelx.nn.hypergraph.allset": [[12, 1, 1, "", "AllSet"]], "topomodelx.nn.hypergraph.allset.AllSet": [[12, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.allset_layer": [[13, 1, 1, "", "AllSetBlock"], [13, 1, 1, "", "AllSetLayer"], [13, 1, 1, "", "MLP"]], "topomodelx.nn.hypergraph.allset_layer.AllSetBlock": [[13, 2, 1, "", "forward"], [13, 2, 1, "", "reset_parameters"]], "topomodelx.nn.hypergraph.allset_layer.AllSetLayer": [[13, 2, 1, "", "forward"], [13, 2, 1, "", "reset_parameters"]], "topomodelx.nn.hypergraph.allset_transformer": [[14, 1, 1, "", "AllSetTransformer"]], "topomodelx.nn.hypergraph.allset_transformer.AllSetTransformer": [[14, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.allset_transformer_layer": [[15, 1, 1, "", "AllSetTransformerBlock"], [15, 1, 1, "", "AllSetTransformerLayer"], [15, 1, 1, "", "MLP"], [15, 1, 1, "", "MultiHeadAttention"]], "topomodelx.nn.hypergraph.allset_transformer_layer.AllSetTransformerBlock": [[15, 2, 1, "", "forward"], [15, 2, 1, "", "reset_parameters"]], "topomodelx.nn.hypergraph.allset_transformer_layer.AllSetTransformerLayer": [[15, 2, 1, "", "forward"], [15, 2, 1, "", "reset_parameters"]], "topomodelx.nn.hypergraph.allset_transformer_layer.MultiHeadAttention": [[15, 2, 1, "", "attention"], [15, 2, 1, "", "forward"], [15, 2, 1, "", "reset_parameters"]], "topomodelx.nn.hypergraph.hmpnn": [[18, 1, 1, "", "HMPNN"]], "topomodelx.nn.hypergraph.hmpnn.HMPNN": [[18, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.hmpnn_layer": [[19, 1, 1, "", "HMPNNLayer"]], "topomodelx.nn.hypergraph.hmpnn_layer.HMPNNLayer": [[19, 2, 1, "", "apply_regular_dropout"], [19, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.hnhn": [[20, 1, 1, "", "HNHN"]], "topomodelx.nn.hypergraph.hnhn.HNHN": [[20, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.hnhn_layer": [[21, 1, 1, "", "HNHNLayer"]], "topomodelx.nn.hypergraph.hnhn_layer.HNHNLayer": [[21, 2, 1, "", "compute_normalization_matrices"], [21, 2, 1, "", "forward"], [21, 2, 1, "", "init_biases"], [21, 2, 1, "", "normalize_incidence_matrices"], [21, 2, 1, "", "reset_parameters"]], "topomodelx.nn.hypergraph.hypergat": [[23, 1, 1, "", "HyperGAT"]], "topomodelx.nn.hypergraph.hypergat.HyperGAT": [[23, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.hypergat_layer": [[24, 1, 1, "", "HyperGATLayer"]], "topomodelx.nn.hypergraph.hypergat_layer.HyperGATLayer": [[24, 2, 1, "", "attention"], [24, 2, 1, "", "forward"], [24, 2, 1, "", "reset_parameters"], [24, 2, 1, "", "update"]], "topomodelx.nn.hypergraph.hypersage": [[25, 1, 1, "", "HyperSAGE"]], "topomodelx.nn.hypergraph.hypersage.HyperSAGE": [[25, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.hypersage_layer": [[26, 1, 1, "", "GeneralizedMean"], [26, 1, 1, "", "HyperSAGELayer"]], "topomodelx.nn.hypergraph.hypersage_layer.GeneralizedMean": [[26, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.hypersage_layer.HyperSAGELayer": [[26, 2, 1, "", "aggregate"], [26, 2, 1, "", "forward"], [26, 2, 1, "", "update"]], "topomodelx.nn.hypergraph.unigcn": [[28, 1, 1, "", "UniGCN"]], "topomodelx.nn.hypergraph.unigcn.UniGCN": [[28, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.unigcn_layer": [[29, 1, 1, "", "UniGCNLayer"]], "topomodelx.nn.hypergraph.unigcn_layer.UniGCNLayer": [[29, 2, 1, "", "forward"], [29, 2, 1, "", "reset_parameters"]], "topomodelx.nn.hypergraph.unigcnii": [[30, 1, 1, "", "UniGCNII"]], "topomodelx.nn.hypergraph.unigcnii.UniGCNII": [[30, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.unigcnii_layer": [[31, 1, 1, "", "UniGCNIILayer"]], "topomodelx.nn.hypergraph.unigcnii_layer.UniGCNIILayer": [[31, 2, 1, "", "forward"], [31, 2, 1, "", "reset_parameters"]], "topomodelx.nn.hypergraph.unigin": [[32, 1, 1, "", "UniGIN"]], "topomodelx.nn.hypergraph.unigin.UniGIN": [[32, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.unigin_layer": [[33, 1, 1, "", "UniGINLayer"]], "topomodelx.nn.hypergraph.unigin_layer.UniGINLayer": [[33, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.unisage": [[34, 1, 1, "", "UniSAGE"]], "topomodelx.nn.hypergraph.unisage.UniSAGE": [[34, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.unisage_layer": [[35, 1, 1, "", "UniSAGELayer"]], "topomodelx.nn.hypergraph.unisage_layer.UniSAGELayer": [[35, 2, 1, "", "forward"], [35, 2, 1, "", "reset_parameters"]], "topomodelx.nn.simplicial": [[37, 0, 0, "-", "dist2cycle"], [38, 0, 0, "-", "dist2cycle_layer"], [39, 0, 0, "-", "hsn"], [40, 0, 0, "-", "hsn_layer"], [42, 0, 0, "-", "san"], [43, 0, 0, "-", "san_layer"], [44, 0, 0, "-", "sca_cmps"], [45, 0, 0, "-", "sca_cmps_layer"], [46, 0, 0, "-", "sccn"], [47, 0, 0, "-", "sccn_layer"], [48, 0, 0, "-", "sccnn"], [49, 0, 0, "-", "sccnn_layer"], [50, 0, 0, "-", "scconv"], [51, 0, 0, "-", "scconv_layer"], [52, 0, 0, "-", "scn2"], [53, 0, 0, "-", "scn2_layer"], [54, 0, 0, "-", "scnn"], [55, 0, 0, "-", "scnn_layer"], [56, 0, 0, "-", "scone"], [57, 0, 0, "-", "scone_layer"]], "topomodelx.nn.simplicial.dist2cycle": [[37, 1, 1, "", "Dist2Cycle"]], "topomodelx.nn.simplicial.dist2cycle.Dist2Cycle": [[37, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.dist2cycle_layer": [[38, 1, 1, "", "Dist2CycleLayer"]], "topomodelx.nn.simplicial.dist2cycle_layer.Dist2CycleLayer": [[38, 2, 1, "", "forward"], [38, 2, 1, "", "reset_parameters"]], "topomodelx.nn.simplicial.hsn": [[39, 1, 1, "", "HSN"]], "topomodelx.nn.simplicial.hsn.HSN": [[39, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.hsn_layer": [[40, 1, 1, "", "HSNLayer"]], "topomodelx.nn.simplicial.hsn_layer.HSNLayer": [[40, 2, 1, "", "forward"], [40, 2, 1, "", "reset_parameters"]], "topomodelx.nn.simplicial.san": [[42, 1, 1, "", "SAN"]], "topomodelx.nn.simplicial.san.SAN": [[42, 2, 1, "", "compute_projection_matrix"], [42, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.san_layer": [[43, 1, 1, "", "SANConv"], [43, 1, 1, "", "SANLayer"]], "topomodelx.nn.simplicial.san_layer.SANConv": [[43, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.san_layer.SANLayer": [[43, 2, 1, "", "forward"], [43, 2, 1, "", "reset_parameters"]], "topomodelx.nn.simplicial.sca_cmps": [[44, 1, 1, "", "SCACMPS"]], "topomodelx.nn.simplicial.sca_cmps.SCACMPS": [[44, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.sca_cmps_layer": [[45, 1, 1, "", "SCACMPSLayer"]], "topomodelx.nn.simplicial.sca_cmps_layer.SCACMPSLayer": [[45, 2, 1, "", "forward"], [45, 2, 1, "", "intra_aggr"], [45, 2, 1, "", "reset_parameters"], [45, 2, 1, "", "weight_func"]], "topomodelx.nn.simplicial.sccn": [[46, 1, 1, "", "SCCN"]], "topomodelx.nn.simplicial.sccn.SCCN": [[46, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.sccn_layer": [[47, 1, 1, "", "SCCNLayer"]], "topomodelx.nn.simplicial.sccn_layer.SCCNLayer": [[47, 2, 1, "", "forward"], [47, 2, 1, "", "reset_parameters"]], "topomodelx.nn.simplicial.sccnn": [[48, 1, 1, "", "SCCNN"]], "topomodelx.nn.simplicial.sccnn.SCCNN": [[48, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.sccnn_layer": [[49, 1, 1, "", "SCCNNLayer"]], "topomodelx.nn.simplicial.sccnn_layer.SCCNNLayer": [[49, 2, 1, "", "aggr_norm_func"], [49, 2, 1, "", "chebyshev_conv"], [49, 2, 1, "", "forward"], [49, 2, 1, "", "reset_parameters"], [49, 2, 1, "", "update"]], "topomodelx.nn.simplicial.scconv": [[50, 1, 1, "", "SCConv"]], "topomodelx.nn.simplicial.scconv.SCConv": [[50, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.scconv_layer": [[51, 1, 1, "", "SCConvLayer"]], "topomodelx.nn.simplicial.scconv_layer.SCConvLayer": [[51, 2, 1, "", "forward"], [51, 2, 1, "", "reset_parameters"]], "topomodelx.nn.simplicial.scn2": [[52, 1, 1, "", "SCN2"]], "topomodelx.nn.simplicial.scn2.SCN2": [[52, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.scn2_layer": [[53, 1, 1, "", "SCN2Layer"]], "topomodelx.nn.simplicial.scn2_layer.SCN2Layer": [[53, 2, 1, "", "forward"], [53, 2, 1, "", "reset_parameters"]], "topomodelx.nn.simplicial.scnn": [[54, 1, 1, "", "SCNN"]], "topomodelx.nn.simplicial.scnn.SCNN": [[54, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.scnn_layer": [[55, 1, 1, "", "SCNNLayer"]], "topomodelx.nn.simplicial.scnn_layer.SCNNLayer": [[55, 2, 1, "", "aggr_norm_func"], [55, 2, 1, "", "chebyshev_conv"], [55, 2, 1, "", "forward"], [55, 2, 1, "", "reset_parameters"], [55, 2, 1, "", "update"]], "topomodelx.nn.simplicial.scone": [[56, 1, 1, "", "SCoNe"], [56, 1, 1, "", "TrajectoriesDataset"], [56, 3, 1, "", "generate_complex"], [56, 3, 1, "", "generate_trajectories"]], "topomodelx.nn.simplicial.scone.SCoNe": [[56, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.scone.TrajectoriesDataset": [[56, 2, 1, "", "vectorize_path"]], "topomodelx.nn.simplicial.scone_layer": [[57, 1, 1, "", "SCoNeLayer"]], "topomodelx.nn.simplicial.scone_layer.SCoNeLayer": [[57, 2, 1, "", "forward"], [57, 2, 1, "", "reset_parameters"]], "topomodelx.utils": [[58, 0, 0, "-", "scatter"]], "topomodelx.utils.scatter": [[58, 3, 1, "", "broadcast"], [58, 3, 1, "", "scatter"], [58, 3, 1, "", "scatter_add"], [58, 3, 1, "", "scatter_mean"], [58, 3, 1, "", "scatter_sum"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"]}, "titleterms": {"aggreg": 0, "conv": 1, "base": 2, "messag": [3, 69, 80], "pass": [3, 69, 80], "api": 4, "refer": [4, 61, 84], "packag": 4, "modul": 4, "can": [5, 62], "can_lay": 6, "ccxn": [7, 63], "ccxn_layer": 8, "cwn": [9, 64], "cwn_layer": 10, "cell": [11, 62, 63], "allset": 12, "allset_lay": 13, "allset_transform": 14, "allset_transformer_lay": 15, "dhgcn": [16, 68], "dhgcn_layer": 17, "hmpnn": [18, 69], "hmpnn_layer": 19, "hnhn": [20, 70], "hnhn_layer": 21, "hnhn_layer_bi": 22, "hypergat": 23, "hypergat_lay": 24, "hypersag": [25, 72], "hypersage_lay": 26, "hypergraph": [27, 68, 69, 70, 71, 74, 76, 87], "unigcn": [28, 73], "unigcn_lay": 29, "unigcnii": [30, 74], "unigcnii_lay": 31, "neural": [36, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87], "network": [36, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "simplici": [41, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87], "util": 58, "icml": 59, "2023": 59, "topolog": [59, 87], "deep": 59, "learn": 59, "challeng": 59, "descript": 59, "public": 59, "outcom": 59, "particip": 59, "deadlin": 59, "how": 59, "submit": 59, "guidelin": 59, "submiss": 59, "requir": 59, "evalu": [59, 86], "question": 59, "contribut": 60, "make": 60, "chang": 60, "write": 60, "test": [60, 85, 86], "run": 60, "document": 60, "intro": 60, "docstr": 60, "The": [60, 62, 63, 64, 65, 79], "anatomi": 60, "exampl": 60, "topomodelx": 61, "tmx": 61, "get": 61, "start": 61, "train": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "attent": [62, 63, 65, 79], "abstract": [62, 79], "task": [62, 63, 64, 65, 79], "set": [62, 63, 64, 65, 66, 67], "up": [62, 63, 64, 65], "pre": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "process": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "creat": [62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "convolut": [63, 81, 82, 83, 84, 85], "complex": [63, 65, 80, 81, 82, 83, 85, 86, 87], "cw": 64, "combinatori": 65, "mesh": 65, "classif": [65, 82, 85], "import": [65, 68, 70, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85], "data": [65, 68, 70, 71, 73, 74, 75, 76, 86], "an": [66, 67], "all": [66, 67], "tnn": [66, 67, 68, 72, 73, 75, 76], "addit": [66, 67, 72], "theoret": [66, 67, 72], "clarif": [66, 67, 72], "transform": 67, "defin": [68, 70, 71, 74, 76, 77, 78, 80, 81, 82, 83, 84, 85], "neighborhood": [68, 70, 71, 74, 76, 77, 78, 80, 81, 82, 84, 85], "structur": [68, 70, 71, 74, 76, 77, 78, 80, 81, 83, 84], "lift": [68, 70, 71, 74, 76], "domain": [68, 70, 71, 74, 76], "hyperedg": 70, "neuron": 70, "us": 74, "layer": 74, "unigin": 75, "uni": 76, "sage": 76, "homologi": 77, "local": 77, "dist2cycl": 77, "dataset": [77, 78, 80, 81, 82, 83, 84, 85, 86], "signal": [77, 78, 80, 81, 82, 83, 85], "binari": [77, 78, 80, 81, 82, 83, 85], "label": [77, 78, 80, 81, 82, 83, 85], "featur": 77, "high": 78, "skip": 78, "hsn": 78, "san": 79, "autoencod": 80, "sca": 80, "coadjac": 80, "scheme": 80, "cmp": 80, "sccn": 81, "sccnn": 82, "we": [82, 85], "model": [82, 85, 86], "perform": [82, 85], "1": [82, 85], "shrec": 82, "strcture": [82, 85], "2": [82, 83, 84, 85], "node": [82, 85], "scconv": 83, "neighbourhood": 83, "simplex": 84, "scn": 84, "rank": 84, "scnn": 85, "karat": 85, "weight": 85, "hodg": 85, "laplacian": 85, "prepar": 85, "split": 85, "net": [86, 87], "scone": 86, "tabl": 86, "content": 86, "gener": 86, "trajectori": 86, "pytorch": 86, "dataload": 86, "suggest": 86, "further": 86, "experiment": 86, "tutori": 87, "cellular": 87}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinx": 60}, "alltitles": {"Aggregation": [[0, "module-topomodelx.base.aggregation"]], "Conv": [[1, "module-topomodelx.base.conv"]], "Base": [[2, "base"]], "Message Passing": [[3, "module-topomodelx.base.message_passing"]], "API Reference": [[4, "api-reference"]], "Packages & Modules": [[4, null]], "CAN": [[5, "module-topomodelx.nn.cell.can"]], "Can_Layer": [[6, "module-topomodelx.nn.cell.can_layer"]], "CCXN": [[7, "module-topomodelx.nn.cell.ccxn"]], "CCXN_Layer": [[8, "module-topomodelx.nn.cell.ccxn_layer"]], "CWN": [[9, "module-topomodelx.nn.cell.cwn"]], "Cwn_Layer": [[10, "module-topomodelx.nn.cell.cwn_layer"]], "Cell": [[11, "cell"]], "AllSet": [[12, "module-topomodelx.nn.hypergraph.allset"]], "AllSet_Layer": [[13, "module-topomodelx.nn.hypergraph.allset_layer"]], "AllSet_Transformer": [[14, "module-topomodelx.nn.hypergraph.allset_transformer"]], "AllSet_Transformer_Layer": [[15, "module-topomodelx.nn.hypergraph.allset_transformer_layer"]], "DHGCN": [[16, "dhgcn"]], "DHGCN_Layer": [[17, "dhgcn-layer"]], "HMPNN": [[18, "module-topomodelx.nn.hypergraph.hmpnn"]], "HMPNN_Layer": [[19, "module-topomodelx.nn.hypergraph.hmpnn_layer"]], "HNHN": [[20, "module-topomodelx.nn.hypergraph.hnhn"]], "HNHN_Layer": [[21, "module-topomodelx.nn.hypergraph.hnhn_layer"]], "HNHN_Layer_Bis": [[22, "hnhn-layer-bis"]], "Hypergat": [[23, "module-topomodelx.nn.hypergraph.hypergat"]], "Hypergat_Layer": [[24, "module-topomodelx.nn.hypergraph.hypergat_layer"]], "Hypersage": [[25, "module-topomodelx.nn.hypergraph.hypersage"]], "Hypersage_Layer": [[26, "module-topomodelx.nn.hypergraph.hypersage_layer"]], "Hypergraph": [[27, "hypergraph"]], "Unigcn": [[28, "module-topomodelx.nn.hypergraph.unigcn"]], "Unigcn_Layer": [[29, "module-topomodelx.nn.hypergraph.unigcn_layer"]], "Unigcnii": [[30, "module-topomodelx.nn.hypergraph.unigcnii"]], "Unigcnii_Layer": [[31, "module-topomodelx.nn.hypergraph.unigcnii_layer"]], "Neural Networks": [[36, "neural-networks"]], "Simplicial": [[41, "simplicial"]], "Utils": [[58, "utils"]], "ICML 2023 Topological Deep Learning Challenge": [[59, "icml-2023-topological-deep-learning-challenge"]], "Description of the Challenge": [[59, "description-of-the-challenge"]], "\u2b50\ufe0f Publication Outcomes for Participants \u2b50\ufe0f": [[59, "publication-outcomes-for-participants"]], "Deadline": [[59, "deadline"]], "How to Submit": [[59, "how-to-submit"]], "Guidelines": [[59, "guidelines"]], "Submission Requirements": [[59, "submission-requirements"]], "Evaluation": [[59, "evaluation"]], "Questions": [[59, "questions"]], "Contributing": [[60, "contributing"]], "Making Changes": [[60, "making-changes"]], "Write Tests": [[60, "write-tests"]], "Run Tests": [[60, "run-tests"]], "Write Documentation": [[60, "write-documentation"]], "Intro to Docstrings": [[60, "intro-to-docstrings"]], "The Anatomy of a Docstring": [[60, "the-anatomy-of-a-docstring"]], "Docstring Examples": [[60, "docstring-examples"]], "\ud83c\udf10 TopoModelX (TMX) \ud83c\udf69": [[61, "topomodelx-tmx"]], "\ud83d\udd0d References": [[61, "references"]], "\ud83e\uddbe Getting Started": [[61, "getting-started"]], "Train a Cell Attention Network (CAN)": [[62, "Train-a-Cell-Attention-Network-(CAN)"]], "Abstract:": [[62, "Abstract:"]], "The Neural Network:": [[62, "The-Neural-Network:"], [63, "The-Neural-Network:"], [64, "The-Neural-Network:"], [65, "The-Neural-Network:"]], "The Task:": [[62, "The-Task:"], [63, "The-Task:"], [64, "The-Task:"], [65, "The-Task:"], [79, "The-Task:"]], "Set-up": [[62, "Set-up"], [63, "Set-up"], [64, "Set-up"], [65, "Set-up"]], "Pre-processing": [[62, "Pre-processing"], [63, "Pre-processing"], [64, "Pre-processing"], [65, "Pre-processing"], [66, "Pre-processing"], [67, "Pre-processing"], [68, "Pre-processing"], [69, "Pre-processing"], [70, "Pre-processing"], [71, "Pre-processing"], [72, "Pre-processing"], [73, "Pre-processing"], [74, "Pre-processing"], [75, "Pre-processing"], [76, "Pre-processing"], [77, "Pre-processing"], [78, "Pre-processing"], [79, "Pre-processing"], [80, "Pre-processing"], [81, "Pre-processing"], [82, "Pre-processing"], [83, "Pre-processing"], [84, "Pre-processing"], [85, "Pre-processing"]], "Create the Neural Network": [[62, "Create-the-Neural-Network"], [63, "Create-the-Neural-Network"], [64, "Create-the-Neural-Network"], [65, "Create-the-Neural-Network"], [66, "Create-the-Neural-Network"], [67, "Create-the-Neural-Network"], [68, "Create-the-Neural-Network"], [70, "Create-the-Neural-Network"], [72, "Create-the-Neural-Network"], [73, "Create-the-Neural-Network"], [75, "Create-the-Neural-Network"], [76, "Create-the-Neural-Network"], [77, "Create-the-Neural-Network"], [78, "Create-the-Neural-Network"], [79, "Create-the-Neural-Network"], [81, "Create-the-Neural-Network"], [83, "Create-the-Neural-Network"]], "Train the Neural Network": [[62, "Train-the-Neural-Network"], [63, "Train-the-Neural-Network"], [64, "Train-the-Neural-Network"], [65, "Train-the-Neural-Network"], [66, "Train-the-Neural-Network"], [67, "Train-the-Neural-Network"], [68, "Train-the-Neural-Network"], [69, "Train-the-Neural-Network"], [70, "Train-the-Neural-Network"], [71, "Train-the-Neural-Network"], [72, "Train-the-Neural-Network"], [73, "Train-the-Neural-Network"], [75, "Train-the-Neural-Network"], [76, "Train-the-Neural-Network"], [77, "Train-the-Neural-Network"], [78, "Train-the-Neural-Network"], [79, "Train-the-Neural-Network"], [80, "Train-the-Neural-Network"], [81, "Train-the-Neural-Network"], [83, "Train-the-Neural-Network"], [84, "Train-the-Neural-Network"], [85, "Train-the-Neural-Network"]], "Train a Convolutional Cell Complex Network (CCXN)": [[63, "Train-a-Convolutional-Cell-Complex-Network-(CCXN)"]], "Train the Neural Network with Attention": [[63, "Train-the-Neural-Network-with-Attention"]], "Train a CW Network (CWN)": [[64, "Train-a-CW-Network-(CWN)"]], "Train a Combinatorial Complex Attention Neural Network for Mesh Classification.": [[65, "Train-a-Combinatorial-Complex-Attention-Neural-Network-for-Mesh-Classification."]], "Import data": [[65, "Import-data"], [68, "Import-data"], [70, "Import-data"], [71, "Import-data"], [73, "Import-data"], [74, "Import-data"], [75, "Import-data"], [76, "Import-data"]], "Train an All-Set TNN": [[66, "Train-an-All-Set-TNN"]], "Additional theoretical clarifications": [[66, "Additional-theoretical-clarifications"], [67, "Additional-theoretical-clarifications"], [72, "Additional-theoretical-clarifications"]], "Train an All-Set-Transformer TNN": [[67, "Train-an-All-Set-Transformer-TNN"]], "Train a DHGCN TNN": [[68, "Train-a-DHGCN-TNN"]], "Define neighborhood structures and lift into hypergraph domain.": [[68, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."], [70, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."], [71, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."], [74, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."], [76, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."]], "Train a Hypergraph Message Passing Neural Network (HMPNN)": [[69, "Train-a-Hypergraph-Message-Passing-Neural-Network-(HMPNN)"]], "Train a Hypergraph Networks with Hyperedge Neurons (HNHN)": [[70, "Train-a-Hypergraph-Networks-with-Hyperedge-Neurons-(HNHN)"]], "Train a Hypergraph Neural Network": [[71, "Train-a-Hypergraph-Neural-Network"]], "Train a Hypersage TNN": [[72, "Train-a-Hypersage-TNN"]], "Train a UNIGCN TNN": [[73, "Train-a-UNIGCN-TNN"]], "Train a hypergraph neural network using UniGCNII layers": [[74, "Train-a-hypergraph-neural-network-using-UniGCNII-layers"]], "Creating a neural network": [[74, "Creating-a-neural-network"]], "Training the neural network": [[74, "Training-the-neural-network"]], "Train a UNIGIN TNN": [[75, "Train-a-UNIGIN-TNN"]], "Train a Uni-sage TNN": [[76, "Train-a-Uni-sage-TNN"]], "Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)": [[77, "Train-a-Simplicial-Neural-Network-for-Homology-Localization-(Dist2Cycle)"]], "Import dataset": [[77, "Import-dataset"], [78, "Import-dataset"], [80, "Import-dataset"], [81, "Import-dataset"], [83, "Import-dataset"], [84, "Import-dataset"]], "Define neighborhood structures.": [[77, "Define-neighborhood-structures."], [78, "Define-neighborhood-structures."], [80, "Define-neighborhood-structures."], [81, "Define-neighborhood-structures."], [84, "Define-neighborhood-structures."]], "Import signal": [[77, "Import-signal"], [78, "Import-signal"], [80, "Import-signal"], [81, "Import-signal"], [82, "Import-signal"], [83, "Import-signal"]], "Define binary labels": [[77, "Define-binary-labels"], [78, "Define-binary-labels"], [80, "Define-binary-labels"], [81, "Define-binary-labels"], [82, "Define-binary-labels"], [83, "Define-binary-labels"]], "Create Features": [[77, "Create-Features"]], "Train a Simplicial High-Skip Network (HSN)": [[78, "Train-a-Simplicial-High-Skip-Network-(HSN)"]], "Train a Simplicial Attention Network (SAN)": [[79, "Train-a-Simplicial-Attention-Network-(SAN)"]], "Abstract": [[79, "Abstract"]], "The Neural Network": [[79, "The-Neural-Network"]], "Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)": [[80, "Train-a-Simplicial-Complex-Autoencoder-(SCA)-with-Coadjacency-Message-Passing-Scheme-(CMPS)"]], "Coadjacency Message Passing Scheme (CMPS):": [[80, "Coadjacency-Message-Passing-Scheme-(CMPS):"]], "Create the Neural Networks": [[80, "Create-the-Neural-Networks"]], "Train a Simplicial Complex Convolutional Network (SCCN)": [[81, "Train-a-Simplicial-Complex-Convolutional-Network-(SCCN)"]], "Train a SCCNN": [[82, "Train-a-SCCNN"]], "We train the model to perform:": [[82, "We-train-the-model-to-perform:"], [85, "We-train-the-model-to-perform:"]], "Simplicial Complex Convolutional Neural Networks [SCCNN]": [[82, "Simplicial-Complex-Convolutional-Neural-Networks-[SCCNN]"]], "1. Complex Classification": [[82, "1.-Complex-Classification"], [85, "1.-Complex-Classification"]], "Import shrec dataset": [[82, "Import-shrec-dataset"]], "Define Neighborhood Strctures": [[82, "Define-Neighborhood-Strctures"], [82, "id1"], [85, "Define-Neighborhood-Strctures"], [85, "id1"]], "Create and Train the Neural Network": [[82, "Create-and-Train-the-Neural-Network"], [82, "id2"]], "2. Node Classification": [[82, "2.-Node-Classification"], [85, "2.-Node-Classification"]], "Train a Simplicial 2-complex convolutional neural network (SCConv)": [[83, "Train-a-Simplicial-2-complex-convolutional-neural-network-(SCConv)"]], "Define Neighbourhood Structures": [[83, "Define-Neighbourhood-Structures"]], "Train a Simplex Convolutional Network (SCN) of Rank 2": [[84, "Train-a-Simplex-Convolutional-Network-(SCN)-of-Rank-2"]], "References": [[84, "References"]], "Train a Simplicial Convolutional Neural Network (SCNN)": [[85, "Train-a-Simplicial-Convolutional-Neural-Network-(SCNN)"]], "Simplicial Convolutional Neural Networks [SCNN]": [[85, "Simplicial-Convolutional-Neural-Networks-[SCNN]"]], "Import Karate dataset": [[85, "Import-Karate-dataset"]], "Weighted Hodge Laplacians": [[85, "Weighted-Hodge-Laplacians"]], "Import signals": [[85, "Import-signals"]], "Define binary labels and Prepare the training-testing split": [[85, "Define-binary-labels-and-Prepare-the-training-testing-split"]], "Create the SCNN for node classification": [[85, "Create-the-SCNN-for-node-classification"]], "Train the SCNN": [[85, "Train-the-SCNN"]], "Train a Simplicial Complex Net (SCoNe)": [[86, "Train-a-Simplicial-Complex-Net-(SCoNe)"]], "Table of contents": [[86, "Table-of-contents"]], "Dataset generation": [[86, "Dataset-generation"]], "Generating trajectories": [[86, "Generating-trajectories"]], "Creating PyTorch dataloaders": [[86, "Creating-PyTorch-dataloaders"]], "Creating the Neural Network": [[86, "Creating-the-Neural-Network"]], "Training the Neural Network": [[86, "Training-the-Neural-Network"]], "Evaluating the model on test data": [[86, "Evaluating-the-model-on-test-data"]], "Suggestions for further experimentation": [[86, "Suggestions-for-further-experimentation"]], "Tutorials": [[87, "tutorials"]], "Topological Neural Nets on Cellular Complexes": [[87, "topological-neural-nets-on-cellular-complexes"]], "Topological Neural Nets on Hypergraphs": [[87, "topological-neural-nets-on-hypergraphs"]], "Topological Neural Nets on Simplicial Complexes": [[87, "topological-neural-nets-on-simplicial-complexes"]]}, "indexentries": {"aggregation (class in topomodelx.base.aggregation)": [[0, "topomodelx.base.aggregation.Aggregation"]], "forward() (topomodelx.base.aggregation.aggregation method)": [[0, "topomodelx.base.aggregation.Aggregation.forward"]], "module": [[0, "module-topomodelx.base.aggregation"], [1, "module-topomodelx.base.conv"], [3, "module-topomodelx.base.message_passing"], [5, "module-topomodelx.nn.cell.can"], [6, "module-topomodelx.nn.cell.can_layer"], [7, "module-topomodelx.nn.cell.ccxn"], [8, "module-topomodelx.nn.cell.ccxn_layer"], [9, "module-topomodelx.nn.cell.cwn"], [10, "module-topomodelx.nn.cell.cwn_layer"], [12, "module-topomodelx.nn.hypergraph.allset"], [13, "module-topomodelx.nn.hypergraph.allset_layer"], [14, "module-topomodelx.nn.hypergraph.allset_transformer"], [15, "module-topomodelx.nn.hypergraph.allset_transformer_layer"], [18, "module-topomodelx.nn.hypergraph.hmpnn"], [19, "module-topomodelx.nn.hypergraph.hmpnn_layer"], [20, "module-topomodelx.nn.hypergraph.hnhn"], [21, "module-topomodelx.nn.hypergraph.hnhn_layer"], [23, "module-topomodelx.nn.hypergraph.hypergat"], [24, "module-topomodelx.nn.hypergraph.hypergat_layer"], [25, "module-topomodelx.nn.hypergraph.hypersage"], [26, "module-topomodelx.nn.hypergraph.hypersage_layer"], [28, "module-topomodelx.nn.hypergraph.unigcn"], [29, "module-topomodelx.nn.hypergraph.unigcn_layer"], [30, "module-topomodelx.nn.hypergraph.unigcnii"], [31, "module-topomodelx.nn.hypergraph.unigcnii_layer"], [32, "module-topomodelx.nn.hypergraph.unigin"], [33, "module-topomodelx.nn.hypergraph.unigin_layer"], [34, "module-topomodelx.nn.hypergraph.unisage"], [35, "module-topomodelx.nn.hypergraph.unisage_layer"], [37, "module-topomodelx.nn.simplicial.dist2cycle"], [38, "module-topomodelx.nn.simplicial.dist2cycle_layer"], [39, "module-topomodelx.nn.simplicial.hsn"], [40, "module-topomodelx.nn.simplicial.hsn_layer"], [42, "module-topomodelx.nn.simplicial.san"], [43, "module-topomodelx.nn.simplicial.san_layer"], [44, "module-topomodelx.nn.simplicial.sca_cmps"], [45, "module-topomodelx.nn.simplicial.sca_cmps_layer"], [46, "module-topomodelx.nn.simplicial.sccn"], [47, "module-topomodelx.nn.simplicial.sccn_layer"], [48, "module-topomodelx.nn.simplicial.sccnn"], [49, "module-topomodelx.nn.simplicial.sccnn_layer"], [50, "module-topomodelx.nn.simplicial.scconv"], [51, "module-topomodelx.nn.simplicial.scconv_layer"], [52, "module-topomodelx.nn.simplicial.scn2"], [53, "module-topomodelx.nn.simplicial.scn2_layer"], [54, "module-topomodelx.nn.simplicial.scnn"], [55, "module-topomodelx.nn.simplicial.scnn_layer"], [56, "module-topomodelx.nn.simplicial.scone"], [57, "module-topomodelx.nn.simplicial.scone_layer"], [58, "module-topomodelx.utils.scatter"]], "topomodelx.base.aggregation": [[0, "module-topomodelx.base.aggregation"]], "update() (topomodelx.base.aggregation.aggregation method)": [[0, "topomodelx.base.aggregation.Aggregation.update"]], "conv (class in topomodelx.base.conv)": [[1, "topomodelx.base.conv.Conv"]], "forward() (topomodelx.base.conv.conv method)": [[1, "topomodelx.base.conv.Conv.forward"]], "topomodelx.base.conv": [[1, "module-topomodelx.base.conv"]], "update() (topomodelx.base.conv.conv method)": [[1, "topomodelx.base.conv.Conv.update"]], "messagepassing (class in topomodelx.base.message_passing)": [[3, "topomodelx.base.message_passing.MessagePassing"]], "aggregate() (topomodelx.base.message_passing.messagepassing method)": [[3, "topomodelx.base.message_passing.MessagePassing.aggregate"]], "attention() (topomodelx.base.message_passing.messagepassing method)": [[3, "topomodelx.base.message_passing.MessagePassing.attention"]], "forward() (topomodelx.base.message_passing.messagepassing method)": [[3, "topomodelx.base.message_passing.MessagePassing.forward"]], "message() (topomodelx.base.message_passing.messagepassing method)": [[3, "topomodelx.base.message_passing.MessagePassing.message"]], "reset_parameters() (topomodelx.base.message_passing.messagepassing method)": [[3, "topomodelx.base.message_passing.MessagePassing.reset_parameters"]], "topomodelx.base.message_passing": [[3, "module-topomodelx.base.message_passing"]], "can (class in topomodelx.nn.cell.can)": [[5, "topomodelx.nn.cell.can.CAN"]], "forward() (topomodelx.nn.cell.can.can method)": [[5, "topomodelx.nn.cell.can.CAN.forward"]], "topomodelx.nn.cell.can": [[5, "module-topomodelx.nn.cell.can"]], "canlayer (class in topomodelx.nn.cell.can_layer)": [[6, "topomodelx.nn.cell.can_layer.CANLayer"]], "liftlayer (class in topomodelx.nn.cell.can_layer)": [[6, "topomodelx.nn.cell.can_layer.LiftLayer"]], "multiheadcellattention (class in topomodelx.nn.cell.can_layer)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention"]], "multiheadcellattention_v2 (class in topomodelx.nn.cell.can_layer)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention_v2"]], "multiheadliftlayer (class in topomodelx.nn.cell.can_layer)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadLiftLayer"]], "poollayer (class in topomodelx.nn.cell.can_layer)": [[6, "topomodelx.nn.cell.can_layer.PoolLayer"]], "add_self_loops() (in module topomodelx.nn.cell.can_layer)": [[6, "topomodelx.nn.cell.can_layer.add_self_loops"]], "attention() (topomodelx.nn.cell.can_layer.multiheadcellattention method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention.attention"]], "attention() (topomodelx.nn.cell.can_layer.multiheadcellattention_v2 method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention_v2.attention"]], "forward() (topomodelx.nn.cell.can_layer.canlayer method)": [[6, "topomodelx.nn.cell.can_layer.CANLayer.forward"]], "forward() (topomodelx.nn.cell.can_layer.liftlayer method)": [[6, "topomodelx.nn.cell.can_layer.LiftLayer.forward"]], "forward() (topomodelx.nn.cell.can_layer.multiheadcellattention method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention.forward"]], "forward() (topomodelx.nn.cell.can_layer.multiheadcellattention_v2 method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention_v2.forward"]], "forward() (topomodelx.nn.cell.can_layer.multiheadliftlayer method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadLiftLayer.forward"]], "forward() (topomodelx.nn.cell.can_layer.poollayer method)": [[6, "topomodelx.nn.cell.can_layer.PoolLayer.forward"]], "message() (topomodelx.nn.cell.can_layer.liftlayer method)": [[6, "topomodelx.nn.cell.can_layer.LiftLayer.message"]], "message() (topomodelx.nn.cell.can_layer.multiheadcellattention method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention.message"]], "message() (topomodelx.nn.cell.can_layer.multiheadcellattention_v2 method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention_v2.message"]], "reset_parameters() (topomodelx.nn.cell.can_layer.canlayer method)": [[6, "topomodelx.nn.cell.can_layer.CANLayer.reset_parameters"]], "reset_parameters() (topomodelx.nn.cell.can_layer.liftlayer method)": [[6, "topomodelx.nn.cell.can_layer.LiftLayer.reset_parameters"]], "reset_parameters() (topomodelx.nn.cell.can_layer.multiheadcellattention method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention.reset_parameters"]], "reset_parameters() (topomodelx.nn.cell.can_layer.multiheadcellattention_v2 method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention_v2.reset_parameters"]], "reset_parameters() (topomodelx.nn.cell.can_layer.multiheadliftlayer method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadLiftLayer.reset_parameters"]], "reset_parameters() (topomodelx.nn.cell.can_layer.poollayer method)": [[6, "topomodelx.nn.cell.can_layer.PoolLayer.reset_parameters"]], "softmax() (in module topomodelx.nn.cell.can_layer)": [[6, "topomodelx.nn.cell.can_layer.softmax"]], "topomodelx.nn.cell.can_layer": [[6, "module-topomodelx.nn.cell.can_layer"]], "ccxn (class in topomodelx.nn.cell.ccxn)": [[7, "topomodelx.nn.cell.ccxn.CCXN"]], "forward() (topomodelx.nn.cell.ccxn.ccxn method)": [[7, "topomodelx.nn.cell.ccxn.CCXN.forward"]], "topomodelx.nn.cell.ccxn": [[7, "module-topomodelx.nn.cell.ccxn"]], "ccxnlayer (class in topomodelx.nn.cell.ccxn_layer)": [[8, "topomodelx.nn.cell.ccxn_layer.CCXNLayer"]], "forward() (topomodelx.nn.cell.ccxn_layer.ccxnlayer method)": [[8, "topomodelx.nn.cell.ccxn_layer.CCXNLayer.forward"]], "topomodelx.nn.cell.ccxn_layer": [[8, "module-topomodelx.nn.cell.ccxn_layer"]], "cwn (class in topomodelx.nn.cell.cwn)": [[9, "topomodelx.nn.cell.cwn.CWN"]], "forward() (topomodelx.nn.cell.cwn.cwn method)": [[9, "topomodelx.nn.cell.cwn.CWN.forward"]], "topomodelx.nn.cell.cwn": [[9, "module-topomodelx.nn.cell.cwn"]], "cwnlayer (class in topomodelx.nn.cell.cwn_layer)": [[10, "topomodelx.nn.cell.cwn_layer.CWNLayer"]], "forward() (topomodelx.nn.cell.cwn_layer.cwnlayer method)": [[10, "topomodelx.nn.cell.cwn_layer.CWNLayer.forward"]], "topomodelx.nn.cell.cwn_layer": [[10, "module-topomodelx.nn.cell.cwn_layer"]], "allset (class in topomodelx.nn.hypergraph.allset)": [[12, "topomodelx.nn.hypergraph.allset.AllSet"]], "forward() (topomodelx.nn.hypergraph.allset.allset method)": [[12, "topomodelx.nn.hypergraph.allset.AllSet.forward"]], "topomodelx.nn.hypergraph.allset": [[12, "module-topomodelx.nn.hypergraph.allset"]], "allsetblock (class in topomodelx.nn.hypergraph.allset_layer)": [[13, "topomodelx.nn.hypergraph.allset_layer.AllSetBlock"]], "allsetlayer (class in topomodelx.nn.hypergraph.allset_layer)": [[13, "topomodelx.nn.hypergraph.allset_layer.AllSetLayer"]], "mlp (class in topomodelx.nn.hypergraph.allset_layer)": [[13, "topomodelx.nn.hypergraph.allset_layer.MLP"]], "forward() (topomodelx.nn.hypergraph.allset_layer.allsetblock method)": [[13, "topomodelx.nn.hypergraph.allset_layer.AllSetBlock.forward"]], "forward() (topomodelx.nn.hypergraph.allset_layer.allsetlayer method)": [[13, "topomodelx.nn.hypergraph.allset_layer.AllSetLayer.forward"]], "reset_parameters() (topomodelx.nn.hypergraph.allset_layer.allsetblock method)": [[13, "topomodelx.nn.hypergraph.allset_layer.AllSetBlock.reset_parameters"]], "reset_parameters() (topomodelx.nn.hypergraph.allset_layer.allsetlayer method)": [[13, "topomodelx.nn.hypergraph.allset_layer.AllSetLayer.reset_parameters"]], "topomodelx.nn.hypergraph.allset_layer": [[13, "module-topomodelx.nn.hypergraph.allset_layer"]], "allsettransformer (class in topomodelx.nn.hypergraph.allset_transformer)": [[14, "topomodelx.nn.hypergraph.allset_transformer.AllSetTransformer"]], "forward() (topomodelx.nn.hypergraph.allset_transformer.allsettransformer method)": [[14, "topomodelx.nn.hypergraph.allset_transformer.AllSetTransformer.forward"]], "topomodelx.nn.hypergraph.allset_transformer": [[14, "module-topomodelx.nn.hypergraph.allset_transformer"]], "allsettransformerblock (class in topomodelx.nn.hypergraph.allset_transformer_layer)": [[15, "topomodelx.nn.hypergraph.allset_transformer_layer.AllSetTransformerBlock"]], "allsettransformerlayer (class in topomodelx.nn.hypergraph.allset_transformer_layer)": [[15, "topomodelx.nn.hypergraph.allset_transformer_layer.AllSetTransformerLayer"]], "mlp (class in topomodelx.nn.hypergraph.allset_transformer_layer)": [[15, "topomodelx.nn.hypergraph.allset_transformer_layer.MLP"]], "multiheadattention (class in topomodelx.nn.hypergraph.allset_transformer_layer)": [[15, "topomodelx.nn.hypergraph.allset_transformer_layer.MultiHeadAttention"]], "attention() (topomodelx.nn.hypergraph.allset_transformer_layer.multiheadattention method)": [[15, "topomodelx.nn.hypergraph.allset_transformer_layer.MultiHeadAttention.attention"]], "forward() (topomodelx.nn.hypergraph.allset_transformer_layer.allsettransformerblock method)": [[15, "topomodelx.nn.hypergraph.allset_transformer_layer.AllSetTransformerBlock.forward"]], "forward() (topomodelx.nn.hypergraph.allset_transformer_layer.allsettransformerlayer method)": [[15, "topomodelx.nn.hypergraph.allset_transformer_layer.AllSetTransformerLayer.forward"]], "forward() (topomodelx.nn.hypergraph.allset_transformer_layer.multiheadattention method)": [[15, "topomodelx.nn.hypergraph.allset_transformer_layer.MultiHeadAttention.forward"]], "reset_parameters() (topomodelx.nn.hypergraph.allset_transformer_layer.allsettransformerblock method)": [[15, "topomodelx.nn.hypergraph.allset_transformer_layer.AllSetTransformerBlock.reset_parameters"]], "reset_parameters() (topomodelx.nn.hypergraph.allset_transformer_layer.allsettransformerlayer method)": [[15, "topomodelx.nn.hypergraph.allset_transformer_layer.AllSetTransformerLayer.reset_parameters"]], "reset_parameters() (topomodelx.nn.hypergraph.allset_transformer_layer.multiheadattention method)": [[15, "topomodelx.nn.hypergraph.allset_transformer_layer.MultiHeadAttention.reset_parameters"]], "topomodelx.nn.hypergraph.allset_transformer_layer": [[15, "module-topomodelx.nn.hypergraph.allset_transformer_layer"]], "hmpnn (class in topomodelx.nn.hypergraph.hmpnn)": [[18, "topomodelx.nn.hypergraph.hmpnn.HMPNN"]], "forward() (topomodelx.nn.hypergraph.hmpnn.hmpnn method)": [[18, "topomodelx.nn.hypergraph.hmpnn.HMPNN.forward"]], "topomodelx.nn.hypergraph.hmpnn": [[18, "module-topomodelx.nn.hypergraph.hmpnn"]], "hmpnnlayer (class in topomodelx.nn.hypergraph.hmpnn_layer)": [[19, "topomodelx.nn.hypergraph.hmpnn_layer.HMPNNLayer"]], "apply_regular_dropout() (topomodelx.nn.hypergraph.hmpnn_layer.hmpnnlayer method)": [[19, "topomodelx.nn.hypergraph.hmpnn_layer.HMPNNLayer.apply_regular_dropout"]], "forward() (topomodelx.nn.hypergraph.hmpnn_layer.hmpnnlayer method)": [[19, "topomodelx.nn.hypergraph.hmpnn_layer.HMPNNLayer.forward"]], "topomodelx.nn.hypergraph.hmpnn_layer": [[19, "module-topomodelx.nn.hypergraph.hmpnn_layer"]], "hnhn (class in topomodelx.nn.hypergraph.hnhn)": [[20, "topomodelx.nn.hypergraph.hnhn.HNHN"]], "forward() (topomodelx.nn.hypergraph.hnhn.hnhn method)": [[20, "topomodelx.nn.hypergraph.hnhn.HNHN.forward"]], "topomodelx.nn.hypergraph.hnhn": [[20, "module-topomodelx.nn.hypergraph.hnhn"]], "hnhnlayer (class in topomodelx.nn.hypergraph.hnhn_layer)": [[21, "topomodelx.nn.hypergraph.hnhn_layer.HNHNLayer"]], "compute_normalization_matrices() (topomodelx.nn.hypergraph.hnhn_layer.hnhnlayer method)": [[21, "topomodelx.nn.hypergraph.hnhn_layer.HNHNLayer.compute_normalization_matrices"]], "forward() (topomodelx.nn.hypergraph.hnhn_layer.hnhnlayer method)": [[21, "topomodelx.nn.hypergraph.hnhn_layer.HNHNLayer.forward"]], "init_biases() (topomodelx.nn.hypergraph.hnhn_layer.hnhnlayer method)": [[21, "topomodelx.nn.hypergraph.hnhn_layer.HNHNLayer.init_biases"]], "normalize_incidence_matrices() (topomodelx.nn.hypergraph.hnhn_layer.hnhnlayer method)": [[21, "topomodelx.nn.hypergraph.hnhn_layer.HNHNLayer.normalize_incidence_matrices"]], "reset_parameters() (topomodelx.nn.hypergraph.hnhn_layer.hnhnlayer method)": [[21, "topomodelx.nn.hypergraph.hnhn_layer.HNHNLayer.reset_parameters"]], "topomodelx.nn.hypergraph.hnhn_layer": [[21, "module-topomodelx.nn.hypergraph.hnhn_layer"]], "hypergat (class in topomodelx.nn.hypergraph.hypergat)": [[23, "topomodelx.nn.hypergraph.hypergat.HyperGAT"]], "forward() (topomodelx.nn.hypergraph.hypergat.hypergat method)": [[23, "topomodelx.nn.hypergraph.hypergat.HyperGAT.forward"]], "topomodelx.nn.hypergraph.hypergat": [[23, "module-topomodelx.nn.hypergraph.hypergat"]], "hypergatlayer (class in topomodelx.nn.hypergraph.hypergat_layer)": [[24, "topomodelx.nn.hypergraph.hypergat_layer.HyperGATLayer"]], "attention() (topomodelx.nn.hypergraph.hypergat_layer.hypergatlayer method)": [[24, "topomodelx.nn.hypergraph.hypergat_layer.HyperGATLayer.attention"]], "forward() (topomodelx.nn.hypergraph.hypergat_layer.hypergatlayer method)": [[24, "topomodelx.nn.hypergraph.hypergat_layer.HyperGATLayer.forward"]], "reset_parameters() (topomodelx.nn.hypergraph.hypergat_layer.hypergatlayer method)": [[24, "topomodelx.nn.hypergraph.hypergat_layer.HyperGATLayer.reset_parameters"]], "topomodelx.nn.hypergraph.hypergat_layer": [[24, "module-topomodelx.nn.hypergraph.hypergat_layer"]], "update() (topomodelx.nn.hypergraph.hypergat_layer.hypergatlayer method)": [[24, "topomodelx.nn.hypergraph.hypergat_layer.HyperGATLayer.update"]], "hypersage (class in topomodelx.nn.hypergraph.hypersage)": [[25, "topomodelx.nn.hypergraph.hypersage.HyperSAGE"]], "forward() (topomodelx.nn.hypergraph.hypersage.hypersage method)": [[25, "topomodelx.nn.hypergraph.hypersage.HyperSAGE.forward"]], "topomodelx.nn.hypergraph.hypersage": [[25, "module-topomodelx.nn.hypergraph.hypersage"]], "generalizedmean (class in topomodelx.nn.hypergraph.hypersage_layer)": [[26, "topomodelx.nn.hypergraph.hypersage_layer.GeneralizedMean"]], "hypersagelayer (class in topomodelx.nn.hypergraph.hypersage_layer)": [[26, "topomodelx.nn.hypergraph.hypersage_layer.HyperSAGELayer"]], "aggregate() (topomodelx.nn.hypergraph.hypersage_layer.hypersagelayer method)": [[26, "topomodelx.nn.hypergraph.hypersage_layer.HyperSAGELayer.aggregate"]], "forward() (topomodelx.nn.hypergraph.hypersage_layer.generalizedmean method)": [[26, "topomodelx.nn.hypergraph.hypersage_layer.GeneralizedMean.forward"]], "forward() (topomodelx.nn.hypergraph.hypersage_layer.hypersagelayer method)": [[26, "topomodelx.nn.hypergraph.hypersage_layer.HyperSAGELayer.forward"]], "topomodelx.nn.hypergraph.hypersage_layer": [[26, "module-topomodelx.nn.hypergraph.hypersage_layer"]], "update() (topomodelx.nn.hypergraph.hypersage_layer.hypersagelayer method)": [[26, "topomodelx.nn.hypergraph.hypersage_layer.HyperSAGELayer.update"]], "unigcn (class in topomodelx.nn.hypergraph.unigcn)": [[28, "topomodelx.nn.hypergraph.unigcn.UniGCN"]], "forward() (topomodelx.nn.hypergraph.unigcn.unigcn method)": [[28, "topomodelx.nn.hypergraph.unigcn.UniGCN.forward"]], "topomodelx.nn.hypergraph.unigcn": [[28, "module-topomodelx.nn.hypergraph.unigcn"]], "unigcnlayer (class in topomodelx.nn.hypergraph.unigcn_layer)": [[29, "topomodelx.nn.hypergraph.unigcn_layer.UniGCNLayer"]], "forward() (topomodelx.nn.hypergraph.unigcn_layer.unigcnlayer method)": [[29, "topomodelx.nn.hypergraph.unigcn_layer.UniGCNLayer.forward"]], "reset_parameters() (topomodelx.nn.hypergraph.unigcn_layer.unigcnlayer method)": [[29, "topomodelx.nn.hypergraph.unigcn_layer.UniGCNLayer.reset_parameters"]], "topomodelx.nn.hypergraph.unigcn_layer": [[29, "module-topomodelx.nn.hypergraph.unigcn_layer"]], "unigcnii (class in topomodelx.nn.hypergraph.unigcnii)": [[30, "topomodelx.nn.hypergraph.unigcnii.UniGCNII"]], "forward() (topomodelx.nn.hypergraph.unigcnii.unigcnii method)": [[30, "topomodelx.nn.hypergraph.unigcnii.UniGCNII.forward"]], "topomodelx.nn.hypergraph.unigcnii": [[30, "module-topomodelx.nn.hypergraph.unigcnii"]], "unigcniilayer (class in topomodelx.nn.hypergraph.unigcnii_layer)": [[31, "topomodelx.nn.hypergraph.unigcnii_layer.UniGCNIILayer"]], "forward() (topomodelx.nn.hypergraph.unigcnii_layer.unigcniilayer method)": [[31, "topomodelx.nn.hypergraph.unigcnii_layer.UniGCNIILayer.forward"]], "reset_parameters() (topomodelx.nn.hypergraph.unigcnii_layer.unigcniilayer method)": [[31, "topomodelx.nn.hypergraph.unigcnii_layer.UniGCNIILayer.reset_parameters"]], "topomodelx.nn.hypergraph.unigcnii_layer": [[31, "module-topomodelx.nn.hypergraph.unigcnii_layer"]], "unigin (class in topomodelx.nn.hypergraph.unigin)": [[32, "topomodelx.nn.hypergraph.unigin.UniGIN"]], "forward() (topomodelx.nn.hypergraph.unigin.unigin method)": [[32, "topomodelx.nn.hypergraph.unigin.UniGIN.forward"]], "topomodelx.nn.hypergraph.unigin": [[32, "module-topomodelx.nn.hypergraph.unigin"]], "uniginlayer (class in topomodelx.nn.hypergraph.unigin_layer)": [[33, "topomodelx.nn.hypergraph.unigin_layer.UniGINLayer"]], "forward() (topomodelx.nn.hypergraph.unigin_layer.uniginlayer method)": [[33, "topomodelx.nn.hypergraph.unigin_layer.UniGINLayer.forward"]], "topomodelx.nn.hypergraph.unigin_layer": [[33, "module-topomodelx.nn.hypergraph.unigin_layer"]], "unisage (class in topomodelx.nn.hypergraph.unisage)": [[34, "topomodelx.nn.hypergraph.unisage.UniSAGE"]], "forward() (topomodelx.nn.hypergraph.unisage.unisage method)": [[34, "topomodelx.nn.hypergraph.unisage.UniSAGE.forward"]], "topomodelx.nn.hypergraph.unisage": [[34, "module-topomodelx.nn.hypergraph.unisage"]], "unisagelayer (class in topomodelx.nn.hypergraph.unisage_layer)": [[35, "topomodelx.nn.hypergraph.unisage_layer.UniSAGELayer"]], "forward() (topomodelx.nn.hypergraph.unisage_layer.unisagelayer method)": [[35, "topomodelx.nn.hypergraph.unisage_layer.UniSAGELayer.forward"]], "reset_parameters() (topomodelx.nn.hypergraph.unisage_layer.unisagelayer method)": [[35, "topomodelx.nn.hypergraph.unisage_layer.UniSAGELayer.reset_parameters"]], "topomodelx.nn.hypergraph.unisage_layer": [[35, "module-topomodelx.nn.hypergraph.unisage_layer"]], "dist2cycle (class in topomodelx.nn.simplicial.dist2cycle)": [[37, "topomodelx.nn.simplicial.dist2cycle.Dist2Cycle"]], "forward() (topomodelx.nn.simplicial.dist2cycle.dist2cycle method)": [[37, "topomodelx.nn.simplicial.dist2cycle.Dist2Cycle.forward"]], "topomodelx.nn.simplicial.dist2cycle": [[37, "module-topomodelx.nn.simplicial.dist2cycle"]], "dist2cyclelayer (class in topomodelx.nn.simplicial.dist2cycle_layer)": [[38, "topomodelx.nn.simplicial.dist2cycle_layer.Dist2CycleLayer"]], "forward() (topomodelx.nn.simplicial.dist2cycle_layer.dist2cyclelayer method)": [[38, "topomodelx.nn.simplicial.dist2cycle_layer.Dist2CycleLayer.forward"]], "reset_parameters() (topomodelx.nn.simplicial.dist2cycle_layer.dist2cyclelayer method)": [[38, "topomodelx.nn.simplicial.dist2cycle_layer.Dist2CycleLayer.reset_parameters"]], "topomodelx.nn.simplicial.dist2cycle_layer": [[38, "module-topomodelx.nn.simplicial.dist2cycle_layer"]], "hsn (class in topomodelx.nn.simplicial.hsn)": [[39, "topomodelx.nn.simplicial.hsn.HSN"]], "forward() (topomodelx.nn.simplicial.hsn.hsn method)": [[39, "topomodelx.nn.simplicial.hsn.HSN.forward"]], "topomodelx.nn.simplicial.hsn": [[39, "module-topomodelx.nn.simplicial.hsn"]], "hsnlayer (class in topomodelx.nn.simplicial.hsn_layer)": [[40, "topomodelx.nn.simplicial.hsn_layer.HSNLayer"]], "forward() (topomodelx.nn.simplicial.hsn_layer.hsnlayer method)": [[40, "topomodelx.nn.simplicial.hsn_layer.HSNLayer.forward"]], "reset_parameters() (topomodelx.nn.simplicial.hsn_layer.hsnlayer method)": [[40, "topomodelx.nn.simplicial.hsn_layer.HSNLayer.reset_parameters"]], "topomodelx.nn.simplicial.hsn_layer": [[40, "module-topomodelx.nn.simplicial.hsn_layer"]], "san (class in topomodelx.nn.simplicial.san)": [[42, "topomodelx.nn.simplicial.san.SAN"]], "compute_projection_matrix() (topomodelx.nn.simplicial.san.san method)": [[42, "topomodelx.nn.simplicial.san.SAN.compute_projection_matrix"]], "forward() (topomodelx.nn.simplicial.san.san method)": [[42, "topomodelx.nn.simplicial.san.SAN.forward"]], "topomodelx.nn.simplicial.san": [[42, "module-topomodelx.nn.simplicial.san"]], "sanconv (class in topomodelx.nn.simplicial.san_layer)": [[43, "topomodelx.nn.simplicial.san_layer.SANConv"]], "sanlayer (class in topomodelx.nn.simplicial.san_layer)": [[43, "topomodelx.nn.simplicial.san_layer.SANLayer"]], "forward() (topomodelx.nn.simplicial.san_layer.sanconv method)": [[43, "topomodelx.nn.simplicial.san_layer.SANConv.forward"]], "forward() (topomodelx.nn.simplicial.san_layer.sanlayer method)": [[43, "topomodelx.nn.simplicial.san_layer.SANLayer.forward"]], "reset_parameters() (topomodelx.nn.simplicial.san_layer.sanlayer method)": [[43, "topomodelx.nn.simplicial.san_layer.SANLayer.reset_parameters"]], "topomodelx.nn.simplicial.san_layer": [[43, "module-topomodelx.nn.simplicial.san_layer"]], "scacmps (class in topomodelx.nn.simplicial.sca_cmps)": [[44, "topomodelx.nn.simplicial.sca_cmps.SCACMPS"]], "forward() (topomodelx.nn.simplicial.sca_cmps.scacmps method)": [[44, "topomodelx.nn.simplicial.sca_cmps.SCACMPS.forward"]], "topomodelx.nn.simplicial.sca_cmps": [[44, "module-topomodelx.nn.simplicial.sca_cmps"]], "scacmpslayer (class in topomodelx.nn.simplicial.sca_cmps_layer)": [[45, "topomodelx.nn.simplicial.sca_cmps_layer.SCACMPSLayer"]], "forward() (topomodelx.nn.simplicial.sca_cmps_layer.scacmpslayer method)": [[45, "topomodelx.nn.simplicial.sca_cmps_layer.SCACMPSLayer.forward"]], "intra_aggr() (topomodelx.nn.simplicial.sca_cmps_layer.scacmpslayer method)": [[45, "topomodelx.nn.simplicial.sca_cmps_layer.SCACMPSLayer.intra_aggr"]], "reset_parameters() (topomodelx.nn.simplicial.sca_cmps_layer.scacmpslayer method)": [[45, "topomodelx.nn.simplicial.sca_cmps_layer.SCACMPSLayer.reset_parameters"]], "topomodelx.nn.simplicial.sca_cmps_layer": [[45, "module-topomodelx.nn.simplicial.sca_cmps_layer"]], "weight_func() (topomodelx.nn.simplicial.sca_cmps_layer.scacmpslayer method)": [[45, "topomodelx.nn.simplicial.sca_cmps_layer.SCACMPSLayer.weight_func"]], "sccn (class in topomodelx.nn.simplicial.sccn)": [[46, "topomodelx.nn.simplicial.sccn.SCCN"]], "forward() (topomodelx.nn.simplicial.sccn.sccn method)": [[46, "topomodelx.nn.simplicial.sccn.SCCN.forward"]], "topomodelx.nn.simplicial.sccn": [[46, "module-topomodelx.nn.simplicial.sccn"]], "sccnlayer (class in topomodelx.nn.simplicial.sccn_layer)": [[47, "topomodelx.nn.simplicial.sccn_layer.SCCNLayer"]], "forward() (topomodelx.nn.simplicial.sccn_layer.sccnlayer method)": [[47, "topomodelx.nn.simplicial.sccn_layer.SCCNLayer.forward"]], "reset_parameters() (topomodelx.nn.simplicial.sccn_layer.sccnlayer method)": [[47, "topomodelx.nn.simplicial.sccn_layer.SCCNLayer.reset_parameters"]], "topomodelx.nn.simplicial.sccn_layer": [[47, "module-topomodelx.nn.simplicial.sccn_layer"]], "sccnn (class in topomodelx.nn.simplicial.sccnn)": [[48, "topomodelx.nn.simplicial.sccnn.SCCNN"]], "forward() (topomodelx.nn.simplicial.sccnn.sccnn method)": [[48, "topomodelx.nn.simplicial.sccnn.SCCNN.forward"]], "topomodelx.nn.simplicial.sccnn": [[48, "module-topomodelx.nn.simplicial.sccnn"]], "sccnnlayer (class in topomodelx.nn.simplicial.sccnn_layer)": [[49, "topomodelx.nn.simplicial.sccnn_layer.SCCNNLayer"]], "aggr_norm_func() (topomodelx.nn.simplicial.sccnn_layer.sccnnlayer method)": [[49, "topomodelx.nn.simplicial.sccnn_layer.SCCNNLayer.aggr_norm_func"]], "chebyshev_conv() (topomodelx.nn.simplicial.sccnn_layer.sccnnlayer method)": [[49, "topomodelx.nn.simplicial.sccnn_layer.SCCNNLayer.chebyshev_conv"]], "forward() (topomodelx.nn.simplicial.sccnn_layer.sccnnlayer method)": [[49, "topomodelx.nn.simplicial.sccnn_layer.SCCNNLayer.forward"]], "reset_parameters() (topomodelx.nn.simplicial.sccnn_layer.sccnnlayer method)": [[49, "topomodelx.nn.simplicial.sccnn_layer.SCCNNLayer.reset_parameters"]], "topomodelx.nn.simplicial.sccnn_layer": [[49, "module-topomodelx.nn.simplicial.sccnn_layer"]], "update() (topomodelx.nn.simplicial.sccnn_layer.sccnnlayer method)": [[49, "topomodelx.nn.simplicial.sccnn_layer.SCCNNLayer.update"]], "scconv (class in topomodelx.nn.simplicial.scconv)": [[50, "topomodelx.nn.simplicial.scconv.SCConv"]], "forward() (topomodelx.nn.simplicial.scconv.scconv method)": [[50, "topomodelx.nn.simplicial.scconv.SCConv.forward"]], "topomodelx.nn.simplicial.scconv": [[50, "module-topomodelx.nn.simplicial.scconv"]], "scconvlayer (class in topomodelx.nn.simplicial.scconv_layer)": [[51, "topomodelx.nn.simplicial.scconv_layer.SCConvLayer"]], "forward() (topomodelx.nn.simplicial.scconv_layer.scconvlayer method)": [[51, "topomodelx.nn.simplicial.scconv_layer.SCConvLayer.forward"]], "reset_parameters() (topomodelx.nn.simplicial.scconv_layer.scconvlayer method)": [[51, "topomodelx.nn.simplicial.scconv_layer.SCConvLayer.reset_parameters"]], "topomodelx.nn.simplicial.scconv_layer": [[51, "module-topomodelx.nn.simplicial.scconv_layer"]], "scn2 (class in topomodelx.nn.simplicial.scn2)": [[52, "topomodelx.nn.simplicial.scn2.SCN2"]], "forward() (topomodelx.nn.simplicial.scn2.scn2 method)": [[52, "topomodelx.nn.simplicial.scn2.SCN2.forward"]], "topomodelx.nn.simplicial.scn2": [[52, "module-topomodelx.nn.simplicial.scn2"]], "scn2layer (class in topomodelx.nn.simplicial.scn2_layer)": [[53, "topomodelx.nn.simplicial.scn2_layer.SCN2Layer"]], "forward() (topomodelx.nn.simplicial.scn2_layer.scn2layer method)": [[53, "topomodelx.nn.simplicial.scn2_layer.SCN2Layer.forward"]], "reset_parameters() (topomodelx.nn.simplicial.scn2_layer.scn2layer method)": [[53, "topomodelx.nn.simplicial.scn2_layer.SCN2Layer.reset_parameters"]], "topomodelx.nn.simplicial.scn2_layer": [[53, "module-topomodelx.nn.simplicial.scn2_layer"]], "scnn (class in topomodelx.nn.simplicial.scnn)": [[54, "topomodelx.nn.simplicial.scnn.SCNN"]], "forward() (topomodelx.nn.simplicial.scnn.scnn method)": [[54, "topomodelx.nn.simplicial.scnn.SCNN.forward"]], "topomodelx.nn.simplicial.scnn": [[54, "module-topomodelx.nn.simplicial.scnn"]], "scnnlayer (class in topomodelx.nn.simplicial.scnn_layer)": [[55, "topomodelx.nn.simplicial.scnn_layer.SCNNLayer"]], "aggr_norm_func() (topomodelx.nn.simplicial.scnn_layer.scnnlayer method)": [[55, "topomodelx.nn.simplicial.scnn_layer.SCNNLayer.aggr_norm_func"]], "chebyshev_conv() (topomodelx.nn.simplicial.scnn_layer.scnnlayer method)": [[55, "topomodelx.nn.simplicial.scnn_layer.SCNNLayer.chebyshev_conv"]], "forward() (topomodelx.nn.simplicial.scnn_layer.scnnlayer method)": [[55, "topomodelx.nn.simplicial.scnn_layer.SCNNLayer.forward"]], "reset_parameters() (topomodelx.nn.simplicial.scnn_layer.scnnlayer method)": [[55, "topomodelx.nn.simplicial.scnn_layer.SCNNLayer.reset_parameters"]], "topomodelx.nn.simplicial.scnn_layer": [[55, "module-topomodelx.nn.simplicial.scnn_layer"]], "update() (topomodelx.nn.simplicial.scnn_layer.scnnlayer method)": [[55, "topomodelx.nn.simplicial.scnn_layer.SCNNLayer.update"]], "scone (class in topomodelx.nn.simplicial.scone)": [[56, "topomodelx.nn.simplicial.scone.SCoNe"]], "trajectoriesdataset (class in topomodelx.nn.simplicial.scone)": [[56, "topomodelx.nn.simplicial.scone.TrajectoriesDataset"]], "forward() (topomodelx.nn.simplicial.scone.scone method)": [[56, "topomodelx.nn.simplicial.scone.SCoNe.forward"]], "generate_complex() (in module topomodelx.nn.simplicial.scone)": [[56, "topomodelx.nn.simplicial.scone.generate_complex"]], "generate_trajectories() (in module topomodelx.nn.simplicial.scone)": [[56, "topomodelx.nn.simplicial.scone.generate_trajectories"]], "topomodelx.nn.simplicial.scone": [[56, "module-topomodelx.nn.simplicial.scone"]], "vectorize_path() (topomodelx.nn.simplicial.scone.trajectoriesdataset method)": [[56, "topomodelx.nn.simplicial.scone.TrajectoriesDataset.vectorize_path"]], "sconelayer (class in topomodelx.nn.simplicial.scone_layer)": [[57, "topomodelx.nn.simplicial.scone_layer.SCoNeLayer"]], "forward() (topomodelx.nn.simplicial.scone_layer.sconelayer method)": [[57, "topomodelx.nn.simplicial.scone_layer.SCoNeLayer.forward"]], "reset_parameters() (topomodelx.nn.simplicial.scone_layer.sconelayer method)": [[57, "topomodelx.nn.simplicial.scone_layer.SCoNeLayer.reset_parameters"]], "topomodelx.nn.simplicial.scone_layer": [[57, "module-topomodelx.nn.simplicial.scone_layer"]], "broadcast() (in module topomodelx.utils.scatter)": [[58, "topomodelx.utils.scatter.broadcast"]], "scatter() (in module topomodelx.utils.scatter)": [[58, "topomodelx.utils.scatter.scatter"]], "scatter_add() (in module topomodelx.utils.scatter)": [[58, "topomodelx.utils.scatter.scatter_add"]], "scatter_mean() (in module topomodelx.utils.scatter)": [[58, "topomodelx.utils.scatter.scatter_mean"]], "scatter_sum() (in module topomodelx.utils.scatter)": [[58, "topomodelx.utils.scatter.scatter_sum"]], "topomodelx.utils.scatter": [[58, "module-topomodelx.utils.scatter"]]}})