{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Set-up, create and train a convolutional CXN\n",
    "\n",
    "In this notebook, we create and train a simplified, non-attentional version of a CXN network, originally proposed in the paper by Hajij et. al : Cell Complex Neural Networks (https://arxiv.org/pdf/2010.00743.pdf). We will load a cell complex dataset from the web and train the model to perform classificaiton on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "from toponetx import CellComplex\n",
    "\n",
    "from topomodelx.nn.cell.convcxn_layer import CXNLayer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPU's are available, we will make use of them. Otherwise, this will run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "device = torch.device(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the hyperparameters for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--lr\", default=1e-3, type=float)\n",
    "parser.add_argument(\"--num_epochs\", default=3, type=int)\n",
    "parser.add_argument(\"--with_rotation\", default=1, type=int, choices=[0, 1])\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "training_cfg = {\n",
    "    \"lr\": args.lr,\n",
    "    \"num_epochs\": args.num_epochs,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Create synthetic data and load its neighborhood structures\n",
    "\n",
    "We start by creating the cell complex on which the neural network will operate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Complex with 6 nodes, 8 edges  and 1 2-cells \n",
      "8\n"
     ]
    }
   ],
   "source": [
    "edge_set = [\n",
    "    [1, 2],\n",
    "    [1, 3],\n",
    "    [2, 4],\n",
    "    [3, 4],\n",
    "    [4, 5],\n",
    "    [1, 6],\n",
    "]  # two edges stick out on diag\n",
    "node_set = [1, 2, 3, 4, 5, 6]\n",
    "face_set = [[1, 2, 3, 4]]\n",
    "complex = CellComplex(edge_set + node_set + face_set)\n",
    "print(complex)\n",
    "print(len(complex.edges))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need the adjacency matrix $A_{\\uparrow, 0}$ and the coboundary matrix $B_2^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidence_2_t = complex.incidence_matrix(rank=2).T\n",
    "adjacency_0 = complex.adjacency_matrix(rank=0)\n",
    "incidence_2_t = torch.from_numpy(incidence_2_t.todense()).to_sparse().float()\n",
    "adjacency_0 = torch.from_numpy(adjacency_0.todense()).to_sparse().float()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create data on this complex. Specifically, we need node features and edge features for both train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0_train = []\n",
    "num_features_0 = 4\n",
    "for _ in range(100):\n",
    "    x_0_train.append(torch.Tensor(np.random.rand(len(complex.nodes), num_features_0)))\n",
    "\n",
    "x_1_train = []\n",
    "num_features_1 = 5\n",
    "for _ in range(100):\n",
    "    x_1_train.append(torch.Tensor(np.random.rand(len(complex.edges), num_features_1)))\n",
    "\n",
    "x_0_test = []\n",
    "num_features_0 = 4\n",
    "for _ in range(10):\n",
    "    x_0_test.append(torch.Tensor(np.random.rand(len(complex.nodes), num_features_0)))\n",
    "\n",
    "x_1_test = []\n",
    "num_features_1 = 5\n",
    "for _ in range(10):\n",
    "    x_1_test.append(torch.Tensor(np.random.rand(len(complex.edges), num_features_1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must define labels associated to these datasets, as we will perform binary node classification. For the purposes of the tutorial, we leave these completely random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = [random.randint(0, 1) for _ in range(100)]\n",
    "labels_test = [random.randint(0, 1) for _ in range(10)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the input feature dimensions as channel dimensions. We will use this to define our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_ch_v 4 in_ch_e 5 in_ch_f 5\n"
     ]
    }
   ],
   "source": [
    "in_ch_0 = num_features_0\n",
    "in_ch_1 = num_features_1\n",
    "in_ch_2 = 5\n",
    "print(f\"in_ch_v {in_ch_0} in_ch_e {in_ch_1} in_ch_f {in_ch_2}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Neural Network\n",
    "\n",
    "Using the CXNLayer class, we create a neural network with stacked layers. We define the amount of channels on the face and edge ranks to be different, making this a heterogenous network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvCXN(torch.nn.Module):\n",
    "    \"\"\"Convolutional CXN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_ch_0 : int\n",
    "        Dimension of input features on nodes.\n",
    "    in_ch_1 : int\n",
    "        Dimension of input features on edges.\n",
    "    in_ch_2 : int\n",
    "        Dimension of input features on faces.\n",
    "    num_classes : int\n",
    "        Number of classes.\n",
    "    n_layers : int\n",
    "        Number of CXN layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_ch_0, in_ch_1, in_ch_2, num_classes, n_layers=2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(\n",
    "                CXNLayer(\n",
    "                    in_channels_0=in_ch_0,\n",
    "                    in_channels_1=in_ch_1,\n",
    "                    in_channels_2=in_ch_2,\n",
    "                )\n",
    "            )\n",
    "        self.layers = layers\n",
    "        self.lin_0 = torch.nn.Linear(in_ch_0, num_classes)\n",
    "        self.lin_1 = torch.nn.Linear(in_ch_1, num_classes)\n",
    "        self.lin_2 = torch.nn.Linear(in_ch_2, num_classes)\n",
    "\n",
    "    def forward(self, x_0, x_1, neighborhood_0_to_0, neighborhood_1_to_2):\n",
    "        \"\"\"Forward computation through ConvCXN layers then linear layers.\"\"\"\n",
    "        for layer in self.layers:\n",
    "            x_0, x_1, x_2 = layer(x_0, x_1, neighborhood_0_to_0, neighborhood_1_to_2)\n",
    "        x_0 = self.lin_0(x_0)\n",
    "        x_1 = self.lin_1(x_1)\n",
    "        x_2 = self.lin_2(x_2)\n",
    "        return torch.mean(x_2, dim=0) + torch.mean(x_1, dim=0) + torch.mean(x_0, dim=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model, initialize loss, and specify an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvCXN(in_ch_0, in_ch_1, in_ch_2, num_classes=2, n_layers=2)\n",
    "model = model.to(device)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell performs the training, looping over the network for 5 epochs and testing after every 2 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 0.2939 Train_acc: 0.9800\n",
      "Epoch: 2 loss: 0.0628 Train_acc: 1.0000\n",
      "Test_acc: 1.0000\n",
      "Epoch: 3 loss: 0.0297 Train_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "test_interval = 2\n",
    "for epoch_i in range(1, args.num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    num_samples = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for x_0, x_1, y in zip(x_0_train, x_1_train, labels_train):\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        y_hat = model(\n",
    "            x_0.float(), x_1.float(), adjacency_0.float(), incidence_2_t.float()\n",
    "        )\n",
    "        y = torch.tensor(y).long()\n",
    "        loss = crit(y_hat, y)\n",
    "        correct += (y_hat.argmax() == y).sum().item()\n",
    "        num_samples += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    train_acc = correct / num_samples\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {train_acc:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    # wandb.log({\"loss\": np.mean(epoch_loss), \"Train_acc\": train_acc, \"epoch\": epoch_i})\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            num_samples = 0\n",
    "            correct = 0\n",
    "            for x_0, x_1, y in zip(x_0_test, x_1_test, labels_test):\n",
    "                y = torch.tensor(y).long()\n",
    "                y_hat = model(x_0, x_1, adjacency_0, incidence_2_t)\n",
    "\n",
    "                correct += (y_hat.argmax() == y).sum().item()\n",
    "                num_samples += 1\n",
    "            test_acc = correct / num_samples\n",
    "            print(f\"Test_acc: {test_acc:.4f}\", flush=True)\n",
    "            # wandb.log({\"Test_acc\": test_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
